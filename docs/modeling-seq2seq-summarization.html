---

title: modeling.seq2seq.summarization


keywords: fastai
sidebar: home_sidebar

summary: "This module contains custom models, custom splitters, etc... summarization tasks."
description: "This module contains custom models, custom splitters, etc... summarization tasks."
nb_path: "nbs/11_modeling-seq2seq-summarization.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/11_modeling-seq2seq-summarization.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using GPU #</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using GPU #1: GeForce GTX 1080 Ti
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summarization">Summarization<a class="anchor-link" href="#Summarization"> </a></h2><p>The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Prepare-the-data">Prepare the data<a class="anchor-link" href="#Prepare-the-data"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./&#39;</span><span class="p">)</span>
<span class="n">cnndm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;cnndm_sample.csv&#39;</span><span class="p">);</span> <span class="nb">len</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1000</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cnndm_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article</th>
      <th>highlights</th>
      <th>ds_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>
      <td>John Sexton: Traditionally, universities have been defined and limited by location .\nGlobal campuses form a network of thought, innovation, he writes .\nFaculty can teach, Sexton says, students can team up in many cities at once .\nSexton: Research, scholarship can be shared and cultural ties made in "century of knowledge"</td>
      <td>train</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will "hopefully bring some order" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>
      <td>NEW: Protest moves after crackdown at Freedom Square .\nOrder sought after protests over last month's election turn violent .\nDemonstrators say the election was fraudulent .\nState of emergency could last until March 20, official says .</td>
      <td>train</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;facebook/bart-large-cnn&quot;</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> 
                                                                  <span class="n">model_cls</span><span class="o">=</span><span class="n">BartForConditionalGeneration</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;bart&#39;,
 transformers.models.bart.configuration_bart.BartConfig,
 transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,
 transformers.models.bart.modeling_bart.BartForConditionalGeneration)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bart&#39;</span><span class="p">,</span> <span class="s1">&#39;t5&#39;</span><span class="p">]):</span>
    <span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">hf_config</span><span class="o">.</span><span class="n">task_specific_params</span><span class="p">[</span><span class="s1">&#39;summarization&#39;</span><span class="p">],</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;max_length&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;min_length&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}}</span>

<span class="c1"># not all &quot;summarization&quot; parameters are for the model.generate method ... remove them here</span>
<span class="n">generate_func_args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">hf_model</span><span class="o">.</span><span class="n">generate</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">text_gen_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">generate_func_args</span><span class="p">:</span> <span class="k">del</span> <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

<span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s1">&#39;mbart&#39;</span><span class="p">):</span>
    <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="s1">&#39;decoder_start_token_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()[</span><span class="s2">&quot;en_XX&quot;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tok_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s1">&#39;mbart&#39;</span><span class="p">):</span>
    <span class="n">tok_kwargs</span><span class="p">[</span><span class="s1">&#39;src_lang&#39;</span><span class="p">],</span> <span class="n">tok_kwargs</span><span class="p">[</span><span class="s1">&#39;tgt_lang&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;en_XX&quot;</span><span class="p">,</span> <span class="s2">&quot;en_XX&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">before_batch_tfm</span> <span class="o">=</span> <span class="n">HF_Seq2SeqBeforeBatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> 
                                                  <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">max_target_length</span><span class="o">=</span><span class="mi">130</span><span class="p">,</span>
                                                  <span class="n">tok_kwargs</span><span class="o">=</span><span class="n">tok_kwargs</span><span class="p">,</span> <span class="n">text_gen_kwargs</span><span class="o">=</span><span class="n">text_gen_kwargs</span><span class="p">)</span>

<span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">HF_Seq2SeqBlock</span><span class="p">(</span><span class="n">before_batch_tfm</span><span class="o">=</span><span class="n">before_batch_tfm</span><span class="p">),</span> <span class="n">noop</span><span class="p">)</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> 
                   <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;article&#39;</span><span class="p">),</span> 
                   <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;highlights&#39;</span><span class="p">),</span> 
                   <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, torch.Size([2, 256]), torch.Size([2, 69]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;s&gt; (CNN) -- Home to up to 10 percent of all known species, Mexico is recognized as one of the most biodiverse regions on the planet. The twin threats of climate change and human encroachment on natural environments are, however, threatening the existence of the country's rich wildlife. And there is a great deal to lose. In the United Nations Environment Program (UNEP) World Conservation Monitoring Centre's list of megadiverse countries Mexico ranks 11th. The list represents a group of 17 countries that harbor the majority of the Earth's species and are therefore considered extremely biodiverse. From its coral reefs in the Caribbean Sea to its tropical jungles in Chiapas and the Yucatan peninsula and its deserts and prairies in the north, Mexico boasts an incredibly rich variety of flora and fauna. Some 574 out of 717 reptile species found in Mexico -- the most in any country -- can only be encountered within its borders. It is home to 502 types of mammals, 290 species of birds, 1,150 varieties of birds and 26,000 classifications of plants. Pronatura, a non-profit organization that works to promote conservation and sustainable development in Mexico, has selected six species which it says symbolize the problems faced by the&lt;/s&gt;</td>
      <td>Mexico hosts to up to 10 percent of all known species on Earth.\nIt is home to 502 types of mammals, 290 bird species and 26,000 types of plants.\nHuman development and climate change is placing a big strain on its biodiversity.\nThe Golden Eagle is under threat in spite of being the country's national symbol.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&lt;s&gt; (CNN Student News) -- October 27, 2009. Downloadable Maps. Download PDF maps related to today's show:  • Afghanistan &amp; Pakistan • Los Angeles &amp; San Diego • Ft. Jackson, South Carolina. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. NATISHA LANCE, CNN STUDENT NEWS ANCHOR: A member of the military is making history. We'll explain how in today's edition of CNN Student News. Hi, everyone. Carl Azuz is off this week. I'm Natisha Lance. First Up: Afghan Crashes. LANCE: First up, Pakistan and Afghanistan. The countries share a border, and they also share a common problem: threats from militant groups and terrorists like the Taliban and al Qaeda. It's an issue facing both nations' governments, and one that the U.S. government is concerned about as well. That's why President Obama has been holding a series of meetings with some of his advisers. They're reviewing the U.S. strategy in Afghanistan and Pakistan. Samantha Hayes has the latest on those meetings and on the violence in the region. (BEGIN VIDEO) SAMANTHA HAYES,&lt;/s&gt;</td>
      <td>Consider U.S. efforts to offer Afghan citizens an alternative to the Taliban.\nHear how a proposed health care bill addresses the issue of the public option.\nMeet a soldier who is making history at the U.S. Army Drill Sergeant School.\nUse the Daily Discussion to help students understand today's featured news stories.</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-model">Train model<a class="anchor-link" href="#Train-model"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seq2seq_metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;rouge&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;compute_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;rouge_types&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">],</span> <span class="s1">&#39;use_stemmer&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">},</span>
            <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s1">&#39;bertscore&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;compute_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;lang&#39;</span><span class="p">:</span> <span class="s1">&#39;en&#39;</span> <span class="p">},</span>
            <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">HF_BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
<span class="n">learn_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">HF_BaseModelCallback</span><span class="p">]</span>
<span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">HF_Seq2SeqMetricsCallback</span><span class="p">(</span><span class="n">custom_metrics</span><span class="o">=</span><span class="n">seq2seq_metrics</span><span class="p">)]</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                <span class="n">model</span><span class="p">,</span>
                <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
                <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span> <span class="c1">#HF_PreCalculatedLoss()</span>
                <span class="n">cbs</span><span class="o">=</span><span class="n">learn_cbs</span><span class="p">,</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">seq2seq_splitter</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">))</span> <span class="c1">#.to_native_fp16() #.to_fp16()</span>

<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">blurr_summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>HF_BaseModelWrapper (Input shape: 2)
============================================================================
Layer (type)         Output Shape         Param #    Trainable 
============================================================================
                     2 x 69 x 1024       
Embedding                                 51470336   False     
Embedding                                 51470336   False     
____________________________________________________________________________
                     2 x 1024            
BartLearnedPositionalEmbedding                      1050624    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 1024       
Embedding                                 51470336   False     
____________________________________________________________________________
                     2 x 1024            
BartLearnedPositionalEmbedding                      1050624    False     
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 69 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 69 x 50264      
Linear                                    51470336   False     
____________________________________________________________________________

Total params: 560,701,440
Total trainable params: 201,613,312
Total non-trainable params: 359,088,128

Optimizer used: functools.partial(&lt;function Adam at 0x7f0888307dc0&gt;)
Loss function: FlattenedLoss of CrossEntropyLoss()

Model frozen up to parameter group #2

Callbacks:
  - TrainEvalCallback
  - HF_BaseModelCallback
  - Recorder
  - ProgressCallback</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span><span class="n">preds</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">preds</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(4, torch.Size([]), torch.Size([2, 69, 50264]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 3, torch.Size([2, 256]), 2, torch.Size([2, 69]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggestions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=6.918309954926372e-05, lr_steep=0.00010964782268274575)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>rouge1</th>
      <th>rouge2</th>
      <th>rougeL</th>
      <th>bertscore_precision</th>
      <th>bertscore_recall</th>
      <th>bertscore_f1</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.669678</td>
      <td>1.708735</td>
      <td>0.293536</td>
      <td>0.131673</td>
      <td>0.231997</td>
      <td>0.888002</td>
      <td>0.861727</td>
      <td>0.874541</td>
      <td>02:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Michael Zehaf-Bibeau, the 32-year-old gunman who attacked the Canadian Parliament and killed a soldier last week, had a familiar profile. It is that of a young man alienated from mainstream society, with few friends, without a steady job, drifting from one place to another -- often with a history of petty crime and drug abuse. Then comes the conversion to or rediscovery of Islam, and the adoption of a jihadist mindset, fed by media and online coverage of the West's involvement in wars in Iraq a</td>
      <td>Like many "lone wolf" terrorists, Ottawa gunman was alienated drifter who converted to Islam.\nConversion to militant Islam is often about seeking identity, purpose or adventure.\nSome countries have tried "de-radicalization" programs to help prevent</td>
      <td>Michael Zehaf-Bibeau, the 32-year-old gunman who attacked the Canadian Parliament, had a familiar</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Kiev, Ukraine (CNN) -- Sporadic heavy artillery barrages and machine gun fire could be heard early Sunday on the outskirts of the southeastern Ukrainian city of Mariupol, raising questions about the viability of a ceasefire between the Ukrainian government and pro-Russian separatists. While the source of the weapons fire was not immediately clear, it came as the ceasefire appeared to be holding, a rare positive sign in a conflict that has ratcheted up tensions between Russia and the West. By la</td>
      <td>Sporadic heavy artillery barrages and machine gun fire heard near Mariupol.\nPoroshenko and Putin talk about ensuring truce lasts, Poroshenko's office says.\nRussia will respond if new EU sanctions are imposed, state media reports.\nEU nations agree on</td>
      <td>NEW: Sporadic heavy artillery barrages and machine gun fire can be heard on the outskirts of Mariupol .\n</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_article</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off </span>
<span class="s2">into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. </span>
<span class="s2">The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino </span>
<span class="s2">Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino&#39;s vault on the lower level </span>
<span class="s2">but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group </span>
<span class="s2">of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the </span>
<span class="s2">cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was </span>
<span class="s2">occurring unknowingly blocked the armed robbers&#39; vehicles. A gunman pulled the woman from her vehicle, beat </span>
<span class="s2">her, and took off for the French border. The other gunmen followed into France, which is only about 100 </span>
<span class="s2">meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. </span>
<span class="s2">There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the </span>
<span class="s2">robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, </span>
<span class="s2">Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN&#39;s Andreena Narayan </span>
<span class="s2">contributed to this report.</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">outputs</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_article</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=== Prediction </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1"> ===</span><span class="se">\n</span><span class="si">{</span><span class="n">o</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>=== Prediction 1 ===
 10 men armed with pistols and small machine guns raid Grand Casino Basel in Switzerland .
About 600 people were in the casino at the time of the robbery .
There were no serious injuries, although one guest was kicked in the head by one of the robbers .
The robbers spoke French and drove vehicles with French lRicense plates, police say .

=== Prediction 2 ===
 10 men armed with pistols and small machine guns raid Grand Casino Basel in Switzerland .
About 600 people were in the casino at the time of the robbery .
There were no serious injuries, although one guest was kicked in the head by one of the robbers .
The robbers spoke French and drove vehicles with French lRicense plates, police officer says .

=== Prediction 3 ===
 10 men armed with pistols and small machine guns raid Grand Casino Basel in Switzerland .
About 600 people were in the casino at the time of the robbery .
There were no serious injuries, although one guest was kicked in the head by one of the robbers .
The robbers spoke French and drove vehicles with French lRicense plates .

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Inference">Inference<a class="anchor-link" href="#Inference"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">export_fname</span> <span class="o">=</span> <span class="s1">&#39;summarize_export&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
<span class="n">inf_learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_article</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39; 10 men armed with pistols and machine guns raid Grand Casino Basel .\nAbout 600 people were in the casino at the time&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h2><p>The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained <strong>summarization models</strong> below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.</p>
<p><strong>Note</strong>: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue <em>(or a PR if you'd like to fix it yourself)</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span> <span class="k">del</span> <span class="n">learn</span><span class="p">;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span> <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span> <span class="n">model_type</span> <span class="k">for</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_models</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;ConditionalGeneration&#39;</span><span class="p">)</span> 
 <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">model_type</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;TF&#39;</span><span class="p">))</span> <span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[transformers.models.bart.modeling_bart.BartForConditionalGeneration,
 transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForConditionalGeneration,
 transformers.models.blenderbot.modeling_blenderbot.BlenderbotForConditionalGeneration,
 transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallForConditionalGeneration,
 transformers.models.fsmt.modeling_fsmt.FSMTForConditionalGeneration,
 transformers.models.led.modeling_led.LEDForConditionalGeneration,
 transformers.models.m2m_100.modeling_m2m_100.M2M100ForConditionalGeneration,
 transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration,
 transformers.models.mt5.modeling_mt5.MT5ForConditionalGeneration,
 transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration,
 transformers.models.prophetnet.modeling_prophetnet.ProphetNetForConditionalGeneration,
 transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextForConditionalGeneration,
 transformers.models.t5.modeling_t5.T5ForConditionalGeneration,
 transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetForConditionalGeneration]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;facebook/bart-base&#39;</span><span class="p">,</span>
    <span class="c1">#&#39;facebook/blenderbot_small-90M&#39;,</span>
    <span class="s1">&#39;allenai/led-base-16384&#39;</span><span class="p">,</span>
    <span class="s1">&#39;sshleifer/tiny-mbart&#39;</span><span class="p">,</span>
    <span class="s1">&#39;google/mt5-small&#39;</span><span class="p">,</span>
    <span class="s1">&#39;sshleifer/distill-pegasus-cnn-16-4&#39;</span><span class="p">,</span>
    <span class="s1">&#39;t5-small&#39;</span><span class="p">,</span> 
    <span class="c1">#&#39;microsoft/prophetnet-large-uncased&#39;,</span>
    <span class="c1">#&#39;microsoft/xprophetnet-large-wiki100-cased&#39;, # XLMProphetNet</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./&#39;</span><span class="p">)</span>
<span class="n">cnndm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;cnndm_sample.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hide_output</span>
<span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span>
<span class="n">bsz</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">inp_seq_sz</span> <span class="o">=</span> <span class="mi">64</span><span class="p">;</span> <span class="n">trg_seq_sz</span> <span class="o">=</span> <span class="mi">40</span>

<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">pretrained_model_names</span><span class="p">:</span>
    <span class="n">error</span><span class="o">=</span><span class="kc">None</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=== </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1"> ===</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">hf_tok_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;sshleifer/tiny-mbart&#39;</span><span class="p">):</span>
        <span class="n">hf_tok_kwargs</span><span class="p">[</span><span class="s1">&#39;src_lang&#39;</span><span class="p">],</span> <span class="n">hf_tok_kwargs</span><span class="p">[</span><span class="s1">&#39;tgt_lang&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;en_XX&quot;</span><span class="p">,</span> <span class="s2">&quot;en_XX&quot;</span>
    
    <span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> 
                                                                      <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">,</span> 
                                                                      <span class="n">tokenizer_kwargs</span><span class="o">=</span><span class="n">hf_tok_kwargs</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;architecture:</span><span class="se">\t</span><span class="si">{</span><span class="n">hf_arch</span><span class="si">}</span><span class="se">\n</span><span class="s1">tokenizer:</span><span class="se">\t</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="se">\n</span><span class="s1">model:</span><span class="se">\t\t</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># 1. build your DataBlock</span>
    <span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bart&#39;</span><span class="p">,</span> <span class="s1">&#39;t5&#39;</span><span class="p">]):</span>
        <span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">hf_config</span><span class="o">.</span><span class="n">task_specific_params</span><span class="p">[</span><span class="s1">&#39;summarization&#39;</span><span class="p">],</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;max_length&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;min_length&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}}</span>
    
    <span class="c1"># not all &quot;summarization&quot; parameters are for the model.generate method ... remove them here</span>
    <span class="n">generate_func_args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">hf_model</span><span class="o">.</span><span class="n">generate</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">text_gen_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">generate_func_args</span><span class="p">:</span> <span class="k">del</span> <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            
    <span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s1">&#39;mbart&#39;</span><span class="p">):</span>
        <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="s1">&#39;decoder_start_token_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()[</span><span class="s2">&quot;en_XX&quot;</span><span class="p">]</span>
            
            
    <span class="k">def</span> <span class="nf">add_t5_prefix</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span> <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;summarize: </span><span class="si">{</span><span class="n">inp</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s1">&#39;t5&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">inp</span>
    
    <span class="n">before_batch_tfm</span> <span class="o">=</span> <span class="n">HF_Seq2SeqBeforeBatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span>
                                                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> 
                                                      <span class="n">max_length</span><span class="o">=</span><span class="n">inp_seq_sz</span><span class="p">,</span> 
                                                      <span class="n">max_target_length</span><span class="o">=</span><span class="n">trg_seq_sz</span><span class="p">,</span> 
                                                      <span class="n">text_gen_kwargs</span><span class="o">=</span><span class="n">text_gen_kwargs</span><span class="p">)</span>
    
    <span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">HF_Seq2SeqBlock</span><span class="p">(</span><span class="n">before_batch_tfm</span><span class="o">=</span><span class="n">before_batch_tfm</span><span class="p">),</span> <span class="n">noop</span><span class="p">)</span>
    <span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> 
                   <span class="n">get_x</span><span class="o">=</span><span class="n">Pipeline</span><span class="p">([</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;article&#39;</span><span class="p">),</span> <span class="n">add_t5_prefix</span><span class="p">]),</span> 
                   <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;highlights&#39;</span><span class="p">),</span> 
                   <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>

    <span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">bsz</span><span class="p">)</span> 
    <span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>

    <span class="c1"># 2. build your Learner</span>
    <span class="n">seq2seq_metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;rouge&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;compute_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;rouge_types&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">],</span> <span class="s1">&#39;use_stemmer&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">},</span>
            <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">HF_BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
    <span class="n">learn_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">HF_BaseModelCallback</span><span class="p">]</span>
    <span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">ShortEpochCallback</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">short_valid</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> 
        <span class="n">HF_Seq2SeqMetricsCallback</span><span class="p">(</span><span class="n">custom_metrics</span><span class="o">=</span><span class="n">seq2seq_metrics</span><span class="p">)</span>
    <span class="p">]</span>
 
    <span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                    <span class="n">model</span><span class="p">,</span>
                    <span class="n">opt_func</span><span class="o">=</span><span class="n">ranger</span><span class="p">,</span>
                    <span class="n">loss_func</span><span class="o">=</span><span class="n">HF_PreCalculatedLoss</span><span class="p">(),</span>
                    <span class="n">cbs</span><span class="o">=</span><span class="n">learn_cbs</span><span class="p">,</span>
                    <span class="n">splitter</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">seq2seq_splitter</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">))</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>

    <span class="n">learn</span><span class="o">.</span><span class="n">create_opt</span><span class="p">()</span> 
    <span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
    
    <span class="c1"># 3. Run your tests</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*** TESTING DataLoaders ***</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]),</span> <span class="n">bsz</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">bsz</span><span class="p">,</span> <span class="n">inp_seq_sz</span><span class="p">]))</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">bsz</span><span class="p">)</span>

<span class="c1">#         print(&#39;*** TESTING One pass through the model ***&#39;)</span>
<span class="c1">#         preds = learn.model(b[0])</span>
<span class="c1">#         test_eq(preds[1].shape[0], bsz)</span>
<span class="c1">#         test_eq(preds[1].shape[2], hf_config.vocab_size)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*** TESTING Training/Results ***&#39;</span><span class="p">)</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>

        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;PASSED&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;FAILED&#39;</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c1"># cleanup</span>
        <span class="k">del</span> <span class="n">learn</span><span class="p">;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>arch</th>
      <th>tokenizer</th>
      <th>model_name</th>
      <th>result</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>bart</td>
      <td>BartTokenizerFast</td>
      <td>BartForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>led</td>
      <td>LEDTokenizerFast</td>
      <td>LEDForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>mbart</td>
      <td>MBartTokenizerFast</td>
      <td>MBartForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>mt5</td>
      <td>T5TokenizerFast</td>
      <td>MT5ForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>pegasus</td>
      <td>PegasusTokenizerFast</td>
      <td>PegasusForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>5</th>
      <td>t5</td>
      <td>T5TokenizerFast</td>
      <td>T5ForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cleanup">Cleanup<a class="anchor-link" href="#Cleanup"> </a></h2>
</div>
</div>
</div>
</div>
 

