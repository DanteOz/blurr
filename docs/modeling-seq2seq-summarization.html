---

title: modeling.seq2seq.summarization


keywords: fastai
sidebar: home_sidebar

summary: "This module contains custom models, custom splitters, etc... summarization tasks."
description: "This module contains custom models, custom splitters, etc... summarization tasks."
nb_path: "nbs/02zc_modeling-seq2seq-summarization.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/02zc_modeling-seq2seq-summarization.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using GPU #</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using GPU #1: GeForce GTX 1080 Ti
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summarization">Summarization<a class="anchor-link" href="#Summarization"> </a></h2><p>The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Prepare-the-data">Prepare the data<a class="anchor-link" href="#Prepare-the-data"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./&#39;</span><span class="p">)</span>
<span class="n">cnndm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;cnndm_sample.csv&#39;</span><span class="p">);</span> <span class="nb">len</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1000</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cnndm_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article</th>
      <th>highlights</th>
      <th>ds_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>
      <td>John Sexton: Traditionally, universities have been defined and limited by location .\nGlobal campuses form a network of thought, innovation, he writes .\nFaculty can teach, Sexton says, students can team up in many cities at once .\nSexton: Research, scholarship can be shared and cultural ties made in "century of knowledge"</td>
      <td>train</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will "hopefully bring some order" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>
      <td>NEW: Protest moves after crackdown at Freedom Square .\nOrder sought after protests over last month's election turn violent .\nDemonstrators say the election was fraudulent .\nState of emergency could last until March 20, official says .</td>
      <td>train</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;facebook/bart-large-cnn&quot;</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> 
                                                                  <span class="n">model_cls</span><span class="o">=</span><span class="n">BartForConditionalGeneration</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;bart&#39;,
 transformers.models.bart.configuration_bart.BartConfig,
 transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,
 transformers.models.bart.modeling_bart.BartForConditionalGeneration)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bart&#39;</span><span class="p">,</span> <span class="s1">&#39;t5&#39;</span><span class="p">]):</span>
    <span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">hf_config</span><span class="o">.</span><span class="n">task_specific_params</span><span class="p">[</span><span class="s1">&#39;summarization&#39;</span><span class="p">],</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;max_length&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;min_length&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}}</span>

<span class="c1"># not all &quot;summarization&quot; parameters are for the model.generate method ... remove them here</span>
<span class="n">generate_func_args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">hf_model</span><span class="o">.</span><span class="n">generate</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">text_gen_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">generate_func_args</span><span class="p">:</span> <span class="k">del</span> <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

<span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s1">&#39;mbart&#39;</span><span class="p">):</span>
    <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="s1">&#39;decoder_start_token_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()[</span><span class="s2">&quot;en_XX&quot;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tok_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s1">&#39;mbart&#39;</span><span class="p">):</span>
    <span class="n">tok_kwargs</span><span class="p">[</span><span class="s1">&#39;src_lang&#39;</span><span class="p">],</span> <span class="n">tok_kwargs</span><span class="p">[</span><span class="s1">&#39;tgt_lang&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;en_XX&quot;</span><span class="p">,</span> <span class="s2">&quot;en_XX&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">before_batch_tfm</span> <span class="o">=</span> <span class="n">HF_Seq2SeqBeforeBatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> 
                                                  <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">max_target_length</span><span class="o">=</span><span class="mi">130</span><span class="p">,</span>
                                                  <span class="n">tok_kwargs</span><span class="o">=</span><span class="n">tok_kwargs</span><span class="p">,</span> <span class="n">text_gen_kwargs</span><span class="o">=</span><span class="n">text_gen_kwargs</span><span class="p">)</span>

<span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">HF_Seq2SeqBlock</span><span class="p">(</span><span class="n">before_batch_tfm</span><span class="o">=</span><span class="n">before_batch_tfm</span><span class="p">),</span> <span class="n">noop</span><span class="p">)</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> 
                   <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;article&#39;</span><span class="p">),</span> 
                   <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;highlights&#39;</span><span class="p">),</span> 
                   <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, torch.Size([2, 256]), torch.Size([2, 84]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(CNN) -- Home to up to 10 percent of all known species, Mexico is recognized as one of the most biodiverse regions on the planet. The twin threats of climate change and human encroachment on natural environments are, however, threatening the existence of the country's rich wildlife. And there is a great deal to lose. In the United Nations Environment Program (UNEP) World Conservation Monitoring Centre's list of megadiverse countries Mexico ranks 11th. The list represents a group of 17 countries that harbor the majority of the Earth's species and are therefore considered extremely biodiverse. From its coral reefs in the Caribbean Sea to its tropical jungles in Chiapas and the Yucatan peninsula and its deserts and prairies in the north, Mexico boasts an incredibly rich variety of flora and fauna. Some 574 out of 717 reptile species found in Mexico -- the most in any country -- can only be encountered within its borders. It is home to 502 types of mammals, 290 species of birds, 1,150 varieties of birds and 26,000 classifications of plants. Pronatura, a non-profit organization that works to promote conservation and sustainable development in Mexico, has selected six species which it says symbolize the problems faced by the</td>
      <td>Mexico hosts to up to 10 percent of all known species on Earth.\nIt is home to 502 types of mammals, 290 bird species and 26,000 types of plants.\nHuman development and climate change is placing a big strain on its biodiversity.\nThe Golden Eagle is under threat in spite of being the country's national symbol.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(CNN) -- Was it George Zimmerman or Trayvon Martin who screamed for help the night the 17-year-old Martin was shot dead? That could depend on which mother the jury believes. Both Zimmerman's and Martin's mothers expressed no hesitation Friday in separate court appearances as to whose panicked voice is heard screaming during a 911 call from that February 26, 2012, night in Sanford, Florida: Each said it was her son. That contradiction -- with Sybrina Fulton insisting it was her son, Trayvon, who cried out, while Gladys Zimmerman said it was her son, George, who was yelling after being attacked by the teen -- was central to Friday's court proceedings, and central to the second-degree murder case unfolding in central Florida. Zimmerman has pleaded not guilty and claimed he shot the teenager in self-defense. The 911 call played twice in court on Friday, his lawyers claim, back up their assertion that it was Martin, and not their client, who was the aggressor. Testifying late Friday afternoon, Gladys Zimmerman said she was sure George was the one yelling. Why? "Because he's my son." She answered "all of the above" when asked whether she had ever before heard her George Zimmerman laugh loudly or cry out for help.</td>
      <td>NEW: A defense lawyer says other evidence, not the 911 call, will determine the case.\nNEW: A lawyer for Martin's family says he thinks the jury will find Zimmerman guilty.\nGladys Zimmerman says she knows the panicked voice is that of her son.\nEarlier, Trayvon Martin's morther said that it her son's voice on the 911 call.</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-model">Train model<a class="anchor-link" href="#Train-model"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seq2seq_metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;rouge&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;compute_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;rouge_types&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">],</span> <span class="s1">&#39;use_stemmer&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">},</span>
            <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s1">&#39;bertscore&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;compute_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;lang&#39;</span><span class="p">:</span> <span class="s1">&#39;en&#39;</span> <span class="p">},</span>
            <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">HF_BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
<span class="n">learn_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">HF_BaseModelCallback</span><span class="p">]</span>
<span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">HF_Seq2SeqMetricsCallback</span><span class="p">(</span><span class="n">custom_metrics</span><span class="o">=</span><span class="n">seq2seq_metrics</span><span class="p">)]</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                <span class="n">model</span><span class="p">,</span>
                <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
                <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span> <span class="c1">#HF_PreCalculatedLoss()</span>
                <span class="n">cbs</span><span class="o">=</span><span class="n">learn_cbs</span><span class="p">,</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">seq2seq_splitter</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">))</span> <span class="c1">#.to_native_fp16() #.to_fp16()</span>

<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">blurr_summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>HF_BaseModelWrapper (Input shape: 2)
============================================================================
Layer (type)         Output Shape         Param #    Trainable 
============================================================================
                     2 x 74 x 1024       
Embedding                                 51470336   False     
Embedding                                 51470336   False     
____________________________________________________________________________
                     2 x 1024            
BartLearnedPositionalEmbedding                      1050624    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
Linear                                    1049600    False     
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 256 x 4096      
Linear                                    4198400    False     
____________________________________________________________________________
                     2 x 256 x 1024      
Linear                                    4195328    False     
LayerNorm                                 2048       True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 1024       
Embedding                                 51470336   False     
____________________________________________________________________________
                     2 x 1024            
BartLearnedPositionalEmbedding                      1050624    False     
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
Linear                                    1049600    True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 4096       
Linear                                    4198400    True      
____________________________________________________________________________
                     2 x 74 x 1024       
Linear                                    4195328    True      
LayerNorm                                 2048       True      
LayerNorm                                 2048       True      
____________________________________________________________________________
                     2 x 74 x 50264      
Linear                                    51470336   False     
____________________________________________________________________________

Total params: 560,701,440
Total trainable params: 201,613,312
Total non-trainable params: 359,088,128

Optimizer used: functools.partial(&lt;function Adam at 0x7f2fc84cb3a0&gt;)
Loss function: FlattenedLoss of CrossEntropyLoss()

Model frozen up to parameter group #2

Callbacks:
  - TrainEvalCallback
  - HF_BaseModelCallback
  - Recorder
  - ProgressCallback</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span><span class="n">preds</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">preds</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(4, torch.Size([]), torch.Size([2, 69, 50264]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 3, torch.Size([2, 256]), 2, torch.Size([2, 69]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggestions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=8.317637839354575e-05, lr_steep=2.0892961401841603e-05)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>rouge1</th>
      <th>rouge2</th>
      <th>rougeL</th>
      <th>bertscore_precision</th>
      <th>bertscore_recall</th>
      <th>bertscore_f1</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.726700</td>
      <td>1.742857</td>
      <td>0.286411</td>
      <td>0.125093</td>
      <td>0.221131</td>
      <td>0.888014</td>
      <td>0.861281</td>
      <td>0.874301</td>
      <td>02:10</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(CNN) -- Wondering where to go for your next holiday? Experts explain which destinations we should be checking out in 2014. Brazil: The World Cup. The modern game of football, or soccer, may have been born in England's public schools, but many will claim its soul has settled in Brazil. It has the world's most successful international team, winning the World Cup five times. It calls what many claim to be the world's greatest player, Pele, one of its own. And company managers and bosses are known</td>
      <td>New Zealand government threw $50 million into the construction of the Nga Haerenga cycle trails.\nNosara in Costa Rica recently awarded a Blue Flag -- a certification awarded to world's best beaches.\nFirst few months of 2014 best period for Northern</td>
      <td>Brazil has the world's most successful international team, winning the World Cup five times .\nThe country has a party culture that</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(CNN) -- To Disney or not to Disney? For many travelers, especially those with children, it's not even a question they ask. They already know the answer. "Yes." To these visitors, Disney is Mickey Mouse, princesses, magic and fun. It's happy memories of childhood brought back to life in your children, a clean place where the rides are safe and the Disney characters are always happy to pose for pictures with your kids. That's Deb Koma, who visited once as a child and walked back into the Magic K</td>
      <td>Disney represents magical stories and fun family to fans.\nSome parents delight in their children's wonder during a first visit to Disney.\nSome critics think the company encourages kids to buy too much stuff.\nOthers worry the princess culture limits</td>
      <td>To some, Disney is Mickey Mouse, princesses, magic and fun .\nTo others, Disney inspires a firm "no</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_article</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off </span>
<span class="s2">into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. </span>
<span class="s2">The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino </span>
<span class="s2">Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino&#39;s vault on the lower level </span>
<span class="s2">but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group </span>
<span class="s2">of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the </span>
<span class="s2">cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was </span>
<span class="s2">occurring unknowingly blocked the armed robbers&#39; vehicles. A gunman pulled the woman from her vehicle, beat </span>
<span class="s2">her, and took off for the French border. The other gunmen followed into France, which is only about 100 </span>
<span class="s2">meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. </span>
<span class="s2">There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the </span>
<span class="s2">robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, </span>
<span class="s2">Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN&#39;s Andreena Narayan </span>
<span class="s2">contributed to this report.</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">outputs</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_article</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=== Prediction </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1"> ===</span><span class="se">\n</span><span class="si">{</span><span class="n">o</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>=== Prediction 1 ===
 About 10 men armed with pistols and machine guns raid a casino in Switzerland&#39;s Grand Casino Basel .
They make off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .
There were no serious injuries, although one guest was kicked in the head by one of the robbers .
The robbers spoke French and drove vehicles with French lRicense plates .

=== Prediction 2 ===
 About 10 men armed with pistols and machine guns raid a casino in Switzerland&#39;s Grand Casino Basel .
They make off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .
There were no serious injuries, although one guest was kicked in the head by one of the robbers .
The robbers spoke French and drove vehicles with French lRicense plates, police officer says .

=== Prediction 3 ===
 About 10 men armed with pistols and machine guns raid a casino in Switzerland&#39;s Grand Casino Basel .
They make off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .
There were no serious injuries, but one guest was kicked in the head by one of the robbers .
The robbers spoke French and drove vehicles with French lRicense plates .

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Inference">Inference<a class="anchor-link" href="#Inference"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">export_fname</span> <span class="o">=</span> <span class="s1">&#39;summarize_export&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
<span class="n">inf_learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_article</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39; About 10 men armed with pistols and machine guns raid a casino in Switzerland .\nThey make off with several hundred thousand Swiss franc&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h2><p>The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained <strong>summarization models</strong> below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.</p>
<p><strong>Note</strong>: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue <em>(or a PR if you'd like to fix it yourself)</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span> <span class="k">del</span> <span class="n">learn</span><span class="p">;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span> <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span> <span class="n">model_type</span> <span class="k">for</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_models</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;ConditionalGeneration&#39;</span><span class="p">)</span> 
 <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">model_type</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;TF&#39;</span><span class="p">))</span> <span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[transformers.models.bart.modeling_bart.BartForConditionalGeneration,
 transformers.models.blenderbot.modeling_blenderbot.BlenderbotForConditionalGeneration,
 transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallForConditionalGeneration,
 transformers.models.fsmt.modeling_fsmt.FSMTForConditionalGeneration,
 transformers.models.led.modeling_led.LEDForConditionalGeneration,
 transformers.models.m2m_100.modeling_m2m_100.M2M100ForConditionalGeneration,
 transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration,
 transformers.models.mt5.modeling_mt5.MT5ForConditionalGeneration,
 transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration,
 transformers.models.prophetnet.modeling_prophetnet.ProphetNetForConditionalGeneration,
 transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextForConditionalGeneration,
 transformers.models.t5.modeling_t5.T5ForConditionalGeneration,
 transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetForConditionalGeneration]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;facebook/bart-base&#39;</span><span class="p">,</span>
    <span class="c1">#&#39;facebook/blenderbot_small-90M&#39;,</span>
    <span class="s1">&#39;allenai/led-base-16384&#39;</span><span class="p">,</span>
    <span class="s1">&#39;sshleifer/tiny-mbart&#39;</span><span class="p">,</span>
    <span class="s1">&#39;google/mt5-small&#39;</span><span class="p">,</span>
    <span class="s1">&#39;sshleifer/distill-pegasus-cnn-16-4&#39;</span><span class="p">,</span>
    <span class="s1">&#39;t5-small&#39;</span><span class="p">,</span> 
    <span class="c1">#&#39;microsoft/prophetnet-large-uncased&#39;,</span>
    <span class="c1">#&#39;microsoft/xprophetnet-large-wiki100-cased&#39;, # XLMProphetNet</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./&#39;</span><span class="p">)</span>
<span class="n">cnndm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;cnndm_sample.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hide_output</span>
<span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span>
<span class="n">bsz</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">inp_seq_sz</span> <span class="o">=</span> <span class="mi">64</span><span class="p">;</span> <span class="n">trg_seq_sz</span> <span class="o">=</span> <span class="mi">40</span>

<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">pretrained_model_names</span><span class="p">:</span>
    <span class="n">error</span><span class="o">=</span><span class="kc">None</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=== </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1"> ===</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">hf_tok_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;sshleifer/tiny-mbart&#39;</span><span class="p">):</span>
        <span class="n">hf_tok_kwargs</span><span class="p">[</span><span class="s1">&#39;src_lang&#39;</span><span class="p">],</span> <span class="n">hf_tok_kwargs</span><span class="p">[</span><span class="s1">&#39;tgt_lang&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;en_XX&quot;</span><span class="p">,</span> <span class="s2">&quot;en_XX&quot;</span>
    
    <span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> 
                                                                      <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">,</span> 
                                                                      <span class="n">tokenizer_kwargs</span><span class="o">=</span><span class="n">hf_tok_kwargs</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;architecture:</span><span class="se">\t</span><span class="si">{</span><span class="n">hf_arch</span><span class="si">}</span><span class="se">\n</span><span class="s1">tokenizer:</span><span class="se">\t</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="se">\n</span><span class="s1">model:</span><span class="se">\t\t</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># 1. build your DataBlock</span>
    <span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bart&#39;</span><span class="p">,</span> <span class="s1">&#39;t5&#39;</span><span class="p">]):</span>
        <span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">hf_config</span><span class="o">.</span><span class="n">task_specific_params</span><span class="p">[</span><span class="s1">&#39;summarization&#39;</span><span class="p">],</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;max_length&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;min_length&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}}</span>
    
    <span class="c1"># not all &quot;summarization&quot; parameters are for the model.generate method ... remove them here</span>
    <span class="n">generate_func_args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">hf_model</span><span class="o">.</span><span class="n">generate</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">text_gen_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">generate_func_args</span><span class="p">:</span> <span class="k">del</span> <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            
    <span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s1">&#39;mbart&#39;</span><span class="p">):</span>
        <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="s1">&#39;decoder_start_token_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()[</span><span class="s2">&quot;en_XX&quot;</span><span class="p">]</span>
            
            
    <span class="k">def</span> <span class="nf">add_t5_prefix</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span> <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;summarize: </span><span class="si">{</span><span class="n">inp</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s1">&#39;t5&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">inp</span>
    
    <span class="n">before_batch_tfm</span> <span class="o">=</span> <span class="n">HF_Seq2SeqBeforeBatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span>
                                                      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> 
                                                      <span class="n">max_length</span><span class="o">=</span><span class="n">inp_seq_sz</span><span class="p">,</span> 
                                                      <span class="n">max_target_length</span><span class="o">=</span><span class="n">trg_seq_sz</span><span class="p">,</span> 
                                                      <span class="n">text_gen_kwargs</span><span class="o">=</span><span class="n">text_gen_kwargs</span><span class="p">)</span>
    
    <span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">HF_Seq2SeqBlock</span><span class="p">(</span><span class="n">before_batch_tfm</span><span class="o">=</span><span class="n">before_batch_tfm</span><span class="p">),</span> <span class="n">noop</span><span class="p">)</span>
    <span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> 
                   <span class="n">get_x</span><span class="o">=</span><span class="n">Pipeline</span><span class="p">([</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;article&#39;</span><span class="p">),</span> <span class="n">add_t5_prefix</span><span class="p">]),</span> 
                   <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;highlights&#39;</span><span class="p">),</span> 
                   <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>

    <span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">bsz</span><span class="p">)</span> 
    <span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>

    <span class="c1"># 2. build your Learner</span>
    <span class="n">seq2seq_metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;rouge&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;compute_kwargs&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;rouge_types&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">],</span> <span class="s1">&#39;use_stemmer&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">},</span>
            <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">HF_BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
    <span class="n">learn_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">HF_BaseModelCallback</span><span class="p">]</span>
    <span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">ShortEpochCallback</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">short_valid</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> 
        <span class="n">HF_Seq2SeqMetricsCallback</span><span class="p">(</span><span class="n">custom_metrics</span><span class="o">=</span><span class="n">seq2seq_metrics</span><span class="p">)</span>
    <span class="p">]</span>
 
    <span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                    <span class="n">model</span><span class="p">,</span>
                    <span class="n">opt_func</span><span class="o">=</span><span class="n">ranger</span><span class="p">,</span>
                    <span class="n">loss_func</span><span class="o">=</span><span class="n">HF_PreCalculatedLoss</span><span class="p">(),</span>
                    <span class="n">cbs</span><span class="o">=</span><span class="n">learn_cbs</span><span class="p">,</span>
                    <span class="n">splitter</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">seq2seq_splitter</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">))</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>

    <span class="n">learn</span><span class="o">.</span><span class="n">create_opt</span><span class="p">()</span> 
    <span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
    
    <span class="c1"># 3. Run your tests</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*** TESTING DataLoaders ***</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]),</span> <span class="n">bsz</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">bsz</span><span class="p">,</span> <span class="n">inp_seq_sz</span><span class="p">]))</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">bsz</span><span class="p">)</span>

<span class="c1">#         print(&#39;*** TESTING One pass through the model ***&#39;)</span>
<span class="c1">#         preds = learn.model(b[0])</span>
<span class="c1">#         test_eq(preds[1].shape[0], bsz)</span>
<span class="c1">#         test_eq(preds[1].shape[2], hf_config.vocab_size)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*** TESTING Training/Results ***&#39;</span><span class="p">)</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>

        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;PASSED&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;FAILED&#39;</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c1"># cleanup</span>
        <span class="k">del</span> <span class="n">learn</span><span class="p">;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>arch</th>
      <th>tokenizer</th>
      <th>model_name</th>
      <th>result</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>bart</td>
      <td>BartTokenizerFast</td>
      <td>BartForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>led</td>
      <td>LEDTokenizerFast</td>
      <td>LEDForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>mbart</td>
      <td>MBartTokenizerFast</td>
      <td>MBartForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>mt5</td>
      <td>T5TokenizerFast</td>
      <td>MT5ForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>pegasus</td>
      <td>PegasusTokenizerFast</td>
      <td>PegasusForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>5</th>
      <td>t5</td>
      <td>T5TokenizerFast</td>
      <td>T5ForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cleanup">Cleanup<a class="anchor-link" href="#Cleanup"> </a></h2>
</div>
</div>
</div>
</div>
 

