---

title: text.modeling.seq2seq.translation


keywords: fastai
sidebar: home_sidebar

summary: "This module contains custom models, custom splitters, etc... translation tasks."
description: "This module contains custom models, custom splitters, etc... translation tasks."
nb_path: "nbs/22_text-modeling-seq2seq-translation.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/22_text-modeling-seq2seq-translation.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>What we&#39;re running with at the time this documentation was generated:
torch: 1.9.0+cu102
fastai: 2.6.3
transformers: 4.18.0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Mid-level-API">Mid-level API<a class="anchor-link" href="#Mid-level-API"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Prepare-the-data">Prepare the data<a class="anchor-link" href="#Prepare-the-data"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example"> </a></h3><p>The objective in translation is to generate a representation of a given text in another style. For example, we may want to translate German into English or modern English into old English.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;wmt16&quot;</span><span class="p">,</span> <span class="s2">&quot;de-en&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1200</span><span class="p">))</span>
<span class="n">wmt_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;translation&quot;</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;de&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">])</span>
<span class="nb">len</span><span class="p">(</span><span class="n">wmt_df</span><span class="p">)</span>
<span class="n">wmt_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading and preparing dataset wmt16/de-en (download: 1.57 GiB, generated: 1.28 GiB, post-processed: Unknown size, total: 2.85 GiB) to /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f...
Generating examples from: %s europarl_v7
Generating examples from: %s commoncrawl
Generating examples from: %s newscommentary_v11
Generating examples from: %s newstest2015
Generating examples from: %s newstest2016
Dataset wmt16 downloaded and prepared to /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f. Subsequent calls will reuse this data.
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>de</th>
      <th>en</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.</td>
      <td>In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>"Dieses Video ist nicht verfügbar loger" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?</td>
      <td>"This video is no loger available" that evil bitch, who had uploaded his video on youtube nearsyx?</td>
    </tr>
  </tbody>
</table>
</div></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;Helsinki-NLP/opus-mt-de-en&quot;</span>
<span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">)</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmppp9i08el
storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json in cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
creating metadata file for /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
Model config MarianConfig {
  &#34;_name_or_path&#34;: &#34;Helsinki-NLP/opus-mt-de-en&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;swish&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;MarianMTModel&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bad_words_ids&#34;: [
    [
      58100
    ]
  ],
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 512,
  &#34;decoder_attention_heads&#34;: 8,
  &#34;decoder_ffn_dim&#34;: 2048,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 58100,
  &#34;decoder_vocab_size&#34;: 58101,
  &#34;dropout&#34;: 0.1,
  &#34;encoder_attention_heads&#34;: 8,
  &#34;encoder_ffn_dim&#34;: 2048,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 0,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;max_length&#34;: 512,
  &#34;max_position_embeddings&#34;: 512,
  &#34;model_type&#34;: &#34;marian&#34;,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: false,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;pad_token_id&#34;: 58100,
  &#34;scale_embedding&#34;: true,
  &#34;share_encoder_decoder_embeddings&#34;: true,
  &#34;static_position_embeddings&#34;: true,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 58101
}

https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpes7wybva
storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json in cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7
creating metadata file for /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7
loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
Model config MarianConfig {
  &#34;_name_or_path&#34;: &#34;Helsinki-NLP/opus-mt-de-en&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;swish&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;MarianMTModel&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bad_words_ids&#34;: [
    [
      58100
    ]
  ],
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 512,
  &#34;decoder_attention_heads&#34;: 8,
  &#34;decoder_ffn_dim&#34;: 2048,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 58100,
  &#34;decoder_vocab_size&#34;: 58101,
  &#34;dropout&#34;: 0.1,
  &#34;encoder_attention_heads&#34;: 8,
  &#34;encoder_ffn_dim&#34;: 2048,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 0,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;max_length&#34;: 512,
  &#34;max_position_embeddings&#34;: 512,
  &#34;model_type&#34;: &#34;marian&#34;,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: false,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;pad_token_id&#34;: 58100,
  &#34;scale_embedding&#34;: true,
  &#34;share_encoder_decoder_embeddings&#34;: true,
  &#34;static_position_embeddings&#34;: true,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 58101
}

https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpmmic75d1
storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm in cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587
creating metadata file for /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587
https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp_780e_84
storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm in cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79
creating metadata file for /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79
https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp9veehttl
storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json in cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7
creating metadata file for /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm from cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm from cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target_vocab.json from cache at None
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/special_tokens_map.json from cache at None
loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
Model config MarianConfig {
  &#34;_name_or_path&#34;: &#34;Helsinki-NLP/opus-mt-de-en&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;swish&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;MarianMTModel&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bad_words_ids&#34;: [
    [
      58100
    ]
  ],
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 512,
  &#34;decoder_attention_heads&#34;: 8,
  &#34;decoder_ffn_dim&#34;: 2048,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 58100,
  &#34;decoder_vocab_size&#34;: 58101,
  &#34;dropout&#34;: 0.1,
  &#34;encoder_attention_heads&#34;: 8,
  &#34;encoder_ffn_dim&#34;: 2048,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 0,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;max_length&#34;: 512,
  &#34;max_position_embeddings&#34;: 512,
  &#34;model_type&#34;: &#34;marian&#34;,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: false,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;pad_token_id&#34;: 58100,
  &#34;scale_embedding&#34;: true,
  &#34;share_encoder_decoder_embeddings&#34;: true,
  &#34;static_position_embeddings&#34;: true,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 58101
}

https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp4evxfupq
storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin in cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514
creating metadata file for /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514
loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514
All model checkpoint weights were used when initializing MarianMTModel.

All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;marian&#39;,
 transformers.models.marian.tokenization_marian.MarianTokenizer,
 transformers.models.marian.configuration_marian.MarianConfig,
 transformers.models.marian.modeling_marian.MarianMTModel)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">Seq2SeqTextBlock</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">),</span> <span class="n">noop</span><span class="p">)</span>
<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;de&quot;</span><span class="p">),</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;en&quot;</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">wmt_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, torch.Size([2, 168]), torch.Size([2, 140]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>"In▁Erwägung▁nachstehender▁Gründe▁sollte das▁Europäische▁Parlament▁keinerlei▁Doppelmoral tolerieren. Indessen und um▁politischen Druck auf▁Journalisten▁auszuüben, die▁Korruptionsfälle aufdecken, die in▁Verbindung mit▁hochrangigen▁Beamten und▁regieren</td>
      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Es▁ist▁jetzt▁wirklich an der Zeit,▁daß nicht▁nur in▁bezug auf den▁Jahreswirtschaftsbericht und die▁wirtschaftspolitischen▁Leitlinien,▁nein,▁auch in▁bezug auf die▁gesamten▁Fragen zum▁Verfahren zur▁Feststellung des▁übermäßigen▁Defizits und▁auch in▁bezu</td>
      <td>It really is time for the European Parliament to be given a codecision right that is consistent with the further democratic development of this European Union; that right must apply not just to the annual economic report and the economic policy guide</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Training">Training<a class="anchor-link" href="#Training"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seq2seq_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;bleu&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;returns&quot;</span><span class="p">:</span> <span class="s2">&quot;bleu&quot;</span><span class="p">},</span> <span class="s2">&quot;meteor&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;returns&quot;</span><span class="p">:</span> <span class="s2">&quot;meteor&quot;</span><span class="p">},</span> <span class="s2">&quot;sacrebleu&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;returns&quot;</span><span class="p">:</span> <span class="s2">&quot;score&quot;</span><span class="p">}}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
<span class="n">learn_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">BaseModelCallback</span><span class="p">]</span>
<span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Seq2SeqMetricsCallback</span><span class="p">(</span><span class="n">custom_metrics</span><span class="o">=</span><span class="n">seq2seq_metrics</span><span class="p">)]</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span>
    <span class="n">dls</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
    <span class="n">loss_func</span><span class="o">=</span><span class="n">PreCalculatedCrossEntropyLoss</span><span class="p">(),</span>  <span class="c1"># CrossEntropyLossFlat()</span>
    <span class="n">cbs</span><span class="o">=</span><span class="n">learn_cbs</span><span class="p">,</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">blurr_seq2seq_splitter</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># learn = learn.to_native_fp16() #.to_fp16()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span> <span class="n">preds</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">preds</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(3, torch.Size([]), torch.Size([2, 140, 58101]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 3, torch.Size([2, 168]), 2, torch.Size([2, 140]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggest_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">minimum</span><span class="p">,</span> <span class="n">steep</span><span class="p">,</span> <span class="n">valley</span><span class="p">,</span> <span class="n">slide</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(minimum=3.981071640737355e-05, steep=6.309573450380412e-07, valley=5.248074739938602e-05, slide=7.585775892948732e-05)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>bleu</th>
      <th>meteor</th>
      <th>sacrebleu</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.088453</td>
      <td>2.097524</td>
      <td>0.295524</td>
      <td>0.543777</td>
      <td>28.882930</td>
      <td>00:58</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Showing-results">Showing results<a class="anchor-link" href="#Showing-results"> </a></h4><p>And here we create a <code>@typedispatch</code>ed implementation of <code>Learner.show_results</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>▁Schließen die▁vorgeschlagenen▁Anwendungszwecke▁Empfehlungen über die▁Bekämpfung von oder den▁Schutz▁gegen▁Organismen ein, die▁unter den in der▁vorgesehenen▁Anwendungsregion▁herrschenden▁Bedingungen in▁bezug auf▁Landwirtschaft,▁Pflanzenschutz und Umwelt -▁einschließlich der▁Witterungsverhältnisse - nach den▁Erfahrungen und dem▁wissenschaftlichen▁Erkenntnisstand nicht▁als▁schädlich▁gelten, oder▁ist▁davon▁auszugehen,▁daß die▁anderen▁Wirkungen▁unter▁diesen▁Bedingungen den▁beabsichtigten▁Zweck nicht</td>
      <td>Where relevant, yield response when the product is used and reduction of loss in storage must be quantitatively and/or qualitatively similar to those resulting from the use of suitable reference products. If no suitable reference product exists, the plant protection product must be shown to give a consistent and defined quantitative and/or qualitative benefit in terms of yield response and reduction of loss in storage under the agricultural, plant health and environmental (including climatic) co</td>
      <td>[Where the proposed uses include recommendations on the control of or protection against organisms which are not considered to be harmful under the conditions prevailing in the intended application region in respect of agriculture, plant health and the environment, including climatic conditions, in the light of experience and scientific knowledge, or where it is assumed that the other effects do not meet the intended purpose under such conditions, no authorisation shall be granted for such uses., That is why we have listened to you and asked you to introduce a further transparent consultation procedure on the Anti-Counterfeiting Agreement (ACTA) to ensure that the European Parliament and the citizens represented by this Parliament are regularly and comprehensively informed about the progress of the negotiations, while respecting the confidentiality clauses that you have just explained to us about the agreement.]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Prediction">Prediction<a class="anchor-link" href="#Prediction"> </a></h4><p>We add here <a href="/blurr/text-modeling-seq2seq-translation.html#Learner.blurr_translate"><code>Learner.blurr_translate</code></a> method to bring the results inline with the format returned via Hugging Face's pipeline method</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_de</span> <span class="o">=</span> <span class="s2">&quot;Ich trinke gerne Bier&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">outputs</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_de</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;translation_texts&quot;</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">outputs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;translation_texts&#39;: [&#39;I like to drink beer&#39;,
   &#39;I like to drink beer.&#39;,
   &#39;I like drinking beer&#39;]}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Learner.blurr_translate" class="doc_header"><code>Learner.blurr_translate</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/text/modeling/seq2seq/translation.py#L30" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Learner.blurr_translate</code>(<strong><code>inp</code></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">blurr_translate</span><span class="p">(</span><span class="n">test_de</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;translation_texts&#39;: [&#39;I like to drink beer&#39;,
   &#39;I like to drink beer.&#39;,
   &#39;I like drinking beer&#39;]}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Inference">Inference<a class="anchor-link" href="#Inference"> </a></h4><p>Using fast.ai <code>Learner.export</code> and <code>load_learner</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">export_fname</span> <span class="o">=</span> <span class="s2">&quot;translation_export&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>
<span class="n">inf_learn</span><span class="o">.</span><span class="n">blurr_translate</span><span class="p">(</span><span class="n">test_de</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;translation_texts&#39;: &#39;I like to drink beer&#39;}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="High-level-API">High-level API<a class="anchor-link" href="#High-level-API"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="BlearnerForTranslation" class="doc_header"><code>class</code> <code>BlearnerForTranslation</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/text/modeling/seq2seq/translation.py#L37" class="source_link" style="float:right">[source]</a></h3><blockquote><p><code>BlearnerForTranslation</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>hf_model</code></strong>:<code>PreTrainedModel</code>, <strong><code>base_model_cb</code></strong>:<a href="/blurr/text-modeling-core.html#BaseModelCallback"><code>BaseModelCallback</code></a>=<em><code>BaseModelCallback</code></em>, <strong><code>loss_func</code></strong>=<em><code>None</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>lr</code></strong>=<em><code>0.001</code></em>, <strong><code>splitter</code></strong>=<em><code>trainable_params</code></em>, <strong><code>cbs</code></strong>=<em><code>None</code></em>, <strong><code>metrics</code></strong>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>None</code></em>, <strong><code>model_dir</code></strong>=<em><code>'models'</code></em>, <strong><code>wd</code></strong>=<em><code>None</code></em>, <strong><code>wd_bn_bias</code></strong>=<em><code>False</code></em>, <strong><code>train_bn</code></strong>=<em><code>True</code></em>, <strong><code>moms</code></strong>=<em><code>(0.95, 0.85, 0.95)</code></em>) :: <a href="/blurr/text-modeling-core.html#Blearner"><code>Blearner</code></a></p>
</blockquote>
<p>Group together a <code>model</code>, some <code>dls</code> and a <code>loss_func</code> to handle training</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">BlearnerForTranslation</span><span class="o">.</span><span class="n">from_data</span><span class="p">(</span>
    <span class="n">wmt_df</span><span class="p">,</span>
    <span class="s2">&quot;Helsinki-NLP/opus-mt-de-en&quot;</span><span class="p">,</span>
    <span class="n">src_lang_name</span><span class="o">=</span><span class="s2">&quot;German&quot;</span><span class="p">,</span>
    <span class="n">src_lang_attr</span><span class="o">=</span><span class="s2">&quot;de&quot;</span><span class="p">,</span>
    <span class="n">trg_lang_name</span><span class="o">=</span><span class="s2">&quot;English&quot;</span><span class="p">,</span>
    <span class="n">trg_lang_attr</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span>
    <span class="n">dl_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;bs&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
Model config MarianConfig {
  &#34;_name_or_path&#34;: &#34;Helsinki-NLP/opus-mt-de-en&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;swish&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;MarianMTModel&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bad_words_ids&#34;: [
    [
      58100
    ]
  ],
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 512,
  &#34;decoder_attention_heads&#34;: 8,
  &#34;decoder_ffn_dim&#34;: 2048,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 58100,
  &#34;decoder_vocab_size&#34;: 58101,
  &#34;dropout&#34;: 0.1,
  &#34;encoder_attention_heads&#34;: 8,
  &#34;encoder_ffn_dim&#34;: 2048,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 0,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;max_length&#34;: 512,
  &#34;max_position_embeddings&#34;: 512,
  &#34;model_type&#34;: &#34;marian&#34;,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: false,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;pad_token_id&#34;: 58100,
  &#34;scale_embedding&#34;: true,
  &#34;share_encoder_decoder_embeddings&#34;: true,
  &#34;static_position_embeddings&#34;: true,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 58101
}

loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514
All model checkpoint weights were used when initializing MarianMTModel.

All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.
loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
Model config MarianConfig {
  &#34;_name_or_path&#34;: &#34;Helsinki-NLP/opus-mt-de-en&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;swish&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;MarianMTModel&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bad_words_ids&#34;: [
    [
      58100
    ]
  ],
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 512,
  &#34;decoder_attention_heads&#34;: 8,
  &#34;decoder_ffn_dim&#34;: 2048,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 58100,
  &#34;decoder_vocab_size&#34;: 58101,
  &#34;dropout&#34;: 0.1,
  &#34;encoder_attention_heads&#34;: 8,
  &#34;encoder_ffn_dim&#34;: 2048,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 0,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;max_length&#34;: 512,
  &#34;max_position_embeddings&#34;: 512,
  &#34;model_type&#34;: &#34;marian&#34;,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: false,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;pad_token_id&#34;: 58100,
  &#34;scale_embedding&#34;: true,
  &#34;share_encoder_decoder_embeddings&#34;: true,
  &#34;static_position_embeddings&#34;: true,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 58101
}

loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
Model config MarianConfig {
  &#34;_name_or_path&#34;: &#34;Helsinki-NLP/opus-mt-de-en&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;swish&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;MarianMTModel&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bad_words_ids&#34;: [
    [
      58100
    ]
  ],
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 512,
  &#34;decoder_attention_heads&#34;: 8,
  &#34;decoder_ffn_dim&#34;: 2048,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 58100,
  &#34;decoder_vocab_size&#34;: 58101,
  &#34;dropout&#34;: 0.1,
  &#34;encoder_attention_heads&#34;: 8,
  &#34;encoder_ffn_dim&#34;: 2048,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 0,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;max_length&#34;: 512,
  &#34;max_position_embeddings&#34;: 512,
  &#34;model_type&#34;: &#34;marian&#34;,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: false,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;pad_token_id&#34;: 58100,
  &#34;scale_embedding&#34;: true,
  &#34;share_encoder_decoder_embeddings&#34;: true,
  &#34;static_position_embeddings&#34;: true,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 58101
}

loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm from cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm from cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target_vocab.json from cache at None
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/special_tokens_map.json from cache at None
loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757
Model config MarianConfig {
  &#34;_name_or_path&#34;: &#34;Helsinki-NLP/opus-mt-de-en&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;swish&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;MarianMTModel&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bad_words_ids&#34;: [
    [
      58100
    ]
  ],
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 512,
  &#34;decoder_attention_heads&#34;: 8,
  &#34;decoder_ffn_dim&#34;: 2048,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 58100,
  &#34;decoder_vocab_size&#34;: 58101,
  &#34;dropout&#34;: 0.1,
  &#34;encoder_attention_heads&#34;: 8,
  &#34;encoder_ffn_dim&#34;: 2048,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 0,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;max_length&#34;: 512,
  &#34;max_position_embeddings&#34;: 512,
  &#34;model_type&#34;: &#34;marian&#34;,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: false,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;pad_token_id&#34;: 58100,
  &#34;scale_embedding&#34;: true,
  &#34;share_encoder_decoder_embeddings&#34;: true,
  &#34;static_position_embeddings&#34;: true,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 58101
}

loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514
All model checkpoint weights were used when initializing MarianMTModel.

All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">metrics_cb</span> <span class="o">=</span> <span class="n">BlearnerForTranslation</span><span class="o">.</span><span class="n">get_metrics_cb</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">metrics_cb</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>bleu</th>
      <th>meteor</th>
      <th>sacrebleu</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.014099</td>
      <td>2.172663</td>
      <td>0.307334</td>
      <td>0.537191</td>
      <td>29.823626</td>
      <td>00:52</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(IT) Herr▁Präsident, Herr▁Kommissar,▁meine▁Damen und Herren, so▁genau▁wie die▁Entschließung mit dem▁Titel "Naturkatastrophen", die von der▁Fraktion der▁Europäischen▁Volkspartei (Christdemokraten)▁vorgelegt wurde,▁ist,▁würde▁ich▁gerne▁trotzdem die▁Aufmerksamkeit auf▁einige▁Punkte▁lenken, die▁heute▁Abend▁angesprochen▁wurden, die▁aber nicht in der▁Entschließung zum▁Thema▁gemacht▁werden, und die▁Gegenstand▁meiner▁Änderungsvorschläge▁sind.</td>
      <td>(IT) Mr President, Commissioner, ladies and gentlemen, as accurate as the resolution entitled 'Natural disasters', tabled by the Group of the European People's Party (Christian Democrats), is, I would nonetheless like to draw attention to some points</td>
      <td>[(IT) Mr President, Commissioner, ladies and gentlemen, just as the resolution on natural disasters presented by the Group of the European People's Party (Christian Democrats), I would like to draw attention to some of the points raised this evening, which are not dealt with in the resolution, and which are the subject of my amendments., This Parliament has always been an example and a champion in the defence of human rights, and at this critical time it must prove that it is not doing a common cause with a corrupt dictator in full decline and that it will allow itself to be carried away by the collaboration of some Members who have always been manipulated by this dictatorship.]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_de</span> <span class="o">=</span> <span class="s2">&quot;Ich trinke gerne Bier&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">blurr_translate</span><span class="p">(</span><span class="n">test_de</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;translation_texts&#39;: &#39;I like to drink beer&#39;}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">export_fname</span> <span class="o">=</span> <span class="s2">&quot;translation_export&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">to_fp32</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>

<span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>
<span class="n">inf_learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_de</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;generated_texts&#39;: &#39;I like to drink beer&#39;}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h2><p>The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained <strong>translation models</strong> below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.</p>
<p><strong>Note</strong>: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained translation models fail, please submit a github issue <em>(or a PR if you'd like to fix it yourself)</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="k">del</span> <span class="n">learn</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span><span class="n">model_type</span> <span class="k">for</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="n">NLP</span><span class="o">.</span><span class="n">get_models</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;ConditionalGeneration&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;TF&quot;</span><span class="p">))]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;BartForConditionalGeneration&#39;,
 &#39;BigBirdPegasusForConditionalGeneration&#39;,
 &#39;BlenderbotForConditionalGeneration&#39;,
 &#39;BlenderbotSmallForConditionalGeneration&#39;,
 &#39;FSMTForConditionalGeneration&#39;,
 &#39;LEDForConditionalGeneration&#39;,
 &#39;M2M100ForConditionalGeneration&#39;,
 &#39;MBartForConditionalGeneration&#39;,
 &#39;MT5ForConditionalGeneration&#39;,
 &#39;PLBartForConditionalGeneration&#39;,
 &#39;PegasusForConditionalGeneration&#39;,
 &#39;ProphetNetForConditionalGeneration&#39;,
 &#39;Speech2TextForConditionalGeneration&#39;,
 &#39;T5ForConditionalGeneration&#39;,
 &#39;XLMProphetNetForConditionalGeneration&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;facebook/bart-base&quot;</span><span class="p">,</span>
    <span class="s2">&quot;facebook/wmt19-de-en&quot;</span><span class="p">,</span>  <span class="c1"># FSMT</span>
    <span class="s2">&quot;Helsinki-NLP/opus-mt-de-en&quot;</span><span class="p">,</span>  <span class="c1"># MarianMT</span>
    <span class="c1">#&#39;sshleifer/tiny-mbart&#39;,</span>
    <span class="c1">#&#39;google/mt5-small&#39;,</span>
    <span class="s2">&quot;t5-small&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;wmt16&quot;</span><span class="p">,</span> <span class="s2">&quot;de-en&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1200</span><span class="p">))</span>
<span class="n">wmt_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;translation&quot;</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;de&quot;</span><span class="p">,</span> <span class="s2">&quot;en&quot;</span><span class="p">])</span>
<span class="nb">len</span><span class="p">(</span><span class="n">wmt_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)
Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1200</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># hide_output</span>
<span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span>
<span class="n">bsz</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">inp_seq_sz</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">trg_seq_sz</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">pretrained_model_names</span><span class="p">:</span>
    <span class="n">error</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;=== </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> ===</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">hf_tok_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;sshleifer/tiny-mbart&quot;</span><span class="p">:</span>
        <span class="n">hf_tok_kwargs</span><span class="p">[</span><span class="s2">&quot;src_lang&quot;</span><span class="p">],</span> <span class="n">hf_tok_kwargs</span><span class="p">[</span><span class="s2">&quot;tgt_lang&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;de_DE&quot;</span><span class="p">,</span> <span class="s2">&quot;en_XX&quot;</span>

    <span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">get_hf_objects</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">,</span> <span class="n">tokenizer_kwargs</span><span class="o">=</span><span class="n">hf_tok_kwargs</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;architecture:</span><span class="se">\t</span><span class="si">{</span><span class="n">hf_arch</span><span class="si">}</span><span class="se">\n</span><span class="s2">tokenizer:</span><span class="se">\t</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="se">\n</span><span class="s2">model:</span><span class="se">\t\t</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># 1. build your DataBlock</span>
    <span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="n">default_text_gen_kwargs</span><span class="p">(</span><span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;translation&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_t5_prefix</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;translate German to English: </span><span class="si">{</span><span class="n">inp</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="p">(</span><span class="n">hf_arch</span> <span class="o">==</span> <span class="s2">&quot;t5&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">inp</span>

    <span class="n">batch_tokenize_tfm</span> <span class="o">=</span> <span class="n">Seq2SeqBatchTokenizeTransform</span><span class="p">(</span>
        <span class="n">hf_arch</span><span class="p">,</span>
        <span class="n">hf_config</span><span class="p">,</span>
        <span class="n">hf_tokenizer</span><span class="p">,</span>
        <span class="n">hf_model</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">inp_seq_sz</span><span class="p">,</span>
        <span class="n">max_target_length</span><span class="o">=</span><span class="n">trg_seq_sz</span><span class="p">,</span>
        <span class="n">text_gen_kwargs</span><span class="o">=</span><span class="n">text_gen_kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">Seq2SeqTextBlock</span><span class="p">(</span><span class="n">batch_tokenize_tfm</span><span class="o">=</span><span class="n">batch_tokenize_tfm</span><span class="p">),</span> <span class="n">noop</span><span class="p">)</span>
    <span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">Pipeline</span><span class="p">([</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;de&quot;</span><span class="p">),</span> <span class="n">add_t5_prefix</span><span class="p">]),</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;en&quot;</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>

    <span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">wmt_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">bsz</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>

    <span class="c1"># 2. build your Learner</span>
    <span class="n">seq2seq_metrics</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
    <span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ShortEpochCallback</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">short_valid</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">Seq2SeqMetricsCallback</span><span class="p">(</span><span class="n">custom_metrics</span><span class="o">=</span><span class="n">seq2seq_metrics</span><span class="p">)]</span>

    <span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span>
        <span class="n">dls</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">opt_func</span><span class="o">=</span><span class="n">ranger</span><span class="p">,</span>
        <span class="n">loss_func</span><span class="o">=</span><span class="n">PreCalculatedCrossEntropyLoss</span><span class="p">(),</span>
        <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">BaseModelCallback</span><span class="p">],</span>
        <span class="n">splitter</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">blurr_seq2seq_splitter</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">),</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>

    <span class="n">learn</span><span class="o">.</span><span class="n">create_opt</span><span class="p">()</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>

    <span class="c1"># 3. Run your tests</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*** TESTING DataLoaders ***</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="n">bsz</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">bsz</span><span class="p">,</span> <span class="n">inp_seq_sz</span><span class="p">]))</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">bsz</span><span class="p">)</span>

        <span class="c1">#         print(&#39;*** TESTING One pass through the model ***&#39;)</span>
        <span class="c1">#         preds = learn.model(b[0])</span>
        <span class="c1">#         test_eq(preds[1].shape[0], bsz)</span>
        <span class="c1">#         test_eq(preds[1].shape[2], hf_config.vocab_size)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*** TESTING Training/Results ***&quot;</span><span class="p">)</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>

        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s2">&quot;PASSED&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s2">&quot;FAILED&quot;</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c1"># cleanup</span>
        <span class="k">del</span> <span class="n">learn</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>arch</th>
      <th>tokenizer</th>
      <th>model_name</th>
      <th>result</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>bart</td>
      <td>BartTokenizerFast</td>
      <td>BartForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>fsmt</td>
      <td>FSMTTokenizer</td>
      <td>FSMTForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>marian</td>
      <td>MarianTokenizer</td>
      <td>MarianMTModel</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>t5</td>
      <td>T5TokenizerFast</td>
      <td>T5ForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

