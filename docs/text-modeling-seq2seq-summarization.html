---

title: text.modeling.seq2seq.summarization


keywords: fastai
sidebar: home_sidebar

summary: "This module contains custom models, custom splitters, etc... summarization tasks."
description: "This module contains custom models, custom splitters, etc... summarization tasks."
nb_path: "nbs/21_text-modeling-seq2seq-summarization.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/21_text-modeling-seq2seq-summarization.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>What we&#39;re running with at the time this documentation was generated:
torch: 1.9.0+cu102
fastai: 2.6.3
transformers: 4.18.0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Mid-level-API">Mid-level API<a class="anchor-link" href="#Mid-level-API"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example"> </a></h3><p>The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;ccdv/cnn_dailymail&quot;</span><span class="p">,</span> <span class="s2">&quot;3.0.0&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train[:1000]&quot;</span><span class="p">)</span>
<span class="n">cnndm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">cnndm_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article</th>
      <th>highlights</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force "to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction." It's a step that is set to turn an internat...</td>
      <td>Syrian official: Obama climbed to the top of the tree, "doesn't know how to get down"\nObama sends a letter to the heads of the House and Senate .\nObama to seek congressional approval on military action against Syria .\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .</td>
      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...</td>
      <td>Usain Bolt wins third gold of world championship .\nAnchors Jamaica to 4x100m relay victory .\nEighth gold at the championships for Bolt .\nJamaica double up in women's 4x100m relay .</td>
      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>
    </tr>
  </tbody>
</table>
</div></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;sshleifer/distilbart-cnn-6-6&quot;</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">BartForConditionalGeneration</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/c457182dd3c47e71636dfe957c948acf12fd6b1d17d3e16a69f9bd731f340157.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/1917cd1903f32920951797d984eff6fb9707c20aa7c0eba679d033d5d5dbc7d3.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer.json from cache at None
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/41a44e7ad55ba42aa9abd4697be8ff844b95c3f33ad59ceb5059b263caf581fe.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8
loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921
All model checkpoint weights were used when initializing BartForConditionalGeneration.

All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;bart&#39;,
 transformers.models.bart.configuration_bart.BartConfig,
 transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,
 transformers.models.bart.modeling_bart.BartForConditionalGeneration)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="n">hf_arch</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;bart&quot;</span><span class="p">,</span> <span class="s2">&quot;t5&quot;</span><span class="p">]:</span>
    <span class="n">text_gen_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">hf_config</span><span class="o">.</span><span class="n">task_specific_params</span><span class="p">[</span><span class="s2">&quot;summarization&quot;</span><span class="p">],</span> <span class="o">**</span><span class="p">{</span><span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span> <span class="s2">&quot;min_length&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}}</span>

<span class="c1"># not all &quot;summarization&quot; parameters are for the model.generate method ... remove them here</span>
<span class="n">generate_func_args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">hf_model</span><span class="o">.</span><span class="n">generate</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">text_gen_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">generate_func_args</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

<span class="k">if</span> <span class="n">hf_arch</span> <span class="o">==</span> <span class="s2">&quot;mbart&quot;</span><span class="p">:</span>
    <span class="n">text_gen_kwargs</span><span class="p">[</span><span class="s2">&quot;decoder_start_token_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()[</span><span class="s2">&quot;en_XX&quot;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tok_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="n">hf_arch</span> <span class="o">==</span> <span class="s2">&quot;mbart&quot;</span><span class="p">:</span>
    <span class="n">tok_kwargs</span><span class="p">[</span><span class="s2">&quot;src_lang&quot;</span><span class="p">],</span> <span class="n">tok_kwargs</span><span class="p">[</span><span class="s2">&quot;tgt_lang&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;en_XX&quot;</span><span class="p">,</span> <span class="s2">&quot;en_XX&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_tokenize_tfm</span> <span class="o">=</span> <span class="n">Seq2SeqBatchTokenizeTransform</span><span class="p">(</span>
    <span class="n">hf_arch</span><span class="p">,</span>
    <span class="n">hf_config</span><span class="p">,</span>
    <span class="n">hf_tokenizer</span><span class="p">,</span>
    <span class="n">hf_model</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">max_target_length</span><span class="o">=</span><span class="mi">130</span><span class="p">,</span>
    <span class="n">tok_kwargs</span><span class="o">=</span><span class="n">tok_kwargs</span><span class="p">,</span>
    <span class="n">text_gen_kwargs</span><span class="o">=</span><span class="n">text_gen_kwargs</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">Seq2SeqTextBlock</span><span class="p">(</span><span class="n">batch_tokenize_tfm</span><span class="o">=</span><span class="n">batch_tokenize_tfm</span><span class="p">),</span> <span class="n">noop</span><span class="p">)</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;article&quot;</span><span class="p">),</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;highlights&quot;</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, torch.Size([2, 256]), torch.Size([2, 75]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;s&gt; (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. "After the abortion, I felt empty, as if something was scooped out of me," Ji told a congressional panel in September. "My husband and I had been so excited for our new baby. Now suddenly all that hope and joy and excitement disappeared.... I was very depressed and despondent. For a long time, whenever I thought about my lost child, I would cry." As she lay unconscious, she said, an IUD to prevent future pregnancies was inserted. The issue of forced abortions -- and in some cases, forced sterilizations -- in China has seized the spotlight in recent days with news of escaped activist Chen Guangcheng. Chen, a blind, self-taught lawyer, rose to fame in the late 1990s because of his advocacy for what he calls victims&lt;/s&gt;</td>
      <td>China's one-child policy results in forced abortions and sterilizations, activists say.\nWomen tell of emotional and physical consequences from the procedures.\nActivist Chen Guangcheng works to advocate for victims of such practices.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&lt;s&gt; (CNN) -- The generation of gays and lesbians that literally created the modern LGBT movement -- from the heroes of the 1969 Stonewall riots to their slightly younger friends -- is at, or nearing, retirement age. That used to mean the beginning of an extremely difficult time in an LGBT person's life. But as gay baby boomers find more acceptance in mainstream society and continue to do what they've always done -- push to make a better world for the LGBT community -- their retirement options are slowly improving. That is, if they decide to retire at all. "The notion of retirement has never been a part of my vocabulary," said Bob Witeck, CEO and co-founder of Witeck Communications. Nearly 61, Witeck has put some thought into what he should do with his strategic public relations and marketing firm as he gets older. Like many friends his age who are also entrepreneurs, he plans to keep working. "Because I run a business, as I get older I can change the intensity of my engagement in the kinds of work I take on," Witeck said. "I know I'm lucky that way, and I'm lucky in my personal life as well. My husband is 50, so I have a younger man to help me&lt;/s&gt;</td>
      <td>LGBT baby boomers changed the visibility of the gay community.\nAs they approach retirement, they face different obstacles than their straight counterparts.\nWithout marriage equality, same-sex couples may face financial hardships.\nAdvocates say the situation is slowly improving.</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Training">Training<a class="anchor-link" href="#Training"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seq2seq_metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;rouge&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;compute_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;rouge_types&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeLsum&quot;</span><span class="p">],</span> <span class="s2">&quot;use_stemmer&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>
        <span class="s2">&quot;returns&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;rouge1&quot;</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">,</span> <span class="s2">&quot;rougeLsum&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="s2">&quot;bertscore&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;compute_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;lang&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">},</span> <span class="s2">&quot;returns&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">]},</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
<span class="n">learn_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">BaseModelCallback</span><span class="p">]</span>
<span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Seq2SeqMetricsCallback</span><span class="p">(</span><span class="n">custom_metrics</span><span class="o">=</span><span class="n">seq2seq_metrics</span><span class="p">)]</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span>
    <span class="n">dls</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
    <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span>
    <span class="n">cbs</span><span class="o">=</span><span class="n">learn_cbs</span><span class="p">,</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">blurr_seq2seq_splitter</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># learn = learn.to_native_fp16() #.to_fp16()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span> <span class="n">preds</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">preds</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(3, torch.Size([]), torch.Size([2, 59, 50264]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 3, torch.Size([2, 256]), 2, torch.Size([2, 59]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggest_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">minimum</span><span class="p">,</span> <span class="n">steep</span><span class="p">,</span> <span class="n">valley</span><span class="p">,</span> <span class="n">slide</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(minimum=4.786300996784121e-05, steep=6.309573450380412e-07, valley=6.30957365501672e-05, slide=1.4454397387453355e-05)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>rouge1</th>
      <th>rouge2</th>
      <th>rougeL</th>
      <th>rougeLsum</th>
      <th>bertscore_precision</th>
      <th>bertscore_recall</th>
      <th>bertscore_f1</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.306568</td>
      <td>2.146496</td>
      <td>0.296782</td>
      <td>0.124385</td>
      <td>0.222347</td>
      <td>0.275367</td>
      <td>0.892347</td>
      <td>0.865695</td>
      <td>0.878717</td>
      <td>01:12</td>
    </tr>
  </tbody>
</table></div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Could not locate the tokenizer configuration file, will try to use the model config instead.
loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
Model config RobertaConfig {
  &#34;_name_or_path&#34;: &#34;roberta-large&#34;,
  &#34;architectures&#34;: [
    &#34;RobertaForMaskedLM&#34;
  ],
  &#34;attention_probs_dropout_prob&#34;: 0.1,
  &#34;bos_token_id&#34;: 0,
  &#34;classifier_dropout&#34;: null,
  &#34;eos_token_id&#34;: 2,
  &#34;hidden_act&#34;: &#34;gelu&#34;,
  &#34;hidden_dropout_prob&#34;: 0.1,
  &#34;hidden_size&#34;: 1024,
  &#34;initializer_range&#34;: 0.02,
  &#34;intermediate_size&#34;: 4096,
  &#34;layer_norm_eps&#34;: 1e-05,
  &#34;max_position_embeddings&#34;: 514,
  &#34;model_type&#34;: &#34;roberta&#34;,
  &#34;num_attention_heads&#34;: 16,
  &#34;num_hidden_layers&#34;: 24,
  &#34;pad_token_id&#34;: 1,
  &#34;position_embedding_type&#34;: &#34;absolute&#34;,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;type_vocab_size&#34;: 1,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50265
}

loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab
loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None
loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
Model config RobertaConfig {
  &#34;_name_or_path&#34;: &#34;roberta-large&#34;,
  &#34;architectures&#34;: [
    &#34;RobertaForMaskedLM&#34;
  ],
  &#34;attention_probs_dropout_prob&#34;: 0.1,
  &#34;bos_token_id&#34;: 0,
  &#34;classifier_dropout&#34;: null,
  &#34;eos_token_id&#34;: 2,
  &#34;hidden_act&#34;: &#34;gelu&#34;,
  &#34;hidden_dropout_prob&#34;: 0.1,
  &#34;hidden_size&#34;: 1024,
  &#34;initializer_range&#34;: 0.02,
  &#34;intermediate_size&#34;: 4096,
  &#34;layer_norm_eps&#34;: 1e-05,
  &#34;max_position_embeddings&#34;: 514,
  &#34;model_type&#34;: &#34;roberta&#34;,
  &#34;num_attention_heads&#34;: 16,
  &#34;num_hidden_layers&#34;: 24,
  &#34;pad_token_id&#34;: 1,
  &#34;position_embedding_type&#34;: &#34;absolute&#34;,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;type_vocab_size&#34;: 1,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50265
}

loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
Model config RobertaConfig {
  &#34;_name_or_path&#34;: &#34;roberta-large&#34;,
  &#34;architectures&#34;: [
    &#34;RobertaForMaskedLM&#34;
  ],
  &#34;attention_probs_dropout_prob&#34;: 0.1,
  &#34;bos_token_id&#34;: 0,
  &#34;classifier_dropout&#34;: null,
  &#34;eos_token_id&#34;: 2,
  &#34;hidden_act&#34;: &#34;gelu&#34;,
  &#34;hidden_dropout_prob&#34;: 0.1,
  &#34;hidden_size&#34;: 1024,
  &#34;initializer_range&#34;: 0.02,
  &#34;intermediate_size&#34;: 4096,
  &#34;layer_norm_eps&#34;: 1e-05,
  &#34;max_position_embeddings&#34;: 514,
  &#34;model_type&#34;: &#34;roberta&#34;,
  &#34;num_attention_heads&#34;: 16,
  &#34;num_hidden_layers&#34;: 24,
  &#34;pad_token_id&#34;: 1,
  &#34;position_embedding_type&#34;: &#34;absolute&#34;,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;type_vocab_size&#34;: 1,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50265
}

loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352
All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.
If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Showing-results">Showing results<a class="anchor-link" href="#Showing-results"> </a></h4><p>And here we create a <code>@typedispatch</code>ed implementation of <code>Learner.show_results</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(CNN Student News) -- January 13, 2011. Download PDF maps related to today's show:. • Arizona • Australia. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN STUDENT NEWS ANCHOR: A problem that won't be solved, even if the solution is clear. The story and the reasons, leading off today's broadcast of CNN Student News! My name is Carl Azuz! First Up: Winter Storm Woes. AZUZ: Florida is the only state in the union without snow on the g</td>
      <td>A winter storm slams the northeastern United States.\nThe U.S. House of Representatives condemns the Arizona shooting.\nMassive floods leave vast areas of Australia underwater.\nUse the Daily Discussion to help students understand today's featured news</td>
      <td>[ Find out how a storm system iced out the southeast . Use the Daily Discussion to help students understand today's featured news stories,  Jeb Bush and Mitt Romney are putting pressure on New Jersey Gov. Chris Christie .\nBush has been a well-liked figure]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Prediction">Prediction<a class="anchor-link" href="#Prediction"> </a></h4><p>We add here <a href="/blurr/text-modeling-seq2seq-summarization.html#Learner.blurr_summarize"><code>Learner.blurr_summarize</code></a> method to bring the results inline with the format returned via Hugging Face's pipeline method</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_article</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off </span>
<span class="s2">into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. </span>
<span class="s2">The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino </span>
<span class="s2">Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino&#39;s vault on the lower level </span>
<span class="s2">but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group </span>
<span class="s2">of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the </span>
<span class="s2">cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was </span>
<span class="s2">occurring unknowingly blocked the armed robbers&#39; vehicles. A gunman pulled the woman from her vehicle, beat </span>
<span class="s2">her, and took off for the French border. The other gunmen followed into France, which is only about 100 </span>
<span class="s2">meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. </span>
<span class="s2">There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the </span>
<span class="s2">robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, </span>
<span class="s2">Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN&#39;s Andreena Narayan </span>
<span class="s2">contributed to this report.</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">outputs</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_generate</span><span class="p">(</span><span class="n">test_article</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;summary_texts&quot;</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">outputs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;summary_texts&#39;: [&#34; 10 men armed with pistols and small machine guns raided a casino in Switzerland .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\nOne group tried to break into the casino&#39;s vault on the lower level but could not get in .\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers&#39; vehicles .&#34;,
   &#34; 10 men armed with pistols and small machine guns raided a casino in Switzerland .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\nOne group tried to break into the casino&#39;s vault on the lower level but could not get in .\nA woman driving by and unaware of what was happening unknowingly blocked the robbers&#39; vehicles .&#34;,
   &#34; 10 men armed with pistols and small machine guns raided a casino in Switzerland .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\nOne group tried to break into the casino&#39;s vault on the lower level but could not get in .&#34;]}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Learner.blurr_summarize" class="doc_header"><code>Learner.blurr_summarize</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/text/modeling/seq2seq/summarization.py#L30" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Learner.blurr_summarize</code>(<strong><code>inp</code></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">blurr_summarize</span><span class="p">(</span><span class="n">test_article</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;summary_texts&#39;: [&#34; 10 men armed with pistols and small machine guns raided a casino in Switzerland .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\nOne group tried to break into the casino&#39;s vault on the lower level but could not get in .\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers&#39; vehicles .&#34;,
   &#34; 10 men armed with pistols and small machine guns raided a casino in Switzerland .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\nOne group tried to break into the casino&#39;s vault on the lower level but could not get in .\nA woman driving by and unaware of what was happening unknowingly blocked the robbers&#39; vehicles .&#34;,
   &#34; 10 men armed with pistols and small machine guns raided a casino in Switzerland .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\nOne group tried to break into the casino&#39;s vault on the lower level but could not get in .&#34;]}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Inference">Inference<a class="anchor-link" href="#Inference"> </a></h4><p>Using fast.ai <code>Learner.export</code> and <code>load_learner</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">export_fname</span> <span class="o">=</span> <span class="s2">&quot;summarize_export&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>
<span class="n">inf_learn</span><span class="o">.</span><span class="n">blurr_summarize</span><span class="p">(</span><span class="n">test_article</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;summary_texts&#39;: &#39; 10 men armed with pistols and small machine guns raided a casino in Switzerland .\nThe men, dressed in black clothes and black ski&#39;}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="High-level-API">High-level API<a class="anchor-link" href="#High-level-API"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="BlearnerForSummarization" class="doc_header"><code>class</code> <code>BlearnerForSummarization</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/text/modeling/seq2seq/summarization.py#L37" class="source_link" style="float:right">[source]</a></h3><blockquote><p><code>BlearnerForSummarization</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>hf_model</code></strong>:<code>PreTrainedModel</code>, <strong><code>base_model_cb</code></strong>:<a href="/blurr/text-modeling-core.html#BaseModelCallback"><code>BaseModelCallback</code></a>=<em><code>BaseModelCallback</code></em>, <strong><code>loss_func</code></strong>=<em><code>None</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>lr</code></strong>=<em><code>0.001</code></em>, <strong><code>splitter</code></strong>=<em><code>trainable_params</code></em>, <strong><code>cbs</code></strong>=<em><code>None</code></em>, <strong><code>metrics</code></strong>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>None</code></em>, <strong><code>model_dir</code></strong>=<em><code>'models'</code></em>, <strong><code>wd</code></strong>=<em><code>None</code></em>, <strong><code>wd_bn_bias</code></strong>=<em><code>False</code></em>, <strong><code>train_bn</code></strong>=<em><code>True</code></em>, <strong><code>moms</code></strong>=<em><code>(0.95, 0.85, 0.95)</code></em>) :: <a href="/blurr/text-modeling-core.html#Blearner"><code>Blearner</code></a></p>
</blockquote>
<p>Group together a <code>model</code>, some <code>dls</code> and a <code>loss_func</code> to handle training</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Example">Example<a class="anchor-link" href="#Example"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">BlearnerForSummarization</span><span class="o">.</span><span class="n">from_data</span><span class="p">(</span>
    <span class="n">cnndm_df</span><span class="p">,</span>
    <span class="s2">&quot;sshleifer/distilbart-cnn-6-6&quot;</span><span class="p">,</span>
    <span class="n">text_attr</span><span class="o">=</span><span class="s2">&quot;article&quot;</span><span class="p">,</span>
    <span class="n">summary_attr</span><span class="o">=</span><span class="s2">&quot;highlights&quot;</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">max_target_length</span><span class="o">=</span><span class="mi">130</span><span class="p">,</span>
    <span class="n">dblock_splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(),</span>
    <span class="n">dl_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;bs&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
<span class="p">)</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921
All model checkpoint weights were used when initializing BartForConditionalGeneration.

All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.
loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/c457182dd3c47e71636dfe957c948acf12fd6b1d17d3e16a69f9bd731f340157.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/1917cd1903f32920951797d984eff6fb9707c20aa7c0eba679d033d5d5dbc7d3.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer.json from cache at None
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/41a44e7ad55ba42aa9abd4697be8ff844b95c3f33ad59ceb5059b263caf581fe.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8
loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496
Model config BartConfig {
  &#34;_name_or_path&#34;: &#34;sshleifer/distilbart-cnn-6-6&#34;,
  &#34;_num_labels&#34;: 3,
  &#34;activation_dropout&#34;: 0.0,
  &#34;activation_function&#34;: &#34;gelu&#34;,
  &#34;add_bias_logits&#34;: false,
  &#34;add_final_layer_norm&#34;: false,
  &#34;architectures&#34;: [
    &#34;BartForConditionalGeneration&#34;
  ],
  &#34;attention_dropout&#34;: 0.0,
  &#34;bos_token_id&#34;: 0,
  &#34;classif_dropout&#34;: 0.0,
  &#34;classifier_dropout&#34;: 0.0,
  &#34;d_model&#34;: 1024,
  &#34;decoder_attention_heads&#34;: 16,
  &#34;decoder_ffn_dim&#34;: 4096,
  &#34;decoder_layerdrop&#34;: 0.0,
  &#34;decoder_layers&#34;: 6,
  &#34;decoder_start_token_id&#34;: 2,
  &#34;dropout&#34;: 0.1,
  &#34;early_stopping&#34;: true,
  &#34;encoder_attention_heads&#34;: 16,
  &#34;encoder_ffn_dim&#34;: 4096,
  &#34;encoder_layerdrop&#34;: 0.0,
  &#34;encoder_layers&#34;: 6,
  &#34;eos_token_id&#34;: 2,
  &#34;extra_pos_embeddings&#34;: 2,
  &#34;force_bos_token_to_be_generated&#34;: true,
  &#34;forced_bos_token_id&#34;: 0,
  &#34;forced_eos_token_id&#34;: 2,
  &#34;gradient_checkpointing&#34;: false,
  &#34;id2label&#34;: {
    &#34;0&#34;: &#34;LABEL_0&#34;,
    &#34;1&#34;: &#34;LABEL_1&#34;,
    &#34;2&#34;: &#34;LABEL_2&#34;
  },
  &#34;init_std&#34;: 0.02,
  &#34;is_encoder_decoder&#34;: true,
  &#34;label2id&#34;: {
    &#34;LABEL_0&#34;: 0,
    &#34;LABEL_1&#34;: 1,
    &#34;LABEL_2&#34;: 2
  },
  &#34;length_penalty&#34;: 2.0,
  &#34;max_length&#34;: 142,
  &#34;max_position_embeddings&#34;: 1024,
  &#34;min_length&#34;: 56,
  &#34;model_type&#34;: &#34;bart&#34;,
  &#34;no_repeat_ngram_size&#34;: 3,
  &#34;normalize_before&#34;: false,
  &#34;normalize_embedding&#34;: true,
  &#34;num_beams&#34;: 4,
  &#34;num_hidden_layers&#34;: 6,
  &#34;output_past&#34;: true,
  &#34;pad_token_id&#34;: 1,
  &#34;prefix&#34;: &#34; &#34;,
  &#34;replacing_rate&#34;: 0,
  &#34;scale_embedding&#34;: false,
  &#34;static_position_embeddings&#34;: false,
  &#34;student_decoder_layers&#34;: null,
  &#34;student_encoder_layers&#34;: null,
  &#34;task_specific_params&#34;: {
    &#34;summarization&#34;: {
      &#34;early_stopping&#34;: true,
      &#34;length_penalty&#34;: 2.0,
      &#34;max_length&#34;: 142,
      &#34;min_length&#34;: 56,
      &#34;no_repeat_ngram_size&#34;: 3,
      &#34;num_beams&#34;: 4
    }
  },
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50264
}

loading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921
All model checkpoint weights were used when initializing BartForConditionalGeneration.

All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">4e-5</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">BlearnerForSummarization</span><span class="o">.</span><span class="n">get_metrics_cb</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>rouge1</th>
      <th>rouge2</th>
      <th>rougeL</th>
      <th>rougeLsum</th>
      <th>bertscore_precision</th>
      <th>bertscore_recall</th>
      <th>bertscore_f1</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.217999</td>
      <td>2.165818</td>
      <td>0.363228</td>
      <td>0.142654</td>
      <td>0.249067</td>
      <td>0.338458</td>
      <td>0.879375</td>
      <td>0.888943</td>
      <td>0.884054</td>
      <td>02:44</td>
    </tr>
  </tbody>
</table></div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Could not locate the tokenizer configuration file, will try to use the model config instead.
loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
Model config RobertaConfig {
  &#34;_name_or_path&#34;: &#34;roberta-large&#34;,
  &#34;architectures&#34;: [
    &#34;RobertaForMaskedLM&#34;
  ],
  &#34;attention_probs_dropout_prob&#34;: 0.1,
  &#34;bos_token_id&#34;: 0,
  &#34;classifier_dropout&#34;: null,
  &#34;eos_token_id&#34;: 2,
  &#34;hidden_act&#34;: &#34;gelu&#34;,
  &#34;hidden_dropout_prob&#34;: 0.1,
  &#34;hidden_size&#34;: 1024,
  &#34;initializer_range&#34;: 0.02,
  &#34;intermediate_size&#34;: 4096,
  &#34;layer_norm_eps&#34;: 1e-05,
  &#34;max_position_embeddings&#34;: 514,
  &#34;model_type&#34;: &#34;roberta&#34;,
  &#34;num_attention_heads&#34;: 16,
  &#34;num_hidden_layers&#34;: 24,
  &#34;pad_token_id&#34;: 1,
  &#34;position_embedding_type&#34;: &#34;absolute&#34;,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;type_vocab_size&#34;: 1,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50265
}

loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab
loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None
loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
Model config RobertaConfig {
  &#34;_name_or_path&#34;: &#34;roberta-large&#34;,
  &#34;architectures&#34;: [
    &#34;RobertaForMaskedLM&#34;
  ],
  &#34;attention_probs_dropout_prob&#34;: 0.1,
  &#34;bos_token_id&#34;: 0,
  &#34;classifier_dropout&#34;: null,
  &#34;eos_token_id&#34;: 2,
  &#34;hidden_act&#34;: &#34;gelu&#34;,
  &#34;hidden_dropout_prob&#34;: 0.1,
  &#34;hidden_size&#34;: 1024,
  &#34;initializer_range&#34;: 0.02,
  &#34;intermediate_size&#34;: 4096,
  &#34;layer_norm_eps&#34;: 1e-05,
  &#34;max_position_embeddings&#34;: 514,
  &#34;model_type&#34;: &#34;roberta&#34;,
  &#34;num_attention_heads&#34;: 16,
  &#34;num_hidden_layers&#34;: 24,
  &#34;pad_token_id&#34;: 1,
  &#34;position_embedding_type&#34;: &#34;absolute&#34;,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;type_vocab_size&#34;: 1,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50265
}

loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
Model config RobertaConfig {
  &#34;_name_or_path&#34;: &#34;roberta-large&#34;,
  &#34;architectures&#34;: [
    &#34;RobertaForMaskedLM&#34;
  ],
  &#34;attention_probs_dropout_prob&#34;: 0.1,
  &#34;bos_token_id&#34;: 0,
  &#34;classifier_dropout&#34;: null,
  &#34;eos_token_id&#34;: 2,
  &#34;hidden_act&#34;: &#34;gelu&#34;,
  &#34;hidden_dropout_prob&#34;: 0.1,
  &#34;hidden_size&#34;: 1024,
  &#34;initializer_range&#34;: 0.02,
  &#34;intermediate_size&#34;: 4096,
  &#34;layer_norm_eps&#34;: 1e-05,
  &#34;max_position_embeddings&#34;: 514,
  &#34;model_type&#34;: &#34;roberta&#34;,
  &#34;num_attention_heads&#34;: 16,
  &#34;num_hidden_layers&#34;: 24,
  &#34;pad_token_id&#34;: 1,
  &#34;position_embedding_type&#34;: &#34;absolute&#34;,
  &#34;transformers_version&#34;: &#34;4.18.0&#34;,
  &#34;type_vocab_size&#34;: 1,
  &#34;use_cache&#34;: true,
  &#34;vocab_size&#34;: 50265
}

loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352
All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.
If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">input_trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">target_trunc_at</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. "After the abortion, I felt empty, as if something was scooped out of me," J</td>
      <td>China's one-child policy results in forced abortions and sterilizations, activists say.\nWomen tell of emotional and physical consequences from the procedures.\nActivist Chen Guangcheng works to advocate for victims of such practices.</td>
      <td>[ Ji Yeqing says she was forced to have an abortion in violation of China's one-child policy .\nShe says she felt "empty" after the abortion .\nThe issue of forced abortions in China has seized the spotlight in recent days .\nIn some cases, forced sterilizations are used to prevent future pregnancies .,  Malala Yousufzai was shot in the neck by Taliban militants on Tuesday .\nMalala is recovering after surgeons worked for three hours to remove a bullet lodged in her neck .\nAn angry chorus of voices in social media, on the street, and over the airwaves decries the attack .\nThe 14-year-old is a defiant blogger .]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_article</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off </span>
<span class="s2">into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. </span>
<span class="s2">The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino </span>
<span class="s2">Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino&#39;s vault on the lower level </span>
<span class="s2">but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group </span>
<span class="s2">of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the </span>
<span class="s2">cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was </span>
<span class="s2">occurring unknowingly blocked the armed robbers&#39; vehicles. A gunman pulled the woman from her vehicle, beat </span>
<span class="s2">her, and took off for the French border. The other gunmen followed into France, which is only about 100 </span>
<span class="s2">meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. </span>
<span class="s2">There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the </span>
<span class="s2">robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, </span>
<span class="s2">Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN&#39;s Andreena Narayan </span>
<span class="s2">contributed to this report.</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_article</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;summary_texts&#39;: [&#34; 10 men raid Swiss casino in early hours of Sunday morning, police say .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\nOne group tried to break into the vault on the lower level but could not get in .\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers&#39; vehicles .&#34;,
   &#34; 10 men raid Swiss casino in early hours of Sunday morning, police say .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\nOne group tried to break into the vault on the lower level but could not get in .\nA woman driving by and unaware of what was happening unknowingly blocked the robbers&#39; vehicles .&#34;,
   &#34; 10 men raid Swiss casino in early hours of Sunday morning, police say .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\nOne group tried to break into the vault on the lower level but could not get in .\nA woman driving by and unaware of what was happening unknowingly blocked the robbers&#39; vehicles .\n&#34;]}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">export_fname</span> <span class="o">=</span> <span class="s2">&quot;summarize_export&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">to_fp32</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>

<span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>
<span class="n">inf_learn</span><span class="o">.</span><span class="n">blurr_summarize</span><span class="p">(</span><span class="n">test_article</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;summary_texts&#39;: &#34; 10 men raid Swiss casino in early hours of Sunday morning, police say .\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\nOne group tried to break into the vault on the lower level but could not get in .\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers&#39; vehicles .&#34;}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h2><p>The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained <strong>summarization models</strong> below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.</p>
<p><strong>Note</strong>: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue <em>(or a PR if you'd like to fix it yourself)</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>arch</th>
      <th>tokenizer</th>
      <th>model_name</th>
      <th>result</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>bart</td>
      <td>BartTokenizerFast</td>
      <td>BartForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>led</td>
      <td>LEDTokenizerFast</td>
      <td>LEDForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>mbart</td>
      <td>MBartTokenizerFast</td>
      <td>MBartForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>mt5</td>
      <td>T5TokenizerFast</td>
      <td>MT5ForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>pegasus</td>
      <td>PegasusTokenizerFast</td>
      <td>PegasusForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>5</th>
      <td>t5</td>
      <td>T5TokenizerFast</td>
      <td>T5ForConditionalGeneration</td>
      <td>PASSED</td>
      <td></td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

