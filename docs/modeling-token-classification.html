---

title: modeling.token_classification


keywords: fastai
sidebar: home_sidebar

summary: "This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
description: "This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
nb_path: "nbs/02a_modeling-token-classification.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/02a_modeling-token-classification.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using GPU #</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using GPU #1: GeForce GTX 1080 Ti
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Token-classification">Token classification<a class="anchor-link" href="#Token-classification"> </a></h2><p>The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_converters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;tokens&#39;</span><span class="p">:</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">,</span> <span class="s1">&#39;nested-labels&#39;</span><span class="p">:</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">}</span>

<span class="c1"># full nlp dataset</span>
<span class="c1"># germ_eval_df = pd.read_csv(&#39;./data/task-token-classification/germeval2014ner_cleaned.csv&#39;, converters=df_converters)</span>

<span class="c1"># demo nlp dataset</span>
<span class="n">germ_eval_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./germeval2014_sample.csv&#39;</span><span class="p">,</span> <span class="n">converters</span><span class="o">=</span><span class="n">df_converters</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">germ_eval_df</span><span class="p">))</span>
<span class="n">germ_eval_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>1000
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>source</th>
      <th>tokens</th>
      <th>labels</th>
      <th>nested-labels</th>
      <th>ds_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>
      <td>[Schartau, sagte, dem, ", Tagesspiegel, ", vom, Freitag, ,, Fischer, sei, ", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, ", .]</td>
      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>
      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>
      <td>train</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>welt.de vom 29.10.2005 [2005-10-29]</td>
      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>
      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>
      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>
      <td>train</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>
      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>
      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>
      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>
      <td>train</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>stern.de vom 21.03.2006 [2006-03-21]</td>
      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>
      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>
      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>
      <td>train</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>
      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>
      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>
      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>
      <td>train</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are only going to be working with small sample from the <a href="https://sites.google.com/site/germeval2014ner/data">GermEval 2014</a> data set ... so the results might not be all that great :).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">lbls</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">germ_eval_df</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">lbls</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;B-LOC&#39;, &#39;B-LOCderiv&#39;, &#39;B-LOCpart&#39;, &#39;B-ORG&#39;, &#39;B-ORGpart&#39;, &#39;B-OTH&#39;, &#39;B-OTHderiv&#39;, &#39;B-OTHpart&#39;, &#39;B-PER&#39;, &#39;B-PERderiv&#39;, &#39;B-PERpart&#39;, &#39;I-LOC&#39;, &#39;I-LOCderiv&#39;, &#39;I-ORG&#39;, &#39;I-ORGpart&#39;, &#39;I-OTH&#39;, &#39;I-PER&#39;, &#39;O&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="n">HF_TASKS_AUTO</span><span class="o">.</span><span class="n">TokenClassification</span>
<span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;bert-base-multilingual-cased&quot;</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>

<span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice above how I set the <code>config.num_labels</code> attribute to the number of labels we want <em>our</em> model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> 
                                                                               <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span> 
                                                                               <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;bert&#39;,
 transformers.models.bert.configuration_bert.BertConfig,
 transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,
 transformers.models.bert.modeling_bert.BertForTokenClassification)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_eq</span><span class="p">(</span><span class="n">hf_config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">before_batch_tfm</span> <span class="o">=</span> <span class="n">HF_TokenClassBeforeBatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">is_split_into_words</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                     <span class="n">tok_kwargs</span><span class="o">=</span><span class="p">{</span> <span class="s1">&#39;return_special_tokens_mask&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">})</span>

<span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">HF_TextBlock</span><span class="p">(</span><span class="n">before_batch_tfms</span><span class="o">=</span><span class="n">before_batch_tfm</span><span class="p">,</span> <span class="n">input_return_type</span><span class="o">=</span><span class="n">HF_TokenClassInput</span><span class="p">),</span> 
    <span class="n">HF_TokenCategoryBlock</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">get_y</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">entity</span><span class="p">))))</span> <span class="k">for</span> <span class="n">entity</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">tokens</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="p">]</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> 
                   <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;tokens&#39;</span><span class="p">),</span>
                   <span class="n">get_y</span><span class="o">=</span><span class="n">get_y</span><span class="p">,</span>
                   <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have to define a <code>get_y</code> that creates the same number of labels as there are subtokens for a particular token. For example, my name "Wayde" gets split up into two subtokens, "Way" and "##de". The label for "Wayde" is "B-PER" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">germ_eval_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>token / target label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[('Helbig', 'B-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S.', 'O'), ('593.', 'O'), ('Wink', 'O'), ('&amp;', 'B-OTH'), ('Seibold', 'I-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'I-OTH'), ('1998', 'O'), (')', 'O'), ('S.', 'O'), ('32', 'O'), ('Inwieweit', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falken,', 'O'), ('wie', 'O'), ('der', 'O'), ('Afrikanische', 'O'), ('Baumfalke', 'O'), ('(', 'O'), ('Falco', 'B-LOCderiv'), ('cuvieri', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Malaienbaumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('serverus', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zuzuzählen', 'O'), ('sind,', 'O'), ('ist', 'O'), ('Gegenstand', 'O'), ('der', 'O'), ('Forschung.', 'O')]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[('Außerdem', 'O'), ('befindet', 'O'), ('sich', 'O'), ('im', 'O'), ('Nordwesten', 'O'), ('der', 'O'), ('Stadt', 'O'), ('(', 'O'), ('auf', 'O'), ('dem', 'O'), ('Gelände', 'O'), ('des', 'O'), ('ehemaligen', 'O'), ('Militärflughafens', 'O'), ('Butzweilerhof', 'B-LOC'), (')', 'O'), ('das', 'O'), ('Coloneum,', 'B-LOC'), ('Europas', 'O'), ('größter', 'B-LOC'), ('Studiokomplex', 'O'), ('mit', 'O'), ('einer', 'O'), ('Fläche', 'O'), ('von', 'O'), ('35', 'O'), ('ha', 'O'), ('und', 'O'), ('20', 'O'), ('Studios', 'O'), ('(', 'O'), ('25.', 'O'), ('000', 'O'), ('m²', 'O'), (')', 'O'), ('mit', 'O'), ('bis', 'O'), ('zu', 'O'), ('30', 'O'), ('Meter', 'O'), ('Deckenhöhe.', 'O')]</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Metrics">Metrics<a class="anchor-link" href="#Metrics"> </a></h3><p>In this section, we'll add helpful metrics for token classification tasks</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="calculate_token_class_metrics" class="doc_header"><code>calculate_token_class_metrics</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/token_classification.py#L20" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>calculate_token_class_metrics</code>(<strong><code>pred_toks</code></strong>, <strong><code>targ_toks</code></strong>, <strong><code>metric_key</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training">Training<a class="anchor-link" href="#Training"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="HF_TokenClassCallback" class="doc_header"><code>class</code> <code>HF_TokenClassCallback</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/token_classification.py#L30" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>HF_TokenClassCallback</code>(<strong><code>tok_metrics</code></strong>=<em><code>['accuracy', 'precision', 'recall', 'f1']</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/blurr/modeling-core.html#HF_BaseModelCallback"><code>HF_BaseModelCallback</code></a></p>
</blockquote>
<p>A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the
<code>seqeval</code> library.  Additionally, this metric knows how to <em>not</em> include your 'ignore_token' in it's
calculations.</p>
<p>See <a href="https://github.com/chakki-works/seqeval">here</a> for more information on <code>seqeval</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">HF_BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                <span class="n">model</span><span class="p">,</span>
                <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
                <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">HF_TokenClassCallback</span><span class="p">],</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">hf_splitter</span><span class="p">)</span>


<span class="n">learn</span><span class="o">.</span><span class="n">create_opt</span><span class="p">()</span>             <span class="c1"># -&gt; will create your layer groups based on your &quot;splitter&quot; function</span>
<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(1, torch.Size([2, 76, 18]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 3, torch.Size([2, 76]), 2, torch.Size([2, 76]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([152, 18]) torch.Size([152])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggestions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.0005248074419796466, lr_steep=1.737800812406931e-05)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span> <span class="mf">3e-5</span><span class="p">,</span> <span class="n">moms</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.8</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>precision</th>
      <th>recall</th>
      <th>f1</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.236967</td>
      <td>0.162253</td>
      <td>0.954620</td>
      <td>0.670732</td>
      <td>0.622642</td>
      <td>0.645793</td>
      <td>00:37</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.103329</td>
      <td>0.096656</td>
      <td>0.969293</td>
      <td>0.731707</td>
      <td>0.728745</td>
      <td>0.730223</td>
      <td>00:36</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.057280</td>
      <td>0.096278</td>
      <td>0.970380</td>
      <td>0.752033</td>
      <td>0.719844</td>
      <td>0.735586</td>
      <td>00:36</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">token_classification_report</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

         LOC       0.87      0.82      0.84        71
    LOCderiv       1.00      0.67      0.80        18
     LOCpart       0.00      0.00      0.00         0
         ORG       0.67      0.65      0.66        52
     ORGpart       0.67      0.25      0.36         8
         OTH       0.56      0.44      0.49        41
     OTHpart       0.00      0.00      0.00         0
         PER       0.88      0.91      0.90        67
    PERderiv       0.00      0.00      0.00         0
     PERpart       0.00      0.00      0.00         0

   micro avg       0.75      0.72      0.74       257
   macro avg       0.46      0.37      0.41       257
weighted avg       0.79      0.72      0.75       257

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Showing-results">Showing results<a class="anchor-link" href="#Showing-results"> </a></h3><p>Below we'll add in additional functionality to more intuitively show the results of our model.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>token / target label / predicted label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[('Erstmals', 'O', 'O'), ('Urkundlich', 'O', 'O'), ('erwähnt', 'O', 'O'), ('ist', 'O', 'O'), ('Nimburg', 'B-LOC', 'O'), ('bereits', 'O', 'O'), ('im', 'O', 'O'), ('Jahre', 'O', 'B-LOC'), ('977.', 'O', 'I-LOC'), ('Im', 'O', 'O')]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[('Anfangs', 'O', 'O'), ('unterstützte', 'O', 'O'), ('Bucharin', 'B-PER', 'O'), ('Stalin', 'B-PER', 'O'), ('mit', 'O', 'B-PER'), ('diesem', 'O', 'I-PER'), ('Kurs,', 'O', 'I-PER'), ('doch', 'O', 'O'), ('später', 'O', 'O'), ('als', 'O', 'O')]</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_predict</span><span class="p">(</span><span class="s1">&#39;My name is Wayde and I live in San Diego&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-PER&#39;, &#39;B-PER&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-LOC&#39;, &#39;B-LOC&#39;, &#39;O&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The default <code>Learner.predict</code> method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Learner.blurr_predict_tokens" class="doc_header"><code>Learner.blurr_predict_tokens</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/token_classification.py#L136" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Learner.blurr_predict_tokens</code>(<strong><code>inp</code></strong>, <strong>**<code>kargs</code></strong>)</p>
</blockquote>
<p>Remove all the unnecessary predicted tokens after calling <code>Learner.predict</code>, so that you only
get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">txt</span> <span class="o">=</span><span class="s2">&quot;Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_predict_tokens</span><span class="p">(</span><span class="n">txt</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="nb">print</span><span class="p">([(</span><span class="n">tok</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span> <span class="k">for</span> <span class="n">tok</span><span class="p">,</span><span class="n">lbl</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(&#39;Hi!&#39;, &#39;O&#39;), (&#39;My&#39;, &#39;O&#39;), (&#39;name&#39;, &#39;O&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;Wayde&#39;, &#39;B-PER&#39;), (&#39;Gilliam&#39;, &#39;I-PER&#39;), (&#39;from&#39;, &#39;O&#39;), (&#39;ohmeow.com.&#39;, &#39;B-ORG&#39;), (&#39;I&#39;, &#39;O&#39;), (&#39;live&#39;, &#39;O&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;California.&#39;, &#39;B-LOC&#39;)]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h2><p>The tests below to ensure the token classification training code above works for <strong>all</strong> pretrained token classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.</p>
<p><strong>Note</strong>: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue <em>(or a PR if you'd like to fix it yourself)</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span> <span class="k">del</span> <span class="n">learn</span><span class="p">;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span> <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_models</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;TokenClassification&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[transformers.models.albert.modeling_albert.AlbertForTokenClassification,
 transformers.models.auto.modeling_auto.AutoModelForTokenClassification,
 transformers.models.bert.modeling_bert.BertForTokenClassification,
 transformers.models.camembert.modeling_camembert.CamembertForTokenClassification,
 transformers.models.distilbert.modeling_distilbert.DistilBertForTokenClassification,
 transformers.models.electra.modeling_electra.ElectraForTokenClassification,
 transformers.models.flaubert.modeling_flaubert.FlaubertForTokenClassification,
 transformers.models.funnel.modeling_funnel.FunnelForTokenClassification,
 transformers.models.layoutlm.modeling_layoutlm.LayoutLMForTokenClassification,
 transformers.models.longformer.modeling_longformer.LongformerForTokenClassification,
 transformers.models.mobilebert.modeling_mobilebert.MobileBertForTokenClassification,
 transformers.models.roberta.modeling_roberta.RobertaForTokenClassification,
 transformers.models.squeezebert.modeling_squeezebert.SqueezeBertForTokenClassification,
 transformers.models.xlm.modeling_xlm.XLMForTokenClassification,
 transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForTokenClassification,
 transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassification]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;albert-base-v1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bert-base-multilingual-cased&#39;</span><span class="p">,</span>
    <span class="s1">&#39;camembert-base&#39;</span><span class="p">,</span>
    <span class="s1">&#39;distilbert-base-uncased&#39;</span><span class="p">,</span>
    <span class="c1">#&#39;&lt;electra&gt;&#39;, # currently no pre-trained electra model works for token classification</span>
    <span class="s1">&#39;allenai/longformer-base-4096&#39;</span><span class="p">,</span>
    <span class="s1">&#39;google/mobilebert-uncased&#39;</span><span class="p">,</span>
    <span class="s1">&#39;roberta-base&#39;</span><span class="p">,</span>
    <span class="s1">&#39;xlm-mlm-ende-1024&#39;</span><span class="p">,</span>
    <span class="s1">&#39;xlm-roberta-base&#39;</span><span class="p">,</span>
    <span class="s1">&#39;xlnet-base-cased&#39;</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hide_output</span>
<span class="n">task</span> <span class="o">=</span> <span class="n">HF_TASKS_AUTO</span><span class="o">.</span><span class="n">TokenClassification</span>
<span class="n">bsz</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">seq_sz</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">pretrained_model_names</span><span class="p">:</span>
    <span class="n">error</span><span class="o">=</span><span class="kc">None</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=== </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1"> ===</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    
    <span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> 
                                                                                   <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span> 
                                                                                   <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;architecture:</span><span class="se">\t</span><span class="si">{</span><span class="n">hf_arch</span><span class="si">}</span><span class="se">\n</span><span class="s1">tokenizer:</span><span class="se">\t</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">before_batch_tfm</span> <span class="o">=</span> <span class="n">HF_TokenClassBeforeBatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> 
                                                         <span class="n">max_length</span><span class="o">=</span><span class="n">seq_sz</span><span class="p">,</span>
                                                         <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span>
                                                         <span class="n">is_split_into_words</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                         <span class="n">tok_kwargs</span><span class="o">=</span><span class="p">{</span> <span class="s1">&#39;return_special_tokens_mask&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">})</span>

    <span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">HF_TextBlock</span><span class="p">(</span><span class="n">before_batch_tfms</span><span class="o">=</span><span class="n">before_batch_tfm</span><span class="p">,</span> <span class="n">input_return_type</span><span class="o">=</span><span class="n">HF_TokenClassInput</span><span class="p">),</span> 
        <span class="n">HF_TokenCategoryBlock</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> 
                       <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;tokens&#39;</span><span class="p">),</span>
                       <span class="n">get_y</span><span class="o">=</span> <span class="k">lambda</span> <span class="n">inp</span><span class="p">:</span> <span class="p">[</span> 
                           <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">entity</span><span class="p">))))</span> 
                           <span class="k">for</span> <span class="n">entity</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">tokens</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> 
                       <span class="p">],</span>
                       <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
    
    <span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">germ_eval_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">bsz</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">HF_BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
    <span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                <span class="n">model</span><span class="p">,</span>
                <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
                <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">HF_TokenClassCallback</span><span class="p">],</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">hf_splitter</span><span class="p">)</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>

    <span class="n">learn</span><span class="o">.</span><span class="n">create_opt</span><span class="p">()</span>             <span class="c1"># -&gt; will create your layer groups based on your &quot;splitter&quot; function</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
    
    <span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*** TESTING DataLoaders ***&#39;</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]),</span> <span class="n">bsz</span><span class="p">)</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">bsz</span><span class="p">,</span> <span class="n">seq_sz</span><span class="p">]))</span>
        <span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">bsz</span><span class="p">)</span>

<span class="c1">#         print(&#39;*** TESTING One pass through the model ***&#39;)</span>
<span class="c1">#         preds = learn.model(b[0])</span>
<span class="c1">#         test_eq(len(preds[0]), bsz)</span>
<span class="c1">#         test_eq(preds[0].shape, torch.Size([bsz, seq_sz, len(labels)]))</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*** TESTING Training/Results ***&#39;</span><span class="p">)</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span> <span class="mf">3e-5</span><span class="p">,</span> <span class="n">moms</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.8</span><span class="p">))</span>

        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;PASSED&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
        <span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;FAILED&#39;</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c1"># cleanup</span>
        <span class="k">del</span> <span class="n">learn</span><span class="p">;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>arch</th>
      <th>tokenizer</th>
      <th>model_name</th>
      <th>result</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>albert</td>
      <td>AlbertTokenizerFast</td>
      <td>AlbertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>bert</td>
      <td>BertTokenizerFast</td>
      <td>BertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>camembert</td>
      <td>CamembertTokenizerFast</td>
      <td>CamembertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>distilbert</td>
      <td>DistilBertTokenizerFast</td>
      <td>DistilBertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>longformer</td>
      <td>LongformerTokenizerFast</td>
      <td>LongformerForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>5</th>
      <td>mobilebert</td>
      <td>MobileBertTokenizerFast</td>
      <td>MobileBertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>6</th>
      <td>roberta</td>
      <td>RobertaTokenizerFast</td>
      <td>RobertaForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>7</th>
      <td>xlm</td>
      <td>XLMTokenizer</td>
      <td>XLMForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>8</th>
      <td>xlm_roberta</td>
      <td>XLMRobertaTokenizerFast</td>
      <td>XLMRobertaForTokenClassification</td>
      <td>FAILED</td>
      <td>CUDA out of memory. Tried to allocate 734.00 MiB (GPU 1; 10.91 GiB total capacity; 9.05 GiB already allocated; 657.88 MiB free; 9.59 GiB reserved in total by PyTorch)</td>
    </tr>
    <tr>
      <th>9</th>
      <td>xlnet</td>
      <td>XLNetTokenizerFast</td>
      <td>XLNetForTokenClassification</td>
      <td>FAILED</td>
      <td>CUDA out of memory. Tried to allocate 94.00 MiB (GPU 1; 10.91 GiB total capacity; 10.13 GiB already allocated; 3.88 MiB free; 10.22 GiB reserved in total by PyTorch)</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cleanup">Cleanup<a class="anchor-link" href="#Cleanup"> </a></h2>
</div>
</div>
</div>
</div>
 

