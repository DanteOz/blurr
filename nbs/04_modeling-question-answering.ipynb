{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.question_answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.question_answering\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for question answering tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, ast, inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, CategoryBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from seqeval import metrics as seq_metrics\n",
    "from transformers import AutoModelForQuestionAnswering, PreTrainedModel, logging\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.core import TextBlock, BlurrDataLoader, first_blurr_tfm\n",
    "from blurr.modeling.core import BaseModelCallback, PreCalculatedLoss, Blearner\n",
    "from blurr.data.question_answering import QAPreprocessor, QATextInput, QABatchTokenizeTransform\n",
    "\n",
    "# metrics we'll use in extractive qa\n",
    "from datasets import load_metric\n",
    "squad_metric = load_metric(\"squad\")\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "from transformers import AutoConfig\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.modeling.core import BaseModelWrapper, PreCalculatedLoss, blurr_splitter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a subset of `squad_v2` to demonstrate how to configure your blurr code for training extractive question answering models. See the `data.question_answering` module if any of this setting up of the `squad_df` below looks unfamiliar to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/wgilliam/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac03e7bb2244707927e8f24e0d7413d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n",
    "\n",
    "raw_train_df = pd.DataFrame(raw_datasets[0])\n",
    "raw_valid_df = pd.DataFrame(raw_datasets[1])\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "squad_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "\n",
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "print(len(squad_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForQuestionAnswering\n",
    "\n",
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "max_seq_len = 128\n",
    "vocab = dict(enumerate(range(max_seq_len)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}</td>\n",
       "      <td>False</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>541</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...   \n",
       "\n",
       "                                                                  question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                           answers  is_valid  \\\n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}     False   \n",
       "\n",
       "   ans_start_char_idx                 answer_text  ans_end_char_idx  \\\n",
       "0                 515  Saint Bernadette Soubirous               541   \n",
       "\n",
       "                                                             proc_question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           proc_context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                    0                  0          False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = QAPreprocessor(\n",
    "    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    ")\n",
    "\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "proc_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab),\n",
    ")\n",
    "\n",
    "# since its preprocessed, we include an \"text\" key with the values of our question and context\n",
    "def get_x(item):\n",
    "    return {\"text\": (item.proc_question, item.proc_context), \"id\": item.id}\n",
    "\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=get_x,\n",
    "    get_y=[ItemGetter(\"ans_start_token_idx\"), ItemGetter(\"ans_end_token_idx\")],\n",
    "    splitter=ColSplitter(),\n",
    "    n_inp=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab), dls.vocab[0], dls.vocab[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 – 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ), so that the logo could prominently feature the arabic numerals 50.</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.valid.show_batch(dataloaders=dls, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QAModelCallback`\n",
    "\n",
    "Here we create a question/answer specific subclass of `BaseModelCallback` in order to get all the start and end prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAModelCallback(BaseModelCallback):\n",
    "    \"\"\"The prediction is a combination start/end logits\"\"\"\n",
    "\n",
    "    def after_pred(self):\n",
    "        super().after_pred()\n",
    "        self.learn.pred = (self.pred.start_logits, self.pred.end_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QAMetricsCallback`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAMetricsCallback(Callback):\n",
    "    def __init__(self, compute_metrics_func, validation_ds, qa_metrics=[\"exact_match\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "\n",
    "        store_attr()\n",
    "        self.custom_metrics_dict = {k: None for k in qa_metrics}\n",
    "        self.do_setup = True\n",
    "\n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if not self.do_setup:\n",
    "            return\n",
    "\n",
    "        # grab the hf_tokenizer from the TokenClassBatchTokenizeTransform\n",
    "        tfm = first_blurr_tfm(self.learn.dls, tfms=[QABatchTokenizeTransform])\n",
    "        self.hf_tokenizer = tfm.hf_tokenizer\n",
    "        self.tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "        # add custom question answering specific metrics\n",
    "        custom_metrics = L([ValueMetric(partial(self.metric_value, metric_key=k), k) for k in self.qa_metrics])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "\n",
    "        self.do_setup = False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.setup()\n",
    "\n",
    "    # --- batch before/after phases ---\n",
    "    def before_batch(self):\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        self.batch_inputs = {k: v.cpu().detach().numpy() if isinstance(v, Tensor) else v for k, v in self.x.items()}\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        for i in range(len(self.batch_inputs[\"input_ids\"])):\n",
    "            batch_inps = {k: self.batch_inputs[k][i] for k in self.batch_inputs.keys()}\n",
    "            self.results.append(\n",
    "                {**batch_inps, \"start_logits\": self.pred[0][i].cpu().detach().numpy(), \"end_logits\": self.pred[1][i].cpu().detach().numpy()}\n",
    "            )\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self):\n",
    "        self.results = []\n",
    "\n",
    "    def after_validate(self):\n",
    "        if len(self.results) < 1:\n",
    "            return\n",
    "\n",
    "        metric_vals_d = self.compute_metrics_func(self.results, self.validation_ds, self.hf_tokenizer, self.tok_kwargs)\n",
    "        for k, v in metric_vals_d.items():\n",
    "            self.custom_metrics_dict[k] = v\n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key):\n",
    "        return self.custom_metrics_dict[metric_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_qa_metrics(results, dataset, hf_tokenizer, tok_kwargs, id_attr=\"id\", n_best=20):\n",
    "    # what is the max length for our inputs?\n",
    "    max_length = tok_kwargs.get(\"max_length\", hf_tokenizer.model_max_length)\n",
    "\n",
    "    # map examples to chunks indicies that are part of the\n",
    "    example_to_chunks = collections.defaultdict(list)\n",
    "    for idx, chunk in enumerate(results):\n",
    "        example_to_chunks[chunk[id_attr]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for item_idx, item in enumerate(dataset):\n",
    "        example_id = item[id_attr]\n",
    "\n",
    "        answers = []\n",
    "        for chunk_idx in example_to_chunks[example_id]:\n",
    "            chunk = results[chunk_idx]\n",
    "            input_ids = chunk[\"input_ids\"]\n",
    "            start_logits = chunk[\"start_logits\"]\n",
    "            end_logits = chunk[\"end_logits\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best - 1 : -1].tolist()\n",
    "\n",
    "            for s_idx, start_index in enumerate(start_indexes):\n",
    "                for e_idx, end_index in enumerate(end_indexes):\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if start_index == 0 and end_index == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_length:\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": hf_tokenizer.decode(input_ids[start_index:end_index], skip_special_tokens=True),\n",
    "                        \"logit_score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    ref_answers = [{\"id\": item[\"id\"], \"answers\": item[\"answers\"]} for item_idx, item in enumerate(dataset)]\n",
    "\n",
    "    metric_vals_d = squad_metric.compute(predictions=predicted_answers, references=ref_answers)\n",
    "    return metric_vals_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PreCalculatedQALoss`\n",
    "\n",
    "Hugging Face question answering models will calculate the loss for you when you include both the `start_positions` and `end_positions` in the inputs dictionary.  This is done by the `QABatchTokenizeTransform` when `include_labels` = True (which is the default).  This also requires fastai developers to set their `Learner`'s loss function to the `PreCalculatedQALoss` for training to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PreCalculatedQALoss(PreCalculatedLoss):\n",
    "    def __init__(self, *args, axis=-1, **kwargs): \n",
    "        super().__init__(nn.CrossEntropyLoss, *args, axis=axis, **kwargs)\n",
    "\n",
    "    def __call__(self, inp, targ, targ2, **kwargs):\n",
    "        return tensor(0.0)\n",
    "\n",
    "    def decodes(self, x):\n",
    "        return x[0].argmax(dim=self.axis), x[1].argmax(dim=self.axis)\n",
    "\n",
    "    def activation(self, x):\n",
    "        return F.softmax(x[0], dim=self.axis), F.softmax(x[1], dim=self.axis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MultiTargetLoss`\n",
    "\n",
    "If you want more control over the loss calculation, we provide here a custom loss function you can use in your question answering tasks.\n",
    "\n",
    "In fact, this new loss function can be used in many other multi-modal architectures, with any mix of loss functions.  For example, this can be ammended to include the `is_impossible` task, as well as the start/end token tasks in the SQUAD v2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiTargetLoss(Module):\n",
    "    \"\"\"Provides the ability to apply different loss functions to multi-modal targets/predictions\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The loss function for each target\n",
    "        loss_classes: List[Callable] = [CrossEntropyLossFlat, CrossEntropyLossFlat],\n",
    "        # Any kwargs you want to pass to the loss functions above\n",
    "        loss_classes_kwargs: List[dict] = [{}, {}],\n",
    "        # The weights you want to apply to each loss (default: [1,1])\n",
    "        weights: Union[List[float], List[int]] = [1, 1],\n",
    "        # The `reduction` parameter of the lass function (default: 'mean')\n",
    "        reduction: str = \"mean\",\n",
    "    ):\n",
    "        loss_funcs = [cls(reduction=reduction, **kwargs) for cls, kwargs in zip(loss_classes, loss_classes_kwargs)]\n",
    "        store_attr(self=self, names=\"loss_funcs, weights\")\n",
    "        self._reduction = reduction\n",
    "\n",
    "    # custom loss function must have either a reduction attribute or a reduction argument (like all fastai and\n",
    "    # PyTorch loss functions) so that the framework can change this as needed (e.g., when doing lear.get_preds\n",
    "    # it will set = 'none'). see this forum topic for more info: https://bit.ly/3br2Syz\n",
    "    @property\n",
    "    def reduction(self):\n",
    "        return self._reduction\n",
    "\n",
    "    @reduction.setter\n",
    "    def reduction(self, v):\n",
    "        self._reduction = v\n",
    "        for lf in self.loss_funcs:\n",
    "            lf.reduction = v\n",
    "\n",
    "    def forward(self, outputs, *targets):\n",
    "        loss = 0.0\n",
    "        for i, loss_func, weights, output, target in zip(range(len(outputs)), self.loss_funcs, self.weights, outputs, targets):\n",
    "            loss += weights * loss_func(output, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def activation(self, outs):\n",
    "        acts = [self.loss_funcs[i].activation(o) for i, o in enumerate(outs)]\n",
    "        return acts\n",
    "\n",
    "    def decodes(self, outs):\n",
    "        decodes = [self.loss_funcs[i].decodes(o) for i, o in enumerate(outs)]\n",
    "        return decodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Notice below how I had to define the loss function *after* creating the `Learner` object.  I'm not sure why, but the `MultiTargetLoss` above prohibits the learner from being exported if I do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [QAModelCallback]\n",
    "\n",
    "validation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\n",
    "fit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n",
    "\n",
    "learn = Learner(dls, model, opt_func=partial(Adam), cbs=learn_cbs, splitter=blurr_splitter)\n",
    "\n",
    "learn.loss_func = PreCalculatedQALoss() #MultiTargetLoss()\n",
    "learn.create_opt()  # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.006918309628963471, steep=1.3182567499825382e-06, valley=0.0012022644514217973, slide=0.004365158267319202)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.502881</td>\n",
       "      <td>0.936964</td>\n",
       "      <td>77.049180</td>\n",
       "      <td>83.651646</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results` for a more intuitive QA task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `QuestionAnswerTextInput` typed inputs\n",
    "    x: QATextInput,\n",
    "    # The targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Whether you want to remove special tokens during decoding/showing the outputs\n",
    "    skip_special_tokens=True,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):\n",
    "    tfm = first_blurr_tfm(learner.dls, tfms=[QABatchTokenizeTransform])\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    res = L()\n",
    "    for sample, input_ids, start, end, pred in zip(samples, x, *y, outs):\n",
    "        txt = hf_tokenizer.decode(sample[0], skip_special_tokens=True)[:trunc_at]\n",
    "        found = start.item() != 0 and end.item() != 0\n",
    "        ans_text = hf_tokenizer.decode(input_ids[start:end], skip_special_tokens=False)\n",
    "\n",
    "        pred_ans_toks = hf_tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=False)[int(pred[0]) : int(pred[1])]\n",
    "        pred_ans_txt = hf_tokenizer.convert_tokens_to_string(pred_ans_toks)\n",
    "\n",
    "        res.append((txt, found, (start.item(), end.item()), ans_text, (int(pred[0]), int(pred[1])), pred_ans_txt))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"found\", \"start/end\", \"answer\", \"pred start/end\", \"pred answer\"]))\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 – 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what year was super bowl 50? bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ), so that the logo could prominently feature the arabic</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(20, 21)</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what was the last super bowl the broncos participated in? – 1 record, while the denver broncos became one of four teams to have made eight appearances in the super bowl. the broncos made their second super bowl appearance in three years, having reached super bowl xlviii, while the panthers made their second super bowl appearance in franchise history, their other appearance being super bowl xxxviii. coincidentally, both teams were coached by john fox in their last super bowl appearance prior to s</td>\n",
       "      <td>True</td>\n",
       "      <td>(50, 55)</td>\n",
       "      <td>super bowl xlviii</td>\n",
       "      <td>(50, 55)</td>\n",
       "      <td>super bowl xlviii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what year did a super bowl play in the bay area around san francisco, prior to super bowl 50? on may 21, 2013, nfl owners at their spring meetings in boston voted and awarded the game to levi's stadium. the $ 1. 2 billion stadium opened in 2014. it is the first super bowl held in the san francisco bay area since super bowl xix in 1985, and the first in california since super bowl xxxvii took place in san diego in 2003.</td>\n",
       "      <td>True</td>\n",
       "      <td>(78, 79)</td>\n",
       "      <td>1985</td>\n",
       "      <td>(78, 79)</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.403862</td>\n",
       "      <td>0.936184</td>\n",
       "      <td>77.704918</td>\n",
       "      <td>84.272411</td>\n",
       "      <td>03:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=slice(1e-9, 1e-7), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD4CAYAAAANbUbJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+6klEQVR4nO3dd3ib1dn48e+R5D3ineUkdvYmixBIgLBDgEAZBdrS0kXflpbR9Qu0L2WUQlval7ZAC+1L25cyG8oOm4QVRhISsve0M+zE8Yi3pPP74xl+JMu2bMuRFN2f68oVjUfSsS3dOs8597mP0lojhBDi+OaKdgOEEEL0PQn2QgiRACTYCyFEApBgL4QQCUCCvRBCJABPtF64oKBAl5SUROvlhRAiLq1cufKQ1rqwu4+LWrAvKSlhxYoV0Xp5IYSIS0qp3T15nAzjCCFEApBgL4QQCUCCvRBCJICojdmH0traSllZGU1NTdFuSp9LTU2luLiYpKSkaDdFCJEAYirYl5WVkZWVRUlJCUqpaDenz2itOXz4MGVlZZSWlka7OUKIBBBTwzhNTU3k5+cf14EeQClFfn5+QpzBCCFiQ0wFe+C4D/SWRPk5hRCxIeaCvRBCiMiTYO9QXV3NQw891O3HzZ8/n+rq6sg3SAghIkSCvUNHwd7r9Xb6uMWLF5OTk9NHrRJCiN6LqWycaFu4cCHbt29nypQpJCUlkZqaSm5uLps2bWLLli1ccskl7N27l6amJm688Uauu+46oK30w9GjRzn//POZM2cOy5YtY/DgwbzwwgukpaVF+ScTQiS6mA32d7y0ng37aiP6nOMHZfOLiyZ0eP+9997LunXrWL16NUuXLuWCCy5g3bp1dnrko48+Sl5eHo2NjZx44olcdtll5OfnBzzH1q1befLJJ/nrX//KF7/4RZ599lm+8pWvRPTnEEKI7orZYB8LZs6cGZAH/8c//pHnnnsOgL1797J169Z2wb60tJQpU6YAMH36dHbt2nWsmiuEEB2K2WDfWQ/8WMnIyLAvL126lLfeeouPPvqI9PR05s6dGzJPPiUlxb7sdrtpbGw8Jm0VQojOyAStQ1ZWFnV1dSHvq6mpITc3l/T0dDZt2sTHH398jFsnhBA9F7M9+2jIz89n9uzZTJw4kbS0NPr372/fN2/ePP7yl78wbtw4xowZw6xZs6LYUiGE6B6ltY7KC8+YMUMHb16yceNGxo0bF5X2REOi/bxCiN5TSq3UWs/o7uNkGEcIIRJAWMFeKTVPKbVZKbVNKbUwxP3DlFJvK6XWKKWWKqWKI99UIYQQPdVlsFdKuYEHgfOB8cDVSqnxQYfdB/yf1noycCdwT6QbKoQQoufC6dnPBLZprXdorVuAp4CLg44ZD7xjXl4S4n4hhBBRFE6wHwzsdVwvM29z+hy41Lz8BSBLKZUfdAxKqeuUUiuUUisqKyt70l4hhBA9EKkJ2h8DpyulVgGnA+WAL/ggrfUjWusZWusZhYWFEXppIYQQXQkn2JcDQxzXi83bbFrrfVrrS7XWU4GfmbdVR6qRsSozMxOAffv2cfnll4c8Zu7cuQSnmAohxLEWTrBfDoxSSpUqpZKBq4AXnQcopQqUUtZz3QI8GtlmxrZBgwaxaNGiaDdDCCE61GWw11p7ge8DrwMbgWe01uuVUncqpRaYh80FNiultgD9gbv7qL19auHChTz44IP29dtvv51f/vKXnHXWWUybNo1JkybxwgsvtHvcrl27mDhxIgCNjY1cddVVjBs3ji984QtSG0cIERPCKpegtV4MLA667TbH5UVAZLu2ry6EA2sj+pQMmATn39vh3VdeeSU33XQT119/PQDPPPMMr7/+OjfccAPZ2dkcOnSIWbNmsWDBgg73kP3zn/9Meno6GzduZM2aNUybNi2yP4MQQvSA1MZxmDp1KhUVFezbt4/Kykpyc3MZMGAAN998M++99x4ul4vy8nIOHjzIgAEDQj7He++9xw033ADA5MmTmTx58rH8EYQQIqTYDfad9MD70hVXXMGiRYs4cOAAV155JY8//jiVlZWsXLmSpKQkSkpKQpY2FkKIWCa1cYJceeWVPPXUUyxatIgrrriCmpoaioqKSEpKYsmSJezevbvTx5922mk88cQTAKxbt441a9Yci2YLIUSnYrdnHyUTJkygrq6OwYMHM3DgQL785S9z0UUXMWnSJGbMmMHYsWM7ffx3v/tdvv71rzNu3DjGjRvH9OnTj1HLhRCiY1LiOIoS7ecVQvSelDgWQgjRIQn2QgiRAGIu2EdrWOlYS5SfUwgRG2Iq2KempnL48OHjPhBqrTl8+DCpqanRbooQIkHEVDZOcXExZWVlJEL549TUVIqLZUMvIcSxEVPBPikpidLS0mg3QwghjjsxNYwjhBCib0iwF0KIBCDBXgghEoAEeyGESAAS7IUQIgFIsBdCiAQgwV4IIRKABHshhEgAEuyFECIBSLAXQogEIMFeCCESgAR7IYRIABLshRAiAUiwF0KIBBBWsFdKzVNKbVZKbVNKLQxx/1Cl1BKl1Cql1Bql1PzIN1UIIURPdRnslVJu4EHgfGA8cLVSanzQYT8HntFaTwWuAh6KdEOFEEL0XDg9+5nANq31Dq11C/AUcHHQMRrINi/3A/ZFrolCCCF6K5xgPxjY67heZt7mdDvwFaVUGbAY+EGoJ1JKXaeUWqGUWpEIWw8KIUSsiNQE7dXAP7TWxcB84DGlVLvn1lo/orWeobWeUVhYGKGXFkII0ZVwgn05MMRxvdi8zembwDMAWuuPgFSgIBINFEII0XvhBPvlwCilVKlSKhljAvbFoGP2AGcBKKXGYQR7GacRQogY0WWw11p7ge8DrwMbMbJu1iul7lRKLTAP+xHwbaXU58CTwLVaa91XjRZCCNE9nnAO0lovxph4dd52m+PyBmB2ZJsmhBAiUmQFrRBCJAAJ9kIIkQAk2AshRAKQYC+EEAlAgr0QQiQACfZCCJEAJNgLIUQCkGAvhBAJQIK9EEIkAAn2QgiRACTYCyFEApBgL4QQCUCCvRBCJAAJ9kIIkQAk2AshRAKQYC+EEAlAgr0QQiQACfZCCJEAJNgLIUQCkGAvhBAJQIK9EEIkAAn2QgiRACTYCyFEApBgL4QQCUCCvRBCJAAJ9kIIkQDCCvZKqXlKqc1KqW1KqYUh7v8fpdRq898WpVR1xFsqhBCixzxdHaCUcgMPAucAZcBypdSLWusN1jFa65sdx/8AmNoHbRVCCNFD4fTsZwLbtNY7tNYtwFPAxZ0cfzXwZCQaJ4QQIjLCCfaDgb2O62Xmbe0opYYBpcA7Hdx/nVJqhVJqRWVlZXfbKoQQoociPUF7FbBIa+0LdafW+hGt9Qyt9YzCwsIIv7QQQoiOhBPsy4EhjuvF5m2hXIUM4QghRMwJJ9gvB0YppUqVUskYAf3F4IOUUmOBXOCjyDZRCCFEb3UZ7LXWXuD7wOvARuAZrfV6pdSdSqkFjkOvAp7SWuu+aaoQ0bF47X5qGlqj3QwheqXL1EsArfViYHHQbbcFXb89cs0SIjYcqGnie49/xuyR+Tz+rVnRbo4QPSYraIXoRKvPD8DG/XVRbokQvSPBXohONHuNxLKjzd4ot0SI3pFgL0QnGluMnn2L1x/llgjROxLshehEkzfkkhEh4o4EeyE60djSFuwl0UzEMwn2QnSiqbUt2H+ys4rpd73J3qqGKLZIiJ6RYC9EJxodwf5nz63lcH0Lr6zdj9aaP7y1VQK/iBsS7IXoRHNr28Ts9sp6AHx+zd6qRv7nrS1857GV0WqaEN0iwV6ITlg9+2R320el7Egjdc3GitoDtU1RaZcQ3SXBXohOWGP2mrbJ2T1V9RypN4J9veTfizghwV6ITpQdaSQzxcOMYXkAnD66kA+3HebjHYcBaJb8exEnwqqNI0SiWrevhvGDsnnoy9NYt6+G5TureHdLJQ8s2WYfo7VGKRXFVgrRNenZC9GJgzVNDM1LJzcjmVNHFTKpOKfdMZVHm499w4ToJgn2QnTC69ckudt67SeW5NqX500YABhDPULEOhnGEaITPr/G7WoL9jnpyey69wIAtlXU8dr6A+w6VM+0obkdPYUQMUF69kJ0otXnx+MK/TEZkpeOS8GuQ/XHuFVCdJ8EeyE6Edyzd0rxuBmUk8bOw7KKVsQ+CfZCdMLr13jcHWfaDMlNp/yIBHsR+yTYC9EJn1/j6aBnD1CcmyYTtCIuSLDHyJNeV14T7WaIGKO1xuvXuDsYswcozk2noq6Z37y2KaBCphCxRoI98OLn+7jwTx/w6tr90W6KiCF+s0JCZz37IXlpADy0dDt//3DXMWiVED0jwR7YevAoAFvM/4UA8PqNUggdTdCC0bO3yNmhiGUS7AHrs+yTnYiEg8/s2nc1Zm95f2ul/Zh4daCmiZfX7It2M0QfSLhg39Tqo2ThKzy9fI99m8v8MPvj/IMqIstrvh8669kP7JdqX65t8nI4DksnNLX6qG0yqnh+4x/L+f4Tq6gzr4vjR8IF+9pG4038m9c227dZ+4w2tMgEm2jj8xnBPsnd8cdEKcVrN53Kd04bDkBFXfwF+1v/s5bJt79BRV2TvfPW/hqp03+8CSvYK6XmKaU2K6W2KaUWdnDMF5VSG5RS65VST0S2mZFjdd6dgb26wfgCOBSHvTLRd1rDGLMHGDsgm3kTjTo5FXXxFyTf2HAQgCWbKkhJMkLCvmpJJz3edBnslVJu4EHgfGA8cLVSanzQMaOAW4DZWusJwE2Rb2pktPqMD7Bzb9GqhhYA9sh+osIhnDF7S/9sYzhn4bNr+7RNfWFwjjHv8OnOI3ap5r2yduC4E07PfiawTWu9Q2vdAjwFXBx0zLeBB7XWRwC01hWRbWbktPjabzZRbr6xdx+WGifx5vFPdlOy8JU+yXH3+roes7cM7JfKsHwj5742zsa7a8yhzWc/K6PSHIZ6f0tlNJsk+kA4wX4wsNdxvcy8zWk0MFop9aFS6mOl1LxQT6SUuk4ptUIptaKyMjJvpqr6lm5tDdcSYmehMnO5+5GGVpmYijP/+tiYaF+/rzbiz2337Dspl2BRSnHvpZMB+HRHVcTb0peqG1va3bbxQNvvs6q+hf010tOPd5GaoPUAo4C5wNXAX5VSOcEHaa0f0VrP0FrPKCwsjMgLT7vrTc7+/bthH98a1LNvaPFS2+RldP9MAA4dbf/GF7Fr/MBsADbsi3yOe1s2Tngfk6lDc0jxuPjI3LIwHjS1+mhqDfxMZKV4qKhtRpupyLPvfYeT73knGs0TERTOu7gcGOK4Xmze5lQGvKi1btVa7wS2YAT/Y6I7mQPOYK+1tidqh+ZlADJJG28KMpOB7o0xb688yqo9R7o8rjtj9gCpSW5GFGayM45KHm+rMBYSThiUbd92/Zkjafb6qW00zpit+S0t61DiWjjBfjkwSilVqpRKBq4CXgw65nmMXj1KqQKMYZ0dkWtm5Dg3iK6oa7aHdQbnGBNsh+IwdS6RWb3vsm5Unjzn9+/yhYeWdbmuwlpBG26wBxiUkxZXmSzWxulfO6UEgJmlefaE7YHawE5UZYjPRkOLl5l3v8VbZkaPiF1dBnuttRf4PvA6sBF4Rmu9Xil1p1JqgXnY68BhpdQGYAnwE611TJ7LtvraPuA7D9XbwX6Q+QaX/UTji9c8UyvvRs/eivGbDtR1elx3xuwtg3NSKY+jYH+koQWPS3HaKGNY9dSRBQzNM0pA7DxUHzAfFqqcyJaDR6moa+a2F9YdmwaLHgtrW0Kt9WJgcdBttzkua+CH5r+o8Pr8eDpZ/GJpdfTsD9Y2kZdhDAMMzEkj2eOyF5WI+NBqBuTPy2rYeaie0oKMLh8zojCD7ZX1vL+1kvGO4Ytg3R2zB6PTUNfkpbaplezUpLAfFy0NLT7SktwM6JfKpz87i/yMFFq8fpSCTQdq7WEygE92HmbOqIKAx1sZbA1S8TPmHTcraOubw3uzOcfsKx3DOKkeF6X5GXE13iraevYAZ9y3NKzHWF/wq/ZUd3pcd8fsoe0McX91fCyuamr1kZbsBqAoKxW3S5GW7KY0P4ON+2u5+q8fA5CTnsTG/e3PhHabu3SF/xsS0XLcBPuG1vDSL5159hV1zfYYfrLHxbD8dPvNK+KDc1guXNYX/O4uzuKsjkE4efYWK9jvi5NUxYaWtmDvNHZgFhv319Hq0+SmJ3FiSR57qtp3hKrqjey1msbWgC9eEXuOm2DfGGZdG2eefUVtk3092eOiMCtFsnHiTKvPT7Kne29j6wt+9+H6Tidpe9KztyY3t1fER7nsRnMYJ9jYAdn2ivLvnzmKYXlGRyj492UFe7+WtOVYd9wE+3CLmFk9wQHZqVQ1tNq9txSPi/yMZKobW+O+TG0i8fo0Jfnp/HTeGAA+CSPH3fqbN7T4eLeTlaLWytLM1LCmtgDon53CpMH9eH51cHZybGpsDd2zHzewbS6jf3YKw/LTafb67UJvtU2tNLX6ONLQFuBl4VVsi+tg78z7DWe5fFV9C7c+Z9Qu6Z+dQnVDS1vP3u0mLyMZreEPb2/tmwaLiPP6/XhcLoaYm4hc+cjHXeaDt/j8XDB5IC4Fq/ZWd3icleFj9dbDoZRizqgCNu2vo9kb+5OWHfXsnRPXg3LSGJpvTHxbE7KTb3+DSx9axvtbD1GQmQIYtfBF7IrrYO/sgIfTs//PZ2X25cKsVI40tNhj+EkeRZI5HPBHCfZxo8WnSfK4GJLXtmNUVxuAt3j9ZCZ7GJCd2ml+/r7qRrJTPWR1M6tm/MBsvH7NU5/u7frgKGto8ZEeomc/OCeNv197In+4agpTh+QwzPz9Ouc5Nuw3SioMyzfuk7LIsS2ug7216AUCq1h2ZGC/th5acW4aR+pbHT17FyX5bWl7MtkUH7w+P0kuZeeGQ1sQ6kirT5PkURTnplNWFfqLYVvFUf750W57wrU7zpswgKKslLjY8amp1UdqiJ49wBlji7h4ymCUUgzOTcPtUqzac6RdLapb548jxeNqtwhLxJa4DvbOsfWOJmjH/PxVvvmP5UDb9oPJ5vj80WYvR803brLHxeyRBdx2oVG9+bMu0vJEbPD6NB63Ii8jmdduOhWArQc7XyzV4vWT7HZTnJfG3g569t95bAVAtyd/rcdcOHkQa8tr2tViijUNHQzjBEtyuxiUk8qTn+7loj99EHDf2AFZZKV6eOS9Hby/Vaplxqq4DvZeR7DvaBin2evn7U0VPPbRLt7aaFRefv57s8kxc62tCSfrQ335jGKUgtteWBdW/RQRXa1+v72T1NgB2QzOSbPrvYTyp7e3crTZi8etGJKbzoHappBj69bwXqgqqeGYMjSHplY/m7tYpXusbT1YxwPvbLXnNeqbvWFPQFtnTzuC1qKkJ7v5+uxSAP73g50A3PPqRu5+ZUPMf9klkrgO9j5HjnVXpYn/+4X1PGuO2WeleshLN4L9QXOcMcVt9G6yU5Mozc9g04E6vvDQsr5otoigVp8/YNvAkoL0DvPnq+pb+N2bWwBje8ri3DS0hn0hFkBlJBsBsCg7td194Zg6JAeANWWRr8bZGzc+tZr73thC2ZFGtNYcbfGSmRJesO9oRbBSiv86fQRzRhbYixIffncHf31/J49/vFsKqMWI+A72jjdRqDonHeVQJ7ld5KYbb9z95jijtR0bwIiizC5fu6axtU82zBDd4/XpgDz4oXkZHS6M+7ys2r5cVd9i/52De9/bK4/a76ffXXFCj9o1KCcNj0t1q0DbsWD14j8vq+beVzehNWEH+1DDPVOH5gDGwrPJxf0oP9IYcDZ0+0sbuPnp1b1ut+i9+A72jmC+IcTmFU0dpL4luRW55jDOhn01JHtcAZNU1hdBZ0644w3Ou/+97jZZRFi7nn1+OlX1Le12i/rnsl28una/fb2qvoUJg7JJ9rhYuTtws5FPHJuPFGal9Khdbpeif3ZqzGWoFOcaE86vrj3Aw+8ZhWkzwgz2owdkBVx/9NoZPPe92fb1YfnpeP2aLUFzJs+v3tfj4TAROXEd7NsKVSl7H1mnox3sYJXkcZFrDuMcOtrS7o142ui2jVU6OwWV0grR5/XrgKqUVhrgnqC/zS9eXM8zK9pSb0f1zyTF42by4H6s2B04N2N92X/15GG9atugnNSYK3dsvZ1fX3/Avi3cnv23Tx3OQ1+eZl9PTw58nJX+urbcGLqaPTLfvk/SmaMvroO9NWafl5Fsr3Z0auigOFqy20VRVgonFPcLef+FkwfxpZOGAh1/YTj98e2tXPd/K8JttujAyt1Huj00ZmTWtL2Nh5nps7s62U/4yW/P4hcXTQBgekku68prAl7Xmpy91qzx3lPFuekxt4l9Q4vxfnYmN6QmhRcG3C7F/EkDOW9CfwBGFAYOd1q/+1v+Yyxc/PoppZw5tgiA1Z0sXhPHRlwHeyvPPi89mRavnzteWs+X//axfX99Swc9e7cLl0vxj6/P7PC5TyzJBUJv2OBU3dDC79/cwhuyeUOv1DS0ctmfl/H9Jz7r1uPqm70BwxBWz9551uU8O1MKTirNs4ftpg/NpdWnAyZSm1vb6iX1xsiiTPbXNMXUvsahstasHanCdd8VJ7D6tnPaDXENyE4N+OLNTPXw4JemUZKfTkVdbA1nJaK4DvbWmL1VsvbvH+7iw21ttVE6KntsVTHM6WRsvijLyMJwBvsHl2yz868tuxxBRSZse85aFGelx4bD2lYyI6VtviU92UNhVoq9rB8CK51qDS7HhO60YcaX+ueOnmezLzLBfpQ5AfzelkO9ep5Icgb7i04YxLnj+3PexAHdeo6s1CRy0pPb3e52KXtOAODEkjzSkt0sOGEQ2yqOhl2sUPSNuA721qloXmb7Nx4QkD893fxQOyllfOizQoxZWr2WCkew/+3rm3l9/cGAoH7Jgx/al3dUSi38nupJHZkWnx+vX7cbOy7JT7e/hDcdqOWexZs6fI6CzBTyMpLZXtmWm2/N4VjpuD11+phCBmSn8uLnsVMUzRnsxw/M5pGvzqBfWuQ2WRlqnlnNmzDA7lRNGNwPv4Z1fbApvAhfXAd7q2efnxEY7K1gbH0ZPPbNmfz8gnEhn2PJj+fyzo/ntru90CzuFGoYp6Pt7G59bq0sxOoh5yR5V3vDWqw5mYyg2i7D8jPsnv28+9/nH8t22feFKlc8sjAzYCGWs+x1b6R43Ewu7sf2GOoENDiGNsPY2K3brIVXzoVas0rzcbsUd7+yMeD1xbEV18HeCubBPZNac7LWa07g5qQl25X5gpUWZIRMr+uXlkSSW9l70joD0P7qRlSIEuer91bLQqwecm4EfzDM8V1r8jw96MystCCDg7XNrCsP7El+b+4Inv7OrHbPM6IogxW7j/CeWe44UsHeeO5Mdh+uj5mVpFX1LZwyIp+CzBQumDwo4s9vBXvn56VfehIZyW5W763mO4+tjPhrivDEdbD3mRO0wcHe2kTBut/jVuR3MNTTEZdLUZCZYvfsnXnb+2uaCM7IzHb0ZMLtmWqt467gms+vue/1zQHDHpHgDPbBaZMdsYYkMpLbB3uAC4NquJwwJIfpw/LaPY+VVfLVRz+lpqGVFp8Pt0t1a4eqjowozKTVp2Nib+PaplbqmrycPrqQFT8/u1ulm8NlPWd1UHactY/E+1sPtfvi+3RnFW9KgkOfi+tgb/Xcg5dxP7DEyOm13mAel2o3rhuOoqwUe8y+3jHWGSp3+oLJA7ljgZHOd7g+vB17fvDkKsbd9lq32xVJrT4/5/3Pe7y27kDXBwMfbjvEA0u2cdbv3u1xwK+obWJXUH0V55j93g5KFNc0tvLTRZ/bC+isbKv0lMBhnDPGFHHF9OJ2jz/Swd/FuWJ6+6Gj7dI5e2NEofHFEwvzOdb7dnBu5IO8Jd88gz4StO7FuQBy1M9e5fYX17PeHMP/4sMf8W1JXe5zcR3srTdQdlpgIG8yU+fsbeXMD+7Aft2rc1KYlUKFWU6hwZFvb+0vOmFQNkPyjA9ObaPXfv5wd+x5ec1+Wn2a51dFbwLvSH0Lmw/W8V//Cu/02rlJt3OlaXec9ft3mRu0ObhzzL6jXvBnu4/wzIoyvvOvFVTWNfPcZ8bvLbhnn5bs5reOMgfXnlJCQWYyp48pJJSRjnzxrQfrjGAfgSEcMNIvk9yKD7Yd6rMaMVrrsMoybDlofDn3RY/eYmUgXR70ZfvzCwPnzP6xbBe3/mctv3x5g31buGfEomfiOthbY/bBPXtrgZV1umhNyr3zo7msuf3csJ+/f3YqB61g7+jZl5uFsy6dVsxdF08EjJ6Mvdl0iMJaoVgfjJc+j17d85ZOhpG8Pj8vrC4P+BBWN7aQkewmM8XDmxvCOxsIVtdkfHHWNLSd6juHcToqO2ylZ+6tauTEu9/isY93A5CXETqbZIBZxOzEkjxW/PycgP0MnJzB7+U1+/nnR7tDLtLriazUJOaOKeLlNfspvWUxf/9wZ0Se1/LX93Zw58sbmPPrJby2bn+Hx3247RA3PLkKgFH9szo8rrdyM5LZec98vnxS4Orjr55cwq57LwjocH1eVsPfPmj7fawpl2ydvhTXwd4qhJaW7CbJsWTemqBt69kr+7iOKveFMrBfKkcaWnluVZk9ZJCV4rG3q0tyK3vit6q+pds9e2tMeOP+2mO+6GT34Xqq6lsCJ0aDNp/498oybnxqNb9+bRNffPgjKuuaqWloJTcjmcumDWbJ5sput9uZtnr/21vsoGr17PMykjvcUKSjPO38jNCT7xMHGyukNZ33GF0uxY/OGU1Wqof3t0Y+J37cwGx7I/s7XtrQxdHdc/fijfz9w10APP7JnoD7mlp9/HPZLrw+P1/+2yf27eGWR+gpFSp7wfTGzaeFTHUGAnr5IvLiO9jbY/KugDF5K4A4a+f0RJ4ZRG5++nPuf8uYBygpyLA/uB6Xy16x+cUZQ8jLSCbZ4wq7+JXVw91X08TMu9/uURt76vTfLuWUe9+2V4tC4A5Pn+1py055+L0d9iRaTWMr/dKSOHu8sWS+s9rxodxqLqUHYxGcteLZ+tIZWZjJxgNt7Vi2/ZD9Gh3tRtZRnvjdX5jIBZMHcuqo0MM3Tj84axTfnTsivB+im6xx+0gLHhay3k+WD7cd4hcvrufD7W0LDe+6eEKftCVcWalJrP7Fufzhqint7tt1uF7KIfehuA72zmDu7K3Ywd7aX9bVsx/TuenypzuN8emSgrYPrsetyEpNYuc98/nGnFKUUgzsF37xq+C6O75jPGbZ1OoPmBgtM8fKNx+o49KHlvFq0KRteXUDb2+qwOfXjCoyhgK6G+yDi46tK6/l/re28Lf3jQqMI/tnUtfk5YXVxnj8l/76CWf//l2zvaGDvauDL/P+2ak8+KVpYS8aCq71EinDCwKfN1JpmM1BBfwOHW2mqdVnP7/1OXDu3HXWuP4Ree3ecLsUp4woaHf7oaMtVIWZ3CC6L6woqJSap5TarJTappRaGOL+a5VSlUqp1ea/b0W+qe05h2mcmyY3e/00tfravgzcPevZTxmSwzPfOTngtrGOMq/WXIDztHVgv/DK2mqtOdrs5aTStlTASFVIfGF1OQ8t3RbWsU2tzrFy4/U7Kt386Ae7AGNRWf/sFLJSPHaw11rzp7e3dpliGKpExf1vbbUXqn3ntOEArCuvCejlXf7nZfZciJXLfeqoAvpn96wEcSjOYL/4hlMj9rylQT37AxEqe1wbNK9QdqSRsf/9Gtf+/VOgrafvrPvT05LNkdZRO4J3wRKR02WwV0q5gQeB84HxwNVKqfEhDn1aaz3F/Pe3CLczJKsQmtul2tXkrm1qtYN9T3v2AGOCang7e/ueEOl5g/qlsT+MoN3Y6sPn18wa3lYG9tTfLIlI3e8bn1rNb17bHNaxznH6jlYGW6xhlN9ePhmlFCOKMtlqZngcOmrsAnXqb5Z0unbAqqly9rgi7rvihHarXwuzUhhZlMmeqgYWrWwrSbxi9xFeXbcfj0vxxs2nse6O83jsmyfxya1nh/VzhsO5aXlwhldvBI+RdzQB3V21ZjCfP2kAPzpntL2+4MNth9Fa2wXYrIqTd148IaD2f6y4dOpgHrlmOgA7zHTeZq+PL/7lI5Zti15doc0H6uJuHUxnwvnLzwS2aa13aK1bgKeAi/u2WeGxe/YuZRfDssbnaxtb7ft7szgmeAhg8uC2sshJIZ53YE4qB+uaQw7JvLelkn+v2AvAUfODWpiVwra7z7eP2VMVumfj82t+/O/P260K7UxH1RadbbMC/JQhOazcVYXPr+3Ccpbg3vMVM4YARjbRNvPD6VwGf+GfPuD2F9eHfO0sc/HZA1+axuXTi9ttiJHqcTMsL50lmyr5yaI1AfcdrG0iLclNapK7TyYZnemW2RGsFwPwr2+exLnmPEekcu6thX5XzBjCD84axRRzK0QwhteeWm6816wyy8EpqtH28DXTuffSSfz+yimcNa4/yR6X/bvZV93Ep7uquPbvy6PStqr6Fs67/z1+/O/Po/L6fSGcYD8Y2Ou4XmbeFuwypdQapdQipdSQUE+klLpOKbVCKbWisrL3u9A7x+ytN7K1KUlNY2u71Mve2nnPfHvRCITu2Q/sl4bPr+0slZqGVrt38tVHP+Uni9YYKxnN8fqsVA8et4vfXDYZgKWbQ/9eDh9tZtHKMi77c/jlGDraXMU59m3tKnRSaR71LT72VDXQ6vVz7SklXHtKCaePLuSTW88OOe49qn8mlXXNVDe0BKSmbjpQxz+W7bK/VBpavNz3+ma2HKyjodnLpMH97BLDY4OCvculuHRacciUUL+G1OTeFSfryr//62Sunjm0w4yRnpozqoCHr5lOerI7YquPy8xhN+s976w4+fzqcvt+S0ZK3/7uuuu8CQO4aqaxb4TbpSjJT2dNWQ0lC1/hDHMdRmepwX3laLOXhc8aHY3nV0cvLTrSInVO9xJQorWeDLwJ/DPUQVrrR7TWM7TWMwoLu86Q6Epbz95l9/Ssomj3vrqJlz7fh0t1PIHXXdbYvHWmEOpLZFCOkX5pjS//6N+f86W/fRKQojjjl29Rba4wtHq68ycPBOARc6s4y/Orypl65xv2ZJs1KXf9459x/1tb2r3+/320y7584Z8+4O2N7ZehOyf2rP1XJ5kbuawrr6Gu2Ut+RjK3L5jAP79h1Py3dm1afds59mNHmusEtlUcDVngytpAZPHaAzywZBvn/s97LNlcGTC/cu6EAfbwg+WUEfkB15/49kn2/gKRyn/vyIkledxz6aRO0wd7SinF8MKMiBVGe2P9AYqyUphoDi1+b+5IFp4/lhSPi+W72hfka/HFdqbL8IJMPtpxuN3tvSmN/NH2w9z41KpuLdh6aMm2gP0pdkS4NEi0hBPsywFnT73YvM2mtT6stbbKQ/4NmB6Z5nXO2bO3lsznmgtslu86wvbK+pC97+5atvBM3rj5NPt6iZlu6Qkx8Wst3LFy7a1hmd+93haYW7x+Xl5jLIDJTEky//dw89mjqahrDlgNeftL6znS0MpmR0ZFs9fHK2v32+mgTre9EDh8cvtL7YdTnD37cnN+YeIgI9g/8I4xseucmwC4+ezRbLxzXkAdc2dGTqi9A6yyBsF/Aufv7YwxRbz1w9MD7s91DCN9/4yRzCrNZ+H5YwHifi/TEYWZbO9mBlNHKuuaKcnPsN/jaclu/uv0EYzqn8lKM+vJuTVgpM9WIm1kUehsqA37e77Y6qPth3hh9T4O1IY/KR5c1+fBJdt7/PqxJJxIuBwYpZQqVUolA1cBLzoPUEoNdFxdAGyMXBM75nMM02TYPfvA8WV3BHpog3LSGO1YdTh2oBEIK2rblz+26o5YtV+srIOnzbH6b8wuBbAXwjjHnk8bbaSjbdrfFtitCbX1jg3VNzsmUrvKS071BJ66+/06ZApjbkYyg3PS2HywDqWMIOzkcinSgoZQBuekkZrkYsvBtp797644ga+dPAy3S9ltDs7/3hw0EWydKVnb3TldeeIQXC7FhEH9mDY0h799dUanP2+sGzsgm/LqRt7f2vthzJrG1pBzC6P7Z9lnvXcsmMi6O87j8W+dxNwOykXEiuD5G4tz85cXVpfbNXXCYZ3NdGfozHkmMWt4Hu9vrYz7TgaEEey11l7g+8DrGEH8Ga31eqXUnUqpBeZhNyil1iulPgduAK7tqwY7OVMrrTH7gszkgIm2jhbi9MbNZxuZD6eOap8rnJ2axIjCDFbuPkJ1Q0vAzlkAk4P2vc1yVMu09vB07luaYv4sKx356c43rrPH4gz8dyyYgNulAnopmw7UMvzWxfYZwUxH2meKx2VnHmWleMIa+nK5FCMKjUlaq2d/Ykked1w8MaBGvBXs77pkIqOKMrn+jJHtnmvHr+bzl6+0nRBa489WLz81yc1/vjfbXswVr752yjCGF2Rw3+vhZUs5eX1++2/8wDtGumpmiHF4a99XMFYkZ6Z4mD2yoE+GpiLposkDeeH62ey69wJ7snlIXhp/eHsrWw7Wsa68hhufWs0Ff/wg7DRlK0h3Zz2ItWjyyhlDmD9pIBV1zZz9+3d5ZU3H5SjiQVhjHFrrxVrr0VrrEVrru83bbtNav2hevkVrPUFrfYLW+gytdcdbA0WQnW2j2nr2HrcrIIWuL4wsymTJj+dSlB26sNrM0jze23qIb/6zfSW/4FLLzpTR3PQkMlM8ds+3orbJLrFsLeoC2Hyg7Y178j3vsHSzsdDpG/9Ybj/PV08exsJ5Y6msa+bw0Wbm/Pod5t3/PgAvmrV4znUEztQkN6P6G6fR3akQOrp/Fu9tqbSHrazhtGH56fYGIrVNrSR7XFwzaxhv/vB0vm6e3Ti5XCogGD39nZP5zeWT+3xp/7GWnuzh7PH92bi/e2l9tU2tjPzZq/ztfaOWzH1vGMOCR0MMn502uq0HnxPhrKK+pJTiBDPI/+tbJ/H89bPtrLWfPbc2YBP5zvYq3l/TaI/Rt/iM3093evYNLT5OGZHPry+fzFdOGsaY/lnsqWrg+ic+i+tFX7GXdNsNgdk4RpDxuFS3q1tG2oklefj8OqA3bklP9tjDFiX56QFZLkopTh1VwHOrymlo8bK2vIZmrz9g4ZUxPBJ4Gvub1zZTUdfEEjOT50fnjgn44Px56fZ2mRnQfox0tDkGX9UQ/hvaOlP5qxmErDOskoIMdlc14Pdrahu9AfX+wzE4J40vzgiZ1BX3RhVl0uLzs7sbNe4PmV/6D7+3PWBFbHWIv1V2ahL3XjqJJ789K2LJCcdaZoqHKUNy7IVuWgcOB3bUUz9S38LJ97zDva8Z/c1WrzmMUxH+pLhzE3uXS/GDs9rORDc4hlPjTVwHe39Anr3xx3G7AlfTRsP8SQM7vC8jxc1HC89kyY/nsvQnZ7RbA3DB5IFGIDjcYOdRn+E4LZ8wKJvVZpnhn84bwy8uGs+G/bW860jZtIaGZpbmMbIok493Bg4l9c9OoX92ChPMSdnx5hyENS/RnfHJa2YNIzXJRU1jKwOyU+1x/aF56bR4/Rysa6KmsYWsbhSgO94NNwOYc1P0rlgLqKobWu1SxQBjB4Ye575q5lBODspqikcPfXkaYCyqW26e3Q7OSaOhxRey7IT1mXncrIhqpW52p2df3+INWOw321Ha4cPtsbN5fHfFdbAP6NmntPXsUzzRDfapSW7e/+kZ/ODMkSw4YRB/unqqfV9Gsoei7NR26YaWEnPc/rv/WsljHxlv2AsnD8SljDd5TnqynaNfkp/BlScOwe1SvODIB3Z+gUwe3I915W29kbljjLz5T249m8KsFFb99zks+q5REqKjbIjOeNwu5ow0hg0mDm7L4LF+jm0VR/lkRxUTgrJ7Epm1B0J3epvO4n4fmOs2/n7tifz8glCL2Y8fRdmpXGeW0PjPqnKUgpvOHoXXrwPmtizWeo/6Fh9NrT472FfUNQfsNgfGHNfOEOUZGpp9gcOrGcncc+kk0pPdIVOZ40VcB3ufX+M2x3qt4QO3y2VPakbTkLx0fnTuGP549VQuOqFtr8+uzjqsQmu7DjfwmdmDL8xK4eNbz+LtH53OJVMCnys92cOwvHRWOjY6d66QdRZue/Lbs/jH12cGvF5uRrI9Rm/1ys/oZtbGOLN3OdGxutiqBnrN/37K4fqWkIWvEpW1mf3dizcGFKLrjHO45slP96CUMTZvLU47njlXdGvdVo8/VAqrc73H0s2BWTTBx7+0Zj9n3LfUru5qOeoYxrFcPXMoXz25hJ2H6vH6/OytarBXw8eLuJ798prBHnAM40BKkhHsTxmRzzkxkr3xlVlD+dfHe8jsYuw6eEIyNclFisdNUZbxob50WjGvrjvAmxsO2mmdI4oy7QJS35pTygWOYaRrZg0jM8WDX2t7YVJnNv9yHp5u1hIaO8DotVu5+oC9kYulL7fCizdKKXLSk6huaGXrwaMBX5IdsYqeWY/LS0+OyB658eDaU0q499W2nI/hZmG5UIvTnCu5V+09QqvPT3aqh9omL9sr65k61PgMVNW3sM2c+/h0ZxWnjS7k3S2VHD7aTLPXH7K0xMgiYz/hKx7+iH3VjRysbWb8oGx7ODTWRb8L3As+v99exdoW7F0ku43AOHdMYcjMj2i4Y8FEVv33Od0eYgpVuOovX5nO6zedZr/JnNlH3507ImAhWW5GMt+YU8q3Th0e1gKzFI+720Hk7PFF3HXxhIBt/4KfI9qT5rHmue/NBoxVzm9uOMhH29uvHLXUNrXyr4/3kJbk5qLJxpldcFbX8Sw1yW0XSgNjAnpQv1SWhRg/t1KAkz0uVu2upsXrZ4S5NeS2iqNorTn3f95l2l1v2jvOHa43Jr+/9uin/PAZoxZOqI/KlCHG523VnmoOmmtsftuDFNpoietgH9Czd2TjWJNWg3P6NgWzO9wuFbAytDN3XTLRznIJVQrW7VIB1TiHOHrNkS7gFY4Uj5trTi5p98VkjU0DDJBgH2CY4wv62/+3gqv/+rGdEhvsnsUb2Xywjt9eMZlJ5lmAuxeVXOPRuRMG8PEtZ7H0x3MBuGx6Me9vPWSPw/v9mvvf2mJnKs0ZWcCa8moaWnykJ7sZWZTFhv217K9psie4rS+LUHMn04a2PwsOtd+BVVE0HsT1MI7Pr+2efW5GMrNH5jO5uB8zS/MYUZgR8g8WD66ZNYxrZg3jkx2HO9w31ak4ty1wxFIJ29duPI33tlTi07pb20EmglApkc8s38sCx/wOwPJdVTz5qTE2fProQrtHOaZ/32y0EsucHQZr6GtnZT0nDMlhbXlNQPmQ2SMLeGdTBWvKqjltdCFThuTwypp9AbWVrH0nVu+tblfb6ZSR7eeYghel5Wckc7i+hSP1LWF35KIpdiJDDxg9e+NHSHK7ePxbszhpeD5KKaYPy4v5FYNdOWl4PkPzuz47GdLHi8h6KiPFw/mTBnLh5EFdH5yAHr02sPTDmrLqduUv3t5YYV/OSk1iZFEm//u1Gdx1ycRj0sZYNdxMPNhxyOilr9oTuKZljhms/RqS3S6mDsmhtsnLmrLqds/V4vPz/55dSzijl8lmZ+pbc0r5xYIJZhviY8OVuA72Pp+OWPnieFYsk59x6cyx/fnJeWPs67VNXv6xbFfAMVZ+uHPO46xx/RN+3cLQ/HRcyujZAxwIqlM1siiTInMINNnjYsrQHKCtzo61L/Do/pkMzknjpc/3YSWxfXFGcYev+5/vncL35o7gZxeMs6uN7pJg3/ecY/aJLDhNTMSP8ycOAOBkc8eyO17aABiVSS/78zLe3HCQc8f3Z9nCM6PWxliU4nEzJC+d7WagrWtqJS8jme2/ms+q/z7H3OfW+J3urWpgZGEmWSkeO83SSgXOTU/mpR/MsZ/31vlj+c3lJ3T4uhMH9+On88ailGJIXjpul2LHoaNxUQY5roO9z+8PWWY4Ef3lK9N44frZ0W6G6KbhhZl8uPBMfvmFtmGZo81e1pTV2OU2RhZlxv2QZF8oLciwd7aqa/KSleoJSIS4df44wBgOdbkUU4bm2AsSL5lqDC2ePqYwII/fOf/VlSS3i5GFmTy4ZDtn/u7dqG6hGI647hJKz77NvIkdl2gQsW1wThpaa84cW8Q7myr41eKNvLG+baVmqE3ahbHZySc7qvD7jf12g5MAirJT2XDneXa68/kTB/L+ViMgTxjUj2ULz6S/Wczw1FEFvL/1UMCe0OGYM6rA3mtiTXlNyIndWBHnPXsdkXr1QkSbUoo/Xj2VzBQPT3yyxy6zCzCzNP5r3PSF4YUZNLb6eHntfrtnH8xZeHDasBz79tQkN4Ny0uz7HvjSNJ797snt9l/uirPC6NqyGp5fVd7lHhPREtfBXnr24niSmeLhC1MDt3fecOd5ARuJizZWNdgfPbOafdWNIYO907C80PWoAPqlJTF9WF6H93fVBoBX1u7npqdX88ra2Kx7H9fB3u/XMmYvjiv/7/yxXH/GCPt6d/YWSDSj+mfxuytOoNWn2VfT1OVaDqv2kzNA91Zqkpv7rjghoIT3gZrwt0A8luI62Dvz7IU4HmSmePjxuWO6PlAAUFrY1ls/IYwzoDW3n8v/fXNml8d1x+XTi1l927n29f0S7CPPuYJWiOOFUoqHr5nOKzfM6frgBDemfxapSS5mluaFtdlNdmpSn5RAd7kUt11olJv+MEazcuL6HNHr98uYvTgunTdhQLSbEBcyUjxsuuv8aDcDgG/MKcWl4PaXNrB6b3XMzbVIz14IISLk8hlDSEtyc8mDH7LncPjbTh4LcR3sJRtHCBFLMlM83DJ/LABPLt8T5dYEiutgLz17IUSs+erJJcwZWcAb6w8E5NzXNLRGNQc/roO91yfZOEKI2HPB5IFsr6xn6WajFs/eqgam/fJNFj67NmptirtI2ez1cdKv3uLNDQelZy+EiEmXTy8mNcnFO5uMEtVPLd+Dz695esVemlrD23c40uIuG2dvVQMHa5v51eKNuBS4ZVGVECLGJLldTBrcj8c+3k2/tCSeWVFm37dqTzUnjzj2JTDC6tkrpeYppTYrpbYppRZ2ctxlSimtlJrR0TG9Ze0xmZHilp69ECJm3XahsbnJA0u2UVnXzN1mZdP1+2qi0p4ug71Syg08CJwPjAeuVkqND3FcFnAj8EmkG+l01CxRmpHsMbJxpBCaECIGTSrux3fntpW+OHVkIUPy0nj0g51U1jV38si+EU7PfiawTWu9Q2vdAjwFXBziuLuAXwN9ulb4SEMLYKQ4+ST1UggRw5wLq/Izk3ng6mmcOa6o29U1IyGcYD8Y2Ou4XmbeZlNKTQOGaK1f6eyJlFLXKaVWKKVWVFZWdruxAEcajA2DM8xgL4XQhBCxaqoj2KcnuzlhSA6/vGRSVDqpvc7GUUq5gN8DP+rqWK31I1rrGVrrGYWFhV0dHlKjuQt8hvTshRAxrii7be/gaO82Fk6wLwecFYaKzdssWcBEYKlSahcwC3ixryZprzttBAWZximQ16/xSJ69ECKGnTehf0TLKvdUOKmXy4FRSqlSjCB/FfAl606tdQ1g78WllFoK/FhrvSKyTW2T4nHT6vNLz14IEfMevqbPkhO7pctusdbaC3wfeB3YCDyjtV6vlLpTKbWgrxsYisetWLSyjKPNXkm9FEKIMIS1qEprvRhYHHTbbR0cO7f3zercbkc1OenZCyFE1+J+wFvS7IUQomtxH+yrzVRMIYQQHYv7YF9V3xLtJgghRMyL+2B/+KgEeyGE6ErcB/t6c5GVEEKIjsVdiWOn75w2nCvC2FFeCCESXVwH+1vmj4t2E4QQIi7EZbB/4lsnsb+mT4trCiHEcSUug/0pIwu6PkgIIYQt7idohRBCdE2CvRBCJAAJ9kIIkQAk2AshRAKQYC+EEAlAgr0QQiQACfZCCJEAJNgLIUQCUFrr6LywUpXA7m4+rAA41AfNiRRpX+9I+3pH2tc78dK+YVrrwu4+OGrBvieUUiu01rGxe28I0r7ekfb1jrSvd4739skwjhBCJAAJ9kIIkQDiLdg/Eu0GdEHa1zvSvt6R9vXOcd2+uBqzF0II0TPx1rMXQgjRAxLshRAiAcRNsFdKzVNKbVZKbVNKLYxSGx5VSlUopdY5bstTSr2plNpq/p9r3q6UUn8027tGKTXtGLRviFJqiVJqg1JqvVLqxlhqo1IqVSn1qVLqc7N9d5i3lyqlPjHb8bRSKtm8PcW8vs28v6Qv22e+plsptUop9XKstc183V1KqbVKqdVKqRXmbTHx9zVfM0cptUgptUkptVEpdXKstE8pNcb8vVn/apVSN8VK+8zXvNn8bKxTSj1pfmYi8x7UWsf8P8ANbAeGA8nA58D4KLTjNGAasM5x22+AheblhcCvzcvzgVcBBcwCPjkG7RsITDMvZwFbgPGx0kbzdTLNy0nAJ+brPgNcZd7+F+C75uXvAX8xL18FPH0Mfoc/BJ4AXjavx0zbzNfaBRQE3RYTf1/zNf8JfMu8nAzkxFL7HO10AweAYbHSPmAwsBNIc7z3ro3Ue/CY/GIj8Es4GXjdcf0W4JYotaWEwGC/GRhoXh4IbDYvPwxcHeq4Y9jWF4BzYrGNQDrwGXASxqpAT/DfGngdONm87DGPU33YpmLgbeBM4GXzQx4TbXO0cRftg31M/H2BfmawUrHYvqA2nQt8GEvtwwj2e4E88z31MnBepN6D8TKMY/0SLGXmbbGgv9Z6v3n5ANDfvBzVNpundFMxes8x00ZzmGQ1UAG8iXHGVq219oZog90+8/4aIL8Pm3c/8FPAb17Pj6G2WTTwhlJqpVLqOvO2WPn7lgKVwN/NobC/KaUyYqh9TlcBT5qXY6J9Wuty4D5gD7Af4z21kgi9B+Ml2McFbXzFRj2XVSmVCTwL3KS1rnXeF+02aq19WuspGL3omcDYaLXFSSl1IVChtV4Z7bZ0YY7WehpwPnC9Uuo0551R/vt6MIY5/6y1ngrUYwyL2KL9/gMwx7wXAP8Ovi+a7TPnCi7G+NIcBGQA8yL1/PES7MuBIY7rxeZtseCgUmoggPl/hXl7VNqslErCCPSPa63/E4ttBNBaVwNLME5Lc5RSnhBtsNtn3t8PONxHTZoNLFBK7QKewhjK+UOMtM1m9v7QWlcAz2F8YcbK37cMKNNaf2JeX4QR/GOlfZbzgc+01gfN67HSvrOBnVrrSq11K/AfjPdlRN6D8RLslwOjzFnpZIxTsBej3CbLi8DXzMtfwxgnt27/qjmjPwuocZwq9gmllAL+F9iotf59rLVRKVWolMoxL6dhzCdsxAj6l3fQPqvdlwPvmD2viNNa36K1LtZal2C8v97RWn85FtpmUUplKKWyrMsY487riJG/r9b6ALBXKTXGvOksYEOstM/hatqGcKx2xEL79gCzlFLp5mfZ+v1F5j14LCZDIjR5MR8ju2Q78LMoteFJjLG0VoxezDcxxsjeBrYCbwF55rEKeNBs71pgxjFo3xyMU9A1wGrz3/xYaSMwGVhltm8dcJt5+3DgU2Abxql1inl7qnl9m3n/8GP0d55LWzZOzLTNbMvn5r/11ucgVv6+5mtOAVaYf+PngdwYa18GRu+3n+O2WGrfHcAm8/PxGJASqfeglEsQQogEEC/DOEIIIXpBgr0QQiQACfZCCJEAJNgLIUQCkGAvhBAJQIK9EEIkAAn2QgiRAP4/us9V1DyXyY8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what was the first super bowl that the carolina panthers played in? for the third straight season, t</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(33, 33)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Note that there is a bug currently in fastai v2 (or with how I'm assembling everything) that currently prevents us from seeing the decoded predictions and probabilities for the \"end\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_predict_answers(\n",
    "    self: Learner,\n",
    "    # The str (or list of strings) you want to get token classification predictions for\n",
    "    question_contexts: Union[dict, List[dict]],\n",
    "    # If using a slow tokenizer, users will need to prove a `slow_word_ids_func` that accepts a\n",
    "    # tokenizzer, example index, and a batch encoding as arguments and in turn returnes the\n",
    "    # equavlient of fast tokenizer's `word_ids``\n",
    "    slow_word_ids_func: Optional[Callable] = None,\n",
    "):\n",
    "    if not is_listy(question_contexts):\n",
    "        question_contexts = [question_contexts]\n",
    "\n",
    "    tfm = first_blurr_tfm(self.dls, tfms=[QABatchTokenizeTransform])\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "    tok_kwargs[\"return_overflowing_tokens\"] = True\n",
    "    tok_kwargs[\"truncation\"] = \"only_second\" if hf_tokenizer.padding_side == \"right\" else \"only_first\"\n",
    "\n",
    "    results = []\n",
    "    for qc in question_contexts:\n",
    "        inps = [qc[\"question\"], qc[\"context\"]] if hf_tokenizer.padding_side == \"right\" else [qc[\"context\"], qc[\"question\"]]\n",
    "\n",
    "        inputs = hf_tokenizer(*inps, max_length=tfm.max_length, padding=tfm.padding, return_tensors=\"pt\", **tok_kwargs)\n",
    "        inputs_offsets = inputs[\"offset_mapping\"]\n",
    "\n",
    "        # run inputs through model\n",
    "        model_inputs = {k: v.to(self.model.hf_model.device) for k, v in inputs.items()}\n",
    "        outputs = self.model(model_inputs)\n",
    "\n",
    "        # grab our start/end logits\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "        # mask any tokens that shouldn't be considered\n",
    "        seq_ids = inputs.sequence_ids()\n",
    "        # mask question tokens\n",
    "        ignore_mask = [i != 1 if hf_tokenizer.padding_side == \"right\" else i != 0 for i in seq_ids]\n",
    "        # unmask the [CLS] token\n",
    "        ignore_mask[0] = False\n",
    "        # mask all the [PAD] tokens\n",
    "        ignore_mask = torch.logical_or(torch.tensor(ignore_mask)[None], (inputs[\"attention_mask\"] == 0))\n",
    "\n",
    "        start_logits[ignore_mask] = tfm.ignore_token_id\n",
    "        end_logits[ignore_mask] = tfm.ignore_token_id\n",
    "\n",
    "        # grab our start/end probabilities\n",
    "        start_probs = F.softmax(start_logits, dim=-1)\n",
    "        end_probs = F.softmax(end_logits, dim=-1)\n",
    "\n",
    "        # get scores for each chunk\n",
    "        candidates = []\n",
    "        for offset_idx, (chunk_start_probs, chunk_end_probs) in enumerate(zip(start_probs, end_probs)):\n",
    "            scores = chunk_start_probs[:, None] * chunk_end_probs[None, :]\n",
    "            idx = torch.triu(scores).argmax().item()\n",
    "\n",
    "            start_idx = idx // scores.shape[0]\n",
    "            end_idx = idx % scores.shape[0]\n",
    "            score = scores[start_idx, end_idx].item()\n",
    "            candidates.append((offset_idx, start_idx, end_idx, score))\n",
    "\n",
    "        # sort our candidates by score\n",
    "        candidates.sort(key=lambda el: el[3], reverse=True)\n",
    "\n",
    "        # return our best answer\n",
    "        best = candidates[0]\n",
    "        if best[1] == 0 and best[2] == 0:\n",
    "            results.append({\"answer\": None, \"start\": 0, \"end\": 0, \"score\": best[3]})\n",
    "        else:\n",
    "            start_char_idx = inputs_offsets[best[0]][best[1]][0]\n",
    "            end_char_idx = inputs_offsets[best[0]][best[2] - 1][1]\n",
    "            ans = inps[1][start_char_idx:end_char_idx].strip()\n",
    "\n",
    "            results.append({\"answer\": ans, \"start\": start_char_idx.item(), \"end\": end_char_idx.item(), \"score\": best[3]})\n",
    "\n",
    "    # build our results\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9453520774841309}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n",
    "\n",
    "learn.blurr_predict_answers({\"question\": \"What did George Lucas make?\", \"context\": context})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9453520774841309},\n",
       " {'answer': '1977', 'start': 34, 'end': 38, 'score': 0.973710834980011},\n",
       " {'answer': 'directed and produced',\n",
       "  'start': 43,\n",
       "  'end': 64,\n",
       "  'score': 0.27373579144477844},\n",
       " {'answer': None, 'start': 0, 'end': 0, 'score': 0.566393256187439}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n",
    "\n",
    "learn.blurr_predict_answers([\n",
    "    {\"question\": \"What did George Lucas make?\", \"context\": context},\n",
    "    {\"question\": \"What year did Star Wars come out?\", \"context\": context},\n",
    "    {\"question\": \"What did George Lucas do?\", \"context\": context},\n",
    "    {\"question\": \"Who plays Spock in the movie?\", \"context\": context},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Note that I had to replace the loss function because of the above-mentioned issue to exporting the model with the `MultiTargetLoss` loss function.  After getting our inference learner, we put it back and we're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"q_and_a_learn_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyLossFlat()\n",
    "learn.export(fname=f\"{export_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9453522562980652},\n",
       " {'answer': '1977', 'start': 34, 'end': 38, 'score': 0.9737107157707214},\n",
       " {'answer': 'directed and produced',\n",
       "  'start': 43,\n",
       "  'end': 64,\n",
       "  'score': 0.2737361192703247},\n",
       " {'answer': None, 'start': 0, 'end': 0, 'score': 0.5663907527923584}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "context = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n",
    "\n",
    "inf_learn.blurr_predict_answers([\n",
    "    {\"question\": \"What did George Lucas make?\", \"context\": context},\n",
    "    {\"question\": \"What year did Star Wars come out?\", \"context\": context},\n",
    "    {\"question\": \"What did George Lucas do?\", \"context\": context},\n",
    "    {\"question\": \"Who plays Spock in the movie?\", \"context\": context},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BLearnerForQuestionAnswering`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForQuestionAnswering(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        kwargs[\"loss_func\"] = kwargs.get(\"loss_func\", PreCalculatedQALoss())\n",
    "        super().__init__(dls, hf_model, base_model_cb=QAModelCallback, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForQuestionAnswering\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, x, qst, ctx, id=None, padding_side=\"right\"):\n",
    "        inps = {}\n",
    "        inps[\"text\"] = (x[qst], x[ctx]) if (padding_side == \"right\") else (x[ctx], x[qst])\n",
    "\n",
    "        if id is not None:\n",
    "            inps[\"id\"] = x[id]\n",
    "\n",
    "        return inps\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths \n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The unique identifier in the dataset. If not specified and \"return_overflowing_tokens\": True, an \"_id\" attribute\n",
    "        # will be added to your dataset with its value a unique, sequential integer, assigned to each record\n",
    "        id_attr: Optional[str] = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"ans_start_token_idx\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"ans_end_token_idx\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type  == 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': \n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type  == 'text/csv': \n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type  == 'application/json': \n",
    "                data = pd.read_json(data, orient='records')\n",
    "            else: \n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, model_cls=cls.get_model_cls())\n",
    "\n",
    "        # potentially used by our preprocess_func, it is the basis for our CategoryBlock vocab\n",
    "        if max_seq_len is None:\n",
    "            max_seq_len = hf_config.get(\"max_position_embeddings\", 128)\n",
    "\n",
    "        # bits required by our \"before_batch_tfm\" and DataBlock\n",
    "        vocab = list(range(max_seq_len))\n",
    "        padding_side = hf_tokenizer.padding_side\n",
    "\n",
    "        # define DataBlock and DataLoaders\n",
    "        before_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n",
    "        blocks = (\n",
    "            TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "            CategoryBlock(vocab=vocab),\n",
    "            CategoryBlock(vocab=vocab),\n",
    "        )\n",
    "        dblock = DataBlock(\n",
    "            blocks=blocks, \n",
    "            get_x=partial(cls._get_x, qst=question_attr, ctx=context_attr, id=id_attr, padding_side=padding_side), \n",
    "            get_y=[ItemGetter(tok_ans_start_attr), ItemGetter(tok_ans_end_attr)],\n",
    "            splitter=dblock_splitter, \n",
    "            n_inp=1)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "`BLearnerForQuestionAnswering` requires a question, context (within which to find the answer to the question), and the start/end indices of where the answer lies in the *tokenized context*. Because those indices vary by tokenizer, we can pass a `preprocess_func` that will take our raw data, perform any preprocessing we want, and return it in a way that will work for extractive QA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/wgilliam/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5575ac17694dee96dfa87040ea81bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}</td>\n",
       "      <td>False</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>541</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...   \n",
       "\n",
       "                                                                  question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                           answers  is_valid  \\\n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}     False   \n",
       "\n",
       "   ans_start_char_idx                 answer_text  ans_end_char_idx  \\\n",
       "0                 515  Saint Bernadette Soubirous               541   \n",
       "\n",
       "                                                             proc_question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           proc_context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                    0                  0          False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build our training and validation DataFrames\n",
    "raw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n",
    "\n",
    "raw_train_df = pd.DataFrame(raw_datasets[0])\n",
    "raw_valid_df = pd.DataFrame(raw_datasets[1])\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "# concatenate into a single DataFrame\n",
    "squad_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "\n",
    "# include the required start/end character indicies and full text of the answer\n",
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "# run our modified DataFrame thru the QAPreprocessor to get the start/end \"token\" indices we want to predict\n",
    "preprocessor = QAPreprocessor(\n",
    "    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    ")\n",
    "\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "proc_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your `Blearner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "learn = BlearnerForQuestionAnswering.from_data(\n",
    "    proc_df,\n",
    "    pretrained_model_name,\n",
    "    id_attr=\"id\",\n",
    "    question_attr=\"proc_question\",\n",
    "    context_attr=\"proc_context\",\n",
    "    max_seq_len=128,\n",
    "    dl_kwargs={\"bs\": 4},\n",
    ").to_fp16()\n",
    "\n",
    "validation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\n",
    "fit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with what institute did notre dame agree to an exchange program in the 1960s? ism. \" thomas blantz, c. s. c., notre dame's vice president of student affairs, added that coeducation \" opened up a whole other pool of very bright students. \" two of the male residence halls were converted for the newly admitted female students that first year, while two others were converted for the next school year. in 1971 mary ann proctor became the first female undergraduate ; she transferred from st. mary's col</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who was the first record label to give the girls a record deal? ped and danced on the talent show circuit in houston. after seeing the group, r &amp; b producer arne frager brought them to his northern california studio and placed them in star search, the largest talent show on national tv at the time. girl's tyme failed to win, and beyonce later said the song they performed was not good. in 1995 beyonce's father resigned from his job to manage the group. the move reduced beyonce's family's income b</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how many octaves does beyonce's voice span? of exploring power ballads, soul, rock belting, operatic flourishes, and hip hop. jon pareles of the new york times commented that her voice is \" velvety yet tart, with an insistent flutter and reserves of soul belting \". rosen notes that the hip hop era highly influenced beyonce's strange rhythmic vocal style, but also finds her quite traditionalist in her use of balladry, gospel and falsetto. other critics praise her range and power, with chris richa</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when did beyonce begin her second world tour? am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the making of her 2003 single \" crazy in love \", selling 482, 000 copies in its first week, debuting atop the billboard 200, and giving beyonce her third consecutive number - one album in the us. the album featured the number - one song \" single ladies ( put a ring on it ) \" and the top - five son</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.164781</td>\n",
       "      <td>1.127530</td>\n",
       "      <td>80.327869</td>\n",
       "      <td>85.923949</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.496204</td>\n",
       "      <td>1.008130</td>\n",
       "      <td>78.360656</td>\n",
       "      <td>84.010026</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.421541</td>\n",
       "      <td>1.071347</td>\n",
       "      <td>77.704918</td>\n",
       "      <td>83.192818</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\n",
    "fit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n",
    "\n",
    "learn.fit_one_cycle(3, lr_max=1e-3, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 – 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who was given the esteemed status of mvp for super bowl 50? the broncos took an early lead in super bowl 50 and never trailed. newton was limited by denver's defense, which sacked him seven times and forced him into three turnovers, including a fumble which they recovered for a touchdown. denver linebacker von miller was named super bowl mvp, recording five solo tackles, 2½ sacks, and two forced fumbles.</td>\n",
       "      <td>True</td>\n",
       "      <td>(64, 66)</td>\n",
       "      <td>von miller</td>\n",
       "      <td>(64, 66)</td>\n",
       "      <td>von miller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp32()\n",
    "learn.loss_func = CrossEntropyLossFlat()\n",
    "learn.export(fname=f\"{export_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.97016841173172},\n",
       " {'answer': '1977', 'start': 34, 'end': 38, 'score': 0.6831641793251038},\n",
       " {'answer': 'directed and produced it',\n",
       "  'start': 43,\n",
       "  'end': 67,\n",
       "  'score': 0.37182292342185974},\n",
       " {'answer': None, 'start': 0, 'end': 0, 'score': 0.9379059672355652}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "context = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n",
    "\n",
    "inf_learn.blurr_predict_answers([\n",
    "    {\"question\": \"What did George Lucas make?\", \"context\": context},\n",
    "    {\"question\": \"What year did Star Wars come out?\", \"context\": context},\n",
    "    {\"question\": \"What did George Lucas do?\", \"context\": context},\n",
    "    {\"question\": \"Who plays Spock in the movie?\", \"context\": context},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module includes all the low, mid, and high-level API bits for extractive Q&A tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
