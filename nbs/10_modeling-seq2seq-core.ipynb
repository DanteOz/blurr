{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.seq2seq.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.seq2seq.core\n",
    "\n",
    "> This module contains core custom models, loss functions, etc... for Seq2Seq based tasks (e.g., language modeling, summarization, translation, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, inspect, torch\n",
    "\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "from fastai.callback.hook import _print_shapes\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import get_blurr_tfm\n",
    "from blurr.data.seq2seq.core import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from datasets import load_metric as hf_load_metric, list_metrics as hf_list_metrics\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.1\n",
      "Using fastai 2.3.1\n",
      "Using transformers 4.6.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>\n",
       "      <td>John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>\n",
       "      <td>NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  (CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...   \n",
       "1  (CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              highlights  \\\n",
       "0  John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"   \n",
       "1                                                                                          NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv')\n",
    "\n",
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.models.bart.configuration_bart.BartConfig,\n",
       " transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n",
       " transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                  max_length=256, max_target_length=130)\n",
    "\n",
    "blocks = (HF_Seq2SeqBlock(before_batch_tfm=before_batch_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('article'), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 256]), torch.Size([2, 78]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; (CNN) -- Home to up to 10 percent of all known species, Mexico is recognized as one of the most biodiverse regions on the planet. The twin threats of climate change and human encroachment on natural environments are, however, threatening the existence of the country's rich wildlife. And there is a great deal to lose. In the United Nations Environment Program (UNEP) World Conservation Monitoring Centre's list of megadiverse countries Mexico ranks 11th. The list represents a group of 17 countries that harbor the majority of the Earth's species and are therefore considered extremely biodiverse. From its coral reefs in the Caribbean Sea to its tropical jungles in Chiapas and the Yucatan peninsula and its deserts and prairies in the north, Mexico boasts an incredibly rich variety of flora and fauna. Some 574 out of 717 reptile species found in Mexico -- the most in any country -- can only be encountered within its borders. It is home to 502 types of mammals, 290 species of birds, 1,150 varieties of birds and 26,000 classifications of plants. Pronatura, a non-profit organization that works to promote conservation and sustainable development in Mexico, has selected six species which it says symbolize the problems faced by the&lt;/s&gt;</td>\n",
       "      <td>Mexico hosts to up to 10 percent of all known species on Earth.\\nIt is home to 502 types of mammals, 290 bird species and 26,000 types of plants.\\nHuman development and climate change is placing a big strain on its biodiversity.\\nThe Golden Eagle is under threat in spite of being the country's national symbol.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; It's an international air disaster in a war zone -- a commercial flight with almost 300 people on board shot down in eastern Ukraine. As new details emerge, here is a look at basic questions about the tragedy:. Was the plane shot down? All evidence so far says yes. President Barack Obama declared Friday that a surface-to-air missile blasted the Malaysia Airlines Boeing 777 on Thursday over the Donetsk region of Ukraine near the Russian border. According to a senior American official, a U.S. radar system saw a surface-to-air missile system turn on and track an aircraft right before plane went down. A second system saw a heat signature, which would indicate a missile rising from the ground into the air at the time the airliner was hit, the official explained. Does anyone dispute that? Not at this point. While the Ukrainian government trades accusations of blame with pro-Russian rebels it is fighting in eastern Ukraine and Russia itself, no one has offered evidence of an alternative theory. The plane's debris field indicates a mid-air explosion. Who did it? A preliminary classified U.S. intelligence analysis concludes the rebels most likely fired the missile, according to an American defense official with direct access to the latest information. \"Evidence indicates that the plane was shot&lt;/s&gt;</td>\n",
       "      <td>Donetsk rebel official: Plane shot down, but not by us.\\nMalaysian official says the crash site's integrity has been compromised.\\nPresident Obama says evidence points to a missile strike by pro-Russian rebels.\\nRussia could face increasing international isolation and tougher sanctions.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here we create a Seq2Seq specific subclass of `HF_BaseModelCallback` in order to include custom, Seq2Seq specific, metrics, and also handle the pre-calculated loss during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq_metrics\n",
    "- {'rouge': { 'compute_args': {'return_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True}, 'returns':[\"rouge1\", \"rouge2\", \"rougeL\"]}\n",
    "- {'bert_score': { 'returns': [\"precision\", \"recall\", \"f1\"] }\n",
    "- {'bleu': { 'returns': \"bleu\" }\n",
    "- {'bleurt': { 'returns': \"scores\" }\n",
    "- {'meteor': { 'returns': \"meteor\" }\n",
    "- {'sacrebleu': { 'returns': \"score\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_Seq2SeqMetricsCallback(Callback):  \n",
    "    def __init__(self, custom_metrics=None, ignore_token_id=CrossEntropyLossFlat().ignore_index, \n",
    "                 text_gen_kwargs={}, **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        self.order = Recorder.order-1   \n",
    "        \n",
    "        store_attr(self=self, names='custom_metrics, ignore_token_id, text_gen_kwargs, kwargs')\n",
    "        self.custom_metric_funcs, self.custom_metric_vals = {}, {}\n",
    "        \n",
    "        if (custom_metrics is not None):\n",
    "            for metric_name, metric_info_dict in custom_metrics.items():\n",
    "                # self.custom_metric_funcs (tuple): the function to compute the metric and what should be returned,\n",
    "                # if the \"compute_func\" is not defined, we assume it is a huggingface metric\n",
    "                if ('compute_func' in metric_info_dict):\n",
    "                    compute_func = metric_info_dict['compute_func']\n",
    "                else:\n",
    "                    compute_func = hf_load_metric(metric_name).compute\n",
    "                    \n",
    "                compute_kwargs = metric_info_dict['compute_kwargs'] if ('compute_kwargs' in metric_info_dict) else {}\n",
    "                metric_returns = metric_info_dict['returns']\n",
    "        \n",
    "                self.custom_metric_funcs[metric_name] = (partial(compute_func, **compute_kwargs),  metric_returns)\n",
    "                \n",
    "                # self.custom_metric_vals (list): all the custom metrics to report as a \"ValueMetric\"\n",
    "                if (metric_name == 'rouge'): \n",
    "                    self.custom_metric_vals.update({ rouge_type:None for rouge_type in metric_returns })\n",
    "                elif (is_listy(metric_returns)):\n",
    "                    self.custom_metric_vals.update({ f'{metric_name}_{ret_val}':None for ret_val in metric_returns })\n",
    "                else:\n",
    "                    self.custom_metric_vals.update({ metric_name:None })\n",
    "\n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the HF_BeforeBatchTransform (used for rouge metrics)\n",
    "        hf_before_batch_tfm = get_blurr_tfm(self.learn.dls.before_batch)\n",
    "        self.hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "        self.tok_kwargs = hf_before_batch_tfm.tok_kwargs\n",
    "        \n",
    "        # use before batch tfm's text_gen_kwargs if user doesn't pass in their own kwargs\n",
    "        if (len(self.text_gen_kwargs) == 0): self.text_gen_kwargs = hf_before_batch_tfm.text_gen_kwargs\n",
    "        \n",
    "        # add seq2seq generation specific metrics (rouge, bertscore, bleu, etc...) to learner metrics\n",
    "        metric_keys = list(self.custom_metric_vals.keys())\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "        \n",
    "        \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None or self.custom_metrics is None): return\n",
    "        \n",
    "        # grab predicted and reference ids for any metrics that need them\n",
    "        input_ids, attention_mask = self.xb[0]['input_ids'], self.xb[0]['attention_mask']\n",
    "        gen_ids = self.learn.model.hf_model.generate(input_ids=input_ids, \n",
    "                                                     attention_mask=attention_mask, \n",
    "                                                     **self.text_gen_kwargs)\n",
    "        \n",
    "        self.generated_ids += gen_ids.tolist()\n",
    "        self.refernce_ids += [ seq[seq != self.ignore_token_id].tolist()  for seq in self.yb[0] ]\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.generated_ids, self.refernce_ids = [], []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (self.learn.y is None or self.custom_metrics is None): return\n",
    "        \n",
    "        # fetch the generated prediction and reference tokens and texts\n",
    "        gen_toks = [ self.hf_tokenizer.convert_ids_to_tokens(ids, skip_special_tokens=True) \n",
    "                    for ids in self.generated_ids ]\n",
    "        \n",
    "        ref_toks = [ self.hf_tokenizer.convert_ids_to_tokens(ids, skip_special_tokens=True) \n",
    "                    for ids in self.refernce_ids ]\n",
    "        \n",
    "        gen_texts = self.hf_tokenizer.batch_decode(self.generated_ids, \n",
    "                                                   skip_special_tokens=True, \n",
    "                                                   clean_up_tokenization_spaces=True)\n",
    "        \n",
    "        ref_texts = self.hf_tokenizer.batch_decode(self.refernce_ids, \n",
    "                                                   skip_special_tokens=True, \n",
    "                                                   clean_up_tokenization_spaces=True)\n",
    "            \n",
    "        # calculate any seq2seq metrics\n",
    "        for metric_name, metric_info in self.custom_metric_funcs.items():\n",
    "            compute_func, return_val = metric_info\n",
    "            \n",
    "            # some metrics work on tokens (bleu), some allow for multiple references (blue, sacrebleu), and most\n",
    "            # work directly on the generated and reference texts; here blurr does the dirty work of getting your\n",
    "            # preds/references formatted for the metric you are using\n",
    "            if (metric_name == 'bleu'):\n",
    "                predictions, references = gen_toks, [ [toks] for toks in ref_toks ]\n",
    "            elif (metric_name == 'sacrebleu'):\n",
    "                predictions, references = gen_texts, [ [txt] for txt in ref_texts ]\n",
    "            else:\n",
    "                predictions, references = gen_texts, ref_texts\n",
    "                \n",
    "            # calls the metrics \"compute\" function\n",
    "            res = compute_func(predictions=predictions, references=references)\n",
    "            \n",
    "            # updates the custom_metric_vals with the metric's value\n",
    "            if (metric_name == 'rouge'):\n",
    "                for rouge_key, scores in res.items(): \n",
    "                    self.custom_metric_vals[rouge_key] = scores.mid.fmeasure\n",
    "            if (metric_name == 'bertscore'):\n",
    "                for score_key, score in res.items(): \n",
    "                    if (f'{metric_name}_{score_key}' not in self.custom_metric_vals): continue\n",
    "                    self.custom_metric_vals[f'{metric_name}_{score_key}'] = np.array(score).mean().item()\n",
    "            elif (is_listy(return_val)):\n",
    "                for score_key, score in res.items(): \n",
    "                    if (f'{metric_name}_{score_key}' not in self.custom_metric_vals): continue\n",
    "                    self.custom_metric_vals[f'{metric_name}_{score_key}'] = score\n",
    "            else:\n",
    "                self.custom_metric_vals[metric_name] = res[return_val]\n",
    "                \n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metric_vals[metric_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a custom param splitter to give us a bit more depth in applying discriminative learning rates for Seq2Seq tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def seq2seq_splitter(m, arch):\n",
    "    \"\"\"Custom param splitter for summarization models\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "\n",
    "    if arch in ['bart', 'blenderbot', 'blenderbot_small', 'fsmt', 'marian', 'mbart', 'pegasus']:     \n",
    "        embeds_modules = [\n",
    "            model.model.encoder.embed_positions, \n",
    "            model.model.encoder.embed_tokens,\n",
    "            model.model.decoder.embed_positions, \n",
    "            model.model.decoder.embed_tokens\n",
    "        ]\n",
    "        if arch != 'fsmt': embeds_modules.insert(0, model.model.shared)\n",
    "            \n",
    "        embeds = nn.Sequential(*embeds_modules)\n",
    "        groups = L(embeds, model.model.encoder, model.model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    if arch in['led']:\n",
    "        embeds_modules = [\n",
    "            model.led.encoder.embed_positions, \n",
    "            model.led.encoder.embed_tokens,\n",
    "            model.led.decoder.embed_positions, \n",
    "            model.led.decoder.embed_tokens\n",
    "        ]\n",
    "\n",
    "        embeds = nn.Sequential(*embeds_modules)\n",
    "        groups = L(embeds, model.led.encoder, model.led.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    if arch in['mt5', 't5']:\n",
    "        embeds = nn.Sequential(\n",
    "            model.shared, \n",
    "            model.encoder.embed_tokens,\n",
    "            model.decoder.embed_tokens\n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.encoder, model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    if arch in ['prophetnet', 'xlm_prophetnet']:\n",
    "        embeds = nn.Sequential(\n",
    "            model.prophetnet.word_embeddings, \n",
    "            model.prophetnet.encoder.word_embeddings, \n",
    "            model.prophetnet.encoder.position_embeddings, \n",
    "            model.prophetnet.decoder.word_embeddings, \n",
    "            model.prophetnet.decoder.position_embeddings, \n",
    "            model.prophetnet.decoder.ngram_embeddings \n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.prophetnet.encoder.layers, model.prophetnet.decoder.layers, model.lm_head)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    \n",
    "    raise ValueError(f'seq2seq_splitter does not support this architecutre: {arch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"seq2seq_splitter\" class=\"doc_header\"><code>seq2seq_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>seq2seq_splitter</code>(**`m`**, **`arch`**)\n",
       "\n",
       "Custom param splitter for summarization models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(seq2seq_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "seq2seq_metrics = {\n",
    "    'rouge': {\n",
    "        'compute_kwargs': {\n",
    "            'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True\n",
    "        }, \n",
    "        'returns': [\"rouge1\", \"rouge2\", \"rougeL\"] \n",
    "    },\n",
    "    'bertscore': {\n",
    "        'compute_kwargs': { 'lang': 'en' },\n",
    "        'returns': [\"precision\", \"recall\", \"f1\"]\n",
    "    }, \n",
    "    'bleu': { 'returns': \"bleu\" },\n",
    "    'meteor': { 'returns': \"meteor\" },\n",
    "    'sacrebleu': { 'returns': \"score\" }\n",
    "}\n",
    "\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                loss_func=CrossEntropyLossFlat(), #HF_PreCalculatedLoss()\n",
    "                cbs=learn_cbs,\n",
    "                splitter=partial(seq2seq_splitter, arch=hf_arch)) #.to_native_fp16() #.to_fp16()\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 69, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds),preds['loss'].shape, preds['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 74, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds),preds['loss'].shape, preds['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.00012022644514217973, lr_steep=8.31763736641733e-06)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.778825</td>\n",
       "      <td>1.660103</td>\n",
       "      <td>0.392363</td>\n",
       "      <td>0.174361</td>\n",
       "      <td>0.264122</td>\n",
       "      <td>0.877209</td>\n",
       "      <td>0.894521</td>\n",
       "      <td>0.885675</td>\n",
       "      <td>0.152929</td>\n",
       "      <td>0.315640</td>\n",
       "      <td>12.394661</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to take advantage of huggingface's `PreTrainedModel.generate` model, which can be used to easily implement beam search, top-k/nucleous sampling, etc... so that we get more human sounding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s> 10About 10 men with with pistols and small machine guns raid a casino in Switzerland. made\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict(test_article)\n",
    "print(hf_tokenizer.decode(res[0][0][0][:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look much like a human-generated text.  Let's use huggingface's `PreTrainedModel.generate` method to create something more human-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target ===\n",
      " Hotel guests who \"go green\" are happier with their stay.\n",
      "Increasing water and energy costs are pushing hotels to cut costs wherever they can.\n",
      "Many hotels find that guests don't mind using the same towels and sheets every night.\n",
      "TripAdvisor will be adding a green label for hotels listed on its site.\n",
      "\n",
      "=== Prediction ===\n",
      " Dan Condon composts when he's at home in Boulder, Colorado, and drives a Honda CR-Z hybrid sports car.\n",
      "When he travels for work and stays in a hotel, he uses a new towel every day.\n",
      "Condon: \"I could care less about rewards for environmentally conscious behavior unless it's miles\"\n",
      "If hotels can't convince Condon to go green while traveling, how can they convince everyone else?\n"
     ]
    }
   ],
   "source": [
    "b = dls.valid.one_batch()\n",
    "\n",
    "b_before_batch_tfm = get_blurr_tfm(dls.before_batch)\n",
    "\n",
    "b_hf_tokenizer = b_before_batch_tfm.hf_tokenizer\n",
    "b_ignore_token_id = b_before_batch_tfm.ignore_token_id\n",
    "\n",
    "test_input_ids = b[0]['input_ids'][0].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "test_trg_ids = b[1][0].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "test_trg_ids = [ trg[trg != b_ignore_token_id] for trg in test_trg_ids ]\n",
    "\n",
    "gen_text = learn.model.hf_model.generate(test_input_ids, num_beams=4, max_length=130, min_length=30)\n",
    "\n",
    "print('=== Target ===')\n",
    "print(f'{b_hf_tokenizer.decode(test_trg_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)}\\n')\n",
    "\n",
    "print('=== Prediction ===')\n",
    "print(b_hf_tokenizer.decode(gen_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add a `blurr_generate` method to `Learner` that uses huggingface's `PreTrainedModel.generate` to create our predictions.  For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_generate(self:Learner, inp, task=None, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text \n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "    hf_config = hf_before_batch_tfm.hf_config\n",
    "    hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_before_batch_tfm.tok_kwargs\n",
    "    \n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = hf_before_batch_tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    if (isinstance(inp, str)):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors='pt', **tok_kwargs)\n",
    "    else:\n",
    "        # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "        input_ids = inp.as_subclass(Tensor)\n",
    "        \n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    \n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [ hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) \n",
    "               for txt in gen_texts ]\n",
    "    \n",
    "    if hf_before_batch_tfm.hf_arch == 'pegasus':\n",
    "        outputs = [o.replace('<n>', ' ') for o in outputs]\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_generate\" class=\"doc_header\"><code>Learner.blurr_generate</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_generate</code>(**`inp`**, **`task`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text \n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " 10 men with pistols and machine guns raid Swiss casino .\n",
      "They make off with several hundred thousand Swiss francs .\n",
      "A woman driving by unknowingly blocks their vehicles and is beaten by one of them .\n",
      "There were about 600 people in the casino at the time of the robbery .\n",
      "No serious injuries, although one guest was kicked in the head .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " 10 men with pistols and machine guns raid Swiss casino .\n",
      "They make off with several hundred thousand Swiss francs .\n",
      "A woman driving by unknowingly blocks their vehicles and is beaten by one of them .\n",
      "There were about 600 people in the casino at the time of the robbery .\n",
      "The robbers spoke French and drove vehicles with French plates .\n",
      "\n",
      "=== Prediction 3 ===\n",
      " 10 men with pistols and machine guns raid Swiss casino .\n",
      "They make off with several hundred thousand Swiss francs .\n",
      "A woman driving by unknowingly blocks their vehicles and is beaten by one of them .\n",
      "There were about 600 people in the casino at the time of the robbery .\n",
      "No serious injuries were reported .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much nicer!!! Now, we can update our @typedispatched `show_results` to use this new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_Seq2SeqInput, y, samples, outs, learner, ctxs=None, max_n=6, \n",
    "                 input_trunc_at=None, target_trunc_at=None, text_gen_kwargs={}, **kwargs):  \n",
    "    \n",
    "    hf_before_batch_tfm = get_blurr_tfm(learner.dls.before_batch)\n",
    "    hf_config = hf_before_batch_tfm.hf_config\n",
    "    hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "    ignore_token_id = hf_before_batch_tfm.ignore_token_id\n",
    "    \n",
    "    if (len(text_gen_kwargs) == 0): text_gen_kwargs = hf_before_batch_tfm.text_gen_kwargs\n",
    "    \n",
    "    gen_text_txts = learner.blurr_generate(x, **text_gen_kwargs)\n",
    "    res = L([(\n",
    "        hf_tokenizer.decode(s[0], skip_special_tokens=True)[:input_trunc_at], \n",
    "        hf_tokenizer.decode(s[1][s[1] != ignore_token_id], skip_special_tokens=True)[:target_trunc_at], \n",
    "        gen_txt[:target_trunc_at]\n",
    "    ) for s, gen_txt in zip(samples, gen_text_txts) ])          \n",
    "    \n",
    "    display_df(pd.DataFrame(res, columns=['text', 'target', 'prediction'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan Condon believes in recycling. Just not when it comes to his hotel towels. Condon composts when he's at home in Boulder, Colorado. He eats local, organic and fair-trade food and drives a Honda CR-Z hybrid sports car. You might call him green. Except he's not so green when he travels for his work at an education nonprofit and stays in a hotel, which happens about 10 weeks per year. There, he uses a new towel every day. And don't try to bribe him with a drink or dessert coupon to get him to re</td>\n",
       "      <td>Hotel guests who \"go green\" are happier with their stay.\\nIncreasing water and energy costs are pushing hotels to cut costs wherever they can.\\nMany hotels find that guests don't mind using the same towels and sheets every night.\\nTripAdvisor will be a</td>\n",
       "      <td>Dan Condon composts when he's at home in Boulder, Colorado, and drives a Honda CR-Z hybrid sports car .\\nWhen he travels for work and stays in a hotel, he uses a new towel every day .\\nCondon: \"I could care less about rewards for environmentally consc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some U.S. officials this year are expected to get smartphones capable of handling classified government documents over cellular networks, according to people involved in the project. The phones will run a modified version of Google's Android software, which is being developed as part of an initiative that spans multiple federal agencies and government contractors, these people said. The smartphones are first being deployed to U.S. soldiers, people familiar with the project said. Later, federal</td>\n",
       "      <td>Government, military officials to get Android phones capable of sharing secret documents.\\nThe phones will run a modified version of Google's Android software, sources say.\\nContractor: Google \"more cooperative\" than Apple working with government on p</td>\n",
       "      <td>Some U.S. officials this year are expected to get smartphones capable of handling classified documents over cellular networks .\\nThe phones will run a modified version of Google's Android software, sources say .\\nThey are first being deployed to soldi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'summarize_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 10 men with pistols and machine guns raid Swiss casino .\\nThey make off with several hundred thousand Swiss francs .\\nA woman driving by unknowingly blocks their vehicles and is beaten by one of them .\\nThere were about 600 people in the casino at the time of the robbery .\\nNo serious injuries, although one guest was kicked in the head .']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
