{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.question_answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data.question_answering\n",
    "\n",
    "> Question/Answering tasks are models that require two text inputs (a context that includes the answer and the question).  The objective is to predict the start/end tokens of the answer in the context). This module contains the bits required to use the fastai DataBlock API and/or mid-level data processing pipelines to organize your data for question/answering tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import ast\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import Dataset\n",
    "from fastcore.all import *\n",
    "from fastai.data.block import DataBlock, CategoryBlock, ColReader, ColSplitter\n",
    "from fastai.imports import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from transformers import AutoModelForQuestionAnswering, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel, logging\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.core import TextInput, BatchTokenizeTransform, Preprocessor, first_blurr_tfm\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.data.transforms import *\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.data.core import TextBlock\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a subset of `squad_v2` to demonstrate how to configure your blurr code for extractive question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_v2 (/home/wgilliam/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712901fe75ad4e35913dd8876c5b8da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad_v2\", split=[\"train[:1000]\", \"validation[:200]\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds, raw_valid_ds = raw_datasets[0], raw_datasets[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "raw_train_df = pd.DataFrame(raw_train_ds)\n",
    "raw_valid_df = pd.DataFrame(raw_valid_ds)\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "print(len(raw_train_df))\n",
    "print(len(raw_valid_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start': [269]}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>{'text': ['singing and dancing'], 'answer_start': [207]}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56be85543aeaaa14008c9063  Beyoncé   \n",
       "1  56be85543aeaaa14008c9065  Beyoncé   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "                                                     question  \\\n",
       "0                    When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was growing up?   \n",
       "\n",
       "                                                    answers  is_valid  \n",
       "0    {'text': ['in the late 1990s'], 'answer_start': [269]}     False  \n",
       "1  {'text': ['singing and dancing'], 'answer_start': [207]}     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>{'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56ddde6b9a695914005b9629</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>{'text': ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56ddde6b9a695914005b9628  Normans   \n",
       "1  56ddde6b9a695914005b9629  Normans   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...   \n",
       "1  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...   \n",
       "\n",
       "                               question  \\\n",
       "0  In what country is Normandy located?   \n",
       "1    When were the Normans in Normandy?   \n",
       "\n",
       "                                                                                               answers  \\\n",
       "0             {'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}   \n",
       "1  {'text': ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries'...   \n",
       "\n",
       "   is_valid  \n",
       "0      True  \n",
       "1      True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_valid_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "len(squad_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>{'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}</td>\n",
       "      <td>True</td>\n",
       "      <td>159</td>\n",
       "      <td>France</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56ddde6b9a695914005b9629</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>{'text': ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries'...</td>\n",
       "      <td>True</td>\n",
       "      <td>94</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56ddde6b9a695914005b9628  Normans   \n",
       "1  56ddde6b9a695914005b9629  Normans   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...   \n",
       "1  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...   \n",
       "\n",
       "                               question  \\\n",
       "0  In what country is Normandy located?   \n",
       "1    When were the Normans in Normandy?   \n",
       "\n",
       "                                                                                               answers  \\\n",
       "0             {'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}   \n",
       "1  {'text': ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries'...   \n",
       "\n",
       "   is_valid ans_start_char_idx              answer_text  ans_end_char_idx  \n",
       "0      True                159                   France               165  \n",
       "1      True                 94  10th and 11th centuries               117  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "print(len(squad_df))\n",
    "squad_df[squad_df.is_valid == True].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForQuestionAnswering\n",
    "\n",
    "pretrained_model_name = \"roberta-base\"  #'xlm-mlm-ende-1024'\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "max_seq_len = 128\n",
    "vocab = dict(enumerate(range(max_seq_len)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "With version 2.0.0 of BLURR, we include a `Preprocessor` for question answering that can either truncate texts or else chunk long documents into multiple examples.\n",
    "\n",
    "**Note**: Unlike other NLP tasks in BLURR, extractive question answering ***requires*** preprocessing in order to convert our raw start/end character indices into start/end token indices unless your dataset includes the later.  Token indicies, rather than character indices, will be used as our targets and are dependent on your tokenizer of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAPreprocessor(Preprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # A Hugging Face tokenizer\n",
    "        hf_tokenizer: PreTrainedTokenizerBase,\n",
    "        # The number of examples to process at a time\n",
    "        batch_size: int = 1000,\n",
    "        # The unique identifier in the dataset. If not specified and \"return_overflowing_tokens\": True, an \"_id\" attribute\n",
    "        # will be added to your dataset with its value a unique, sequential integer, assigned to each record\n",
    "        id_attr: Optional[str] = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        ctx_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        qst_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        ans_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        ans_start_char_idx: str = \"ans_start_char_idx\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        ans_end_char_idx: str = \"ans_end_char_idx\",\n",
    "        # The attribute that should be created if your are processing individual training and validation\n",
    "        # datasets into a single dataset, and will indicate to which each example is associated\n",
    "        is_valid_attr: Optional[str] = \"is_valid\",\n",
    "        # Tokenization kwargs that will be applied with calling the tokenizer (default: {\"return_overflowing_tokens\": True})\n",
    "        tok_kwargs: dict = {\"return_overflowing_tokens\": True},\n",
    "    ):\n",
    "        # these values are mandatory\n",
    "        tok_kwargs = {**tok_kwargs, \"return_offsets_mapping\": True}\n",
    "\n",
    "        # shift the question and context appropriately based on the tokenizers padding strategy\n",
    "        if hf_tokenizer.padding_side == \"right\":\n",
    "            tok_kwargs[\"truncation\"] = \"only_second\"\n",
    "            text_attrs = [qst_attr, ctx_attr]\n",
    "        else:\n",
    "            tok_kwargs[\"truncation\"] = \"only_first\"\n",
    "            text_attrs = [ctx_attr, qst_attr]\n",
    "\n",
    "        super().__init__(hf_tokenizer, batch_size, text_attr=text_attrs[0], text_pair_attr=text_attrs[1], tok_kwargs=tok_kwargs)\n",
    "        store_attr()\n",
    "\n",
    "    def process_df(self, training_df: pd.DataFrame, validation_df: Optional[pd.DataFrame] = None):\n",
    "        df = super().process_df(training_df, validation_df)\n",
    "\n",
    "        # a unique Id for each example is required to properly score question answering results when chunking long\n",
    "        # documents (e.g., return_overflowing_tokens=True)\n",
    "        chunk_docs = self.tok_kwargs.get(\"return_overflowing_tokens\", False)\n",
    "        max_length = self.tok_kwargs.get(\"max_length\", self.hf_tokenizer.model_max_length)\n",
    "\n",
    "        if self.id_attr is None and chunk_docs:\n",
    "            df.insert(0, \"_id\", range(len(df)))\n",
    "\n",
    "        # process df in mini-batches\n",
    "        final_df = pd.DataFrame()\n",
    "        for g, batch_df in df.groupby(np.arange(len(df)) // self.batch_size):\n",
    "            final_df = final_df.append(self._process_df_batch(batch_df, chunk_docs, max_length))\n",
    "\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "        return final_df\n",
    "\n",
    "    def process_hf_dataset(self, training_ds: Dataset, validation_ds: Optional[Dataset] = None):\n",
    "        ds = super().process_hf_dataset(training_ds, validation_ds)\n",
    "        return Dataset.from_pandas(self.process_df(pd.DataFrame(ds)))\n",
    "\n",
    "    # ----- utility methods -----\n",
    "    def _process_df_batch(self, batch_df, is_chunked, max_length):\n",
    "        batch_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # grab our inputs\n",
    "        inputs = self._tokenize_function(batch_df.to_dict(orient=\"list\"))\n",
    "\n",
    "        offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "        sample_map = inputs.pop(\"overflow_to_sample_mapping\", batch_df.index.tolist())\n",
    "\n",
    "        proc_data = []\n",
    "        for idx, offsets in enumerate(offset_mapping):\n",
    "            example_idx = sample_map[idx]\n",
    "            row = batch_df.iloc[example_idx]\n",
    "            input_ids = inputs[\"input_ids\"][idx]\n",
    "            seq_ids = inputs.sequence_ids(idx)\n",
    "\n",
    "            # get question and context associated with the inputs at \"idx\"\n",
    "            qst_mask = [i != 1 if self.hf_tokenizer.padding_side == \"right\" else i != 0 for i in seq_ids]\n",
    "            qst_offsets = [offsets[i] for i, is_qst in enumerate(qst_mask) if is_qst and seq_ids[i] is not None]\n",
    "            ctx_offsets = [offsets[i] for i, is_qst in enumerate(qst_mask) if not is_qst and seq_ids[i] is not None]\n",
    "\n",
    "            proc_qst = row[self.qst_attr][min(qst_offsets)[0] : max(qst_offsets)[1]]\n",
    "            proc_ctx = row[self.ctx_attr][min(ctx_offsets)[0] : max(ctx_offsets)[1]]\n",
    "\n",
    "            # if we are chunking long documents, we need to tokenize the chunked question, context in order to correctly assign\n",
    "            # the start/end token indices, else we can just the above since we are only looking at one example at a time\n",
    "            if is_chunked:\n",
    "                chunk_texts = (proc_qst, proc_ctx) if self.hf_tokenizer.padding_side == \"right\" else (proc_ctx, proc_qst)\n",
    "                chunk_inputs = self.hf_tokenizer(chunk_texts[0], chunk_texts[1])\n",
    "                chunk_input_ids = chunk_inputs[\"input_ids\"]\n",
    "                chunk_qst_mask = [i != 1 if self.hf_tokenizer.padding_side == \"right\" else i != 0 for i in chunk_inputs.sequence_ids()]\n",
    "            else:\n",
    "                chunk_input_ids, chunk_qst_mask = input_ids, qst_mask\n",
    "\n",
    "            # lastly we iterate over the input tokens to see if we can fine the answer tokens within (ignoring the input tokens\n",
    "            # belonging to the \"question\" as we only want to find answers that exist in the \"context\")\n",
    "            tok_input = self.hf_tokenizer.convert_ids_to_tokens(chunk_input_ids)\n",
    "            tok_ans = self.hf_tokenizer.tokenize(str(row[self.ans_attr]))\n",
    "\n",
    "            start_idx, end_idx = 0, 0\n",
    "            for idx, (tok, is_qst_tok) in enumerate(zip(tok_input, chunk_qst_mask)):\n",
    "                try:\n",
    "                    if is_qst_tok == False and tok == tok_ans[0] and tok_input[idx : idx + len(tok_ans)] == tok_ans:\n",
    "                        # ensure we are within the max_length\n",
    "                        last_idx = idx + len(tok_ans)\n",
    "                        if last_idx < max_length:\n",
    "                            start_idx, end_idx = idx, idx + len(tok_ans)\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # update the oringal example information with the processed question, context, start/end \"token\" indices, and\n",
    "            # a boolean indicating whether the question is answerable\n",
    "            overflow_row = row.copy()\n",
    "            overflow_row[f\"proc_{self.qst_attr}\"] = proc_qst\n",
    "            overflow_row[f\"proc_{self.ctx_attr}\"] = proc_ctx\n",
    "            overflow_row[\"ans_start_token_idx\"] = start_idx\n",
    "            overflow_row[\"ans_end_token_idx\"] = end_idx\n",
    "            overflow_row[\"is_answerable\"] = start_idx != 0 and end_idx != 0\n",
    "\n",
    "            proc_data.append(overflow_row)\n",
    "\n",
    "        return pd.DataFrame(proc_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to preprocess your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3560\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start': [269]}</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>286</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start': [269]}</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>286</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in Houston, Texas, she performed in various singing and dancing competitions as a child, and ro...</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start': [269]}</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>286</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>group became one of the world's best-selling girl groups of all time. Their hiatus saw the rele...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>{'text': ['singing and dancing'], 'answer_start': [207]}</td>\n",
       "      <td>False</td>\n",
       "      <td>207</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>226</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56be85543aeaaa14008c9063  Beyoncé   \n",
       "1  56be85543aeaaa14008c9063  Beyoncé   \n",
       "2  56be85543aeaaa14008c9063  Beyoncé   \n",
       "3  56be85543aeaaa14008c9065  Beyoncé   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "                                                     question  \\\n",
       "0                    When did Beyonce start becoming popular?   \n",
       "1                    When did Beyonce start becoming popular?   \n",
       "2                    When did Beyonce start becoming popular?   \n",
       "3  What areas did Beyonce compete in when she was growing up?   \n",
       "\n",
       "                                                    answers  is_valid  \\\n",
       "0    {'text': ['in the late 1990s'], 'answer_start': [269]}     False   \n",
       "1    {'text': ['in the late 1990s'], 'answer_start': [269]}     False   \n",
       "2    {'text': ['in the late 1990s'], 'answer_start': [269]}     False   \n",
       "3  {'text': ['singing and dancing'], 'answer_start': [207]}     False   \n",
       "\n",
       "  ans_start_char_idx          answer_text  ans_end_char_idx  \\\n",
       "0                269    in the late 1990s               286   \n",
       "1                269    in the late 1990s               286   \n",
       "2                269    in the late 1990s               286   \n",
       "3                207  singing and dancing               226   \n",
       "\n",
       "                                                proc_question  \\\n",
       "0                    When did Beyonce start becoming popular?   \n",
       "1                    When did Beyonce start becoming popular?   \n",
       "2                    When did Beyonce start becoming popular?   \n",
       "3  What areas did Beyonce compete in when she was growing up?   \n",
       "\n",
       "                                                                                          proc_context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "1   in Houston, Texas, she performed in various singing and dancing competitions as a child, and ro...   \n",
       "2   group became one of the world's best-selling girl groups of all time. Their hiatus saw the rele...   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                   84                 89           True  \n",
       "1                   32                 37           True  \n",
       "2                    0                  0          False  \n",
       "3                   77                 80           True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_kwargs = {\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    "preprocessor = QAPreprocessor(hf_tokenizer, id_attr=\"id\", tok_kwargs=tok_kwargs)\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "\n",
    "print(len(proc_df))\n",
    "proc_df.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = proc_df.sample(n=10)\n",
    "for row_idx, row in sampled_df.iterrows():\n",
    "    test_example = row\n",
    "\n",
    "    inputs = hf_tokenizer(row.proc_question, row.proc_context)\n",
    "\n",
    "    if test_example.is_answerable:\n",
    "        # print(test_example.answer_text)\n",
    "        test_eq(\n",
    "            test_example.answer_text,\n",
    "            hf_tokenizer.decode(inputs[\"input_ids\"][test_example.ans_start_token_idx : test_example.ans_end_token_idx]).strip(),\n",
    "        )\n",
    "    else:\n",
    "        test_eq(test_example.ans_start_token_idx, 0)\n",
    "        test_eq(test_example.ans_end_token_idx, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to remove texts longer than your model will hold (and include only answerable contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start': [269]}</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>286</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>{'text': ['singing and dancing'], 'answer_start': [207]}</td>\n",
       "      <td>False</td>\n",
       "      <td>207</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>226</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56be85543aeaaa14008c9063  Beyoncé   \n",
       "1  56be85543aeaaa14008c9065  Beyoncé   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "                                                     question  \\\n",
       "0                    When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was growing up?   \n",
       "\n",
       "                                                    answers  is_valid  \\\n",
       "0    {'text': ['in the late 1990s'], 'answer_start': [269]}     False   \n",
       "1  {'text': ['singing and dancing'], 'answer_start': [207]}     False   \n",
       "\n",
       "  ans_start_char_idx          answer_text  ans_end_char_idx  \\\n",
       "0                269    in the late 1990s               286   \n",
       "1                207  singing and dancing               226   \n",
       "\n",
       "                                                proc_question  \\\n",
       "0                    When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was growing up?   \n",
       "\n",
       "                                                                                          proc_context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                   84                 89           True  \n",
       "1                   77                 80           True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = QAPreprocessor(hf_tokenizer, tok_kwargs={\"return_overflowing_tokens\": False, \"max_length\": max_seq_len})\n",
    "proc2_df = preprocessor.process_df(squad_df)\n",
    "proc2_df = proc2_df[(proc2_df.ans_end_token_idx < max_seq_len) & (proc2_df.is_answerable)]\n",
    "\n",
    "print(len(proc2_df))\n",
    "proc2_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QATextInput`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QATextInput(TextInput):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QABatchTokenizeTransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QABatchTokenizeTransform(BatchTokenizeTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n",
    "        hf_arch: str,\n",
    "        # A specific configuration instance you want to use\n",
    "        hf_config: PretrainedConfig,\n",
    "        # A Hugging Face tokenizer\n",
    "        hf_tokenizer: PreTrainedTokenizerBase,\n",
    "        # A Hugging Face model\n",
    "        hf_model: PreTrainedModel,\n",
    "        # To control whether the \"labels\" are included in your inputs. If they are, the loss will be calculated in\n",
    "        # the model's forward function and you can simply use `PreCalculatedLoss` as your `Learner`'s loss function to use it\n",
    "        include_labels: bool = True,\n",
    "        # The token ID that should be ignored when calculating the loss\n",
    "        ignore_token_id=CrossEntropyLossFlat().ignore_index,\n",
    "        # To control the length of the padding/truncation. It can be an integer or None,\n",
    "        # in which case it will default to the maximum length the model can accept. If the model has no\n",
    "        # specific maximum input length, truncation/padding to max_length is deactivated.\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        max_length: int = None,\n",
    "        # To control the `padding` applied to your `hf_tokenizer` during tokenization. If None, will default to\n",
    "        # `False` or `'do_not_pad'.\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        padding: Union[bool, str] = True,\n",
    "        # To control `truncation` applied to your `hf_tokenizer` during tokenization. If None, will default to\n",
    "        # `False` or `do_not_truncate`.\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        truncation: Union[bool, str] = \"only_second\",\n",
    "        # The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. Set this to `True`\n",
    "        # if your inputs are pre-tokenized (not numericalized)\n",
    "        is_split_into_words: bool = False,\n",
    "        # Any other keyword arguments you want included when using your `hf_tokenizer` to tokenize your inputs.\n",
    "        tok_kwargs: dict = {},\n",
    "        # Keyword arguments to apply to `BatchTokenizeTransform`\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        # \"return_special_tokens_mask\" and \"return_offsets_mapping\" are mandatory for extractive QA in blurr\n",
    "        tok_kwargs = {**tok_kwargs, **{\"return_special_tokens_mask\": True, \"return_offsets_mapping\": True}}\n",
    "\n",
    "        super().__init__(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            include_labels=include_labels,\n",
    "            ignore_token_id=ignore_token_id,\n",
    "            max_length=max_length,\n",
    "            padding=padding,\n",
    "            truncation=truncation,\n",
    "            is_split_into_words=is_split_into_words,\n",
    "            tok_kwargs=tok_kwargs,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def encodes(self, samples):\n",
    "        samples, batch_encoding = super().encodes(samples, return_batch_encoding=True)\n",
    "\n",
    "        for idx, s in enumerate(samples):\n",
    "            # cls_index: location of CLS token (used by xlnet and xlm); is a list.index(value) for pytorch tensor's\n",
    "            s[0][\"cls_index\"] = (s[0][\"input_ids\"] == self.hf_tokenizer.cls_token_id).nonzero()[0]\n",
    "            # p_mask: mask with 1 for token than cannot be in the answer, else 0 (used by xlnet and xlm)\n",
    "            s[0][\"p_mask\"] = s[0][\"special_tokens_mask\"]\n",
    "\n",
    "            trgs = s[1:]\n",
    "            if self.include_labels and len(trgs) > 0:\n",
    "                s[0].pop(\"labels\") # this is added by base class, but is not needed for extractive QA\n",
    "                s[0][\"start_positions\"] = trgs[0]\n",
    "                s[0][\"end_positions\"] = trgs[1]\n",
    "                \n",
    "        return samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "The following eamples demonstrate several approaches to construct your `DataBlock` for question answering tasks using the mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch-Time Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Get your Hugging Face objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"distilroberta-base\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=AutoModelForQuestionAnswering)\n",
    "\n",
    "max_seq_len = 128\n",
    "vocab = dict(enumerate(range(max_seq_len)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start': [269]}</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>286</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56be85543aeaaa14008c9063  Beyoncé   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "                                   question  \\\n",
       "0  When did Beyonce start becoming popular?   \n",
       "\n",
       "                                                  answers  is_valid  \\\n",
       "0  {'text': ['in the late 1990s'], 'answer_start': [269]}     False   \n",
       "\n",
       "  ans_start_char_idx        answer_text  ans_end_char_idx  \\\n",
       "0                269  in the late 1990s               286   \n",
       "\n",
       "                              proc_question  \\\n",
       "0  When did Beyonce start becoming popular?   \n",
       "\n",
       "                                                                                          proc_context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                   84                 89           True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_kwargs = {\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 24}\n",
    "preprocessor = QAPreprocessor(hf_tokenizer, id_attr=\"id\", tok_kwargs=tok_kwargs)\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "\n",
    "proc_df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 3: Create your `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab),\n",
    ")\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=lambda x: (x.proc_question, x.proc_context),\n",
    "    get_y=[ColReader(\"ans_start_token_idx\"), ColReader(\"ans_end_token_idx\")],\n",
    "    splitter=ColSplitter(),\n",
    "    n_inp=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Build your `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 94)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=4)\n",
    "len(dls.train), len(dls.valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 4, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), len(b[0]), len(b[1]), len(b[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 128]), torch.Size([4, 128]), torch.Size([4]), torch.Size([4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][\"input_ids\"].shape, b[0][\"attention_mask\"].shape, b[1].shape, b[2].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorCategory([  0,  85, 108,   0], device='cuda:1'),\n",
       " TensorCategory([  0,  88, 110,   0], device='cuda:1'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][\"start_positions\"], b[0][\"end_positions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_batch(\n",
    "    # This typedispatched `show_batch` will be called for `QuestionAnswerTextInput` typed inputs\n",
    "    x: QATextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # Your `DataLoaders`. This is required so as to get at the Hugging Face objects for\n",
    "    # decoding them into something understandable\n",
    "    dataloaders,\n",
    "    # Your `show_batch` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_batch`\n",
    "    **kwargs\n",
    "):\n",
    "    # grab our tokenizer\n",
    "    tfm = first_blurr_tfm(dataloaders, tfms=[QABatchTokenizeTransform])\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    res = L()\n",
    "    for sample, input_ids, start, end in zip(samples, x, *y):\n",
    "        txt = hf_tokenizer.decode(sample[0], skip_special_tokens=True)[:trunc_at]\n",
    "        found = start.item() != 0 and end.item() != 0\n",
    "        ans_text = hf_tokenizer.decode(input_ids[start:end], skip_special_tokens=True)\n",
    "        res.append((txt, found, (start.item(), end.item()), ans_text))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"found\", \"start/end\", \"answer\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `show_batch` method above allows us to create a more interpretable view of our question/answer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyonce has been awarded how many Grammy nominations? ously in Love, B'Day and I Am... Sasha Fierce have all won Best Contemporary R&amp;B Album. Beyoncé set the record for the most Grammy awards won by a female artist in one night in 2010 when she won six awards, breaking the tie she previously held with Alicia Keys, Norah Jones, Alison Krauss, and Amy Winehouse, with Adele equaling this in 2012. Following her role in Dreamgirls she was nominated for Best Original Song for \"Listen\" and Best Actress at the Golden Globe Awards, and Outstanding Actress</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many Grammy awards did Crazy in Love get?'s \"Say My Name\" and discussed his relationship with women. In January 2012, research scientist Bryan Lessard named Scaptia beyonceae, a species of horse fly found in Northern Queensland, Australia after Beyoncé due to the fly's unique golden hairs on its abdomen. In July 2014, a Beyoncé exhibit was introduced into the \"Legends of Rock\" section of the Rock and Roll Hall of Fame. The black leotard from the \"Single Ladies\" video and her outfit from the Super Bowl half time performance are among several pieces housed at</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which song did Beyoncé release as the lead single for Austin Powers in Goldmember's soundtrack? cé starred opposite Cuba Gooding, Jr., in the musical comedy The Fighting Temptations as Lilly, a single mother whom Gooding's character falls in love with. The film received mixed reviews from critics but grossed $30 million in the U.S. Beyoncé released \"Fighting Temptation\" as the lead single from the film's soundtrack album, with Missy Elliott, MC Lyte, and Free which was also used to promote the film. Another of Beyoncé's contributions to the soundtrack, \"</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For which decade, did Beyonce have more top ten songs than any other woman? ving the accomplishment of becoming her longest-running Hot 100 single in her career, \"Halo\"'s success in the US helped Beyoncé attain more top-ten singles on the list than any other woman during the 2000s. It also included the successful \"Sweet Dreams\", and singles \"Diva\", \"Ego\", \"Broken-Hearted Girl\" and \"Video Phone\". The music video for \"Single Ladies\" has been parodied and imitated around the world, spawning the \"first major dance craze\"</td>\n",
       "      <td>True</td>\n",
       "      <td>(64, 66)</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passing extra information\n",
    "\n",
    "As mentioned in the `data.core` module documentation, BLURR now also allows you to pass extra information alongside your inputs in the form of a dictionary.  If we are splitting long documents into chunks but want to predict/aggregation by example (rather than by chunk), we'll need to include a unique identifier for each example. When we look at `modeling.question_answer` module, we'll see how the question answering bits can use such an Id for this purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Get your Hugging Face objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=AutoModelForQuestionAnswering)\n",
    "\n",
    "max_seq_len = 128\n",
    "vocab = dict(enumerate(range(max_seq_len)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start': [269]}</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>286</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...</td>\n",
       "      <td>75</td>\n",
       "      <td>79</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56be85543aeaaa14008c9063  Beyoncé   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "                                   question  \\\n",
       "0  When did Beyonce start becoming popular?   \n",
       "\n",
       "                                                  answers  is_valid  \\\n",
       "0  {'text': ['in the late 1990s'], 'answer_start': [269]}     False   \n",
       "\n",
       "  ans_start_char_idx        answer_text  ans_end_char_idx  \\\n",
       "0                269  in the late 1990s               286   \n",
       "\n",
       "                              proc_question  \\\n",
       "0  When did Beyonce start becoming popular?   \n",
       "\n",
       "                                                                                          proc_context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                   75                 79           True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = QAPreprocessor(\n",
    "    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    ")\n",
    "\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "proc_df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Create your `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab),\n",
    ")\n",
    "\n",
    "# since its preprocessed, we include an \"text\" key with the values of our question and context\n",
    "def get_x(item):\n",
    "    return {\"text\": (item.proc_question, item.proc_context), \"id\": item.id}\n",
    "\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=get_x,\n",
    "    get_y=[ItemGetter(\"ans_start_token_idx\"), ItemGetter(\"ans_end_token_idx\")],\n",
    "    splitter=ColSplitter(),\n",
    "    n_inp=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Build your `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(733, 108)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=4)\n",
    "len(dls.train), len(dls.valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 4, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), len(b[0]), len(b[1]), len(b[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'offset_mapping', 'id', 'cls_index', 'p_mask', 'start_positions', 'end_positions'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 128]), torch.Size([4, 128]), torch.Size([4]), torch.Size([4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][\"input_ids\"].shape, b[0][\"attention_mask\"].shape, b[1].shape, b[2].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that any additional data is now located in the inputs dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['56be8bab3aeaaa14008c90a1',\n",
       " '56cbedde6d243a140015edf6',\n",
       " '56cbdbf36d243a140015ed9a',\n",
       " '56bf725c3aeaaa14008c9646']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][\"id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who was the first record label to give the girls a record deal? ped and danced on the talent show circuit in houston. after seeing the group, r &amp; b producer arne frager brought them to his northern california studio and placed them in star search, the largest talent show on national tv at the time. girl's tyme failed to win, and beyonce later said the song they performed was not good. in 1995 beyonce's father resigned from his job to manage the group. the move reduced beyonce's family's income by half, and her parents were forced to move into separated apartments. mathew</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when did chopin die? zek chopin, [ n 1 ] was a polish and french ( by citizenship and birth of father ) composer and a virtuoso pianist of the romantic era, who wrote primarily for the solo piano. he gained and has maintained renown worldwide as one of the leading musicians of his era, whose \" poetic genius was based on a professional technique that was without equal in his generation. \" chopin was born in what was then the duchy of warsaw, and grew up in warsaw, which after 1815 became part of congress poland. a child prodigy, he completed his musical education and composed his earlier works</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for what network, did beyonce land a major movie role in? the remaining band members recorded \" independent women part i \", which appeared on the soundtrack to the 2000 film, charlie's angels. it became their best - charting single, topping the u. s. billboard hot 100 chart for eleven consecutive weeks. in early 2001, while destiny's child was completing their third album, beyonce landed a major role in the mtv made - for - television film, carmen : a hip hopera, starring alongside american actor mekhi phifer. set in philadelphia, the film is a modern interpretation of the 19th century opera</td>\n",
       "      <td>True</td>\n",
       "      <td>(87, 88)</td>\n",
       "      <td>mtv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>which of chopin's sisters would play music with him? fryderyk may have had some piano instruction from his mother, but his first professional music tutor, from 1816 to 1821, was the czech pianist wojciech zywny. his elder sister ludwika also took lessons from zywny, and occasionally played duets with her brother. it quickly became apparent that he was a child prodigy. by the age of seven fryderyk had begun giving public concerts, and in 1817 he composed two polonaises, in g minor and b - flat major. his next work, a polonaise in</td>\n",
       "      <td>True</td>\n",
       "      <td>(54, 58)</td>\n",
       "      <td>ludwika</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module includes all the low, mid, and high-level API bits for extractive Q&A tasks data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
