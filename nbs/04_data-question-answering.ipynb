{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.question_answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data.question_answering\n",
    "\n",
    "> Question/Answering tasks are models that require two text inputs (a context that includes the answer and the question).  The objective is to predict the start/end tokens of the answer in the context). This module contains the bits required to use the fastai DataBlock API and/or mid-level data processing pipelines to organize your data for question/answering tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import ast\n",
    "from functools import reduce\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.data.block import DataBlock, CategoryBlock, ColReader, ColSplitter\n",
    "from fastai.imports import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from transformers import AutoModelForQuestionAnswering, logging, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.core import HF_BaseInput, HF_AfterBatchTransform, HF_BeforeBatchTransform, first_blurr_tfm\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.15.0\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.data.transforms import *\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.data.core import HF_TextBlock\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a subset of `squad_v2` to demonstrate how to configure your blurr code for extractive question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_v2 (/home/wgilliam/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/ba48bc29b974701e9ba8d80ac94f3e3df924aba41b764dcf9851debea7c672e4)\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset(\"squad_v2\", split='train[:1000]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [269], 'text': ['in the late 1990s']}</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [207], 'text': ['singing and dancing']}</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...</td>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    answers  \\\n",
       "0    {'answer_start': [269], 'text': ['in the late 1990s']}   \n",
       "1  {'answer_start': [207], 'text': ['singing and dancing']}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...   \n",
       "\n",
       "                         id  \\\n",
       "0  56be85543aeaaa14008c9063   \n",
       "1  56be85543aeaaa14008c9065   \n",
       "\n",
       "                                                     question    title  \n",
       "0                    When did Beyonce start becoming popular?  Beyoncé  \n",
       "1  What areas did Beyonce compete in when she was growing up?  Beyoncé  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df = pd.DataFrame(train_ds)\n",
    "\n",
    "print(len(squad_df))\n",
    "squad_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForQuestionAnswering\n",
    "\n",
    "pretrained_model_name = \"roberta-base\"  #'xlm-mlm-ende-1024'\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "max_seq_len = 128\n",
    "vocab = dict(enumerate(range(max_seq_len)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility methods\n",
    "\n",
    "Starting with version 2.0.0, blurr provides a `find_answer_token_idxs` method that can be used in preprocessing your raw dataset beforehand, or on the fly.  It returns tensors indicating the start/end token indicies and one indicating whether the answer can be found in the provided set of `input_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_answer_token_idxs(ans_data, input_ids, offset_mapping, qst_mask):\n",
    "    # mask the question tokens so they aren't included in the search\n",
    "    masked_offset_mapping = offset_mapping.clone()\n",
    "    masked_offset_mapping[qst_mask] = tensor([-100, -100])\n",
    "\n",
    "    # based on the character start/end index, see if we can find the span of tokens in the `offset_mapping`\n",
    "    starts = torch.where((masked_offset_mapping[:, 0] == ans_data[1]) | (masked_offset_mapping[:, 1] == ans_data[1]))[0]\n",
    "    ends = torch.where((masked_offset_mapping[:, 0] <= ans_data[2]) & (masked_offset_mapping[:, 1] >= ans_data[2]))[0]\n",
    "\n",
    "    if len(starts) > 0 and len(ends) > 0:\n",
    "        start, end = starts[-1], ends[-1]\n",
    "        for s, e in itertools.product(starts, ends):\n",
    "            txt = hf_tokenizer.decode(input_ids[s:e])\n",
    "            if txt.strip() == ans_data[0].strip():\n",
    "                start, end = s, e\n",
    "                break\n",
    "\n",
    "        if end < len(masked_offset_mapping):\n",
    "            return (start, end, tensor(1))\n",
    "\n",
    "    # if neither star or end is found, or the end token is part of this chunk, consider the answer not found\n",
    "    return (tensor(0), tensor(0), tensor(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"find_answer_token_idxs\" class=\"doc_header\"><code>find_answer_token_idxs</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>find_answer_token_idxs</code>(**`ans_data`**, **`input_ids`**, **`offset_mapping`**, **`qst_mask`**)\n",
       "\n",
       "\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`ans_data`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`input_ids`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`offset_mapping`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`qst_mask`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(find_answer_token_idxs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing methods\n",
    "\n",
    "With version 2.0.0 of blurr, we include a generalized preprocessing function you can use for finding the start/end token indicies based on your tokenizer of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def pre_process_qa(\n",
    "    # Your pd.DataFrame\n",
    "    raw_df,\n",
    "    # The abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n",
    "    hf_arch: str,\n",
    "    # A Hugging Face tokenizer\n",
    "    hf_tokenizer: PreTrainedTokenizerBase,\n",
    "    # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "    ctx_attr: str = \"context\",\n",
    "    # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "    qst_attr: str = \"question\",\n",
    "    # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "    ans_attr: str = \"answer_text\",\n",
    "    # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "    ans_start_char_idx: str = \"ans_start_char_idx\",\n",
    "    # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "    ans_end_char_idx: str = \"ans_end_char_idx\",\n",
    "    # Other column data from the raw DataFrame you want to include in the processed DataFrame\n",
    "    keep_cols: list = [],\n",
    "    # Any keyword arguments you want your Hugging Face tokenizer to use during tokenization\n",
    "    tok_kwargs: dict = {\"return_overflowing_tokens\": True},\n",
    "):\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    # these values are mandatory\n",
    "    tok_kwargs[\"return_offsets_mapping\"] = True\n",
    "    tok_kwargs[\"padding\"] = tok_kwargs.get(\"padding\", True)\n",
    "    tok_kwargs[\"return_tensors\"] = \"pt\"\n",
    "\n",
    "    proc_data = []\n",
    "    for row_idx, row in df.iterrows():\n",
    "        # fetch data elements required to build a modelable dataset\n",
    "        context, qst = row[ctx_attr], row[qst_attr]\n",
    "        ans_text, start_char_idx, end_char_idx = row[ans_attr], row[ans_start_char_idx], row[ans_end_char_idx] + 1\n",
    "        ans_data = (ans_text, start_char_idx, end_char_idx)\n",
    "\n",
    "        # shift the question and context appropriately based on the tokenizers padding strategy\n",
    "        if hf_tokenizer.padding_side == \"right\":\n",
    "            tok_kwargs[\"truncation\"] = \"only_second\"\n",
    "            tok_d = hf_tokenizer(qst.lstrip(), context, **tok_kwargs)\n",
    "        else:\n",
    "            tok_kwargs[\"truncation\"] = \"only_first\"\n",
    "            tok_d = hf_tokenizer(context, qst.lstrip(), **tok_kwargs)\n",
    "\n",
    "        overflow_mapping = tok_d[\"overflow_to_sample_mapping\"] if (\"overflow_to_sample_mapping\" in tok_d) else [0]\n",
    "\n",
    "        for idx in overflow_mapping:\n",
    "            # update the targets: is_found (s[1]), answer start token index (s[2]), and answer end token index (s[3])\n",
    "            qst_mask = [i != 1 for i in tok_d.sequence_ids(idx)]\n",
    "            start, end, has_ans = find_answer_token_idxs(ans_data, tok_d[\"input_ids\"][idx], tok_d[\"offset_mapping\"][idx], qst_mask)\n",
    "            start, end, has_ans = start.item(), end.item(), has_ans.item()\n",
    "\n",
    "            row_data = [qst, context, ans_text, has_ans, start, end, start_char_idx, end_char_idx]\n",
    "            row_data += [row[col] for col in keep_cols]\n",
    "\n",
    "            proc_data.append(row_data)\n",
    "\n",
    "    proc_df = pd.DataFrame(\n",
    "        proc_data,\n",
    "        columns=[\n",
    "            \"question\",\n",
    "            \"context\",\n",
    "            \"answer_text\",\n",
    "            \"has_answer\",\n",
    "            \"ans_start_token_idx\",\n",
    "            \"ans_end_token_idx\",\n",
    "            \"ans_start_char_idx\",\n",
    "            \"ans_end_char_idx\",\n",
    "        ]\n",
    "        + keep_cols,\n",
    "    )\n",
    "    return proc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"pre_process_qa\" class=\"doc_header\"><code>pre_process_qa</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>pre_process_qa</code>(**`raw_df`**, **`hf_arch`**:`str`, **`hf_tokenizer`**:`PreTrainedTokenizerBase`, **`ctx_attr`**:`str`=*`'context'`*, **`qst_attr`**:`str`=*`'question'`*, **`ans_attr`**:`str`=*`'answer_text'`*, **`ans_start_char_idx`**:`str`=*`'ans_start_char_idx'`*, **`ans_end_char_idx`**:`str`=*`'ans_end_char_idx'`*, **`keep_cols`**:`list`=*`[]`*, **`tok_kwargs`**:`dict`=*`{'return_overflowing_tokens': True}`*)\n",
       "\n",
       "\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`raw_df`** : *`<class 'inspect._empty'>`*\t<p>Your pd.DataFrame</p>\n",
       "\n",
       "\n",
       " - **`hf_arch`** : *`<class 'str'>`*\t<p>The abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)</p>\n",
       "\n",
       "\n",
       " - **`hf_tokenizer`** : *`<class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'>`*\t<p>A Hugging Face tokenizer</p>\n",
       "\n",
       "\n",
       " - **`ctx_attr`** : *`<class 'str'>`*, *optional*\t<p>The attribute in your dataset that contains the context (where the answer is included) (default: 'context')</p>\n",
       "\n",
       "\n",
       " - **`qst_attr`** : *`<class 'str'>`*, *optional*\t<p>The attribute in your dataset that contains the question being asked (default: 'question')</p>\n",
       "\n",
       "\n",
       " - **`ans_attr`** : *`<class 'str'>`*, *optional*\t<p>The attribute in your dataset that contains the actual answer (default: 'answer_text')</p>\n",
       "\n",
       "\n",
       " - **`ans_start_char_idx`** : *`<class 'str'>`*, *optional*\t<p>The attribute in your dataset that contains the actual answer (default: 'answer_text')</p>\n",
       "\n",
       "\n",
       " - **`ans_end_char_idx`** : *`<class 'str'>`*, *optional*\t<p>The attribute in your dataset that contains the actual answer (default: 'answer_text')</p>\n",
       "\n",
       "\n",
       " - **`keep_cols`** : *`<class 'list'>`*, *optional*\t<p>Other column data from the raw DataFrame you want to include in the processed DataFrame</p>\n",
       "\n",
       "\n",
       " - **`tok_kwargs`** : *`<class 'dict'>`*, *optional*\t<p>Any keyword arguments you want your Hugging Face tokenizer to use during tokenization</p>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(pre_process_qa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to preprocess your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [269], 'text': ['in the late 1990s']}</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>269</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [207], 'text': ['singing and dancing']}</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...</td>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>207</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    answers  \\\n",
       "0    {'answer_start': [269], 'text': ['in the late 1990s']}   \n",
       "1  {'answer_start': [207], 'text': ['singing and dancing']}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...   \n",
       "\n",
       "                         id  \\\n",
       "0  56be85543aeaaa14008c9063   \n",
       "1  56be85543aeaaa14008c9065   \n",
       "\n",
       "                                                     question    title  \\\n",
       "0                    When did Beyonce start becoming popular?  Beyoncé   \n",
       "1  What areas did Beyonce compete in when she was growing up?  Beyoncé   \n",
       "\n",
       "   ans_start_char_idx          answer_text  ans_end_char_idx  \n",
       "0                 269    in the late 1990s               286  \n",
       "1                 207  singing and dancing               226  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0])\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0])\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "print(len(squad_df))\n",
    "squad_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>has_answer</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>269</td>\n",
       "      <td>287</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>269</td>\n",
       "      <td>287</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   question  \\\n",
       "0  When did Beyonce start becoming popular?   \n",
       "1  When did Beyonce start becoming popular?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...   \n",
       "\n",
       "         answer_text  has_answer  ans_start_token_idx  ans_end_token_idx  \\\n",
       "0  in the late 1990s           1                   84                 89   \n",
       "1  in the late 1990s           1                   84                 89   \n",
       "\n",
       "   ans_start_char_idx  ans_end_char_idx                        id    title  \n",
       "0                 269               287  56be85543aeaaa14008c9063  Beyoncé  \n",
       "1                 269               287  56be85543aeaaa14008c9063  Beyoncé  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_df = pre_process_qa(\n",
    "    squad_df,\n",
    "    hf_arch,\n",
    "    hf_tokenizer,\n",
    "    keep_cols=[\"id\", \"title\"],\n",
    "    tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 2},\n",
    ")\n",
    "\n",
    "print(len(proc_df))\n",
    "proc_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = proc_df.sample(n=10)\n",
    "for row_idx, row in sampled_df.iterrows():\n",
    "    test_example = row\n",
    "    tok_d = hf_tokenizer(test_example.question, test_example.context)\n",
    "\n",
    "    if test_example.has_answer == 1:\n",
    "        # print(test_example.answer_text.strip())\n",
    "        # print(hf_tokenizer.decode(tok_d[\"input_ids\"][test_example.ans_start_token_idx : test_example.ans_end_token_idx]).strip())\n",
    "        test_eq(\n",
    "            test_example.answer_text,\n",
    "            hf_tokenizer.decode(tok_d[\"input_ids\"][test_example.ans_start_token_idx : test_example.ans_end_token_idx]).strip(),\n",
    "        )\n",
    "    else:\n",
    "        test_eq(test_example.ans_start_token_idx, 0)\n",
    "        test_eq(test_example.ans_end_token_idx, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to remove texts longer than your model will hold (and include only answerable contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>has_answer</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>269</td>\n",
       "      <td>287</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>269</td>\n",
       "      <td>287</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   question  \\\n",
       "0  When did Beyonce start becoming popular?   \n",
       "1  When did Beyonce start becoming popular?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five G...   \n",
       "\n",
       "         answer_text  has_answer  ans_start_token_idx  ans_end_token_idx  \\\n",
       "0  in the late 1990s           1                   84                 89   \n",
       "1  in the late 1990s           1                   84                 89   \n",
       "\n",
       "   ans_start_char_idx  ans_end_char_idx                        id    title  \n",
       "0                 269               287  56be85543aeaaa14008c9063  Beyoncé  \n",
       "1                 269               287  56be85543aeaaa14008c9063  Beyoncé  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc2_df = proc_df[(proc_df.ans_end_token_idx < max_seq_len) & (proc_df.has_answer == 1)]\n",
    "\n",
    "print(len(proc2_df))\n",
    "proc2_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `HF_QuestionAnswerInput`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_QuestionAnswerInput(HF_BaseInput):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `HF_QABeforeBatchTransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_QABeforeBatchTransform(HF_BeforeBatchTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n",
    "        hf_arch: str,\n",
    "        # A specific configuration instance you want to use\n",
    "        hf_config: PretrainedConfig,\n",
    "        # A Hugging Face tokenizer\n",
    "        hf_tokenizer: PreTrainedTokenizerBase,\n",
    "        # A Hugging Face model\n",
    "        hf_model: PreTrainedModel,\n",
    "        # To control the length of the padding/truncation. It can be an integer or None,\n",
    "        # in which case it will default to the maximum length the model can accept. If the model has no\n",
    "        # specific maximum input length, truncation/padding to max_length is deactivated.\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        max_length: int = None,\n",
    "        # To control the `padding` applied to your `hf_tokenizer` during tokenization. If None, will default to\n",
    "        # `False` or `'do_not_pad'.\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        padding: Union[bool, str] = True,\n",
    "        # To control `truncation` applied to your `hf_tokenizer` during tokenization. If None, will default to\n",
    "        # `False` or `do_not_truncate`.\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        truncation: Union[bool, str] = \"only_second\",\n",
    "        # The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. Set this to `True`\n",
    "        # if your inputs are pre-tokenized (not numericalized)\n",
    "        is_split_into_words: bool = False,\n",
    "        # The token ID that should be ignored when calculating the loss\n",
    "        ignore_token_id=CrossEntropyLossFlat().ignore_index,\n",
    "        # Any other keyword arguments you want included when using your `hf_tokenizer` to tokenize your inputs\n",
    "        tok_kwargs: dict = {},\n",
    "        # Keyword arguments to apply to `HF_BeforeBatchTransform`\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        # \"return_special_tokens_mask\" and \"return_offsets_mapping\" are mandatory for extractive QA in blurr\n",
    "        tok_kwargs = { **tok_kwargs, **{\"return_special_tokens_mask\": True, \"return_offsets_mapping\": True}}\n",
    "\n",
    "        super().__init__(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            max_length=max_length,\n",
    "            padding=padding,\n",
    "            truncation=truncation,\n",
    "            is_split_into_words=is_split_into_words,\n",
    "            ignore_token_id = ignore_token_id,\n",
    "            tok_kwargs=tok_kwargs,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def encodes(self, samples):\n",
    "        samples, batch_encoding = super().encodes(samples, return_batch_encoding=True)\n",
    "\n",
    "        updated_samples = []\n",
    "        for idx, s in enumerate(samples):\n",
    "            # update the targets: is_found (s[1]), answer start token index (s[2]), and answer end token index (s[3])\n",
    "            qst_mask = [i != 1 for i in batch_encoding.sequence_ids(idx)]\n",
    "            start, end, has_ans = find_answer_token_idxs(s[1], s[0][\"input_ids\"], s[0][\"offset_mapping\"], qst_mask)\n",
    "            start_t, end_t, has_ans_t = TensorCategory(start), TensorCategory(end), TensorCategory(has_ans)\n",
    "\n",
    "            # cls_index: location of CLS token (used by xlnet and xlm); is a list.index(value) for pytorch tensor's\n",
    "            s[0][\"cls_index\"] = (s[0][\"input_ids\"] == self.hf_tokenizer.cls_token_id).nonzero()[0]\n",
    "            # p_mask: mask with 1 for token than cannot be in the answer, else 0 (used by xlnet and xlm)\n",
    "            s[0][\"p_mask\"] = s[0][\"special_tokens_mask\"]\n",
    "\n",
    "            updated_samples.append((s[0], has_ans_t, start_t, end_t))\n",
    "\n",
    "        return updated_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_dummy_token_idx(r):\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Using a pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_QABeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_QuestionAnswerInput),\n",
    "    None,\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab),\n",
    ")\n",
    "\n",
    "\n",
    "def get_ans_and_start_end_char_idxs(r):\n",
    "    start = r.answers[\"answer_start\"][0]\n",
    "    answer_text = r.answers[\"text\"][0]\n",
    "    end = start + len(answer_text) + 1\n",
    "    return (answer_text, start, end)\n",
    "\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=lambda x: (x.question, x.context),\n",
    "    get_y=[get_ans_and_start_end_char_idxs, get_dummy_token_idx, get_dummy_token_idx],\n",
    "    splitter=RandomSplitter(),\n",
    "    n_inp=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(squad_df, bs=4)\n",
    "len(dls.train), len(dls.valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6, 4, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), len(b[0]), len(b[1]), len(b[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 128]), torch.Size([4, 128]), torch.Size([4]), torch.Size([4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][\"input_ids\"].shape, b[0][\"attention_mask\"].shape, b[1].shape, b[2].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_batch(\n",
    "    # This typedispatched `show_batch` will be called for `HF_QuestionAnswerInput` typed inputs\n",
    "    x: HF_QuestionAnswerInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # Your `DataLoaders`. This is required so as to get at the Hugging Face objects for\n",
    "    # decoding them into something understandable\n",
    "    dataloaders,\n",
    "    # Your `show_batch` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_batch`\n",
    "    **kwargs\n",
    "):\n",
    "    # grab our tokenizer\n",
    "    tfm = first_blurr_tfm(dataloaders, HF_QABeforeBatchTransform)\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    res = L()\n",
    "    for sample, input_ids, has_ans, start, end in zip(samples, x, *y):\n",
    "        txt = hf_tokenizer.decode(sample[0], skip_special_tokens=True)[:trunc_at]\n",
    "        found = has_ans.item() == 1\n",
    "        ans_text = hf_tokenizer.decode(input_ids[start:end], skip_special_tokens=False)\n",
    "        res.append((txt, found, (start.item(), end.item()), ans_text))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"found\", \"start/end\", \"answer\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `show_batch` method above allows us to create a more interpretable view of our question/answer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where did Beyoncé exclusively release her single, Formation? On February 6, 2016, one day before her performance at the Super Bowl, Beyoncé released a new single exclusively on music streaming service Tidal called \"Formation\".</td>\n",
       "      <td>True</td>\n",
       "      <td>(41, 43)</td>\n",
       "      <td>Tidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In what year did Frédéric officially acquire French citizenship? Chopin arrived in Paris in late September 1831; he would never return to Poland, thus becoming one of many expatriates of the Polish Great Emigration. In France he used the French versions of his given names, and after receiving French citizenship in 1835, he travelled on a French passport. However, Chopin remained close to his fellow Poles in exile as friends and confidants and he never felt fully comfortable speaking French. Cho</td>\n",
       "      <td>True</td>\n",
       "      <td>(68, 70)</td>\n",
       "      <td>1835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What did Beyonce's Fashion Diva  feature? In 2005, Beyoncé teamed up with House of Brands, a shoe company, to produce a range of footwear for House of Deréon. In January 2008, Starwave Mobile launched Beyoncé Fashion Diva, a \"high-style\" mobile game with a social networking component, featuring the House of Deréon collection. In July 2009, Beyoncé and her mother launched a new junior apparel label, Sasha Fierce for Deréon, for back-to-school selling. The collection included sportswear, outerwea</td>\n",
       "      <td>True</td>\n",
       "      <td>(73, 79)</td>\n",
       "      <td>House of Deréon collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many Grammys has Beyoncé won? Beyoncé has won 20 Grammy Awards, both as a solo artist and member of Destiny's Child, making her the second most honored female artist by the Grammys, behind Alison Krauss and the most nominated woman in Grammy Award history with 52 nominations. \"Single Ladies (Put a Ring on It)\" won Song of the Year in 2010 while \"Say My Name\" and \"Crazy in Love\" had previously won Best R&amp;B Song. Dangerously in Love, B'Day and I Am... Sasha Fierce have all won Best Contempora</td>\n",
       "      <td>True</td>\n",
       "      <td>(16, 17)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "for idx, b in enumerate(dls.valid):\n",
    "    pass\n",
    "    # for input_ids, start_idx, end_idx in zip(b[0][\"input_ids\"], b[2], b[3]):\n",
    "    #     print(hf_tokenizer.decode(input_ids))\n",
    "    #     if start_idx.item() != 0:\n",
    "    #         print(f\"*** ANSWER: {hf_tokenizer.decode(input_ids[start_idx:end_idx])} ***\\n\")\n",
    "    #     else:\n",
    "    #         print(\"*** NO ANSWER ***\")\n",
    "\n",
    "    # if (idx == 1):\n",
    "    #     break\n",
    "\n",
    "print(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Batch-time targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_QABeforeBatchTransform(\n",
    "    hf_arch,\n",
    "    hf_config,\n",
    "    hf_tokenizer,\n",
    "    hf_model,\n",
    "    max_length=max_seq_len,\n",
    "    padding=\"max_length\",\n",
    "    tok_kwargs={\"return_overflowing_tokens\": True, \"stride\": 2},\n",
    ")\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_QuestionAnswerInput),\n",
    "    None,\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab),\n",
    ")\n",
    "\n",
    "\n",
    "def get_ans_and_start_end_char_idxs(r):\n",
    "    start = r.answers[\"answer_start\"][0]\n",
    "    answer_text = r.answers[\"text\"][0]\n",
    "    end = start + len(answer_text) + 1\n",
    "    return (answer_text, start, end)\n",
    "\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=lambda x: (x.question, x.context),\n",
    "    get_y=[get_ans_and_start_end_char_idxs, get_dummy_token_idx, get_dummy_token_idx],\n",
    "    splitter=RandomSplitter(),\n",
    "    n_inp=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(squad_df, bs=4)\n",
    "len(dls.train), len(dls.valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7, 4, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), len(b[0]), len(b[1]), len(b[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 128]), torch.Size([4, 128]), torch.Size([4]), torch.Size([4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][\"input_ids\"].shape, b[0][\"attention_mask\"].shape, b[1].shape, b[2].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which prominent star felt the 2009 Female Video of the Year award should have went to Beyoncé instead of Taylor Swift?, Beyoncé embarked on the I Am... World Tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $119.5 million.</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 2009, Beyonce started her second world tour and grossed how much money? On April 4, 2008, Beyoncé married Jay Z. She publicly revealed their marriage in a video montage at the listening party for her third studio album, I Am... Sasha Fierce, in Manhattan's Sony Club on October 22, 2008. I Am... Sasha Fierce was released on November 18, 2008 in the United States. The album formally introduces Beyoncé's alter ego Sasha Fierce, conceived during the making of her 2003 single \"Crazy in Love\", sel</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 2009, Beyonce started her second world tour and grossed how much money?, debuting atop the Billboard 200, and giving Beyoncé her third consecutive number-one album in the US. The album featured the number-one song \"Single Ladies (Put a Ring on It)\" and the top-five songs \"If I Were a Boy\" and \"Halo\". Achieving the accomplishment of becoming her longest-running Hot 100 single in her career, \"Halo\"'s success in the US helped Beyoncé attain more top-ten singles on the list than any other woman</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 2009, Beyonce started her second world tour and grossed how much money?s. It also included the successful \"Sweet Dreams\", and singles \"Diva\", \"Ego\", \"Broken-Hearted Girl\" and \"Video Phone\". The music video for \"Single Ladies\" has been parodied and imitated around the world, spawning the \"first major dance craze\" of the Internet age according to the Toronto Star. The video has won several awards, including Best Video at the 2009 MTV Europe Music Awards, the 2009 Scottish MOBO Awards, and the</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "for idx, b in enumerate(dls.valid):\n",
    "    pass\n",
    "    # for input_ids, start_idx, end_idx in zip(b[0][\"input_ids\"], b[2], b[3]):\n",
    "    #     print(hf_tokenizer.decode(input_ids))\n",
    "    #     if start_idx.item() != 0:\n",
    "    #         print(f\"*** ANSWER: {hf_tokenizer.decode(input_ids[start_idx:end_idx])} ***\\n\")\n",
    "    #     else:\n",
    "    #         print(\"*** NO ANSWER ***\")\n",
    "\n",
    "    # if (idx == 1):\n",
    "    #     break\n",
    "\n",
    "print(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module includes all the low, mid, and high-level API bits for extractive Q&A tasks data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
