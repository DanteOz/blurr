{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp examples.blurr_high_level_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the high-level Blurr API\n",
    "\n",
    "> Show all of the high-level `BlurrFor<Task>` classes in action here with the raw data sourced from the [Hugging Face Datasets library](https://huggingface.co/docs/datasets/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from blurr.data.language_modeling import BertMLMStrategy, CausalLMStrategy\n",
    "from blurr.modeling.language_modeling import *\n",
    "\n",
    "from blurr.modeling.token_classification import *\n",
    "from blurr.modeling.question_answering import *\n",
    "from blurr.modeling.seq2seq.summarization import *\n",
    "from blurr.modeling.seq2seq.translation import *\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.7.1\n",
      "fastai: 2.5.0\n",
      "transformers: 4.9.2\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "import pdb\n",
    "\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Here's what we're running with ...\\n\")\n",
    "print_versions('torch fastai transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "#hide_input\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most of the code and examples in the documentation show how to work with Blurr given a pandas Dataframe, these set of examples will show you how to use the high-level Blurr API with any Hugging Face dataset. The high-level API provides one liners to build your DataBlock, DataLoaders, and Learner (with sensible defaults) from a DataFrame, CSV file, or a list of dictionaries as we do so here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclassification (one input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n",
      "\n",
      "{'idx': 0, 'label': 1, 'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\"}\n",
      "\n",
      "{'sentence': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=2, names=['unacceptable', 'acceptable'], names_file=None, id=None), 'idx': Value(dtype='int32', id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('glue', 'cola') \n",
    "print(f'{raw_datasets}\\n')\n",
    "print(f'{raw_datasets[\"train\"][0]}\\n')\n",
    "print(f'{raw_datasets[\"train\"].features}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture the indexes for both train and validation sets, use the datasets `concatenate_datasets` to put them into a single dataset, and finally use the `IndexSplitter` method to define our train/validation splits as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets['train']#.select(range(10000))\n",
    "valid_ds = raw_datasets['validation']#.select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid = train_ds.num_rows, valid_ds.num_rows\n",
    "train_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\n",
    "raw_ds = concatenate_datasets([train_ds, valid_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_kwargs = {'bs': 4, 'val_bs': 8}\n",
    "learn_kwargs = { 'metrics': [accuracy] }\n",
    "\n",
    "learn = BlearnerForSequenceClassification.from_dictionaries(raw_ds, 'distilroberta-base', \n",
    "                                                            text_attr='sentence', label_attr='label',\n",
    "                                                            dblock_splitter=IndexSplitter(valid_idxs),\n",
    "                                                            dl_kwargs=dl_kwargs, learner_kwargs=learn_kwargs)\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everybody who has ever, worked in any office which contained any typewriter which had ever been used to type any letters which had to be signed by any administrator who ever worked in any department like mine will know what I mean.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The more contented the nurses began to believe that we were going to pretend to be, the more angry we grew at the doctors.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The girl who the by works in a skyscraper and in a quonset but has a dimple on her nose.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Girl in the red coat, this girl in the red coat will put a picture of Bill on your desk before tomorrow.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, trunc_at=500, max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.497798</td>\n",
       "      <td>0.511438</td>\n",
       "      <td>0.760307</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scientists at the South Hanoi Institute of Technology have succeeded in raising one dog with five legs, another with a cow's liver, and a third with no head.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The newspaper has reported that they are about to appoint someone, but I can't remember who the newspaper has reported that they are about to appoint.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sandy is very anxious to see if the students will be able to solve the homework problem in a particular way, but she won't tell us which.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Most columnists claim that a senior White House official has been briefing them, and the newspaper today reveals which one.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sandy was trying to work out which students would be able to solve a certain problem, but she wouldn't tell us which one.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.blurr_predict` works here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1',), (#1) [tensor(1)], (#1) [tensor([0.4573, 0.5427])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict('Blurr aint no joke yo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclassification (two inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "\n",
      "{'idx': 0, 'label': 1, 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}\n",
      "\n",
      "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], names_file=None, id=None), 'idx': Value(dtype='int32', id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('glue', 'mrpc') \n",
    "print(f'{raw_datasets}\\n')\n",
    "print(f'{raw_datasets[\"train\"][0]}\\n')\n",
    "print(f'{raw_datasets[\"train\"].features}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets['train']#.select(range(10000))\n",
    "valid_ds = raw_datasets['validation']#.select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid = train_ds.num_rows, valid_ds.num_rows\n",
    "train_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\n",
    "raw_ds = concatenate_datasets([train_ds, valid_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_kwargs = {'bs': 4, 'val_bs': 8}\n",
    "learn_kwargs = { 'metrics': [F1Score(), accuracy] }\n",
    "\n",
    "learn = BlearnerForSequenceClassification.from_dictionaries(raw_ds, 'distilroberta-base', \n",
    "                                                            text_attr=['sentence1', 'sentence2'], \n",
    "                                                            label_attr='label',\n",
    "                                                            dblock_splitter=IndexSplitter(valid_idxs),\n",
    "                                                            dl_kwargs=dl_kwargs, learner_kwargs=learn_kwargs)\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" In Iraq, \" Sen. Pat Roberts, R-Kan., chairman of the intelligence committee, said on CNN's \" Late Edition \" Sunday, \" we're now fighting an anti-guerrilla... effort. \" \" In Iraq, \" Sen. Pat Roberts ( R-Kan. ), chairman of the intelligence committee, said on CNN's \" Late Edition \" yesterday, \" we're now fighting an anti-guerrilla... effort. \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With Claritin's decline, Schering-Plough's best-selling products now are two drugs used together to treat hepatitis C, the antiviral pill ribavirin and an interferon medicine called Peg-Intron. With Claritin's decline, Schering-Plough's best-selling products are now antiviral drug ribavirin and an interferon medicine called Peg-Intron -- two drugs used together to treat hepatitis C.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 30-year bond US30YT = RR grew 1-3 / 32 for a yield of 4.30 percent, down from 4.35 percent late Wednesday. At 11 a.m. ( 1500 GMT ), the 10-year note US10YT = RR was up 11 / 32 for a yield of 3.36 percent from 3.40 percent Wednesday.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Under the NBC proposal, Vivendi would merge its U.S. film and TV business with NBC's broadcast network, Spanish-language network and cable channels including CNBC and Bravo. Under a deal with General Electric's NBC, Vivendi's film and TV business would merge with NBC's broadcast network, Spanish- language network and cable channels including CNBC and Bravo.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, trunc_at=500, max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.536673</td>\n",
       "      <td>0.467462</td>\n",
       "      <td>0.852989</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said the foodservice pie business doesn 't fit the company's long-term growth strategy. \" The foodservice pie business does not fit our long-term growth strategy.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The worm attacks Windows computers via a hole in the operating system, an issue Microsoft on July 16 had warned about. The worm attacks Windows computers via a hole in the operating system, which Microsoft warned of 16 July.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The U.S. Supreme Court will hear arguments on Wednesday on whether companies can be sued under the Americans with Disabilities Act for refusing to rehire rehabilitated drug users. The high court will hear arguments today on whether companies can be sued under the ADA for refusing to rehire rehabilitated drug users.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war. His wife said he was \" 100 percent behind George Bush \" and looked forward to using his years of training in the war.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The announcement, which economists said was not a surprise, may be bittersweet for the millions of Americans without jobs. Economists said the announcement was not a surprise, and politicians said it offered little comfort to the millions of Americans without jobs.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset civil_comments (/home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit'],\n",
      "        num_rows: 1804874\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit'],\n",
      "        num_rows: 97320\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit'],\n",
      "        num_rows: 97320\n",
      "    })\n",
      "})\n",
      "\n",
      "{'identity_attack': 0.0, 'insult': 0.0, 'obscene': 0.0, 'severe_toxicity': 0.0, 'sexual_explicit': 0.0, 'text': \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\", 'threat': 0.0, 'toxicity': 0.0}\n",
      "\n",
      "{'text': Value(dtype='string', id=None), 'toxicity': Value(dtype='float32', id=None), 'severe_toxicity': Value(dtype='float32', id=None), 'obscene': Value(dtype='float32', id=None), 'threat': Value(dtype='float32', id=None), 'insult': Value(dtype='float32', id=None), 'identity_attack': Value(dtype='float32', id=None), 'sexual_explicit': Value(dtype='float32', id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('civil_comments')\n",
    "print(f'{raw_datasets}\\n')\n",
    "print(f'{raw_datasets[\"train\"][0]}\\n')\n",
    "print(f'{raw_datasets[\"train\"].features}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_cols =  ['identity_attack', 'insult', 'obscene', 'toxicity', 'severe_toxicity', 'sexual_explicit', 'threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets['train'].select(range(10000))\n",
    "valid_ds = raw_datasets['validation'].select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid = len(train_ds), len(valid_ds)\n",
    "train_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\n",
    "raw_ds = concatenate_datasets([train_ds, valid_ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels need to be OHE as ints (the raw data has them as floats). We could also do this kind of preprocessing by passing in a `preprocess_func` to our `BlearnerForSequenceClassification` factory method, especially useful if such preprocessing depends on one or more of the Hugging Face objects (e.g., config, tokenizer, model, architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-615cf128814440d8.arrow\n"
     ]
    }
   ],
   "source": [
    "def make_ohe(item):\n",
    "    for k in item.keys():\n",
    "        if (k in lbl_cols):\n",
    "            item[k] = int(np.round(item[k]))\n",
    "    return item\n",
    "\n",
    "raw_ds = raw_ds.map(make_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_kwargs = {'bs': 4, 'val_bs': 8}\n",
    "learn_kwargs = { 'metrics': [F1ScoreMulti(), accuracy_multi] }\n",
    "\n",
    "# using a List[dict] such as a Hugging Face dataset\n",
    "learn = BlearnerForSequenceClassification.from_dictionaries(raw_ds, 'distilroberta-base', \n",
    "                                                            text_attr='text', label_attr=lbl_cols,\n",
    "                                                            dblock_splitter=IndexSplitter(valid_idxs),\n",
    "                                                            dl_kwargs=dl_kwargs, learner_kwargs=learn_kwargs)\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have had a question about Einstein's Special Theory of Relativity for some time which scientists all seem to run away from.  Until 1887 the equations used for Relativity were the Galilean transformation equations.\\n\\n                                                   x'=x-vt\\n                                                   y'=y\\n                                                   z'=z\\n                                                   t'=t\\n\\nAfter 1887, scientists threw away the Galilean transfo</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've went to Pizza Jerk three times and to Red Sauce twice. Pizza Jerk's menu is larger and more complicated, and they changed several menu items after the first two, which is why it got that third visit.\\n\\nThe photos are assigned after all of my visits (so that we don't tip off owners to a coming review) and also after the first draft of my review is written. I consult with the art director about what to take photos of. In this case, yes, I did say to take more shots of Pizza Jerk.\\n\\nA few days</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The problem is that tens of millions of adult Americans work for less than a living wage.  I work in a production environment.  My job doesn't require a degree, but we have to do math, and we have to be focused.  There are no teenagers at my workplace.  Most of us are middle-aged, experienced people with a good work ethic.  When someone comes in who's not so bright, or has bad work habits, they get cycled out very quickly.  Yet most of us earn less than $12 per hour.  Our economy has devolved t</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Craig, light rail DOES NOT RELIEVE CONGESTION - NEVER HAS&lt; NEVER WILL. It carries less than one lane of traffic worth of people at many times the cost. It is a TOY TRAIN, not real transportation. Why don't you explain why people will walk 1/4 mile to a bus stop, wait 5 min, then transfer to a train, wait another 5 minutes in a bad neighborhood to transfer to the second bus that drops you off 1/4 mile from your destination. \\nTraveling to work by transit takes, on average, twice the time of drivi</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, trunc_at=500, max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.033941</td>\n",
       "      <td>0.041363</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.987642</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everyone tries to hack everyone else.   I have no doubt Russia would try to hack even canada.   However, the US has been doing the same, if we recall Snowden.\\n\\nEven Merkel's phone conversations were being tapped by the CIA. \\n\\nThe real purpose of this issue is political.  Trump is upset because people are trying to imply that he didn't deserve his victory, that the Russians helped him.  It's an ego thing.  Good CEOs sometimes have giant egos.  I have no problem with that as long as they produce results, I gladly buy shares in their company.\\n\\nOtoh, Russia did invade Crimea recently, and their missile brought down a commercial airliner and killed lots of innocent people.  The world has a right to be annoyed at the Russians.\\n\\nIf you want to find evidence of Russians hacking, you will find them.  But if you want to find China or some guy in a basement somewhere, I have no doubt you can find the same as well.  Whether they succeeded or not, that's hard to prove, but there's lots of blackhats</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you for this article.\\nErrata: My father, Dr. James Ford Lewis, was minister of the First Unitarian Church in Portland in '58-'60; he wasn't Portland's \"first Unitarian minister.\" The church was founded here in 1867 (http://bit.ly/29ClQCp).  \\nI met Mr. Ellison at Sacramento City College, not at my own university.\\nAt PCS, for \"Astoria\" I am coaching the Shoshoni language, not \"Shoshona,\" which does not exist, and there is no such thing as \"Scotch-Canadian patois.\" The Scots-Canadian accent is what I spoke of. The Iowa, Arikara, Hawaiian languages will also be heard, along with another 10+ accents of English. \\nMy work as OnStar's voice began with years of work at General Magic, where I recorded tens of thousands of prompts (rather than \"a succession of responses\") for a system, not doomed but premature, that supported 2.5 million users at its peak. (http://bit.ly/29Q7P7a).  And I am the longest-working pro voice in *speech recognition,* not in general. That would be some bold claim!</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. Alali, I am sympathetic to your position and feelings. As a Canadian I hold no ill will towards you or your family relocating to Canada. You should be aware that you and your family have been used as political pawns following the glib and ill conceived election promise made by our Prime Minister to bring 25 thousand of your compatriots to Canada by the end of 2015. It sounds as if Mr McCallum and assistants scoured UN refugee lists in an effort to press gang hapless individuals and coerce them into settling and being shipped to Canada. The expedition of your arrival was made with no regard to the logistics of accommodating vulnerable and traumatized families in a respectful and decent manner following your staged and publicized arrivals. As for your future in Canada I fear you will be lucky to find some subsistence level employment. The chances are that your children, if you allow them to assimilate into the Canadian culture, will thrive and have a rewarding life in here. Good Luck</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chittester quotes Biden--an excommunicated Catholic.\\nHilliary did not represent Catholics-- which is why Trump won the Catholic vote.\\nThese posters represent PC--progressive communists and propaganda suckers. They seem to soak up every piece of propaganda issued by progressive operatives.\\nI' m sure they all \" believe\" in AGW and population control as the remedy through abortion, they \" believe\" Adam and Eve are mythological but evolution-- long ago debunked-- is fact, they\\n \" belive\" women' s rights and feminism are not really code words for abortion and they \\n\" believe\" poor Hilliary missed her chance to make partial birth abortions taxpayer funded, religious rights non- existent, create more world chaos, incite more racial riots and divisive conflict, shut down oil companies and erect windmills, gut the country of any remaining blue collar jobs, ensure no conservative speaks outbin any college classroom, make sure all young college men have no rights when accused by disturbed girls.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regarding \"Lonely Woman\" Yes, involve herself in organizations but perhaps not a church. I enjoy my church and it is important but... Many have gossips. When living in Denver my best friend Linda and I attended together for years and I was a maid of honer in her wedding. When they moved, I attended alone and some wives began speculating I was looking for a husband. Some of the single guys heard variations of that speculation. During service a guy slid across to me and began flirting. I whispered loud enough for all around me to hear, \"Who are you! Get lost!\" The minister heard. He took a second to force down a laugh and nodded at me. The guy slithered away. The gossips saw and were nice to me afterward but that was my last day. I still saw friends who assured me it was only a few bad apples. Point being to \"Lonely Woman\" Some churches have gossip mongrels who ruin it for young, decent women. Here's an oldie but goodie for you gossips. \"Do not bare false witness against your neighbor.\"</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trun_at=500, max_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset germ_eval14 (/home/wgilliam/.cache/huggingface/datasets/germ_eval14/germeval_14/2.0.0/0f174b84866aa3b8ebae65c271610520be4422405d7e8467bd24cfd493d325f0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'source', 'tokens', 'ner_tags', 'nested_ner_tags'],\n",
      "        num_rows: 24000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'source', 'tokens', 'ner_tags', 'nested_ner_tags'],\n",
      "        num_rows: 2200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'source', 'tokens', 'ner_tags', 'nested_ner_tags'],\n",
      "        num_rows: 5100\n",
      "    })\n",
      "})\n",
      "\n",
      "{'id': '0', 'ner_tags': [19, 0, 0, 0, 7, 0, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'nested_ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'source': 'n-tv.de vom 26.02.2005 [2005-02-26] ', 'tokens': ['Schartau', 'sagte', 'dem', '\"', 'Tagesspiegel', '\"', 'vom', 'Freitag', ',', 'Fischer', 'sei', '\"', 'in', 'einer', 'Weise', 'aufgetreten', ',', 'die', 'alles', 'andere', 'als', 'überzeugend', 'war', '\"', '.']}\n",
      "\n",
      "{'id': Value(dtype='string', id=None), 'source': Value(dtype='string', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=25, names=['O', 'B-LOC', 'I-LOC', 'B-LOCderiv', 'I-LOCderiv', 'B-LOCpart', 'I-LOCpart', 'B-ORG', 'I-ORG', 'B-ORGderiv', 'I-ORGderiv', 'B-ORGpart', 'I-ORGpart', 'B-OTH', 'I-OTH', 'B-OTHderiv', 'I-OTHderiv', 'B-OTHpart', 'I-OTHpart', 'B-PER', 'I-PER', 'B-PERderiv', 'I-PERderiv', 'B-PERpart', 'I-PERpart'], names_file=None, id=None), length=-1, id=None), 'nested_ner_tags': Sequence(feature=ClassLabel(num_classes=25, names=['O', 'B-LOC', 'I-LOC', 'B-LOCderiv', 'I-LOCderiv', 'B-LOCpart', 'I-LOCpart', 'B-ORG', 'I-ORG', 'B-ORGderiv', 'I-ORGderiv', 'B-ORGpart', 'I-ORGpart', 'B-OTH', 'I-OTH', 'B-OTHderiv', 'I-OTHderiv', 'B-OTHpart', 'I-OTHpart', 'B-PER', 'I-PER', 'B-PERderiv', 'I-PERderiv', 'B-PERpart', 'I-PERpart'], names_file=None, id=None), length=-1, id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('germeval_14') \n",
    "print(f'{raw_datasets}\\n')\n",
    "print(f'{raw_datasets[\"train\"][0]}\\n')\n",
    "print(f'{raw_datasets[\"train\"].features}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets['train']#.select(range(1000))\n",
    "valid_ds = raw_datasets['validation']#.select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid = train_ds.num_rows, valid_ds.num_rows\n",
    "train_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\n",
    "raw_ds = concatenate_datasets([train_ds, valid_ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab the \"labels\" a token can be associated with as we do here or we can let the `BlearnerForTokenClassification` factory methods figure it out for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_ds.features['ner_tags'].feature.names\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we need pass the tag (not the index) for each example's tokens in a list, we use the handy `datasets.map` function to create a new attribute, \"token_labels\", with that data.  This could also be done by passing in a `preprocess_func`  to a `BlearnerForTokenClassification` factory method; especially useful if we need to use one or more of the Hugging Face objects (e.g., tokenzier, model, config, or architecture name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5225a3e2f0d04022bcb40836384d0eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26200 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_item_labels(example):\n",
    "    example['token_labels'] = [ labels[tag_idx] for tag_idx in example['ner_tags'] ]\n",
    "    return example\n",
    "                         \n",
    "raw_ds = raw_ds.map(get_item_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTokenClassification.from_dictionaries(raw_ds, 'bert-base-multilingual-cased', \n",
    "                                                         tokens_attr='tokens', token_labels_attr='token_labels', \n",
    "                                                         labels=labels, dblock_splitter=IndexSplitter(valid_idxs), \n",
    "                                                         dl_kwargs={'bs':2})\n",
    "\n",
    "learn.unfreeze()\n",
    "fit_cbs = [HF_TokenClassMetricsCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Andere', 'O'), ('Albumtitel', 'O'), ('sind', 'O'), ('an', 'O'), ('bekannte', 'O'), ('Begriffe', 'O'), ('angelehnt', 'O'), (':', 'O'), ('Fettes', 'B-OTH'), ('Brot', 'I-OTH'), ('für', 'I-OTH'), ('die', 'I-OTH'), ('Welt', 'I-OTH'), ('(', 'O'), ('Brot', 'O'), ('für', 'O'), ('die', 'O'), ('Welt', 'O'), ('),', 'O'), ('Auf', 'O'), ('einem', 'B-OTH'), ('Auge', 'I-OTH'), ('blöd', 'I-OTH'), ('(', 'I-OTH'), ('„', 'O'), ('Auf', 'O'), ('einem', 'O'), ('Auge', 'O'), ('blind', 'O'), ('),', 'O'), ('Am', 'O'), ('Wasser', 'O'), ('gebaut', 'O'), ('(', 'B-OTH'), ('„', 'I-OTH'), ('Nah', 'I-OTH'), ('am', 'O'), ('Wasser', 'O'), ('gebaut', 'O'), (')', 'O'), ('und', 'O'), ('Strom', 'O'), ('und', 'O'), ('Drang', 'O'), ('(', 'O'), ('„', 'B-OTH'), ('Sturm', 'I-OTH'), ('und', 'I-OTH'), ('Drang', 'O'), (').', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Das', 'O'), ('Spiel', 'O'), ('Während', 'O'), ('der', 'O'), ('drei', 'O'), ('Jahrtausende,', 'O'), ('in', 'O'), ('denen', 'O'), ('das', 'O'), ('Spiel', 'O'), ('gespielt', 'O'), ('wurde,', 'O'), ('änderten', 'O'), ('sich', 'O'), ('die', 'O'), ('Regeln', 'O'), ('immer', 'O'), ('wieder', 'O'), (':', 'O'), ('Die', 'O'), ('Zahl', 'O'), ('der', 'O'), ('teilnehmenden', 'O'), ('Spieler,', 'O'), ('die', 'O'), ('Körperstellen', 'O'), ('mit', 'O'), ('denen', 'O'), ('der', 'O'), ('Ball', 'O'), ('berührt', 'O'), ('werden', 'O'), ('durfte,', 'O'), ('die', 'O'), ('Folgen', 'O'), ('eines', 'O'), ('verlorenen', 'O'), ('Spieles.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.077180</td>\n",
       "      <td>0.062497</td>\n",
       "      <td>0.979905</td>\n",
       "      <td>0.855273</td>\n",
       "      <td>0.826228</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>16:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Darüber', 'O', 'O'), ('hinaus', 'O', 'O'), ('produziert', 'O', 'O'), ('der', 'O', 'O'), ('hr', 'B-ORG', 'O'), ('allein', 'O', 'B-ORG'), ('oder', 'O', 'O'), ('federführend', 'O', 'O'), ('mit', 'O', 'O'), ('anderen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Dass', 'O', 'O'), ('eine', 'O', 'O'), ('interne', 'O', 'O'), ('Lösung,', 'O', 'O'), ('für', 'O', 'O'), ('die', 'O', 'O'), ('sich', 'O', 'O'), ('Benjamin', 'O', 'O'), ('Schwarz', 'B-PER', 'O'), ('und', 'I-PER', 'B-PER')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.91      0.87      0.89       798\n",
      "    LOCderiv       0.90      0.83      0.86       256\n",
      "     LOCpart       0.62      0.73      0.67        44\n",
      "         ORG       0.81      0.73      0.77       549\n",
      "    ORGderiv       0.00      0.00      0.00         0\n",
      "     ORGpart       0.79      0.75      0.77        96\n",
      "         OTH       0.68      0.69      0.69       264\n",
      "    OTHderiv       0.69      0.73      0.71        15\n",
      "     OTHpart       0.50      0.64      0.56        14\n",
      "         PER       0.94      0.92      0.93       725\n",
      "    PERderiv       0.00      0.00      0.00         0\n",
      "     PERpart       0.11      0.29      0.16         7\n",
      "\n",
      "   micro avg       0.86      0.83      0.84      2768\n",
      "   macro avg       0.58      0.60      0.58      2768\n",
      "weighted avg       0.86      0.83      0.84      2768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.blurr_predict_tokens` works here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"I live in California, but I'd love to travel to Scotland and visit the Macallan distillery.\"\n",
    "txt2 = \"Jane Doe loves working for ohmeow.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'O'), ('live', 'O'), ('in', 'O'), ('California,', 'B-LOC'), ('but', 'O'), (\"I'd\", 'O'), ('love', 'O'), ('to', 'O'), ('travel', 'O'), ('to', 'O'), ('Scotland', 'B-LOC'), ('and', 'O'), ('visit', 'O'), ('the', 'O'), ('Macallan', 'B-ORG'), ('distillery.', 'O')]\n",
      "\n",
      "[('Jane', 'B-PER'), ('Doe', 'I-PER'), ('loves', 'O'), ('working', 'O'), ('for', 'O'), ('ohmeow.com.', 'B-OTH')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_v2 (/home/wgilliam/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/ba48bc29b974701e9ba8d80ac94f3e3df924aba41b764dcf9851debea7c672e4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 130319\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 11873\n",
      "    })\n",
      "})\n",
      "\n",
      "{'answers': {'answer_start': [269], 'text': ['in the late 1990s']}, 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".', 'id': '56be85543aeaaa14008c9063', 'question': 'When did Beyonce start becoming popular?', 'title': 'Beyoncé'}\n",
      "\n",
      "{'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('squad_v2')\n",
    "print(f'{raw_datasets}\\n')\n",
    "print(f'{raw_datasets[\"train\"][0]}\\n')\n",
    "print(f'{raw_datasets[\"train\"].features}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets['train'].select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `preprocess_func` here as the preprocessing is dependent upon the Hugging Face tokenizer which will vary dependending on the pretrained model we use for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ds(ds, hf_arch, hf_config, hf_tokenizer, hf_model, max_seq_len, \n",
    "                  context_attr, question_attr, answer_text_attr, tok_ans_start, tok_ans_end):\n",
    "    \n",
    "    def _preprocess(item):\n",
    "        tok_kwargs = {}\n",
    "        if(hf_tokenizer.padding_side == 'right'):\n",
    "            tok_input = hf_tokenizer.convert_ids_to_tokens(hf_tokenizer.encode(item[question_attr], item[context_attr]), \n",
    "                                                           **tok_kwargs)\n",
    "        else:\n",
    "            tok_input = hf_tokenizer.convert_ids_to_tokens(hf_tokenizer.encode(item[context_attr], item[question_attr]), \n",
    "                                                           **tok_kwargs)\n",
    "\n",
    "        tok_ans = hf_tokenizer.tokenize(str(item['answers']['text'][0]), **tok_kwargs)\n",
    "        \n",
    "        start_idx, end_idx = 0,0\n",
    "        \n",
    "        if(len(tok_input) < max_seq_len):\n",
    "            for idx, tok in enumerate(tok_input):\n",
    "                try:\n",
    "                    if (tok == tok_ans[0] and tok_input[idx:idx + len(tok_ans)] == tok_ans): \n",
    "                        start_idx, end_idx = idx, idx + len(tok_ans)\n",
    "                        break\n",
    "                except: pass\n",
    "\n",
    "        item['tokenized_input'] = tok_input\n",
    "        item['tokenized_input_len'] = len(tok_input)\n",
    "        item['tok_answer_start'] = start_idx\n",
    "        item['tok_answer_end'] = end_idx\n",
    "\n",
    "        return item\n",
    "    \n",
    "    ds = ds.map(_preprocess)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3641fd71797433490d74b891f792c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "\n",
    "learn = BlearnerForQuestionAnswering.from_dataframe(train_ds, pretrained_model_name,\n",
    "                                                    preprocess_func=preprocess_ds, max_seq_len=256,\n",
    "                                                    dblock_splitter=RandomSplitter(), dl_kwargs={ 'bs': 4 })\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which prominent star felt the 2009 female video of the year award should have went to beyonce instead of taylor swift? on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the mak</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>her third album, \" i am... sasha fierce \" was released when? on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the making of her 2003 single \" crazy in love \", selling 482, 000</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.205399</td>\n",
       "      <td>1.983614</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who released the single girls love beyonce? her debut single, \" crazy in love \" was named vh1's \" greatest song of the 2000s \", nme's \" best track of the 00s \" and \" pop song of the century \", considered by rolling stone to be one of the 500 greatest songs of all time, earned two grammy awards and is one of the best - selling singles of all time at around 8 million copies. the music video for \" single ladies ( put a ring on it ) \", which achieved fame for its intricate choreography and its deplo</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(171, 172)</td>\n",
       "      <td>drake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who said that she is the reigning national voice? in the new yorker music critic jody rosen described beyonce as \" the most important and compelling popular musician of the twenty - first century..... the result, the logical end point, of a century - plus of pop. \" when the guardian named her artist of the decade, llewyn - smith wrote, \" why beyonce? [... ] because she made not one but two of the decade's greatest singles, with crazy in love and single ladies ( put a ring on it ), not to mention</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/wgilliam/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4358\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 36718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3760\n",
      "    })\n",
      "})\n",
      "\n",
      "{'text': ''}\n",
      "\n",
      "{'text': Value(dtype='string', id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "print(f'{raw_datasets}\\n')\n",
    "print(f'{raw_datasets[\"train\"][0]}\\n')\n",
    "print(f'{raw_datasets[\"train\"].features}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets['train'].select(range(1000))\n",
    "valid_ds = raw_datasets['validation'].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid = train_ds.num_rows, valid_ds.num_rows\n",
    "train_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\n",
    "raw_ds = concatenate_datasets([train_ds, valid_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a99d861af541a8b1cc1e3f4148b112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_empty_text(example):\n",
    "    if (example['text'].strip() == ''): example['text'] = '  '\n",
    "    return example\n",
    "raw_ds = raw_ds.map(remove_empty_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/fastai/callback/core.py:51: UserWarning: You are shadowing an attribute (__class__) that exists in the learner. Use `self.learn.__class__` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "learn = BlearnerForLM.from_dictionaries(raw_ds, 'gpt2', text_attr='text', \n",
    "                                        lm_strategy_cls=CausalLMStrategy,\n",
    "                                        dblock_splitter=IndexSplitter(valid_idxs), \n",
    "                                        dl_kwargs={'bs':2}).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A lookout aboard Weehawken spotted Atlanta at 04 : 10 on the morning of 17 June. When the latter ship closed to within about 1 @.@ 5 miles ( 2 @.@ 4 km ) of the two Union ships, she fired one round from her bow gun that passed over Weehawken and lan</td>\n",
       "      <td>lookout aboard Weehawken spotted Atlanta at 04 : 10 on the morning of 17 June. When the latter ship closed to within about 1 @.@ 5 miles ( 2 @.@ 4 km ) of the two Union ships, she fired one round from her bow gun that passed over Weehawken and lande</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N @-@ 88 starts at the Nebraska – Wyoming state line in Banner County, where WYO 151 ends, and travels northeast. The road quickly bends east after less than one mile ( 1 @.@ 6 km ), and continues in a straight line. For the next twenty miles ( 32 k</td>\n",
       "      <td>@-@ 88 starts at the Nebraska – Wyoming state line in Banner County, where WYO 151 ends, and travels northeast. The road quickly bends east after less than one mile ( 1 @.@ 6 km ), and continues in a straight line. For the next twenty miles ( 32 km</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.796121</td>\n",
       "      <td>4.396461</td>\n",
       "      <td>81.163162</td>\n",
       "      <td>0.276044</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=3e-4, cbs=[BlearnerForLM.get_metrics_cb()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meridian is rightly considered an architectural treasure trove being one the nations most intact cities from the turn of the last century. Architecture students from around the nation and Canada are known to visit Meridian in groups as part of their coursework due to numerous structures in the city having been designed by noted architects. The only home in the US south designed by noted Canadian born Architect Louis S. Curtiss, famous for inventing the glass curtain wall skyscraper, is extant o</td>\n",
       "      <td>is rightly considered an architectural treasure trove being one the nations most intact cities from the turn of the last century. Architecture students from around the nation and Canada are known to visit Meridian in groups as part of their coursework due to numerous structures in the city having been designed by noted architects. The only home in the US south designed by noted Canadian born Architect Louis S. Curtiss, famous for inventing the glass curtain wall skyscraper, is extant on Highlan</td>\n",
       "      <td>\\n a the.. of most and in the time of the century century.\\n is are the the world are around are rightly for be the. their of well of the academic.. to the historical and the city. been built by the architect and\\n city of the city of of by renowned architects architect and anda.Siss. and for hising the first and,,raper, famous well in the Park, The onlyfort, by Mile and, a considered an of the most buildingsistico buildingsrap in the world. is generally considered to the'ss Three Threeman. The onl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Headlam became Officer Commanding North @-@ Western Area in January 1946. Posted to Britain at the end of the year, he attended the Royal Air Force Staff College, Andover, and served with RAAF Overseas Headquarters, London. On his return to Australia, in November 1947, he became Director of Training at RAAF Headquarters. In November 1950, Headlam was appointed to take over command of No. 90 ( Composite ) Wing from Group Captain Paddy Heffernan. Headquartered at RAF Changi, Singapore, No. 90 Win</td>\n",
       "      <td>lam became Officer Commanding North @-@ Western Area in January 1946. Posted to Britain at the end of the year, he attended the Royal Air Force Staff College, Andover, and served with RAAF Overseas Headquarters, London. On his return to Australia, in November 1947, he became Director of Training at RAAF Headquarters. In November 1950, Headlam was appointed to take over command of No. 90 ( Composite ) Wing from Group Captain Paddy Heffernan. Headquartered at RAF Changi, Singapore, No. 90 Wing con</td>\n",
       "      <td>of, ofing Officer AmericaThe\\n-\\n of the of.\\n by the by the end of the war. and was the Royal Navy Force Academy, in andres, and the as the.,as Air, and, Posted the return to the, he 1946, he was Officer of the, theAAF,, On 1947, he of became appointed Director the charge the of the. 1 SquadronAir ) of, the 1,. (berternan, Inlam in R Headquartersi, China. and. 90 (, byAAF,, in the waray War.\\n. 90, Composite ),, No theid,.,ns, flying flying ( Bomber ) Squadron, flying Av A--,, (aras,, aircraftinco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.blurr_generate` works here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Blurr is fun to work with because , you are the best\\n \\xa0and you   you are a good friend  \\xa0we \\xa0have  \\xa0we \\xa0have \\xa0we ']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate('Blurr is fun to work with because', max_length=50, do_sample=True, top_k=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masked language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForLM.from_dictionaries(raw_ds, 'bert-base-uncased', text_attr='text', \n",
    "                                        lm_strategy_cls=BertMLMStrategy,\n",
    "                                        dblock_splitter=IndexSplitter(valid_idxs), \n",
    "                                        dl_kwargs={'bs':2}).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.869442</td>\n",
       "      <td>0.880874</td>\n",
       "      <td>2.413007</td>\n",
       "      <td>0.662066</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=3e-4, cbs=[BlearnerForLM.get_metrics_cb()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meridian is right ##ly [MASK] an architectural treasure tr ##ove being [MASK] the nations most intact [MASK] from the turn [MASK] the last century . architecture students [MASK] around the nation and canada are known to visit [MASK] in [groups] as part [MASK] their course [MASK] due to numerous structures in the city having been designed by noted architects . the [MASK] home in the us south designed by [MASK] canadian born architect louis s . [MASK] , famous [MASK] in ##venting the glass [infrared] wall skyscraper , is extant on highland park [MASK] the frank fort designed three ##foot [MASK] is generally considered one of the best [MASK] [MASK] skyscraper ##s in the us and is often [MASK] to detroit ' s famed fisher building . noted california architect wallace ne [judgments] designed a number of homes in meridian as well as in the alabama black [MASK] which ad ##jo ##ins the city across the nearby alabama state line . he had relatives in meridian and selma who [switch] executives in the [MASK] thriving railroad industry and [MASK] take [MASK] in the area when [MASK] in california were lean . his work is mostly concentrated in the lower numbered blocks of pop ##lar springs [MASK] where his [MASK] ##6 pop ##lar [MASK] drive is [often] compared to the similarly designed falcon lair , the [MASK] hills home in benedict canyon of [MASK] valentin [MASK] . one ne ##ff work was [MASK] to an expansion of anderson [MASK] in 1990 and another in marion park [burned] in the [MASK] . the meridian post office with its interior done entirely of bronze and [MASK] marble [MASK] [MASK] noteworthy as a very fine example of the type of post office structures built in thriving and well to [MASK] cities [MASK] [MASK] 1920s and originally had [MASK] ##ique lighting which was [removed] sadly during [MASK] [driving] re ##mo ##del ##ing [and] which are now in private residences on [MASK] [manager] springs drive and in north hills .</td>\n",
       "      <td>meridian is right ##ly [considered] an architectural treasure tr ##ove being [one] the nations most intact [cities] from the turn [of] the last century . architecture students [from] around the nation and canada are known to visit [meridian] in [groups] as part [of] their course [##work] due to numerous structures in the city having been designed by noted architects . the [only] home in the us south designed by [noted] canadian born architect louis s . [curtiss] , famous [for] in ##venting the glass [curtain] wall skyscraper , is extant on highland park [.] the frank fort designed three ##foot [building] is generally considered one of the best [art] [deco] skyscraper ##s in the us and is often [compared] to detroit ' s famed fisher building . noted california architect wallace ne [##ff] designed a number of homes in meridian as well as in the alabama black [belt] which ad ##jo ##ins the city across the nearby alabama state line . he had relatives in meridian and selma who [were] executives in the [then] thriving railroad industry and [would] take [commissions] in the area when [commissions] in california were lean . his work is mostly concentrated in the lower numbered blocks of pop ##lar springs [drive] where his [251] ##6 pop ##lar [springs] drive is [often] compared to the similarly designed falcon lair , the [beverly] hills home in benedict canyon of [rudolph] valentin [##o] . one ne ##ff work was [lost] to an expansion of anderson [hospital] in 1990 and another in marion park [burned] in the [1950s] . the meridian post office with its interior done entirely of bronze and [verde] marble [is] [also] noteworthy as a very fine example of the type of post office structures built in thriving and well to [do] cities [in] [the] 1920s and originally had [lal] ##ique lighting which was [removed] sadly during [a] [1960s] re ##mo ##del ##ing [and] which are now in private residences on [pop] [##lar] springs drive and in north hills .</td>\n",
       "      <td>meridian is right ##ly [considered] an architectural treasure tr ##ove being [among] the nations most intact [homes] from the turn [of] the last century . architecture students [from] around the nation and canada are known to visit [meridian] in [groups] as part [of] their course [,] due to numerous structures in the city having been designed by noted architects . the [first] home in the us south designed by [the] canadian born architect louis s . [smith] , famous [for] in ##venting the glass [-] wall skyscraper , is extant on highland park [.] the frank fort designed three ##foot [building] is generally considered one of the best [high] [brick] skyscraper ##s in the us and is often [compared] to detroit ' s famed fisher building . noted california architect wallace ne [##ff] designed a number of homes in meridian as well as in the alabama black [hills] which ad ##jo ##ins the city across the nearby alabama state line . he had relatives in meridian and selma who [were] executives in the [once] thriving railroad industry and [would] take [residence] in the area when [conditions] in california were lean . his work is mostly concentrated in the lower numbered blocks of pop ##lar springs [drive] where his [66] ##6 pop ##lar [springs] drive is [often] compared to the similarly designed falcon lair , the [north] hills home in benedict canyon of [the] valentin [##o] . one ne ##ff work was [donated] to an expansion of anderson [park] in 1990 and another in marion park [burned] in the [1990s] . the meridian post office with its interior done entirely of bronze and [white] marble [,] [is] noteworthy as a very fine example of the type of post office structures built in thriving and well to [do] cities [in] [the] 1920s and originally had [angel] ##ique lighting which was [removed] sadly during [the] [drive] re ##mo ##del ##ing [and] which are now in private residences on [both] [spring] springs drive and in north hills .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>during january 1942 , [MASK] . 2 squadron ' [MASK] aircraft [MASK] dispersed at pen [##fu] ##i [MASK] boer [MASK] island , and darwin . the pen ##fu [MASK] detachment [MASK] japanese shipping taking part in [[unused60]] invasion of ce ##le ##bes . two hudson ##s shot down or [MASK] three japanese [MASK] ##planes that attacked them as [MASK] [MASK] bombing a transport ship on 11 [MASK] [MASK] [MASK] [resentment] day both hudson ##s were themselves shot down by mitsubishi zero ##s . pen ##fu ##i was bombed by the [japanese] for [MASK] first time on 26 january 1942 , [and] attacked regularly thereafter , [MASK] some [MASK] [MASK] the intact hudson ##s were [MASK] to darwin but head [MASK] and his staff remained at pen ##fu ##i [MASK] [MASK] the base to [MASK] [MASK] by aircraft during reconnaissance missions from australia [MASK] on 18 february , [MASK] ##lam was ordered to evacuate [MASK] his personnel except a [MASK] party to demo ##lish the [MASK] with assistance from sparrow force . he returned to darwin the following day , just as the [MASK] experienced its first raid by the [MASK] [MASK] four of no [##mage] 2 squadron ' [##ona] hudson ##s were destroyed in the attack ; the [MASK] were relocated [to] daly [MASK] , [where] [MASK] [MASK] to carry out [MASK] and bombing [MASK] [MASK] [##lette] targets in [MASK] .</td>\n",
       "      <td>during january 1942 , [no] . 2 squadron ' [s] aircraft [were] dispersed at pen [##fu] ##i [,] boer [##oe] island , and darwin . the pen ##fu [##i] detachment [attacked] japanese shipping taking part in [the] invasion of ce ##le ##bes . two hudson ##s shot down or [damaged] three japanese [float] ##planes that attacked them as [they] [were] bombing a transport ship on 11 [january] [;] [the] [next] day both hudson ##s were themselves shot down by mitsubishi zero ##s . pen ##fu ##i was bombed by the [japanese] for [the] first time on 26 january 1942 , [and] attacked regularly thereafter , [damaging] some [aircraft] [.] the intact hudson ##s were [withdrawn] to darwin but head [##lam] and his staff remained at pen ##fu ##i [to] [enable] the base to [be] [used] by aircraft during reconnaissance missions from australia [.] on 18 february , [head] ##lam was ordered to evacuate [all] his personnel except a [small] party to demo ##lish the [airfield] with assistance from sparrow force . he returned to darwin the following day , just as the [city] experienced its first raid by the [japanese] [.] four of no [.] 2 squadron ' [s] hudson ##s were destroyed in the attack ; the [remainder] were relocated [to] daly [waters] , [where] [they] [continued] to carry out [reconnaissance] and bombing [missions] [against] [japanese] targets in [timor] .</td>\n",
       "      <td>during january 1942 , [no] . 2 squadron ' [s] aircraft [were] dispersed at pen [##fu] ##i [,] boer [##e] island , and darwin . the pen ##fu [##i] detachment [attacked] japanese shipping taking part in [the] invasion of ce ##le ##bes . two hudson ##s shot down or [destroyed] three japanese [float] ##planes that attacked them as [well] [as] bombing a transport ship on 11 [january] [,] [,] [the] day both hudson ##s were themselves shot down by mitsubishi zero ##s . pen ##fu ##i was bombed by the [japanese] for [the] first time on 26 january 1942 , [and] attacked regularly thereafter , [and] some [of] [of] the intact hudson ##s were [moved] to darwin but head [##lam] and his staff remained at pen ##fu ##i [,] [allowing] the base to [be] [attacked] by aircraft during reconnaissance missions from australia [.] on 18 february , [head] ##lam was ordered to evacuate [all] his personnel except a [small] party to demo ##lish the [base] with assistance from sparrow force . he returned to darwin the following day , just as the [base] experienced its first raid by the [japanese] [.] four of no [.] 2 squadron ' [s] hudson ##s were destroyed in the attack ; the [rest] were relocated [to] daly [city] , [where] [they] [continued] to carry out [reconnaissance] and bombing [the] [col] [##ore] targets in [darwin] .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = first_blurr_tfm(learn.dls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.blurr_fill_mask` works here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blurr is a joke.',\n",
       " 'Blurr is a word.',\n",
       " 'Blurr is a name.',\n",
       " 'Blurr is a metaphor.',\n",
       " 'Blurr is a term.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_fill_mask(f'Blurr is a {tfm.hf_tokenizer.mask_token}.', n_preds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 287113\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 13368\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 11490\n",
      "    })\n",
      "})\n",
      "\n",
      "{'article': 'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It\\'s a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama\\'s full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama\\'s remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there\\'s no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team\\'s final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: \\'This menace must be confronted\\' Obama\\'s senior advisers have debated the next steps to take, and the president\\'s comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament\\'s vote against military action earlier this week was a blow to Obama\\'s hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria\\'s alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It\\'s unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama\\'s speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama\\'s announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama\\'s decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama\\'s fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama\\'s speech in a Twitter post Saturday. \"I understand and support Barack Obama\\'s position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we\\'re just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria\\'s neighbors think? Why Russia, China, Iran stand by Assad . Syria\\'s government unfazed . After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria\\'s prime minister appeared unfazed by the saber-rattling. \"The Syrian Army\\'s status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama\\'s address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria\\'s ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don\\'t know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark \\'disaster\\' Opinion: Why strikes in Syria are a bad idea .', 'highlights': 'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .', 'id': '0001d1afc246a7964130f43ae940af6bc6c57f01'}\n",
      "\n",
      "{'article': Value(dtype='string', id=None), 'highlights': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "print(f'{raw_datasets}\\n')\n",
    "print(f'{raw_datasets[\"train\"][0]}\\n')\n",
    "print(f'{raw_datasets[\"train\"].features}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets['train'].select(range(1000))\n",
    "valid_ds = raw_datasets['validation'].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid = train_ds.num_rows, valid_ds.num_rows\n",
    "train_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\n",
    "raw_ds = concatenate_datasets([train_ds, valid_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSummarization.from_dictionaries(raw_ds, 'facebook/bart-large-cnn', \n",
    "                                                   text_attr='article', summary_attr='highlights', \n",
    "                                                   max_length=256, max_target_length=130,\n",
    "                                                   dblock_splitter=IndexSplitter(valid_idxs),\n",
    "                                                   dl_kwargs={'bs':2}).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,</td>\n",
       "      <td>China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; (CNN) -- The player tumbles to the ground, writhing around as if he has been mortally wounded. Television replays, however, show that his opponent has made no contact at all. It's an ever-increasing sight on football grounds around the world, and -- in the English Premier League, at least -- it's becoming an increasingly emotive issue. Santi Cazorla was labeled a \"con artist\" after his theatricals earned Arsenal a match-turning penalty kick in a game against West Brom on Saturday. Earlier th</td>\n",
       "      <td>Arsenal midfielder Santi Cazorla's theatrics reignite debate about diving in football.\\nFormer anti-doping chief gives five reasons why athletes choose to cheat.\\nWorld's major sports organizations face major battle to combat sporting fraud.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.730929</td>\n",
       "      <td>1.827253</td>\n",
       "      <td>0.342983</td>\n",
       "      <td>0.142611</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.869126</td>\n",
       "      <td>0.892681</td>\n",
       "      <td>0.880644</td>\n",
       "      <td>12:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForSummarization.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)Reading the headlines out of Madison, Wisconsin, it's hard not to think about Ferguson, Missouri. But law enforcement's response to the shooting of 19-year-old Tony Robinson will not unfold in the same chaotic, violent and distrusting way as the shooting of 18-year-old Michael Brown, Madison's top police leaders vowed. \"I think it's very clear that Madison, Wisconsin, is not Ferguson, Missouri,\" said Jim Palmer, the executive director of the Wisconsin Professional Police Association. The h</td>\n",
       "      <td>Police officials in Madison say their responses to shooting by officer reflect their role in community.\\nOne example: Madison chief talked to teen's family soon after shooting.\\nA month went by before Ferguson chief apologized to Brown's family.</td>\n",
       "      <td>Madison Police Chief Mike Koval has been out front and outspoken about Tony Robinson's shooting .\\nThe head of the state's largest law enforcement group says the Madison police department has a strong relationship with the people it serves .\\n\"I think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London (CNN)Mohammed Emwazi, the British-Kuwaiti ISIS fighter the world knows as \"Jihadi John,\" was fuming with righteous indignation when he met with a representative of Cage Prisoners -- a Muslim advocacy group now known as CAGE -- shortly after being deported from Tanzania in August 2009. In a meeting recorded by the advocacy group, he claimed his plans for a safari vacation were ruined when he was detained at the airport and sent back first to Amsterdam and then to Dover, England, where he</td>\n",
       "      <td>The man now known as \"Jihadi John\" was on Britain's terror radar for several years.\\nCourt documents claim he was a member of a terror recruitment network in London.\\nThe papers spell out his connections to other known terrorists in Somalia.</td>\n",
       "      <td>Mohammed Emwazi is the British-Kuwaiti ISIS fighter the world knows as \"Jihadi John\" .\\nCourt documents obtained by CNN paint a very different picture of his life .\\nEmwazi was on British security services' radar before he made the trip to Tanzania, d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.blurr_generate` works here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " About 10 men robbed a casino in Switzerland and made off with several hundred thousand Swiss francs, police say .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles and was beaten to death .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " About 10 men robbed a casino in Switzerland and made off with several hundred thousand Swiss francs, police say .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles, and a gunman beat her up .\n",
      "\n",
      "=== Prediction 3 ===\n",
      " About 10 men robbed a casino in Switzerland and made off with several hundred thousand Swiss francs, police say .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles, and a gunman beat her .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4548885\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2169\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2999\n",
      "    })\n",
      "})\n",
      "\n",
      "{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}}\n",
      "\n",
      "{'translation': Translation(languages=['de', 'en'], id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('wmt16', 'de-en')\n",
    "print(f'{raw_datasets}\\n')\n",
    "print(f'{raw_datasets[\"train\"][0]}\\n')\n",
    "print(f'{raw_datasets[\"train\"].features}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_datasets['train'].select(range(1000))\n",
    "valid_ds = raw_datasets['validation'].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid = train_ds.num_rows, valid_ds.num_rows\n",
    "train_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\n",
    "raw_ds = concatenate_datasets([train_ds, valid_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a/cache-2d203da04becbf79.arrow\n"
     ]
    }
   ],
   "source": [
    "def make_dict(item):\n",
    "    return item['translation']\n",
    "\n",
    "raw_ds = raw_ds.map(make_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTranslation.from_dataframe(raw_ds, 'Helsinki-NLP/opus-mt-de-en', \n",
    "                                              src_lang_name='German', src_lang_attr='de', \n",
    "                                              trg_lang_name='English', trg_lang_attr='en', \n",
    "                                              dblock_splitter=RandomSplitter(),\n",
    "                                              dl_kwargs={'bs':2}).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Angesichts▁dieser Situation▁muß▁aus dem▁Bericht, den das▁Parlament annimmt,▁klar▁hervorgehen,▁daß▁Maßnahmen▁notwendig▁sind, die▁eindeutig auf die▁Bekämpfung der relativen▁Armut und der Arbeitslosigkeit▁gerichtet▁sind.▁Maßnahmen▁wie die für diese▁Zwecke▁angemessene▁Verwendung der▁Strukturfonds, die▁häufig▁unsachgemäß▁eingesetzt▁werden, und▁zwar mit▁zentralen▁staatlichen▁Politiken, die▁Modernisierung der▁Bereiche Telekommunikation und▁Kommunikation,▁indem man vor▁allem die am▁wenigsten▁entwickelt</td>\n",
       "      <td>Given this situation, the report approved by Parliament must highlight the need for measures that aim unequivocally to fight relative poverty and unemployment: measures such as the appropriate use of structural funds for these purposes, which are oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wir▁sollten▁auch die▁Bescheidenheit aufbringen einzusehen,▁daß wir nicht▁erst eine▁Woche vor der▁eigentlichen▁Debatte in▁diesem Haus die▁Mechanismen▁einrichten▁können, die▁erforderlich▁sind, um eine▁strategische▁Debatte▁durchzuführen, die sich nicht▁nur auf eine▁Präsentation und▁Erläuterungen▁seitens des▁Präsidenten der▁Kommission▁beschränkt,▁sondern in der▁auch ein▁Fünfjahresprogramm▁vorgelegt▁wird.▁Nur so▁können wir der▁Kommission▁rechtzeitig▁unsere▁Wünsche▁übermitteln und diese▁entsprechend▁d</td>\n",
       "      <td>We should also have the humility to recognise that, if we wanted to have a strategic debate accompanied not just by a presentation and elucidation by the President of the Commission, but also by a five-year programme, we should have the mechanisms in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.259604</td>\n",
       "      <td>1.223431</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.569973</td>\n",
       "      <td>32.854164</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForTranslation.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nach▁meiner▁Ansicht▁würde diese▁zweite▁Hypothese▁einem▁Verzicht auf▁unsere▁Verantwortung▁als▁Parlament und▁darüber▁hinaus dem Aufwerfen▁einer▁originellen These,▁einer▁unbekannten▁Methode▁gleichkommen, die▁darin bestände, den▁Fraktionen die programmatische▁Rede der▁Kommission in▁schriftlicher Form eine▁Woche▁vorher - und nicht,▁wie▁vereinbart, am Tag▁zuvor - zur▁Kenntnis zu▁geben,▁wobei zu▁berücksichtigen▁ist,▁daß das▁Legislativprogramm im▁Februar▁diskutiert▁werden▁wird, so▁daß wir auf die▁Ausspr</td>\n",
       "      <td>In my opinion, this second hypothesis would imply the failure of Parliament in its duty as a Parliament, as well as introducing an original thesis, an unknown method which consists of making political groups aware, in writing, of a speech concerning</td>\n",
       "      <td>In my view, this second hypothesis would be tantamount to abandoning our responsibilities as Parliament and, moreover, to raising an original thesis, an unknown method, which would consist in informing the political groups of the Commission' s progra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sie▁wird▁aber auf▁Seite 5▁dieser▁Leitlinien▁ganz▁eindeutig▁genannt, und▁ich▁möchte▁darauf▁verweisen -▁weil▁sie▁mich▁dazu▁aufgefordert▁haben -,▁daß diese▁Partnerschaft für▁mich - und▁ich▁habe▁lange▁genug eine Region▁betreut, um dies▁beurteilen zu▁können - ein▁sehr▁wirkungsvolles Instrument zur▁Mobilisierung der▁geistigen▁Ressourcen auf▁lokaler▁Ebene▁ist -▁sowohl derer im▁öffentlichen▁Sektor - die Stadt- und▁Gemeinderäte, den▁schulischen und▁gesellschaftlichen▁Bereich, die▁Vereine und▁Verbände -▁a</td>\n",
       "      <td>However, I do wish to mention - since you have asked me to do so - that, as far as I am concerned, this partnership - and I spent long enough as a regional administrator within my own country to be able to say this most sincerely - is a tool, one use</td>\n",
       "      <td>However, it is clearly mentioned on page 5 of these guidelines, and I would like to point out - because they have called on me - that this partnership is a very effective instrument for mobilising intellectual resources at local level - both in the p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.blurr_generate` works here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like drinking beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, whether you want to work with Blurr's low, mid, or high-level API ... we got you covered :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
