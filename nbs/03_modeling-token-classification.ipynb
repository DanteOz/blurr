{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.data.token_classification import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.1\n",
      "Using fastai 2.4\n",
      "Using transformers 4.8.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForTokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.models.bert.configuration_bert.BertConfig,\n",
       " transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=model_cls, \n",
    "                                                                  config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                     is_split_into_words=True, \n",
    "                                                     tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O'), ('und', 'O'), ('Engagement', 'O'), (':', 'O'), ('das', 'O'), ('eigentlich', 'O'), ('Neue', 'O'), ('an', 'O'), ('der', 'O'), ('Netz', 'O'), ('(', 'O'), ('werk', 'O'), (')', 'O'), ('kunst,', 'O'), ('in', 'O'), (':', 'O'), ('Medien', 'O'), ('Kunst', 'O'), ('Netz,', 'O'), ('2004,', 'O'), ('URL', 'O'), (':', 'O'), ('*', 'O'), ('Arns,', 'B-PER'), ('Inke', 'O'), (':', 'B-PER'), ('Netzkulturen,', 'O'), ('Hamburg', 'O'), ('(', 'O'), ('eva', 'B-LOC'), ('),', 'O'), ('2002,', 'O'), ('S.', 'O'), ('46', 'O'), ('und', 'O'), ('81', 'O'), ('*', 'O'), ('Armin', 'O'), ('Medosch', 'O'), (':', 'O'), ('Public', 'B-PER'), ('Netbase', 'I-PER'), ('Wien.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Die', 'O'), ('Flügel', 'O'), ('Die', 'O'), ('geöffneten', 'O'), ('Flügel', 'O'), ('zeigen', 'O'), ('in', 'O'), ('vier', 'O'), ('Szenen', 'O'), ('Höhepunkte', 'O'), ('aus', 'O'), ('dem', 'O'), ('Leben', 'O'), ('von', 'O'), ('Maria', 'B-PER'), ('und', 'O'), ('Jesus,', 'B-PER'), ('passend', 'O'), ('zu', 'O'), ('den', 'O'), ('christlichen', 'O'), ('Festen', 'O'), ('Weihnachten,', 'O'), ('Ostern', 'O'), ('und', 'O'), ('Pfingsten', 'O'), (':', 'O'), ('Der', 'O'), ('Hauptschrein', 'O'), ('Im', 'O'), ('Hauptschrein', 'O'), ('ist', 'O'), ('die', 'O'), ('Krönung', 'O'), ('Mariens', 'O'), ('durch', 'O'), ('Christus', 'B-PER'), ('dargestellt.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(filter(lambda el: isinstance(el, HF_TokenCategorize), learn.dls.tfms[1]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in learn.dls.tfms[1]: print(isinstance(x,HF_TokenCategorize), type(x), HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdf = HF_TokenCategorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isinstance(asdf,HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_blurr_tfm(learn.dls.tfms, tfm_class=HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassMetricsCallback(Callback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the HF_TokenClassBeforeBatchTransform\n",
    "        hf_before_batch_tfm = get_blurr_tfm(self.learn.dls.before_batch)\n",
    "        hf_tok_categorize_tfm = get_blurr_tfm(self.learn.dls.tfms[1], tfm_class=HF_TokenCategorize)\n",
    "        \n",
    "        self.hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = hf_tok_categorize_tfm.ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_before_batch_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        try:\n",
    "            self.learn.token_classification_report = calculate_token_class_metrics(targs, \n",
    "                                                                                   preds, \n",
    "                                                                                   'classification_report')\n",
    "        except ZeroDivisionError as err:\n",
    "            print(f'Couldn\\'t calcualte classification report: {err}')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_TokenClassMetricsCallback()]\n",
    "\n",
    "learn = Learner(dls, model, opt_func=partial(Adam),cbs=learn_cbs,splitter=hf_splitter)\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HF_BaseModelWrapper (Input shape: 2)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 61 x 768        \n",
       "Embedding                                 91812096   False     \n",
       "Embedding                                 393216     False     \n",
       "Embedding                                 1536       False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 61 x 18         \n",
       "Linear                                    13842      True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 177,276,690\n",
       "Total trainable params: 52,242\n",
       "Total non-trainable params: 177,224,448\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7f0d8c096160>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - HF_BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2, 61, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 61]), 2, torch.Size([2, 61]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([122, 18]) torch.Size([122])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.0015848932787775993, steep=2.511886486900039e-05, valley=tensor(0.0001), slide=tensor(0.0006))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.190367</td>\n",
       "      <td>0.190803</td>\n",
       "      <td>0.944988</td>\n",
       "      <td>0.567347</td>\n",
       "      <td>0.528517</td>\n",
       "      <td>0.547244</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.76      0.47      0.58        87\n",
      "    LOCderiv       0.44      0.50      0.47        16\n",
      "     LOCpart       0.00      0.00      0.00         0\n",
      "         ORG       0.47      0.29      0.36        78\n",
      "     ORGpart       0.00      0.00      0.00         0\n",
      "         OTH       0.00      0.00      0.00         4\n",
      "    OTHderiv       0.00      0.00      0.00         0\n",
      "     OTHpart       0.00      0.00      0.00         0\n",
      "         PER       0.97      0.86      0.91        78\n",
      "     PERpart       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.57      0.53      0.55       263\n",
      "   macro avg       0.26      0.21      0.23       263\n",
      "weighted avg       0.71      0.53      0.60       263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner, \n",
    "                 ctxs=None, max_n=6, trunc_at=None, **kwargs):    \n",
    "    \n",
    "    hf_before_batch_tfm = get_blurr_tfm(learner.dls.before_batch)\n",
    "    hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "    ignore_token_id = hf_before_batch_tfm.ignore_token_id\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x, y, samples, outs):\n",
    "        # recontstruct the string and split on space to get back your pre-tokenized list of tokens\n",
    "        toks = hf_tokenizer.convert_ids_to_tokens(inp, skip_special_tokens=True)\n",
    "        pretokenized_toks =  hf_tokenizer.convert_tokens_to_string(toks).split()\n",
    "        \n",
    "        # get predictions for subtokens that aren't ignored (e.g. special toks and token parts)\n",
    "        pred_labels = [ pred_lbl for lbl_id, pred_lbl in zip(trg, ast.literal_eval(pred[0])) if lbl_id != -ignore_token_id ]\n",
    "        \n",
    "        trg_labels = ast.literal_eval(sample[1])\n",
    "        res.append([f'{[ (tok, trg, pred) for idx, (tok, pred, trg) in enumerate(zip(pretokenized_toks, pred_labels, trg_labels)) if (trunc_at is None or idx < trunc_at) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'I-PER'), ('al.', 'I-OTH', 'I-PER'), ('(', 'O', 'I-PER'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('S.', 'O', 'O'), ('593.', 'O', 'O'), ('Wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Erstmals', 'O', 'O'), ('Urkundlich', 'O', 'O'), ('erwähnt', 'O', 'O'), ('ist', 'O', 'O'), ('Nimburg', 'B-LOC', 'O'), ('bereits', 'O', 'O'), ('im', 'O', 'O'), ('Jahre', 'O', 'B-LOC'), ('977.', 'O', 'B-LOC'), ('Im', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O']\",)\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _blurr_predict_tokens(predict_func, items, hf_before_batch_tfm):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.blurr_predict` or `blurrONNX.predict.\n",
    "    Aligns the predicted labels, label ids, and probabilities with what you passed in excluding subword tokens\n",
    "    \"\"\"\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_before_batch_tfm.tok_kwargs\n",
    "    \n",
    "    if (isinstance(items[0], str)): items = [items]\n",
    "        \n",
    "    outs = []\n",
    "    for inp, res in zip(items, predict_func(items)):\n",
    "        # blurr_predict returns a list for each, we only doing one at a time so git first element of each\n",
    "        pred_lbls, pred_lbl_ids, probs = res[0][0], res[1][0], res[2][0]\n",
    "  \n",
    "        # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "        # return\n",
    "        subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "        # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "        # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "        # (e.g., [CLS], [SEP], etc...)\n",
    "        res = hf_tokenizer(inp, None, \n",
    "                           max_length=hf_before_batch_tfm.max_length,\n",
    "                           padding=hf_before_batch_tfm.padding,\n",
    "                           truncation=hf_before_batch_tfm.truncation,\n",
    "                           is_split_into_words=hf_before_batch_tfm.is_split_into_words,\n",
    "                           **tok_kwargs)\n",
    "\n",
    "        special_toks_msk = L(res['special_tokens_mask'])\n",
    "        actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "        # using the indexes to the actual tokens, get that info from the results returned above\n",
    "        pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "        actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "        actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "        actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "        # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "        # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "        offset = 0\n",
    "        raw_trg_idxs = []\n",
    "        for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "            raw_trg_idxs.append(idx+offset)\n",
    "            offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "            \n",
    "        outs.append((inp, \n",
    "                     actual_pred_lbls[raw_trg_idxs], \n",
    "                     actual_pred_lbl_ids[raw_trg_idxs], \n",
    "                     actual_probs[raw_trg_idxs]))\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, items, **kargs):\n",
    "    hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "    return _blurr_predict_tokens(self.blurr_predict, items, hf_before_batch_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`items`**, **\\*\\*`kargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\n",
    "txt2 = \"I wish covid was over so I could go to Germany and watch Bayern Munich play in the Bundesliga.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'B-PER'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'I-ORG'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'tok_class_learn_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'B-PER'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'I-ORG'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "\n",
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# @patch\n",
    "# def predict_tokens(self:blurrONNX, items, **kargs):\n",
    "#     hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "#     return _blurr_predict_tokens(self.predict, items, hf_before_batch_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# learn.blurr_to_onnx(export_fname, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# onnx_inf = blurrONNX(export_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# res = onnx_inf.predict_tokens(txt.split())\n",
    "# for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLearnerForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTokenClassification(Blearner):\n",
    "\n",
    "    def __init__(self, dls, hf_model, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "        \n",
    "    @classmethod\n",
    "    def get_model_cls(self): \n",
    "        return AutoModelForTokenClassification\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_y(cls, r, tokens, token_labels, tokenizer): \n",
    "        return [ (label, len(tokenizer.tokenize(str(entity)))) for entity, label in zip(r[tokens], r[token_labels]) ]\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_learner(cls, data, pretrained_model_name_or_path, preprocess_func, \n",
    "                        tokens, token_labels, labels, dblock_splitter, dl_kwargs, learner_kwargs):\n",
    "        \n",
    "        # get our hf objects\n",
    "        n_labels = len(labels)\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, \n",
    "                                                                          model_cls=cls.get_model_cls(), \n",
    "                                                                          config_kwargs={'num_labels': n_labels})\n",
    "        \n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if (preprocess_func):\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, tokens, token_labels, labels)\n",
    "            \n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if (hf_tokenizer.pad_token is None): \n",
    "            hf_tokenizer.add_special_tokens({'pad_token': '<pad>'})  \n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()['<pad>']\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "        \n",
    "        # build dblock, dls, and default metrics (optionsl)\n",
    "        if (isinstance(data, pd.DataFrame)):\n",
    "            get_x = ColReader(tokens)\n",
    "            get_y = partial(cls._get_y, tokens=tokens, token_labels=token_labels, tokenizer=hf_tokenizer)\n",
    "        else:\n",
    "            get_x = ItemGetter(tokens)\n",
    "            get_y = partial(cls._get_y, tokens=tokens, token_labels=token_labels, tokenizer=hf_tokenizer)\n",
    "             \n",
    "        before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                             is_split_into_words=True, \n",
    "                                                             tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "        \n",
    "        blocks = (\n",
    "            HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "            HF_TokenCategoryBlock(vocab=labels)\n",
    "        )\n",
    "        \n",
    "        dblock = DataBlock(blocks=blocks, \n",
    "                           get_x=get_x,\n",
    "                           get_y=get_y,\n",
    "                           splitter=dblock_splitter)\n",
    "        \n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "        \n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df, pretrained_model_name_or_path, preprocess_func=None,\n",
    "                       tokens='tokens', token_labels='token_labels', labels=None, dblock_splitter=ColSplitter(), \n",
    "                       dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if (labels is None):\n",
    "            labels = sorted(list(set([lbls for sublist in df[token_labels].tolist() for lbls in sublist])))\n",
    "            \n",
    "        return cls._create_learner(df, pretrained_model_name_or_path, preprocess_func, \n",
    "                                   tokens, token_labels, labels, dblock_splitter, dl_kwargs, learner_kwargs)\n",
    "    \n",
    "        \n",
    "    @classmethod\n",
    "    def from_csv(cls, csv_file, pretrained_model_name_or_path, preprocess_func=None,\n",
    "                 tokens='tokens', token_labels='labels', labels=None, dblock_splitter=ColSplitter(), \n",
    "                 dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        return cls.from_dataframe(df, \n",
    "                                  pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                  preprocess_func=preprocess_func,\n",
    "                                  tokens=tokens, token_labels=token_labels, labels=labels, \n",
    "                                  dblock_splitter=dblock_splitter, \n",
    "                                  dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dictionaries(cls, ds, pretrained_model_name_or_path, preprocess_func=None,\n",
    "                       tokens='tokens', token_labels='token_labels', labels=None, dblock_splitter=RandomSplitter(), \n",
    "                       dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if (labels is None):\n",
    "            all_labels = []\n",
    "            for item in raw_ds: all_labels += item[token_labels]\n",
    "            labels = sorted(list(set(all_labels)))\n",
    "\n",
    "        return cls._create_learner(ds, pretrained_model_name_or_path, preprocess_func, \n",
    "                                   tokens, token_labels, labels, dblock_splitter, dl_kwargs, learner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTokenClassification.from_dataframe(germ_eval_df, 'bert-base-multilingual-cased', \n",
    "                                                      tokens='tokens', token_labels='labels', \n",
    "                                                      dblock_splitter=RandomSplitter(), \n",
    "                                                      dl_kwargs={'bs':2})\n",
    "\n",
    "learn.unfreeze()\n",
    "fit_cbs = [HF_TokenClassMetricsCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S.', 'O'), ('593.', 'O'), ('Wink', 'O'), ('&amp;', 'B-OTH'), ('Seibold', 'I-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'I-OTH'), ('1998', 'O'), (')', 'O'), ('S.', 'O'), ('32', 'O'), ('Inwieweit', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falken,', 'O'), ('wie', 'O'), ('der', 'O'), ('Afrikanische', 'O'), ('Baumfalke', 'O'), ('(', 'O'), ('Falco', 'B-LOCderiv'), ('cuvieri', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Malaienbaumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('serverus', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zuzuzählen', 'O'), ('sind,', 'O'), ('ist', 'O'), ('Gegenstand', 'O'), ('der', 'O'), ('Forschung.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Scenes', 'B-OTH'), ('of', 'I-OTH'), ('a', 'I-OTH'), ('Sexual', 'I-OTH'), ('Nature', 'I-OTH'), ('(', 'O'), ('GB', 'O'), ('2006', 'O'), (')', 'O'), ('-', 'O'), ('Regie', 'O'), (':', 'O'), ('Ed', 'B-PER'), ('Blum', 'I-PER'), ('Shortbus', 'B-OTH'), ('(', 'O'), ('USA', 'B-LOC'), ('2006', 'O'), (')', 'O'), ('-', 'O'), ('Regie', 'O'), (':', 'O'), ('John', 'B-PER'), ('Cameron', 'I-PER'), ('Mitchell', 'I-PER'), (':', 'O'), ('Film', 'O'), ('über', 'O'), ('den', 'O'), ('gleichnamigen', 'B-LOCderiv'), ('New', 'I-LOCderiv'), ('Yorker', 'O'), ('Club,', 'O'), ('der', 'O'), ('verschiedensten', 'O'), ('Paaren', 'O'), ('eine', 'O'), ('Plattform', 'O'), ('zur', 'O'), ('Aufarbeitung', 'O'), ('ihrer', 'O'), ('Probleme', 'O'), ('bietet.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.185531</td>\n",
       "      <td>0.158151</td>\n",
       "      <td>0.953766</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.562278</td>\n",
       "      <td>0.588454</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Mit', 'O', 'O'), ('der', 'O', 'O'), ('Servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('Bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'B-PER'), ('Art', 'O', 'O'), ('Freundschaft', 'O', 'O'), ('oder', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O', 'O'), ('notenbeste', 'O', 'O'), ('Zweitligaspieler', 'O', 'O'), ('(', 'O', 'O'), ('2,', 'O', 'O'), ('91', 'O', 'O'), ('),', 'O', 'O'), ('der', 'O', 'O'), ('seine', 'O', 'O'), ('persönliche', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.92      0.53      0.67       114\n",
      "    LOCderiv       0.65      0.50      0.57        34\n",
      "     LOCpart       0.00      0.00      0.00         0\n",
      "         ORG       0.44      0.31      0.36        62\n",
      "     ORGpart       0.00      0.00      0.00         0\n",
      "         OTH       0.03      1.00      0.06         1\n",
      "    OTHderiv       0.00      0.00      0.00         0\n",
      "     OTHpart       0.00      0.00      0.00         0\n",
      "         PER       0.91      0.87      0.89        70\n",
      "     PERpart       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.62      0.56      0.59       281\n",
      "   macro avg       0.30      0.32      0.26       281\n",
      "weighted avg       0.78      0.56      0.64       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\n",
    "txt2 = \"I wish covid was over so I could watch Lewandowski score some more goals for Bayern Munich in the Bundesliga.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'O'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('watch', 'O'), ('Lewandowski', 'B-PER'), ('score', 'O'), ('some', 'O'), ('more', 'O'), ('goals', 'O'), ('for', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'B-ORG'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the token classification training code above works for **all** pretrained token classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.models.albert.modeling_albert.AlbertForTokenClassification,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification,\n",
       " transformers.models.big_bird.modeling_big_bird.BigBirdForTokenClassification,\n",
       " transformers.models.camembert.modeling_camembert.CamembertForTokenClassification,\n",
       " transformers.models.convbert.modeling_convbert.ConvBertForTokenClassification,\n",
       " transformers.models.deberta.modeling_deberta.DebertaForTokenClassification,\n",
       " transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2ForTokenClassification,\n",
       " transformers.models.distilbert.modeling_distilbert.DistilBertForTokenClassification,\n",
       " transformers.models.electra.modeling_electra.ElectraForTokenClassification,\n",
       " transformers.models.flaubert.modeling_flaubert.FlaubertForTokenClassification,\n",
       " transformers.models.funnel.modeling_funnel.FunnelForTokenClassification,\n",
       " transformers.models.ibert.modeling_ibert.IBertForTokenClassification,\n",
       " transformers.models.layoutlm.modeling_layoutlm.LayoutLMForTokenClassification,\n",
       " transformers.models.longformer.modeling_longformer.LongformerForTokenClassification,\n",
       " transformers.models.mpnet.modeling_mpnet.MPNetForTokenClassification,\n",
       " transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertForTokenClassification,\n",
       " transformers.models.mobilebert.modeling_mobilebert.MobileBertForTokenClassification,\n",
       " transformers.models.roberta.modeling_roberta.RobertaForTokenClassification,\n",
       " transformers.models.squeezebert.modeling_squeezebert.SqueezeBertForTokenClassification,\n",
       " transformers.models.xlm.modeling_xlm.XLMForTokenClassification,\n",
       " transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForTokenClassification,\n",
       " transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ model_type for model_type in BLURR.get_models(task='TokenClassification') \n",
    " if (not model_type.__name__.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'google/electra-small-discriminator',\n",
    "    'flaubert/flaubert_small_cased',\n",
    "    'huggingface/funnel-small-base',\n",
    "    'allenai/longformer-base-4096',\n",
    "    'microsoft/mpnet-base',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'squeezebert/squeezebert-uncased',\n",
    "    'xlm-mlm-en-2048',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.753859</td>\n",
       "      <td>1.560172</td>\n",
       "      <td>0.886901</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('da', 'O', 'O'), ('ich', 'O', 'O'), ('mir', 'O', 'O'), ('als', 'O', 'O'), ('kleine', 'O', 'O'), ('rentnerin', 'O', 'O'), ('nicht', 'O', 'O'), ('sehr', 'O', 'O'), ('viel', 'O', 'O'), ('leisten', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('der', 'O', 'O'), ('notenbeste', 'O', 'O'), ('zweitligaspieler', 'O', 'O'), ('(', 'O', 'O'), ('2,91', 'O', 'O'), (')', 'O', 'O'), (',', 'O', 'O'), ('der', 'O', 'O'), ('seine', 'O', 'O'), ('personliche', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-multilingual-cased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.952468</td>\n",
       "      <td>1.748683</td>\n",
       "      <td>0.899259</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Der', 'O', 'B-PER'), ('28', 'O', 'O'), ('-', 'O', 'O'), ('Jährige', 'O', 'O'), ('und', 'O', 'O'), ('sein', 'O', 'O'), ('Team,', 'O', 'O'), ('zu', 'O', 'O'), ('dem', 'O', 'O'), ('auch', 'B-PER', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O', 'O'), ('notenbeste', 'O', 'O'), ('Zweitligaspieler', 'O', 'O'), ('(', 'O', 'O'), ('2,', 'O', 'O'), ('91', 'O', 'O'), ('),', 'O', 'O'), ('der', 'O', 'O'), ('seine', 'O', 'O'), ('persönliche', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.368666</td>\n",
       "      <td>2.320432</td>\n",
       "      <td>0.892068</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('R&lt;unk&gt;ckkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('In', 'O', 'O'), ('einer', 'O', 'O'), ('Fernsehdiskussion', 'O', 'O'), ('traf', 'O', 'O'), ('er', 'O', 'O'), ('auf', 'O', 'O'), ('den', 'O', 'O'), ('Kritiker', 'O', 'O'), ('Alexander', 'B-PER', 'O'), ('Walker', 'I-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.909185</td>\n",
       "      <td>1.762218</td>\n",
       "      <td>0.891033</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('mit', 'O', 'O'), ('der', 'O', 'O'), ('servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('art', 'O', 'O'), ('freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('außerdem', 'O', 'B-LOC'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/electra-small-discriminator ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.299630</td>\n",
       "      <td>2.176142</td>\n",
       "      <td>0.865857</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('standard', 'B-ORG', 'O'), ('oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'O'), ('new', 'I-ORG', 'O'), ('jersey', 'I-ORG', 'B-ORG'), ('),', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O'), ('„', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('außerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.795369</td>\n",
       "      <td>1.376650</td>\n",
       "      <td>0.839656</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Rückkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Außerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('Nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('Stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== huggingface/funnel-small-base ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.111540</td>\n",
       "      <td>0.901469</td>\n",
       "      <td>0.870572</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('newsru.', 'B-OTH', 'B-PERpart'), ('ua', 'O', 'O'), ('/', 'O', 'O'), (':', 'B-OTH', 'O'), ('политисполком', 'I-OTH', 'O'), ('спу', 'I-OTH', 'O'), ('отказал', 'I-OTH', 'O'), ('морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('in', 'O', 'B-PERpart'), ('einer', 'O', 'O'), ('fernsehdiskussion', 'O', 'O'), ('traf', 'O', 'O'), ('er', 'O', 'O'), ('auf', 'O', 'O'), ('den', 'O', 'O'), ('kritiker', 'O', 'O'), ('alexander', 'B-PER', 'O'), ('walker,', 'I-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.071100</td>\n",
       "      <td>1.976320</td>\n",
       "      <td>0.894503</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Rückkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Mit', 'O', 'O'), ('der', 'O', 'O'), ('Servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('Bianca', 'B-PER', 'B-OTHpart'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('Art', 'O', 'O'), ('Freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/mpnet-base ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.316131</td>\n",
       "      <td>2.235843</td>\n",
       "      <td>0.901261</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al.', 'I-OTH', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s.', 'O', 'O'), ('593.', 'O', 'O'), ('wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('zugang', 'O', 'O'), ('und', 'O', 'O'), ('engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('netz', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.879590</td>\n",
       "      <td>4.328593</td>\n",
       "      <td>0.013803</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'B-LOC'), ('et', 'I-OTH', 'I-ORG'), ('al.', 'I-OTH', 'I-ORGpart'), ('(', 'O', 'B-OTHpart'), ('1994', 'O', 'O'), (')', 'O', 'B-ORG'), ('s.', 'O', 'I-LOC'), ('593.', 'O', 'I-ORG'), ('wink', 'O', 'B-ORG'), ('&amp;', 'B-OTH', 'I-LOC')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('zugang', 'O', 'B-LOC'), ('und', 'O', 'I-ORG'), ('engagement', 'O', 'B-OTHpart'), (':', 'O', 'I-LOCderiv'), ('das', 'O', 'I-ORG'), ('eigentlich', 'O', 'I-LOCderiv'), ('neue', 'O', 'I-ORG'), ('an', 'O', 'I-ORG'), ('der', 'O', 'I-LOCderiv'), ('netz', 'O', 'B-OTHpart')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.432458</td>\n",
       "      <td>2.342887</td>\n",
       "      <td>0.743219</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('NEWSru.ua', 'B-OTH', 'I-PER'), ('/', 'O', 'I-PER'), (':', 'O', 'I-PER'), ('Политисполком', 'B-OTH', 'I-PER'), ('СПУ', 'I-OTH', 'I-PER'), ('отказал', 'I-OTH', 'I-PER'), ('Морозу', 'I-OTH', 'I-LOC'), ('в', 'I-OTH', 'I-LOC'), ('отставке', 'I-OTH', 'I-PER'), ('Die', 'O', 'I-PER')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Die', 'O', 'I-PER'), ('Flügel', 'O', 'O'), ('Die', 'O', 'O'), ('geöffneten', 'O', 'O'), ('Flügel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'I-PER'), ('Szenen', 'O', 'O'), ('Höhepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.528191</td>\n",
       "      <td>2.486881</td>\n",
       "      <td>0.892171</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('sexual', 'I-OTH', 'O'), ('nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('gb', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('das', 'O', 'O'), ('\"', 'O', 'O'), ('torchwood', 'B-OTH', 'O'), ('\"', 'O', 'O'), ('-', 'O', 'O'), ('team', 'O', 'O'), ('besteht', 'O', 'O'), ('neben', 'O', 'O'), ('captain', 'B-PER', 'O'), ('jack', 'I-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.770426</td>\n",
       "      <td>0.818806</td>\n",
       "      <td>0.870680</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('die', 'O', 'O'), ('flugel', 'O', 'O'), ('die', 'O', 'O'), ('geoffneten', 'O', 'O'), ('flugel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('szenen', 'O', 'O'), ('hohepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('senden', 'O', 'O'), ('exxon', 'B-ORG', 'O'), ('mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.de', 'B-ORG', 'O'), ('ag', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.269574</td>\n",
       "      <td>2.213655</td>\n",
       "      <td>0.901466</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('Sexual', 'I-OTH', 'O'), ('Nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('GB', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('\"', 'O', 'O'), ('Wenn', 'O', 'O'), ('kleine', 'O', 'O'), ('Gymnasiasten', 'O', 'O'), ('schon', 'O', 'O'), ('in', 'O', 'O'), ('der', 'O', 'O'), ('fünften', 'O', 'O'), ('Klasse', 'O', 'O'), ('mit', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.383684</td>\n",
       "      <td>1.137120</td>\n",
       "      <td>0.593841</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Senden', 'O', 'I-ORGpart'), ('Exxon', 'B-ORG', 'O'), ('Mobil', 'I-ORG', 'B-PERpart'), ('\"', 'O', 'O'), ('buy', 'O', 'I-ORGpart'), ('\"', 'O', 'B-OTH'), ('Paris', 'B-LOC', 'O'), ('(', 'O', 'I-ORGpart'), ('aktiencheck.de', 'B-ORG', 'I-ORGpart'), ('AG', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('\"', 'O', 'B-OTH'), ('Es', 'O', 'B-OTH'), ('ist', 'O', 'O'), ('beabsichtigt', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('Aktien', 'O', 'O'), ('im', 'O', 'B-OTH'), ('ersten', 'O', 'B-OTH'), ('Halbjahr', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "model_cls = AutoModelForTokenClassification\n",
    "bsz = 4\n",
    "seq_sz = 64\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.num_labels = len(labels)\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      config=config)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n')\n",
    "    \n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if (hf_tokenizer.pad_token is None): \n",
    "        hf_tokenizer.add_special_tokens({'pad_token': '<pad>'})  \n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()['<pad>']\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer)) \n",
    "    \n",
    "    before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                         max_length=seq_sz,\n",
    "                                                         padding='max_length',\n",
    "                                                         is_split_into_words=True, \n",
    "                                                         tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "    blocks = (\n",
    "        HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "        HF_TokenCategoryBlock(vocab=labels)\n",
    "    )\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('tokens'),\n",
    "                       get_y= lambda inp: [ \n",
    "                           (label, len(hf_tokenizer.tokenize(str(entity)))) \n",
    "                           for entity, label in zip(inp.tokens, inp.labels) \n",
    "                       ],\n",
    "                       splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(germ_eval_df, bs=bsz)\n",
    "\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter).to_fp16()\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), \n",
    "                            cbs=[HF_TokenClassMetricsCallback(tok_metrics=['accuracy'])])\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=10)\n",
    "        \n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "        \n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
