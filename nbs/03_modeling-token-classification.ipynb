{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os, ast, inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import perplexity\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar,master_bar\n",
    "from seqeval import metrics as seq_metrics\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification, logging,\n",
    "    PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    ")\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.core import HF_TextBlock, BlurrDataLoader, get_blurr_tfm, first_blurr_tfm\n",
    "from blurr.modeling.core import HF_PreCalculatedLoss, Blearner\n",
    "from blurr.data.token_classification import (\n",
    "    HF_TokenClassInput, HF_TokenTensorCategory, HF_TokenCategorize, \n",
    "    HF_TokenCategoryBlock, HF_TokenClassBeforeBatchTransform\n",
    ")\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.7.1\n",
      "fastai: 2.5.0\n",
      "transformers: 4.9.2\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "from transformers import AutoConfig\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.modeling.core import HF_BaseModelWrapper, HF_BaseModelCallback, HF_PreCalculatedLoss, hf_splitter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions('torch fastai transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForTokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.models.bert.configuration_bert.BertConfig,\n",
       " transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=model_cls, \n",
    "                                                                  config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                     is_split_into_words=True, \n",
    "                                                     tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S.', 'O'), ('593.', 'O'), ('Wink', 'O'), ('&amp;', 'B-OTH'), ('Seibold', 'I-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'I-OTH'), ('1998', 'O'), (')', 'O'), ('S.', 'O'), ('32', 'O'), ('Inwieweit', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falken,', 'O'), ('wie', 'O'), ('der', 'O'), ('Afrikanische', 'O'), ('Baumfalke', 'O'), ('(', 'O'), ('Falco', 'B-LOCderiv'), ('cuvieri', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Malaienbaumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('serverus', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zuzuzählen', 'O'), ('sind,', 'O'), ('ist', 'O'), ('Gegenstand', 'O'), ('der', 'O'), ('Forschung.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Zugang', 'O'), ('und', 'O'), ('Engagement', 'O'), (':', 'O'), ('das', 'O'), ('eigentlich', 'O'), ('Neue', 'O'), ('an', 'O'), ('der', 'O'), ('Netz', 'O'), ('(', 'O'), ('werk', 'O'), (')', 'O'), ('kunst,', 'O'), ('in', 'O'), (':', 'O'), ('Medien', 'O'), ('Kunst', 'O'), ('Netz,', 'O'), ('2004,', 'O'), ('URL', 'O'), (':', 'O'), ('*', 'O'), ('Arns,', 'B-PER'), ('Inke', 'O'), (':', 'B-PER'), ('Netzkulturen,', 'O'), ('Hamburg', 'O'), ('(', 'O'), ('eva', 'B-LOC'), ('),', 'O'), ('2002,', 'O'), ('S.', 'O'), ('46', 'O'), ('und', 'O'), ('81', 'O'), ('*', 'O'), ('Armin', 'O'), ('Medosch', 'O'), (':', 'O'), ('Public', 'B-PER'), ('Netbase', 'I-PER'), ('Wien.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# next(filter(lambda el: isinstance(el, HF_TokenCategorize), learn.dls.tfms[1]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# for x in learn.dls.tfms[1]: print(isinstance(x,HF_TokenCategorize), type(x), HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# asdf = HF_TokenCategorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# isinstance(asdf,HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# get_blurr_tfm(learn.dls.tfms, tfm_class=HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassMetricsCallback(Callback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the HF_TokenClassBeforeBatchTransform\n",
    "        tfm = first_blurr_tfm(self.learn.dls, before_batch_tfm_class=HF_TokenClassBeforeBatchTransform) \n",
    "        hf_tok_categorize_tfm = get_blurr_tfm(self.learn.dls.tfms[1], tfm_class=HF_TokenCategorize)\n",
    "        \n",
    "        self.hf_tokenizer = tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = hf_tok_categorize_tfm.ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        try:\n",
    "            self.learn.token_classification_report = calculate_token_class_metrics(targs, \n",
    "                                                                                   preds, \n",
    "                                                                                   'classification_report')\n",
    "        except ZeroDivisionError as err:\n",
    "            print(f'Couldn\\'t calcualte classification report: {err}')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_TokenClassMetricsCallback()]\n",
    "\n",
    "learn = Learner(dls, model, opt_func=partial(Adam),cbs=learn_cbs,splitter=hf_splitter)\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HF_BaseModelWrapper (Input shape: 2)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 76 x 768        \n",
       "Embedding                                 91812096   False     \n",
       "Embedding                                 393216     False     \n",
       "Embedding                                 1536       False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 3072       \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 768        \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 76 x 18         \n",
       "Linear                                    13842      True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 177,276,690\n",
       "Total trainable params: 52,242\n",
       "Total non-trainable params: 177,224,448\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7f66b1dd6280>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - HF_BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2, 76, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 76]), 2, torch.Size([2, 76]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([152, 18]) torch.Size([152])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.005754399299621582, steep=3.630780702224001e-05, valley=0.0002290867705596611, slide=0.0020892962347716093)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.192442</td>\n",
       "      <td>0.143492</td>\n",
       "      <td>0.959979</td>\n",
       "      <td>0.631179</td>\n",
       "      <td>0.570447</td>\n",
       "      <td>0.599278</td>\n",
       "      <td>00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_TokenClassInput` typed inputs\n",
    "    x:HF_TokenClassInput, \n",
    "    # This typedispatched `show_results` will be called for `HF_TokenTensorCategory` typed targets\n",
    "    y:HF_TokenTensorCategory, \n",
    "    # Your raw inputs/targets\n",
    "    samples,     \n",
    "    # The model's predictions\n",
    "    outs,           \n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into \n",
    "    # something understandable\n",
    "    learner, \n",
    "    # Your `show_results` context\n",
    "    ctxs=None, \n",
    "    # The maximum number of items to show\n",
    "    max_n=6, \n",
    "     # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None, \n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):    \n",
    "    tfm = first_blurr_tfm(learner.dls, before_batch_tfm_class=HF_TokenClassBeforeBatchTransform) \n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    ignore_token_id = tfm.ignore_token_id\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x, y, samples, outs):\n",
    "        # recontstruct the string and split on space to get back your pre-tokenized list of tokens\n",
    "        toks = hf_tokenizer.convert_ids_to_tokens(inp, skip_special_tokens=True)\n",
    "        pretokenized_toks =  hf_tokenizer.convert_tokens_to_string(toks).split()\n",
    "        \n",
    "        # get predictions for subtokens that aren't ignored (e.g. special toks and token parts)\n",
    "        pred_labels = [ pred_lbl for lbl_id, pred_lbl in zip(trg, ast.literal_eval(pred[0])) if lbl_id != -ignore_token_id ]\n",
    "        \n",
    "        trg_labels = ast.literal_eval(sample[1])\n",
    "        res.append([f'{[ (tok, trg, pred) for idx, (tok, pred, trg) in enumerate(zip(pretokenized_toks, pred_labels, trg_labels)) if (trunc_at is None or idx < trunc_at) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'B-OTH'), ('a', 'I-OTH', 'I-OTH'), ('Sexual', 'I-OTH', 'I-OTH'), ('Nature', 'I-OTH', 'I-OTH'), ('(', 'O', 'I-OTH'), ('GB', 'O', 'I-OTH'), ('2006', 'O', 'O'), (')', 'O', 'B-LOC'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O', 'O'), ('notenbeste', 'O', 'O'), ('Zweitligaspieler', 'O', 'O'), ('(', 'O', 'O'), ('2,', 'O', 'O'), ('91', 'O', 'O'), ('),', 'O', 'O'), ('der', 'O', 'O'), ('seine', 'O', 'O'), ('persönliche', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O']\",)\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _blurr_predict_tokens(\n",
    "    # The function to do the base predictions (default: self.blurr_predict)\n",
    "    predict_func:Callable, \n",
    "    # The str (or list of strings) you want to get token classification predictions for\n",
    "    items:Union[str, List[str]], \n",
    "    # The Blurr Transform with information about the Hugging Face objects used in your training\n",
    "    tfm:Transform\n",
    "):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.blurr_predict` or `blurrONNX.predict.\n",
    "    Aligns the predicted labels, label ids, and probabilities with what you passed in excluding subword tokens\n",
    "    \"\"\"\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "    \n",
    "    if (isinstance(items[0], str)): items = [items]\n",
    "        \n",
    "    outs = []\n",
    "    for inp, res in zip(items, predict_func(items)):\n",
    "        # blurr_predict returns a list for each, we only doing one at a time so git first element of each\n",
    "        pred_lbls, pred_lbl_ids, probs = res[0][0], res[1][0], res[2][0]\n",
    "  \n",
    "        # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "        # return\n",
    "        subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "        # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "        # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "        # (e.g., [CLS], [SEP], etc...)\n",
    "        res = hf_tokenizer(inp, None, \n",
    "                           max_length=tfm.max_length,\n",
    "                           padding=tfm.padding,\n",
    "                           truncation=tfm.truncation,\n",
    "                           is_split_into_words=tfm.is_split_into_words,\n",
    "                           **tok_kwargs)\n",
    "\n",
    "        special_toks_msk = L(res['special_tokens_mask'])\n",
    "        actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "        # using the indexes to the actual tokens, get that info from the results returned above\n",
    "        pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "        actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "        actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "        actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "        # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "        # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "        offset = 0\n",
    "        raw_trg_idxs = []\n",
    "        for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "            raw_trg_idxs.append(idx+offset)\n",
    "            offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "            \n",
    "        outs.append((inp, \n",
    "                     actual_pred_lbls[raw_trg_idxs], \n",
    "                     actual_pred_lbl_ids[raw_trg_idxs], \n",
    "                     actual_probs[raw_trg_idxs]))\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(\n",
    "    self:Learner, \n",
    "    # The str (or list of strings) you want to get token classification predictions for\n",
    "    items:Union[str, List[str]],\n",
    "    # Keyword arguments for `blurr_predict_tokens`\n",
    "    **kwargs\n",
    "):\n",
    "    tfm = first_blurr_tfm(self.dls, before_batch_tfm_class=HF_TokenClassBeforeBatchTransform) \n",
    "    return _blurr_predict_tokens(self.blurr_predict, items, tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`items`**:`Union`\\[`str`, `List`\\[`str`\\]\\], **\\*\\*`kwargs`**)\n",
       "\n",
       "\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`items`** : *`typing.Union[str, typing.List[str]]`*\t<p>The str (or list of strings) you want to get token classification predictions for</p>\n",
       "\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\n",
    "txt2 = \"I wish covid was over so I could go to Germany and watch Bayern Munich play in the Bundesliga.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'O'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'B-LOC'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'tok_class_learn_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'O'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'B-LOC'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "\n",
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLearnerForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTokenClassification(Blearner):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        dls:DataLoaders,\n",
    "        hf_model:PreTrainedModel,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "        \n",
    "    @classmethod\n",
    "    def get_model_cls(self): \n",
    "        return AutoModelForTokenClassification\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_y(cls, r, tokens, token_labels, tokenizer): \n",
    "        return [ (label, len(tokenizer.tokenize(str(entity)))) for entity, label in zip(r[tokens], r[token_labels]) ]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        return HF_TokenClassMetricsCallback()\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls, \n",
    "        # Your raw dataset\n",
    "        data, \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The attribute in your dataset that contains a list of your tokens\n",
    "        tokens_attr:List[str]='tokens', \n",
    "        # The attribute in your dataset that contains the entity labels for each token in your raw text\n",
    "        token_labels_attr:List[str]='token_labels', \n",
    "        # The unique entity labels (or vocab) available in your dataset\n",
    "        labels:List[str]=None, \n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(), \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={}\n",
    "    ):\n",
    "        # get our hf objects\n",
    "        n_labels = len(labels)\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, \n",
    "                                                                          model_cls=cls.get_model_cls(), \n",
    "                                                                          config_kwargs={'num_labels': n_labels})\n",
    "        \n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if (preprocess_func):\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, tokens, token_labels, labels)\n",
    "            \n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if (hf_tokenizer.pad_token is None): \n",
    "            hf_tokenizer.add_special_tokens({'pad_token': '<pad>'})  \n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()['<pad>']\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "        \n",
    "        # build getters\n",
    "        if (isinstance(data, pd.DataFrame)):\n",
    "            get_x = ColReader(tokens_attr)\n",
    "            get_y = partial(cls._get_y, tokens=tokens_attr, token_labels=token_labels_attr, tokenizer=hf_tokenizer)\n",
    "        else:\n",
    "            get_x = ItemGetter(tokens_attr)\n",
    "            get_y = partial(cls._get_y, tokens=tokens_attr, token_labels=token_labels_attr, tokenizer=hf_tokenizer)\n",
    "             \n",
    "        before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                             is_split_into_words=True, \n",
    "                                                             tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "        \n",
    "        blocks = (\n",
    "            HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "            HF_TokenCategoryBlock(vocab=labels)\n",
    "        )\n",
    "        \n",
    "        dblock = DataBlock(blocks=blocks, \n",
    "                           get_x=get_x,\n",
    "                           get_y=get_y,\n",
    "                           splitter=dblock_splitter)\n",
    "        \n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "        \n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "         cls, \n",
    "        # Your pandas DataFrame\n",
    "        df:pd.DataFrame, \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The attribute in your dataset that contains a list of your tokens\n",
    "        tokens_attr:List[str]='tokens', \n",
    "        # The attribute in your dataset that contains the entity labels for each token in your raw text\n",
    "        token_labels_attr:List[str]='token_labels', \n",
    "        # The unique entity labels (or vocab) available in your dataset\n",
    "        labels:List[str]=None, \n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=ColSplitter(), \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={}\n",
    "    ):\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if (labels is None):\n",
    "            labels = sorted(list(set([lbls for sublist in df[token_labels_attr].tolist() for lbls in sublist])))\n",
    "            \n",
    "        return cls._create_learner(df, pretrained_model_name_or_path, preprocess_func, \n",
    "                                   tokens_attr, token_labels_attr, labels, dblock_splitter, \n",
    "                                   dl_kwargs, learner_kwargs)\n",
    "    \n",
    "        \n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls, \n",
    "        # The path to your csv file\n",
    "        csv_file:Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The attribute in your dataset that contains a list of your tokens\n",
    "        tokens_attr:List[str]='tokens', \n",
    "        # The attribute in your dataset that contains the entity labels for each token in your raw text\n",
    "        token_labels_attr:List[str]='token_labels', \n",
    "        # The unique entity labels (or vocab) available in your dataset\n",
    "        labels:List[str]=None, \n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=ColSplitter(), \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={}\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        return cls.from_dataframe(df, \n",
    "                                  pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                  preprocess_func=preprocess_func,\n",
    "                                  tokens_attr=tokens_attr, token_labels_attr=token_labels_attr, labels=labels, \n",
    "                                  dblock_splitter=dblock_splitter, \n",
    "                                  dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls, \n",
    "        # A list of dictionaries\n",
    "        ds:List[Dict], \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The attribute in your dataset that contains a list of your tokens\n",
    "        tokens_attr:List[str]='tokens', \n",
    "        # The attribute in your dataset that contains the entity labels for each token in your raw text\n",
    "        token_labels_attr:List[str]='token_labels', \n",
    "        # The unique entity labels (or vocab) available in your dataset\n",
    "        labels:List[str]=None, \n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(), \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={}\n",
    "    ):\n",
    "        \n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if (labels is None):\n",
    "            all_labels = []\n",
    "            for item in raw_ds: all_labels += item[token_labels_attr]\n",
    "            labels = sorted(list(set(all_labels)))\n",
    "\n",
    "        return cls._create_learner(ds, pretrained_model_name_or_path, preprocess_func, \n",
    "                                   tokens_attr, token_labels_attr, labels, dblock_splitter, \n",
    "                                   dl_kwargs, learner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTokenClassification.from_dataframe(germ_eval_df, 'bert-base-multilingual-cased', \n",
    "                                                      tokens_attr='tokens', token_labels_attr='labels', \n",
    "                                                      dblock_splitter=RandomSplitter(), \n",
    "                                                      dl_kwargs={'bs':2})\n",
    "\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O'), ('Standard', 'B-ORG'), ('Oil', 'I-ORG'), ('of', 'I-ORG'), ('New', 'I-ORG'), ('Jersey', 'I-ORG'), ('),', 'O'), ('die', 'O'), ('ausgesprochen', 'O'), ('„', 'O'), ('Esso', 'O'), ('ergeben', 'B-ORG'), ('(', 'O'), ('heute', 'O'), ('ExxonMobil', 'O'), (').', 'O'), (';', 'B-ORG'), ('Exxon', 'O'), (':', 'O'), ('Ein', 'O'), ('Name,', 'B-ORG'), ('der', 'O'), ('in', 'O'), ('den', 'O'), ('frühen', 'O'), ('1970ern', 'O'), ('von', 'O'), ('Esso', 'O'), ('erfunden', 'O'), ('wurde,', 'O'), ('um', 'O'), ('ein', 'B-ORG'), ('neutrales', 'O'), ('aber', 'O'), ('eindeutiges', 'O'), ('Markenzeichen', 'O'), ('für', 'O'), ('das', 'O'), ('Unternehmen', 'O'), ('zu', 'O'), ('haben.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O'), ('notenbeste', 'O'), ('Zweitligaspieler', 'O'), ('(', 'O'), ('2,', 'O'), ('91', 'O'), ('),', 'O'), ('der', 'O'), ('seine', 'O'), ('persönliche', 'O'), ('Bilanz', 'O'), ('auf', 'O'), ('sieben', 'O'), ('Tore', 'O'), ('und', 'O'), ('13', 'O'), ('Assists', 'O'), ('aufstockte', 'O'), ('und', 'O'), ('schon', 'O'), ('vor', 'O'), ('Wochen', 'O'), ('seinen', 'O'), ('Wechsel', 'O'), ('zu', 'O'), ('Dortmund', 'B-ORG'), ('bekannt', 'O'), ('gegeben', 'O'), ('hatte,', 'O'), ('war', 'O'), ('zuletzt', 'O'), ('in', 'O'), ('Mainz', 'O'), ('in', 'B-LOC'), ('die', 'O'), ('Kritik', 'O'), ('geraten.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.195376</td>\n",
       "      <td>0.180452</td>\n",
       "      <td>0.945981</td>\n",
       "      <td>0.548638</td>\n",
       "      <td>0.550781</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), cbs=[BlearnerForTokenClassification.get_metrics_cb()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'B-PER'), ('al.', 'I-OTH', 'I-PER'), ('(', 'O', 'I-PER'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('S.', 'O', 'O'), ('593.', 'O', 'O'), ('Wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('NEWSru.', 'B-OTH', 'O'), ('ua', 'O', 'B-ORG'), ('/', 'O', 'B-ORG'), (':', 'B-OTH', 'O'), ('Политисполком', 'I-OTH', 'O'), ('СПУ', 'I-OTH', 'O'), ('отказал', 'I-OTH', 'O'), ('Морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.76      0.48      0.59        79\n",
      "    LOCderiv       0.48      0.73      0.58        15\n",
      "     LOCpart       0.00      0.00      0.00         0\n",
      "         ORG       0.42      0.31      0.35        75\n",
      "     ORGpart       0.00      0.00      0.00         0\n",
      "         OTH       0.03      0.25      0.05         4\n",
      "    OTHderiv       0.00      0.00      0.00         0\n",
      "         PER       0.86      0.82      0.84        83\n",
      "    PERderiv       0.00      0.00      0.00         0\n",
      "     PERpart       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       256\n",
      "   macro avg       0.25      0.26      0.24       256\n",
      "weighted avg       0.66      0.55      0.59       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\n",
    "txt2 = \"I wish covid was over so I could watch Lewandowski score some more goals for Bayern Munich in the Bundesliga.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'O'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'O'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'O'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('watch', 'O'), ('Lewandowski', 'B-PER'), ('score', 'O'), ('some', 'O'), ('more', 'O'), ('goals', 'O'), ('for', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'B-LOC'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the token classification training code above works for **all** pretrained token classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlbertForTokenClassification',\n",
       " 'BertForTokenClassification',\n",
       " 'BigBirdForTokenClassification',\n",
       " 'CamembertForTokenClassification',\n",
       " 'CanineForTokenClassification',\n",
       " 'ConvBertForTokenClassification',\n",
       " 'DebertaForTokenClassification',\n",
       " 'DebertaV2ForTokenClassification',\n",
       " 'DistilBertForTokenClassification',\n",
       " 'ElectraForTokenClassification',\n",
       " 'FlaubertForTokenClassification',\n",
       " 'FunnelForTokenClassification',\n",
       " 'IBertForTokenClassification',\n",
       " 'LayoutLMForTokenClassification',\n",
       " 'LongformerForTokenClassification',\n",
       " 'MPNetForTokenClassification',\n",
       " 'MegatronBertForTokenClassification',\n",
       " 'MobileBertForTokenClassification',\n",
       " 'RoFormerForTokenClassification',\n",
       " 'RobertaForTokenClassification',\n",
       " 'SqueezeBertForTokenClassification',\n",
       " 'XLMForTokenClassification',\n",
       " 'XLMRobertaForTokenClassification',\n",
       " 'XLNetForTokenClassification']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "[ model_type for model_type in BLURR.get_models(task='TokenClassification') \n",
    " if (not model_type.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'google/electra-small-discriminator',\n",
    "    'flaubert/flaubert_small_cased',\n",
    "    'huggingface/funnel-small-base',\n",
    "    'allenai/longformer-base-4096',\n",
    "    'microsoft/mpnet-base',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'squeezebert/squeezebert-uncased',\n",
    "    'xlm-mlm-en-2048',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.883653</td>\n",
       "      <td>1.723884</td>\n",
       "      <td>0.834756</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'B-ORGpart'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'B-OTHpart'), ('.', 'O', 'B-PER'), ('(', 'O', 'B-ORGpart'), ('1994', 'O', 'B-ORGpart'), (')', 'O', 'O'), ('s.', 'O', 'O'), ('593.', 'O', 'O'), ('wink', 'B-OTH', 'I-OTH')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('auerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-multilingual-cased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.671894</td>\n",
       "      <td>1.435831</td>\n",
       "      <td>0.911207</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'B-OTH'), ('et', 'I-OTH', 'O'), ('al.', 'I-OTH', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('S.', 'O', 'O'), ('593.', 'O', 'O'), ('Wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'B-OTH'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('Sexual', 'I-OTH', 'O'), ('Nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('GB', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.539994</td>\n",
       "      <td>2.471204</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('R&lt;unk&gt;ckkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Au&lt;unk&gt;erdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('Nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('Stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.925654</td>\n",
       "      <td>1.762854</td>\n",
       "      <td>0.902619</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('mit', 'O', 'O'), ('der', 'O', 'O'), ('servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('art', 'O', 'O'), ('freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('senden', 'O', 'O'), ('exxon', 'B-ORG', 'O'), ('mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.', 'B-ORG', 'O'), ('de', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/electra-small-discriminator ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.574281</td>\n",
       "      <td>2.523330</td>\n",
       "      <td>0.697583</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('nach', 'O', 'B-PER'), ('seiner', 'O', 'O'), ('ruckkehr', 'O', 'B-OTHderiv'), ('hielt', 'O', 'O'), ('strummer', 'B-PER', 'B-OTHderiv'), ('ein', 'O', 'O'), ('bandmeeting', 'O', 'O'), ('ab,', 'O', 'O'), ('in', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('die', 'O', 'B-PER'), ('flugel', 'O', 'O'), ('die', 'O', 'O'), ('geoffneten', 'O', 'O'), ('flugel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('szenen', 'O', 'O'), ('hohepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.415370</td>\n",
       "      <td>1.350314</td>\n",
       "      <td>0.876126</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'O'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('S.', 'O', 'O'), ('593', 'O', 'O'), ('.', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('Sexual', 'I-OTH', 'O'), ('Nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('GB', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== huggingface/funnel-small-base ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.942134</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.897079</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al.', 'I-OTH', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'B-LOC'), ('s.', 'O', 'O'), ('593.', 'O', 'O'), ('wink', 'O', 'B-LOC'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('nach', 'O', 'O'), ('seiner', 'O', 'O'), ('ruckkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('bandmeeting', 'O', 'O'), ('ab,', 'O', 'O'), ('in', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.009505</td>\n",
       "      <td>1.924495</td>\n",
       "      <td>0.893286</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('NEWSru.ua', 'B-OTH', 'O'), ('/', 'O', 'O'), (':', 'O', 'O'), ('Политисполком', 'B-OTH', 'O'), ('СПУ', 'I-OTH', 'O'), ('отказал', 'I-OTH', 'O'), ('Морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'I-OTH', 'I-OTH'), ('Die', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/mpnet-base ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.415749</td>\n",
       "      <td>2.318348</td>\n",
       "      <td>0.903304</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('mit', 'O', 'O'), ('der', 'O', 'O'), ('servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('art', 'O', 'O'), ('freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('die', 'O', 'O'), ('flugel', 'O', 'O'), ('die', 'O', 'O'), ('geoffneten', 'O', 'O'), ('flugel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('szenen', 'O', 'O'), ('hohepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.573552</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.024443</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'B-LOC'), ('standard', 'B-ORG', 'I-LOCderiv'), ('oil', 'I-ORG', 'B-OTHderiv'), ('of', 'I-ORG', 'I-OTH'), ('new', 'I-ORG', 'B-OTHderiv'), ('jersey', 'I-ORG', 'B-ORG'), ('),', 'O', 'I-LOCderiv'), ('die', 'O', 'B-LOCderiv'), ('ausgesprochen', 'O', 'I-PER'), ('„', 'O', 'B-LOCpart')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('scenes', 'B-OTH', 'B-LOC'), ('of', 'I-OTH', 'I-ORG'), ('a', 'I-OTH', 'B-OTHderiv'), ('sexual', 'I-OTH', 'B-OTHderiv'), ('nature', 'I-OTH', 'I-ORG'), ('(', 'O', 'B-LOC'), ('gb', 'O', 'B-PERderiv'), ('2006', 'O', 'B-LOC'), (')', 'O', 'I-ORGpart'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.833194</td>\n",
       "      <td>2.730294</td>\n",
       "      <td>0.133167</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'B-LOCderiv'), ('Standard', 'B-ORG', 'B-ORGpart'), ('Oil', 'I-ORG', 'I-OTH'), ('of', 'I-ORG', 'B-OTHpart'), ('New', 'I-ORG', 'B-PERpart'), ('Jersey', 'I-ORG', 'B-ORG'), (')', 'O', 'B-PERpart'), (',', 'O', 'B-ORG'), ('die', 'O', 'B-OTHpart'), ('ausgesprochen', 'O', 'B-PERpart')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('\"', 'O', 'B-LOCderiv'), ('Es', 'O', 'B-LOCderiv'), ('ist', 'O', 'B-PERpart'), ('beabsichtigt', 'O', 'B-PERpart'), (',', 'O', 'B-LOCderiv'), ('die', 'O', 'B-PERpart'), ('Aktien', 'O', 'B-ORG'), ('im', 'O', 'O'), ('ersten', 'O', 'B-PERpart'), ('Halbjahr', 'O', 'B-ORGpart')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.455795</td>\n",
       "      <td>2.400356</td>\n",
       "      <td>0.893222</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('standard', 'B-ORG', 'O'), ('oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'O'), ('new', 'I-ORG', 'O'), ('jersey', 'I-ORG', 'O'), ('),', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O'), ('„', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('sexual', 'I-OTH', 'O'), ('nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('gb', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.886470</td>\n",
       "      <td>0.829503</td>\n",
       "      <td>0.874527</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('sexual', 'I-OTH', 'O'), ('nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('gb', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('mit', 'O', 'O'), ('der', 'O', 'O'), ('servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('art', 'O', 'O'), ('freundschaft', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.857473</td>\n",
       "      <td>2.802217</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'I-LOCderiv'), ('und', 'O', 'B-PERpart'), ('Engagement', 'O', 'I-LOCderiv'), (':', 'O', 'B-PERpart'), ('das', 'O', 'B-PERpart'), ('eigentlich', 'O', 'B-PERpart'), ('Neue', 'O', 'B-PERpart'), ('an', 'O', 'B-PERpart'), ('der', 'O', 'B-PERpart'), ('Netz(', 'O', 'I-LOCderiv')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'I-LOCderiv'), ('of', 'I-OTH', 'B-PERpart'), ('a', 'I-OTH', 'B-PERpart'), ('Sexual', 'I-OTH', 'B-PERpart'), ('Nature', 'I-OTH', 'B-PERpart'), ('(', 'O', 'B-PERpart'), ('GB', 'O', 'B-PERpart'), ('2006', 'O', 'B-PERpart'), (')', 'O', 'B-PERpart'), ('-', 'O', 'B-PERpart')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.763870</td>\n",
       "      <td>1.787236</td>\n",
       "      <td>0.451639</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'I-LOC'), ('und', 'O', 'B-LOCpart'), ('Engagement', 'O', 'B-LOCpart'), (':', 'O', 'O'), ('das', 'O', 'I-LOC'), ('eigentlich', 'O', 'I-LOC'), ('Neue', 'O', 'I-PER'), ('an', 'O', 'B-LOCpart'), ('der', 'O', 'B-LOCpart'), ('Netz(', 'O', 'B-LOCpart')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Ruckkehr', 'O', 'B-LOCpart'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "model_cls = AutoModelForTokenClassification\n",
    "bsz = 4\n",
    "seq_sz = 64\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.num_labels = len(labels)\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      config=config)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n')\n",
    "    \n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if (hf_tokenizer.pad_token is None): \n",
    "        hf_tokenizer.add_special_tokens({'pad_token': '<pad>'})  \n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()['<pad>']\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer)) \n",
    "    \n",
    "    before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                         max_length=seq_sz,\n",
    "                                                         padding='max_length',\n",
    "                                                         is_split_into_words=True, \n",
    "                                                         tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "    blocks = (\n",
    "        HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "        HF_TokenCategoryBlock(vocab=labels)\n",
    "    )\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('tokens'),\n",
    "                       get_y= lambda inp: [ \n",
    "                           (label, len(hf_tokenizer.tokenize(str(entity)))) \n",
    "                           for entity, label in zip(inp.tokens, inp.labels) \n",
    "                       ],\n",
    "                       splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(germ_eval_df, bs=bsz)\n",
    "\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter).to_fp16()\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), \n",
    "                            cbs=[HF_TokenClassMetricsCallback(tok_metrics=['accuracy'])])\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=10)\n",
    "        \n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "        \n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes all the low, mid, and high-level API bits for token classification tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
