{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp modeling.seq2seq.translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.seq2seq.translation\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... translation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, inspect, torch\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from datasets import load_metric as hf_load_metric, list_metrics as hf_list_metrics\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar,master_bar\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM, logging,\n",
    "    PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    ")\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.seq2seq.core import Seq2SeqTextBlock, Seq2SeqBatchTokenizeTransform, default_text_gen_kwargs\n",
    "from blurr.modeling.core import BaseModelWrapper, BaseModelCallback, PreCalculatedLoss, Blearner\n",
    "from blurr.modeling.seq2seq.core import Seq2SeqMetricsCallback, blurr_seq2seq_splitter\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "import os, ast, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import list_datasets, load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions('torch fastai transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "Translation tasks attempt to convert text in one language into another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('wmt16', 'de-en', split='train[:1%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45489"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "wmt_df = pd.DataFrame(ds['translation'], columns=['de', 'en']); len(wmt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_df = wmt_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Resumption of the session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.</td>\n",
       "      <td>I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                           de  \\\n",
       "0                                                                                                                                                                                          Wiederaufnahme der Sitzungsperiode   \n",
       "1  Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.   \n",
       "\n",
       "                                                                                                                                                                                                                en  \n",
       "0                                                                                                                                                                                        Resumption of the session  \n",
       "1  I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmt_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('marian',\n",
       " transformers.models.marian.tokenization_marian.MarianTokenizer,\n",
       " transformers.models.marian.configuration_marian.MarianConfig,\n",
       " transformers.models.marian.modeling_marian.MarianMTModel)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('de'), get_y=ColReader('en'), splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(wmt_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 141]), torch.Size([2, 101]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Angesichts▁dieser Situation▁muß▁aus dem▁Bericht, den das▁Parlament annimmt,▁klar▁hervorgehen,▁daß▁Maßnahmen▁notwendig▁sind, die▁eindeutig auf die▁Bekämpfung der relativen▁Armut und der Arbeitslosigkeit▁gerichtet▁sind.▁Maßnahmen▁wie die für diese▁Zwe</td>\n",
       "      <td>Given this situation, the report approved by Parliament must highlight the need for measures that aim unequivocally to fight relative poverty and unemployment: measures such as the appropriate use of structural funds for these purposes, which are oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Ich▁möchte▁daher die▁Kommission auf▁zwei▁Punkte▁hinweisen:▁Erstens▁muß die▁Konzertierung▁als Instrument der▁Koordinierung und der▁Beteiligung▁sämtlicher▁lokaler und▁regionaler▁Marktteilnehmer an den▁Entscheidungen optimal▁genutzt▁werden, um▁speziell</td>\n",
       "      <td>Firstly, we need to make the best possible use of consultation as a means of ensuring proper coordination and participation by all local and regional operators in decision-making, precisely so that imbalances and inequalities can be avoided. Secondly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "seq2seq_metrics = {\n",
    "    'bleu': { 'returns': \"bleu\" },\n",
    "    'meteor': { 'returns': \"meteor\" },\n",
    "    'sacrebleu': { 'returns': \"score\" }\n",
    "}\n",
    "\n",
    "model = BaseModelWrapper(hf_model)\n",
    "\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                loss_func=CrossEntropyLossFlat(), #PreCalculatedLoss()\n",
    "                cbs=learn_cbs,\n",
    "                splitter=partial(blurr_seq2seq_splitter, arch=hf_arch)) #.to_native_fp16() #.to_fp16()\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = dls.one_batch()\n",
    "# preds = learn.model(b[0])\n",
    "\n",
    "# len(preds),preds['loss'].shape, preds['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 141]), 2, torch.Size([2, 101]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=8.317637839354575e-05, steep=1.0964781722577754e-06, valley=3.630780702224001e-05, slide=5.248074739938602e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.364456</td>\n",
       "      <td>1.188517</td>\n",
       "      <td>0.316544</td>\n",
       "      <td>0.620779</td>\n",
       "      <td>31.041190</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Aufgrund▁meinen▁Vorstellungen vom▁Aufbau▁Europas und von▁regionaler▁Entwicklungspolitik im▁besonderen▁halte▁ich das für eine Situation, die▁ich nicht▁akzeptieren▁kann.▁Ich▁habe die▁Absicht, im▁Rahmen▁meiner▁Möglichkeiten und mit▁Ihrer▁Unterstützung▁sämtliche Mittel, für die▁ich▁Verantwortung▁trage, für eine▁verbesserte▁soziale,▁menschliche und▁territoriale▁Kohäsion zu▁verwenden, um zu▁verhindern,▁daß es,▁wie▁ich es vor▁diesem▁Hause▁nannte, ein Europa der▁zwei▁Geschwindigkeiten▁gibt, ein Europa</td>\n",
       "      <td>As far as I am concerned - taking into account my own concept of the construction of Europe and regional development policy in particular - this is a situation which I find unacceptable and I have every intention, as far as possible, with your support, of dedicating all the appropriations for which I am responsible to this improved social, human and territorial cohesion, particularly in order to prevent what I once called in this House a two-speed Europe, a Europe of wealthy districts but, at th</td>\n",
       "      <td>On the basis of my ideas about the construction of Europe and of regional development policy in particular, I consider this to be a situation which I cannot accept, and I intend, within my possibilities and with your support, to use all the means for which I am responsible, in order to improve social, human and territorial cohesion in order to prevent, as I called it before this House, a Europe of two speeds, a Europe of chic neighbourhoods and a Europe of poor suburbs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frau▁Präsidentin! Wir▁können und▁dürfen▁uns nicht▁damit▁abfinden,▁immer▁häufiger von▁Unfällen zu▁hören,▁bei▁denen auf der Straße,▁aber▁auch auf der▁Schiene oder auf Wasserwegen▁große▁Schäden▁entstehen, nicht▁nur,▁aber▁auch,▁weil die▁Betroffenen den Transit von▁gefährlichen▁Gütern nicht▁ernst▁genug▁nehmen oder▁weil durch Unwissen oder▁aufgrund▁mangelnder▁Ausbildung der▁Fahrer oder▁sonstiger▁Verantwortlicher für die▁diversen▁Verkehrsmittel▁aus▁einem▁kleinen▁Unfall▁allzu▁oft eine▁große▁Katastrophe▁</td>\n",
       "      <td>Madam President, we cannot and must not accept the fact that we hear ever more frequently of accidents causing major damage on our roads, but also on our railways and waterways, not solely but at least partly because those involved do not take the transport of dangerous goods seriously enough or because - as a result of ignorance or a lack of training on the part of the drivers or others responsible for the various vehicles - a minor accident has all too often become a major disaster.</td>\n",
       "      <td>Madam President, we cannot and must not accept the fact that there is an increasing number of accidents involving serious damage to the road, rail or waterways, not only, but also because the persons concerned do not take the transit of dangerous goods seriously enough, or because all too often a major disaster has been caused by ignorance or lack of training of drivers or other persons responsible for the various modes of transport resulting from a small accident.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      "I like to drink beer\n",
      "\n",
      "=== Prediction 2 ===\n",
      "I like to drink beer.\n",
      "\n",
      "=== Prediction 3 ===\n",
      "I like to drink\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_de, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'translation_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlearnerForTranslation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTranslation(Blearner):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        dls: DataLoaders, \n",
    "        hf_model: PreTrainedModel, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "            \n",
    "    @classmethod\n",
    "    def get_model_cls(cls): \n",
    "        return AutoModelForSeq2SeqLM\n",
    "    \n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp, src_lang_name, trg_lang_name): \n",
    "        return f'translate {src_lang_name} to {trg_lang_name}: {inp}'\n",
    "    \n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\n",
    "            'bleu': { 'returns': \"bleu\" },\n",
    "            'meteor': { 'returns': \"meteor\" },\n",
    "            'sacrebleu': { 'returns': \"score\" }\n",
    "        }\n",
    "            \n",
    "        return Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls, \n",
    "        # Your raw dataset\n",
    "        data, \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name:str='English', \n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr:str='src_lang', \n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name:str='English',\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr:str='trg_lang', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = BLURR.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        if (hf_arch == 'mbart'): \n",
    "            hf_tok_kwargs = { **{'src_lang': 'en_XX', 'tgt_lang': 'en_XX'}, **hf_tok_kwargs }\n",
    "            \n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, \n",
    "                                                                          model_cls=model_cls, \n",
    "                                                                          tokenizer_kwargs=hf_tok_kwargs)\n",
    "        \n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if (preprocess_func):\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, src_lang_attr, trg_lang_attr)\n",
    "            \n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = { **text_gen_kwargs, **default_text_gen_kwargs(hf_config, hf_model, task='translation') }\n",
    "        \n",
    "        # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args: del text_gen_kwargs[k]\n",
    "                \n",
    "        # update our text generation kwargs for mbart\n",
    "        if (hf_arch == 'mbart'):\n",
    "            text_gen_kwargs = { **{'decoder_start_token_id': 'en_XX'}, **text_gen_kwargs }\n",
    "            \n",
    "        # build dblock, dls, and default metrics (optional)\n",
    "        if (isinstance(data, pd.DataFrame)):\n",
    "            get_x = Pipeline(funcs=[ColReader(src_lang_attr)])\n",
    "            get_y = ColReader(trg_lang_attr)\n",
    "        else:\n",
    "            get_x = Pipeline(funcs=[ItemGetter(src_lang_attr)])\n",
    "            get_y = ItemGetter(trg_lang_attr)\n",
    "                               \n",
    "        if (hf_arch == 't5'):\n",
    "            get_x.add(partial(cls._add_t5_prefix, src_lang_name=src_lang_name, trg_lang_name=trg_lang_name))\n",
    "            \n",
    "        batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                          max_length=max_length, \n",
    "                                                          max_target_length=max_target_length, \n",
    "                                                          text_gen_kwargs=text_gen_kwargs)\n",
    "        \n",
    "        blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "        dblock = DataBlock(blocks=blocks, \n",
    "                           get_x=get_x, \n",
    "                           get_y=get_y, \n",
    "                           splitter=dblock_splitter)\n",
    "        \n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "        \n",
    "        # return BLearner instance\n",
    "        learner_kwargs['splitter'] = learner_kwargs.pop('splitter', partial(blurr_seq2seq_splitter, arch=hf_arch))\n",
    "        learner_kwargs['loss_func'] = learner_kwargs.pop('loss_func', CrossEntropyLossFlat())\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls, \n",
    "        # Your pandas DataFrame\n",
    "        df, \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name:str='English', \n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr:str='src_lang', \n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name:str='English',\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr:str='trg_lang', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        return cls._create_learner(df, \n",
    "                                   pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                   preprocess_func=preprocess_func, \n",
    "                                   src_lang_name=src_lang_name, \n",
    "                                   src_lang_attr=src_lang_attr, \n",
    "                                   trg_lang_name=trg_lang_name, \n",
    "                                   trg_lang_attr=trg_lang_attr, \n",
    "                                   max_length=max_length, \n",
    "                                   max_target_length=max_target_length,  \n",
    "                                   dblock_splitter=dblock_splitter, \n",
    "                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "        \n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls, \n",
    "        # The path to your csv file\n",
    "        csv_file:Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name:str='English', \n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr:str='src_lang', \n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name:str='English',\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr:str='trg_lang', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        return cls.from_dataframe(df, \n",
    "                                  pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                  preprocess_func=preprocess_func, \n",
    "                                  src_lang_name=src_lang_name, \n",
    "                                  src_lang_attr=src_lang_attr, \n",
    "                                  trg_lang_name=trg_lang_name, \n",
    "                                  trg_lang_attr=trg_lang_attr, \n",
    "                                  max_length=max_length, \n",
    "                                  max_target_length=max_target_length,  \n",
    "                                  dblock_splitter=dblock_splitter, \n",
    "                                  hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                  dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls, \n",
    "        # A list of dictionaries\n",
    "        ds:List[Dict], \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name:str='English', \n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr:str='src_lang', \n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name:str='English',\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr:str='trg_lang', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        return cls._create_learner(ds, \n",
    "                                   pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                   preprocess_func=preprocess_func, \n",
    "                                   src_lang_name=src_lang_name, \n",
    "                                   src_lang_attr=src_lang_attr, \n",
    "                                   trg_lang_name=trg_lang_name, \n",
    "                                   trg_lang_attr=trg_lang_attr, \n",
    "                                   max_length=max_length, \n",
    "                                   max_target_length=max_target_length,  \n",
    "                                   dblock_splitter=dblock_splitter, \n",
    "                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTranslation.from_dataframe(wmt_df, 'Helsinki-NLP/opus-mt-de-en', \n",
    "                                              src_lang_name='German', src_lang_attr='de', \n",
    "                                              trg_lang_name='English', trg_lang_attr='en', \n",
    "                                              dblock_splitter=RandomSplitter(),\n",
    "                                              dl_kwargs={'bs':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.244795</td>\n",
       "      <td>1.311637</td>\n",
       "      <td>0.325591</td>\n",
       "      <td>0.586610</td>\n",
       "      <td>31.701792</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForTranslation.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sie▁wird▁aber auf▁Seite 5▁dieser▁Leitlinien▁ganz▁eindeutig▁genannt, und▁ich▁möchte▁darauf▁verweisen -▁weil▁sie▁mich▁dazu▁aufgefordert▁haben -,▁daß diese▁Partnerschaft für▁mich - und▁ich▁habe▁lange▁genug eine Region▁betreut, um dies▁beurteilen zu▁können - ein▁sehr▁wirkungsvolles Instrument zur▁Mobilisierung der▁geistigen▁Ressourcen auf▁lokaler▁Ebene▁ist -▁sowohl derer im▁öffentlichen▁Sektor - die Stadt- und▁Gemeinderäte, den▁schulischen und▁gesellschaftlichen▁Bereich, die▁Vereine und▁Verbände -▁a</td>\n",
       "      <td>However, I do wish to mention - since you have asked me to do so - that, as far as I am concerned, this partnership - and I spent long enough as a regional administrator within my own country to be able to say this most sincerely - is a tool, one use</td>\n",
       "      <td>However, it is clearly mentioned on page 5 of these guidelines, and I would like to point out - because they have asked me to do so - that this partnership is a very effective instrument for me - and I have maintained a region long enough to be able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vor▁allen▁Dingen▁besteht die▁Gefahr,▁daß die - in▁vielerlei▁Hinsicht▁notwendige -▁Verlagerung der▁Zuständigkeiten auf die▁einzelstaatliche▁Ebene▁dazu▁führt,▁daß▁Maßnahmen im▁Bereich des▁Wettbewerbs▁enorm▁zunehmen und die▁Versuchung▁besteht, das▁Kartellverbot nicht▁als▁letztinstanzliche▁Garantie für das▁einwandfreie und▁vorhersehbare▁Funktionieren der▁Märkte▁einzusetzen,▁sondern▁als▁wirtschafts- und industriepolitisches Instrument,▁als Instrument der▁Planung und des▁Eingreifens in die▁spontanen▁E</td>\n",
       "      <td>First of all, there is a risk that the decentralisation of powers, though necessary in many ways, will cause an abnormal increase in competition-related initiatives, and that some people will be tempted to use competition law, not as a means to be re</td>\n",
       "      <td>Above all, there is a risk that the transfer of responsibilities to the national level, which is necessary in many respects, will result in an enormous increase in competition measures and the temptation to use the ban on cartels not as a last resort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = 'translation_export'\n",
    "\n",
    "learn.metrics = None\n",
    "learn = learn.to_fp32()\n",
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **translation models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained translation models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ model_type for model_type in BLURR.get_models(task='ConditionalGeneration') \n",
    " if (not model_type.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'facebook/bart-base',\n",
    "    'facebook/wmt19-de-en',                      # FSMT\n",
    "    'Helsinki-NLP/opus-mt-de-en',                # MarianMT\n",
    "    #'sshleifer/tiny-mbart',\n",
    "    #'google/mt5-small',\n",
    "    't5-small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n"
     ]
    }
   ],
   "source": [
    "path = Path('./')\n",
    "ds = load_dataset('wmt16', 'de-en', split='train[:1%]')\n",
    "wmt_df = pd.DataFrame(ds['translation'], columns=['de', 'en']); len(wmt_df)\n",
    "wmt_df = wmt_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angesichts dieser Situation muß aus dem Bericht, den das Parlament annimmt, klar hervorgehen, daß Maßnahmen notwendig sind, die eindeutig auf die Bekämpfung der relativen Armut und der Arbeitslosigkeit gerichtet sind. Maßnahmen wie die für diese Zwecke angemessene Verwendung der Strukturfonds, die häufig unsachgemäß eingesetzt wer</td>\n",
       "      <td>Given this situation, the report approved by Parliament must highlight the need for measures that aim unequivocally to fight relative poverty and unemployment: measures such as the appropriate use of structural funds for these purposes, which are of</td>\n",
       "      <td>Angesichts dieser Situation muß aus dem Bericht, den d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diese Änderungen, sollten sie heute von diesem Hohen Haus angenommen werden, sind meiner Ansicht nach ein weiterer entscheidender Schritt zur Erreichung der historisch bedeutsamen Ziele, für die die Fonds ursprünglich eingerichtet worden waren, nämlich die finanziell nachhaltige Unterstützung der benachteiligten Gebiete in der Europäischen</td>\n",
       "      <td>If these changes to the report are supported by the House today, I believe that they will move us forward in the next phase of achieving the historic objectives which the funds were set up to bring about, namely to assist - in a financially sustaina</td>\n",
       "      <td>Diese Änderungen, sollten sie heute von</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/wmt19-de-en ===\n",
      "\n",
      "architecture:\tfsmt\n",
      "tokenizer:\tFSMTTokenizer\n",
      "model:\t\tFSMTForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aufgrund meinen Vorstellungen vom Aufbau Europas und von regionaler Entwicklungspolitik im besonderen halte ich das für eine Situation, die ich nicht akzeptieren kann. Ich habe die Absicht, im Rahmen meiner Möglichkeiten und mit Ihrer Unterstützung sämtliche Mittel, für die ich Verantwortung trage, für eine verbesserte soziale, menschliche und territoriale Kohäsion zu verwenden, um zu verhindern, daß es, wie ich es vor diesem Hause nannte, ein Europa der zwei Geschwindigkeiten gibt, ein Europa d</td>\n",
       "      <td>As far as I am concerned - taking into account my own concept of the construction of Europe and regional development policy in particular - this is a situation which I find unacceptable and I have every intention, as far as possible, with your suppor</td>\n",
       "      <td>In view of my vision of the construction of Europe and regional development policy in particular, I consider this to be a situation that I cannot accept, and I intend to use all the means for which I am responsible, within my means and with your supp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frau Präsidentin! Wir können und dürfen uns nicht damit abfinden, immer häufiger von Unfällen zu hören, bei denen auf der Straße, aber auch auf der Schiene oder auf Wasserwegen große Schäden entstehen, nicht nur, aber auch, weil die Betroffenen den Transit von gefährlichen Gütern nicht ernst genug nehmen oder weil durch Unwissen oder aufgrund mangelnder Ausbildung der Fahrer oder sonstiger Verantwortlicher für die diversen Verkehrsmittel aus einem kleinen Unfall allzu oft eine große Katastrophe</td>\n",
       "      <td>Madam President, we cannot and must not accept the fact that we hear ever more frequently of accidents causing major damage on our roads, but also on our railways and waterways, not solely but at least partly because those involved do not take the tr</td>\n",
       "      <td>Madam President, we cannot and must not resign ourselves to hearing more and more about accidents that cause serious damage not only on the roads but also on the railways and waterways, but also because those affected do not take the transit of dange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Helsinki-NLP/opus-mt-de-en ===\n",
      "\n",
      "architecture:\tmarian\n",
      "tokenizer:\tMarianTokenizer\n",
      "model:\t\tMarianMTModel\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nach▁meiner▁Ansicht▁würde diese▁zweite▁Hypothese▁einem▁Verzicht auf▁unsere▁Verantwortung▁als▁Parlament und▁darüber▁hinaus dem Aufwerfen▁einer▁originellen These,▁einer▁unbekannten▁Methode▁gleichkommen, die▁darin bestände, den▁Fraktionen die programmatische▁Rede der▁Kommission in▁schriftlicher Form eine▁Woche▁vorher - und nicht,▁wie▁vereinbart, am Tag▁zuvor - zur▁Kenntnis zu▁geben,▁wobei zu▁berücksichtigen▁ist,▁daß das▁Legislativprogramm im▁Februar▁diskutiert▁werden▁wird, so▁daß wir auf die▁Ausspr</td>\n",
       "      <td>In my opinion, this second hypothesis would imply the failure of Parliament in its duty as a Parliament, as well as introducing an original thesis, an unknown method which consists of making political groups aware, in writing, of a speech concerning</td>\n",
       "      <td>In my view, this second hypothesis would be tantamount to relinquishing our responsibilities as a Parliament and, in addition, to raising an original thesis, an unknown method of informing the political groups of the Commission's programmatic speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In▁unseren Änderungsanträgen▁haben wir▁festgeschrieben,▁welche▁Bedeutung wir der Herausbildung der▁notwendigen▁Synergien▁zwischen den▁Strukturfonds, dem▁Kohäsionsfonds und den▁Gemeinschaftsinitiativen▁beimessen, so▁daß▁ihre▁Anwendung auf▁optimale und rentabelste▁Weise im▁zunehmenden▁Abbau der▁regionalen▁Ungleichheiten und in der▁Schaffung von▁Arbeitsplätzen▁ihren▁Niederschlag▁findet, die▁letztendlich die▁beiden▁Hauptziele der hier zur▁Debatte▁stehenden▁Fonds▁sind.</td>\n",
       "      <td>In our amendments, we have stated the importance of the necessary synergies being produced between the Structural Funds, the Cohesion Fund and Community initiatives, so that their application should be reflected, in the best and most profitable way,</td>\n",
       "      <td>In our amendments, we have laid down the importance we attach to the necessary synergies between the Structural Funds, the Cohesion Fund and the Community initiatives, so that their application in the best and most profitable way is reflected in the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate German to English: Aus diesem Grund ist es eines der wichtigsten und weitreichendsten Ziele, die wir uns in der Europäischen Union stellen sollten, Anstrengungen zur Schaffung neuer Arbeitsplätze in den ländlichen Gebieten außerhalb des Agrarsektors zu unternehmen, unter anderem in den Bereichen ländlicher Tourismus, Sport, Kultur, Sanierung der Ressourcen, Umstellung von Unternehmen, neue Technologien, Dienstleistungen usw. Doch obwohl die Landwirtschaft keine ausschließliche Rolle me</td>\n",
       "      <td>For this reason, one of the most important and essential objectives which we should set in the European Union is to make efforts to create new jobs in rural areas, outside of the agricultural sector, in sectors such as rural tourism, sport, culture,</td>\n",
       "      <td>Aus diesem Grund ist es eines der wichtigsten und weitreichendsten Ziel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>translate German to English: Ich möchte daher die Kommission auf zwei Punkte hinweisen: Erstens muß die Konzertierung als Instrument der Koordinierung und der Beteiligung sämtlicher lokaler und regionaler Marktteilnehmer an den Entscheidungen optimal genutzt werden, um speziell Ungleichgewichte und Ungleichheiten zu vermeiden; zweitens bedarf es einer Vereinfachung und transparenteren Gestaltung der Verwaltungsprozesse, die sich allzu häufig unnötig in die Länge ziehen und derart kompliziert sin</td>\n",
       "      <td>Firstly, we need to make the best possible use of consultation as a means of ensuring proper coordination and participation by all local and regional operators in decision-making, precisely so that imbalances and inequalities can be avoided. Secondly</td>\n",
       "      <td>Ich möchte daher die Kommission auf zwei Punkte hinweisen: Erstens muß</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 128; trg_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_tok_kwargs = {}\n",
    "    if (model_name == 'sshleifer/tiny-mbart'):\n",
    "        hf_tok_kwargs['src_lang'], hf_tok_kwargs['tgt_lang'] = \"de_DE\", \"en_XX\"\n",
    "            \n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      tokenizer_kwargs=hf_tok_kwargs)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "    \n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task='translation')\n",
    "    \n",
    "    def add_t5_prefix(inp): return f'translate German to English: {inp}' if (hf_arch == 't5') else inp\n",
    "    \n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                      padding='max_length', \n",
    "                                                      max_length=inp_seq_sz, \n",
    "                                                      max_target_length=trg_seq_sz, \n",
    "                                                      text_gen_kwargs=text_gen_kwargs)\n",
    "    \n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=Pipeline([ColReader('de'), add_t5_prefix]), \n",
    "                   get_y=ColReader('en'), \n",
    "                   splitter=RandomSplitter())\n",
    "\n",
    "    dls = dblock.dataloaders(wmt_df, bs=bsz) \n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {}\n",
    "    \n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    fit_cbs = [\n",
    "        ShortEpochCallback(0.05, short_valid=True), \n",
    "        Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    ]\n",
    "\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=ranger,\n",
    "                    loss_func=PreCalculatedLoss(),\n",
    "                    cbs=[BaseModelCallback],\n",
    "                    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "    learn.create_opt() \n",
    "    learn.freeze()\n",
    "    \n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***\\n')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "#         print('*** TESTING One pass through the model ***')\n",
    "#         preds = learn.model(b[0])\n",
    "#         test_eq(preds[1].shape[0], bsz)\n",
    "#         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsmt</td>\n",
       "      <td>FSMTTokenizer</td>\n",
       "      <td>FSMTForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marian</td>\n",
       "      <td>MarianTokenizer</td>\n",
       "      <td>MarianMTModel</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental bits to use Blurr for translation tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
