{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp modeling.seq2seq.translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.seq2seq.translation\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... translation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from datasets import list_datasets, load_dataset\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import get_blurr_tfm\n",
    "from blurr.data.seq2seq.core import *\n",
    "from blurr.data.seq2seq.translation import *\n",
    "from blurr.modeling.core import *\n",
    "from blurr.modeling.seq2seq.core import *\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.1\n",
      "Using fastai 2.4\n",
      "Using transformers 4.8.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "Translation tasks attempt to convert text in one language into another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('wmt16', 'de-en', split='train[:1%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45489"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "wmt_df = pd.DataFrame(ds['translation'], columns=['de', 'en']); len(wmt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_df = wmt_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Resumption of the session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.</td>\n",
       "      <td>I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                           de  \\\n",
       "0                                                                                                                                                                                          Wiederaufnahme der Sitzungsperiode   \n",
       "1  Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.   \n",
       "\n",
       "                                                                                                                                                                                                                en  \n",
       "0                                                                                                                                                                                        Resumption of the session  \n",
       "1  I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmt_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('marian',\n",
       " transformers.models.marian.tokenization_marian.MarianTokenizer,\n",
       " transformers.models.marian.configuration_marian.MarianConfig,\n",
       " transformers.models.marian.modeling_marian.MarianMTModel)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (HF_Seq2SeqBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('de'), get_y=ColReader('en'), splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(wmt_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 141]), torch.Size([2, 85]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Angesichts▁dieser Situation▁muß▁aus dem▁Bericht, den das▁Parlament annimmt,▁klar▁hervorgehen,▁daß▁Maßnahmen▁notwendig▁sind, die▁eindeutig auf die▁Bekämpfung der relativen▁Armut und der Arbeitslosigkeit▁gerichtet▁sind.▁Maßnahmen▁wie die für diese▁Zwe</td>\n",
       "      <td>Given this situation, the report approved by Parliament must highlight the need for measures that aim unequivocally to fight relative poverty and unemployment: measures such as the appropriate use of structural funds for these purposes, which are oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Da▁meine▁Fraktion der▁Meinung▁ist,▁daß ein▁Parlament▁dazu da▁ist, zuzuhören, zu▁diskutieren und▁nachzudenken,▁gibt es▁unserer▁Ansicht nach▁keinen Grund zur▁Rechtfertigung▁dieser▁Verzögerung, und wir▁glauben,▁wenn die▁Kommission▁dazu in der▁Lage▁ist,▁</td>\n",
       "      <td>My Group believes that since a parliament is meant to listen, debate and reflect, there can be no justification whatsoever for this delay and we believe that, if the Commission is ready to do so, we still have time to re-establish the original agreem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "seq2seq_metrics = {\n",
    "    'bleu': { 'returns': \"bleu\" },\n",
    "    'meteor': { 'returns': \"meteor\" },\n",
    "    'sacrebleu': { 'returns': \"score\" }\n",
    "}\n",
    "\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                loss_func=CrossEntropyLossFlat(), #HF_PreCalculatedLoss()\n",
    "                cbs=learn_cbs,\n",
    "                splitter=partial(seq2seq_splitter, arch=hf_arch)) #.to_native_fp16() #.to_fp16()\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HF_BaseModelWrapper (Input shape: 2)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 122 x 512       \n",
       "Embedding                                 29747712   False     \n",
       "Embedding                                 29747712   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 512             \n",
       "MarianSinusoidalPositionalEmbedding                      262144     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 512       \n",
       "Embedding                                 29747712   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 512             \n",
       "MarianSinusoidalPositionalEmbedding                      262144     False     \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 122 x 58101     \n",
       "Linear                                    29747712   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 163,653,632\n",
       "Total trainable params: 25,236,480\n",
       "Total non-trainable params: 138,417,152\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7ff869a09310>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - HF_BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = dls.one_batch()\n",
    "# preds = learn.model(b[0])\n",
    "\n",
    "# len(preds),preds['loss'].shape, preds['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 141]), 2, torch.Size([2, 85]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=5.754399462603033e-05, steep=6.309573450380412e-07, valley=tensor(3.6308e-05), slide=tensor(0.1738))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.290596</td>\n",
       "      <td>1.242831</td>\n",
       "      <td>0.315434</td>\n",
       "      <td>0.528891</td>\n",
       "      <td>31.111169</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Deshalb▁besteht der▁Vorschlag der▁Fraktion der▁Sozialdemokratischen▁Partei▁Europas, den Sie▁erwähnt▁haben,▁darin, den▁Mittwoch▁als▁Termin der▁Vorstellung des▁Programms der▁Kommission Prodi für die▁Wahlperiode▁beizubehalten, und in▁dieses▁Programm▁auch das▁Verwaltungsreformprojekt▁einzubeziehen, da wir▁andernfalls in eine paradoxe Situation▁geraten▁könnten: Mit der Ausrede, der▁Wortlaut liege nicht vor,▁wird▁einerseits dem▁Präsidenten der▁Kommission das▁Recht▁abgesprochen, in▁diesem▁Parlament zu</td>\n",
       "      <td>Therefore, the proposal of the Group of the Party of European Socialists, and which you have mentioned, is that the Prodi Commission present its legislative programme on Wednesday, including its proposed administrative reform, because, otherwise, we could find ourselves in a paradoxical situation: on the pretext that there is no text, on the one hand, the President of the Commission would be denied his right to speak in this Parliament and, on the other hand, there would be a debate on a reform</td>\n",
       "      <td>That is why the proposal of the Group of the Party of European Socialists, which you have mentioned, is to maintain Wednesday as the date for the presentation of the Prodi Commission' s programme for the parliamentary term, and to include in this programme the administrative reform project, otherwise we could find ourselves in a paradoxical situation. With the excuse that the wording is not available, the President of the Commission is on the one hand denied the right to speak in this Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In▁unseren Änderungsanträgen▁haben wir▁festgeschrieben,▁welche▁Bedeutung wir der Herausbildung der▁notwendigen▁Synergien▁zwischen den▁Strukturfonds, dem▁Kohäsionsfonds und den▁Gemeinschaftsinitiativen▁beimessen, so▁daß▁ihre▁Anwendung auf▁optimale und rentabelste▁Weise im▁zunehmenden▁Abbau der▁regionalen▁Ungleichheiten und in der▁Schaffung von▁Arbeitsplätzen▁ihren▁Niederschlag▁findet, die▁letztendlich die▁beiden▁Hauptziele der hier zur▁Debatte▁stehenden▁Fonds▁sind.</td>\n",
       "      <td>In our amendments, we have stated the importance of the necessary synergies being produced between the Structural Funds, the Cohesion Fund and Community initiatives, so that their application should be reflected, in the best and most profitable way, by the gradual elimination of disparities between regions and by the creation of jobs which are, when all is said and done, the two central purposes of the funds we are discussing.</td>\n",
       "      <td>In our amendments, we have laid down the importance we attach to developing the necessary synergies between the Structural Funds, the Cohesion Fund and Community initiatives, so that their application is reflected, in the best possible and most profitable way, in the increasing reduction of regional disparities and the creation of jobs, which are ultimately the two main objectives of the funds under discussion.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      "I like to drink beer\n",
      "\n",
      "=== Prediction 2 ===\n",
      "I like to drink beer.\n",
      "\n",
      "=== Prediction 3 ===\n",
      "I like drinking beer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_de, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'translation_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlearnerForTranslation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTranslation(Blearner):\n",
    "\n",
    "    def __init__(self, dls, hf_model, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "            \n",
    "    @classmethod\n",
    "    def get_model_cls(cls): \n",
    "        return AutoModelForSeq2SeqLM\n",
    "    \n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp, src_lang_name, trg_lang_name): \n",
    "        return f'translate {src_lang_name} to {trg_lang_name}: {inp}'\n",
    "    \n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\n",
    "            'bleu': { 'returns': \"bleu\" },\n",
    "            'meteor': { 'returns': \"meteor\" },\n",
    "            'sacrebleu': { 'returns': \"score\" }\n",
    "        }\n",
    "            \n",
    "        return HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_learner(cls, data, \n",
    "                        pretrained_model_name_or_path, \n",
    "                        preprocess_func, \n",
    "                        src_lang_name, src_lang_attr, \n",
    "                        trg_lang_name, trg_lang_attr, \n",
    "                        max_length, max_target_length, \n",
    "                        dblock_splitter, \n",
    "                        hf_tok_kwargs, text_gen_kwargs, dl_kwargs, learner_kwargs):\n",
    "        \n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = BLURR.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        if (hf_arch == 'mbart'): \n",
    "            hf_tok_kwargs = { **{'src_lang': 'en_XX', 'tgt_lang': 'en_XX'}, **hf_tok_kwargs }\n",
    "            \n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, \n",
    "                                                                          model_cls=model_cls, \n",
    "                                                                          tokenizer_kwargs=hf_tok_kwargs)\n",
    "        \n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if (preprocess_func):\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, text_attr, summary_attr)\n",
    "            \n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = { **text_gen_kwargs, **default_text_gen_kwargs(hf_config, hf_model, task='translation') }\n",
    "        \n",
    "        # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args: del text_gen_kwargs[k]\n",
    "                \n",
    "        # update our text generation kwargs for mbart\n",
    "        if (hf_arch == 'mbart'):\n",
    "            text_gen_kwargs = { **{'decoder_start_token_id': 'en_XX'}, **text_gen_kwargs }\n",
    "            \n",
    "        # build dblock, dls, and default metrics (optional)\n",
    "        if (isinstance(data, pd.DataFrame)):\n",
    "            get_x = Pipeline(funcs=[ColReader(src_lang_attr)])\n",
    "            get_y = ColReader(trg_lang_attr)\n",
    "        else:\n",
    "            get_x = Pipeline(funcs=[ItemGetter(src_lang_attr)])\n",
    "            get_y = ItemGetter(trg_lang_attr)\n",
    "                               \n",
    "        if (hf_arch == 't5'):\n",
    "            get_x.add(partial(cls._add_t5_prefix, src_lang_name=src_lang_name, trg_lang_name=trg_lang_name))\n",
    "            \n",
    "        before_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                          max_length=max_length, \n",
    "                                                          max_target_length=max_target_length, \n",
    "                                                          text_gen_kwargs=text_gen_kwargs)\n",
    "        \n",
    "        blocks = (HF_Seq2SeqBlock(before_batch_tfm=before_batch_tfm), noop)\n",
    "        dblock = DataBlock(blocks=blocks, \n",
    "                           get_x=get_x, \n",
    "                           get_y=get_y, \n",
    "                           splitter=dblock_splitter)\n",
    "        \n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "        \n",
    "        # return BLearner instance\n",
    "        learner_kwargs['splitter'] = learner_kwargs.pop('splitter', partial(seq2seq_splitter, arch=hf_arch))\n",
    "        learner_kwargs['loss_func'] = learner_kwargs.pop('loss_func', CrossEntropyLossFlat())\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df, \n",
    "                       pretrained_model_name_or_path, \n",
    "                       preprocess_func=None, \n",
    "                       src_lang_name='English', src_lang_attr='src_lang', \n",
    "                       trg_lang_name='English', trg_lang_attr='trg_lang', \n",
    "                       max_length=None, max_target_length=None,  \n",
    "                       dblock_splitter=ColSplitter(), \n",
    "                       hf_tok_kwargs={}, text_gen_kwargs={}, dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        return cls._create_learner(df, \n",
    "                                   pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                   preprocess_func=preprocess_func, \n",
    "                                   src_lang_name=src_lang_name, \n",
    "                                   src_lang_attr=src_lang_attr, \n",
    "                                   trg_lang_name=trg_lang_name, \n",
    "                                   trg_lang_attr=trg_lang_attr, \n",
    "                                   max_length=max_length, \n",
    "                                   max_target_length=max_target_length,  \n",
    "                                   dblock_splitter=dblock_splitter, \n",
    "                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "        \n",
    "    @classmethod\n",
    "    def from_csv(cls, csv_file, \n",
    "                 pretrained_model_name_or_path, \n",
    "                 preprocess_func=None, \n",
    "                 src_lang_name='English', src_lang_attr='src_lang', \n",
    "                 trg_lang_name='English', trg_lang_attr='trg_lang', \n",
    "                 max_length=None, max_target_length=None,  \n",
    "                 dblock_splitter=ColSplitter(), \n",
    "                 hf_tok_kwargs={}, text_gen_kwargs={}, dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        return cls.from_dataframe(df, \n",
    "                                  pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                  preprocess_func=preprocess_func, \n",
    "                                  src_lang_name=src_lang_name, \n",
    "                                  src_lang_attr=src_lang_attr, \n",
    "                                  trg_lang_name=trg_lang_name, \n",
    "                                  trg_lang_attr=trg_lang_attr, \n",
    "                                  max_length=max_length, \n",
    "                                  max_target_length=max_target_length,  \n",
    "                                  dblock_splitter=dblock_splitter, \n",
    "                                  hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                  dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dictionaries(cls, ds, \n",
    "                          pretrained_model_name_or_path, \n",
    "                          preprocess_func=None, \n",
    "                          src_lang_name='English', src_lang_attr='src_lang', \n",
    "                          trg_lang_name='English', trg_lang_attr='trg_lang', \n",
    "                          max_length=None, max_target_length=None,  \n",
    "                          dblock_splitter=RandomSplitter(), \n",
    "                          hf_tok_kwargs={}, text_gen_kwargs={}, dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        return cls._create_learner(ds, \n",
    "                                   pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                   preprocess_func=preprocess_func, \n",
    "                                   src_lang_name=src_lang_name, \n",
    "                                   src_lang_attr=src_lang_attr, \n",
    "                                   trg_lang_name=trg_lang_name, \n",
    "                                   trg_lang_attr=trg_lang_attr, \n",
    "                                   max_length=max_length, \n",
    "                                   max_target_length=max_target_length,  \n",
    "                                   dblock_splitter=dblock_splitter, \n",
    "                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTranslation.from_dataframe(wmt_df, 'Helsinki-NLP/opus-mt-de-en', \n",
    "                                              src_lang_name='German', src_lang_attr='de', \n",
    "                                              trg_lang_name='English', trg_lang_attr='en', \n",
    "                                              dblock_splitter=RandomSplitter(),\n",
    "                                              dl_kwargs={'bs':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.366711</td>\n",
       "      <td>1.226650</td>\n",
       "      <td>0.323918</td>\n",
       "      <td>0.539581</td>\n",
       "      <td>31.577392</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForTranslation.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sie▁wird▁aber auf▁Seite 5▁dieser▁Leitlinien▁ganz▁eindeutig▁genannt, und▁ich▁möchte▁darauf▁verweisen -▁weil▁sie▁mich▁dazu▁aufgefordert▁haben -,▁daß diese▁Partnerschaft für▁mich - und▁ich▁habe▁lange▁genug eine Region▁betreut, um dies▁beurteilen zu▁können - ein▁sehr▁wirkungsvolles Instrument zur▁Mobilisierung der▁geistigen▁Ressourcen auf▁lokaler▁Ebene▁ist -▁sowohl derer im▁öffentlichen▁Sektor - die Stadt- und▁Gemeinderäte, den▁schulischen und▁gesellschaftlichen▁Bereich, die▁Vereine und▁Verbände -▁a</td>\n",
       "      <td>However, I do wish to mention - since you have asked me to do so - that, as far as I am concerned, this partnership - and I spent long enough as a regional administrator within my own country to be able to say this most sincerely - is a tool, one use</td>\n",
       "      <td>However, it is clearly mentioned on page 5 of these guidelines, and I would like to point out - because they have asked me to do so - that this partnership is a very effective instrument for the mobilisation of intellectual resources at local level -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nach der▁Tagesordnung▁folgt der▁Bericht (A5-0105/1999) von▁Herrn Koch im▁Namen des▁Ausschusses für▁Regionalpolitik,▁Verkehr und▁Fremdenverkehr über den▁Gemeinsamen▁Standpunkt des Rates im▁Hinblick auf den▁Erlaß der▁Richtlinie des▁Europäischen▁Parlaments und des Rates über die▁Mindestanforderungen für die▁Prüfung der▁Sicherheitsberater für die▁Beförderung▁gefährlicher▁Güter auf Straße,▁Schiene oder▁Binnenwasserstraßen (C5-0208/1999 - 1998/0106(COD)).</td>\n",
       "      <td>The next item is the report (A5-0105/1999) by Mr Koch, on behalf of the Committee on Regional Policy, Transport and Tourism, on the common position adopted by the Council with a view to adopting a European Parliament and Council directive on the harm</td>\n",
       "      <td>The next item is the report (A5-0105/1999) by Mr Koch, on behalf of the Committee on Regional Policy, Transport and Tourism, on the common position adopted by the Council with a view to adopting a directive of the European Parliament and of the Counc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = 'translation_export'\n",
    "\n",
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **translation models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained translation models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.models.bart.modeling_bart.BartForConditionalGeneration,\n",
       " transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForConditionalGeneration,\n",
       " transformers.models.blenderbot.modeling_blenderbot.BlenderbotForConditionalGeneration,\n",
       " transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallForConditionalGeneration,\n",
       " transformers.models.fsmt.modeling_fsmt.FSMTForConditionalGeneration,\n",
       " transformers.models.led.modeling_led.LEDForConditionalGeneration,\n",
       " transformers.models.m2m_100.modeling_m2m_100.M2M100ForConditionalGeneration,\n",
       " transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration,\n",
       " transformers.models.mt5.modeling_mt5.MT5ForConditionalGeneration,\n",
       " transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration,\n",
       " transformers.models.prophetnet.modeling_prophetnet.ProphetNetForConditionalGeneration,\n",
       " transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextForConditionalGeneration,\n",
       " transformers.models.t5.modeling_t5.T5ForConditionalGeneration,\n",
       " transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetForConditionalGeneration]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ model_type for model_type in BLURR.get_models(task='ConditionalGeneration') \n",
    " if (not model_type.__name__.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'facebook/bart-base',\n",
    "    'facebook/wmt19-de-en',                      # FSMT\n",
    "    'Helsinki-NLP/opus-mt-de-en',                # MarianMT\n",
    "    #'sshleifer/tiny-mbart',\n",
    "    #'google/mt5-small',\n",
    "    't5-small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    }
   ],
   "source": [
    "path = Path('./')\n",
    "ds = load_dataset('wmt16', 'de-en', split='train[:1%]')\n",
    "wmt_df = pd.DataFrame(ds['translation'], columns=['de', 'en']); len(wmt_df)\n",
    "wmt_df = wmt_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nach meiner Ansicht würde diese zweite Hypothese einem Verzicht auf unsere Verantwortung als Parlament und darüber hinaus dem Aufwerfen einer originellen These, einer unbekannten Methode gleichkommen, die darin bestände, den Fraktionen die programmatische Rede der Kommission in schriftlicher Form eine Woche vorher - und nicht, wie vereinbart, am Tag zuvor -</td>\n",
       "      <td>In my opinion, this second hypothesis would imply the failure of Parliament in its duty as a Parliament, as well as introducing an original thesis, an unknown method which consists of making political groups aware, in writing, of a speech concerning</td>\n",
       "      <td>Nach meiner Ansicht würde diese zweite Hypothese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die Verkehrssicherheit bestimmte in letzter Zeit häufig die Negativschlagzeilen: Das Eisenbahnunglück nahe dem Londoner Bahnhof Paddington, das furchtbare Eisenbahnunglück in Norwegen, zwei Flugzeugabstürze, bei denen EU-Bürger zu Schaden kamen, und die von der Erika vor der bretonischen Küste verursachte Naturkatastrophe sind Ereignisse</td>\n",
       "      <td>Transport safety has sadly been in the news recently: the Paddington rail crash in London, the terrible rail crash in Norway, the two aviation crashes involving EU citizens and the natural disaster involving the Erika off Brittany - all within the l</td>\n",
       "      <td>Die Verkehrssicherheit bestimmte in letzter Zeit h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/wmt19-de-en ===\n",
      "\n",
      "architecture:\tfsmt\n",
      "tokenizer:\tFSMTTokenizer\n",
      "model:\t\tFSMTForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nach meiner Ansicht würde diese zweite Hypothese einem Verzicht auf unsere Verantwortung als Parlament und darüber hinaus dem Aufwerfen einer originellen These, einer unbekannten Methode gleichkommen, die darin bestände, den Fraktionen die programmatische Rede der Kommission in schriftlicher Form eine Woche vorher - und nicht, wie vereinbart, am Tag zuvor - zur Kenntnis zu geben, wobei zu berücksichtigen ist, daß das Legislativprogramm im Februar diskutiert werden wird, so daß wir auf die Ausspr</td>\n",
       "      <td>In my opinion, this second hypothesis would imply the failure of Parliament in its duty as a Parliament, as well as introducing an original thesis, an unknown method which consists of making political groups aware, in writing, of a speech concerning</td>\n",
       "      <td>In my opinion, this second hypothesis would amount to a renunciation of our responsibility as Parliament and, moreover, to the introduction of an original hypothesis, an unknown method, namely to inform the political groups of the Commission's progra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sie wird aber auf Seite 5 dieser Leitlinien ganz eindeutig genannt, und ich möchte darauf verweisen - weil sie mich dazu aufgefordert haben -, daß diese Partnerschaft für mich - und ich habe lange genug eine Region betreut, um dies beurteilen zu können - ein sehr wirkungsvolles Instrument zur Mobilisierung der geistigen Ressourcen auf lokaler Ebene ist - sowohl derer im öffentlichen Sektor - die Stadt- und Gemeinderäte, den schulischen und gesellschaftlichen Bereich, die Vereine und Verbände - a</td>\n",
       "      <td>However, I do wish to mention - since you have asked me to do so - that, as far as I am concerned, this partnership - and I spent long enough as a regional administrator within my own country to be able to say this most sincerely - is a tool, one use</td>\n",
       "      <td>However, it is very clearly stated on page 5 of these guidelines and I would like to point out - because they have asked me to - that this partnership is for me - and I have looked after a region long enough to be able to assess this - a very effecti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Helsinki-NLP/opus-mt-de-en ===\n",
      "\n",
      "architecture:\tmarian\n",
      "tokenizer:\tMarianTokenizer\n",
      "model:\t\tMarianMTModel\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nach▁meiner▁Ansicht▁würde diese▁zweite▁Hypothese▁einem▁Verzicht auf▁unsere▁Verantwortung▁als▁Parlament und▁darüber▁hinaus dem Aufwerfen▁einer▁originellen These,▁einer▁unbekannten▁Methode▁gleichkommen, die▁darin bestände, den▁Fraktionen die programmatische▁Rede der▁Kommission in▁schriftlicher Form eine▁Woche▁vorher - und nicht,▁wie▁vereinbart, am Tag▁zuvor - zur▁Kenntnis zu▁geben,▁wobei zu▁berücksichtigen▁ist,▁daß das▁Legislativprogramm im▁Februar▁diskutiert▁werden▁wird, so▁daß wir auf die▁Ausspr</td>\n",
       "      <td>In my opinion, this second hypothesis would imply the failure of Parliament in its duty as a Parliament, as well as introducing an original thesis, an unknown method which consists of making political groups aware, in writing, of a speech concerning</td>\n",
       "      <td>In my view, this second hypothesis would be tantamount to relinquishing our responsibilities as a Parliament and, in addition, to raising an original thesis, an unknown method of informing the political groups of the Commission's programmatic speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Deshalb▁besteht der▁Vorschlag der▁Fraktion der▁Sozialdemokratischen▁Partei▁Europas, den Sie▁erwähnt▁haben,▁darin, den▁Mittwoch▁als▁Termin der▁Vorstellung des▁Programms der▁Kommission Prodi für die▁Wahlperiode▁beizubehalten, und in▁dieses▁Programm▁auch das▁Verwaltungsreformprojekt▁einzubeziehen, da wir▁andernfalls in eine paradoxe Situation▁geraten▁könnten: Mit der Ausrede, der▁Wortlaut liege nicht vor,▁wird▁einerseits dem▁Präsidenten der▁Kommission das▁Recht▁abgesprochen, in▁diesem▁Parlament zu</td>\n",
       "      <td>Therefore, the proposal of the Group of the Party of European Socialists, and which you have mentioned, is that the Prodi Commission present its legislative programme on Wednesday, including its proposed administrative reform, because, otherwise, we</td>\n",
       "      <td>That is why the proposal of the Group of the Party of European Socialists, which you have mentioned, is to maintain Wednesday as the date for the presentation of the Prodi Commission's programme for the parliamentary term, and to include in this prog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate German to English: Vor allen Dingen besteht die Gefahr, daß die - in vielerlei Hinsicht notwendige - Verlagerung der Zuständigkeiten auf die einzelstaatliche Ebene dazu führt, daß Maßnahmen im Bereich des Wettbewerbs enorm zunehmen und die Versuchung besteht, das Kartellverbot nicht als letztinstanzliche Garantie für das einwandfreie und vorhersehbare Funktionieren der Märkte einzusetzen, sondern als wirtschafts- und industriepolitisches Instrument, als Instrument der Planung und des E</td>\n",
       "      <td>First of all, there is a risk that the decentralisation of powers, though necessary in many ways, will cause an abnormal increase in competition-related initiatives, and that some people will be tempted to use competition law, not as a means to be re</td>\n",
       "      <td>Vor allen Dingen besteht die Gefahr, daß die - in vielerlei H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>translate German to English: Die Leitlinien gehen im übrigen von zwei horizontalen Prinzipien aus: Die Entwicklung des ländlichen Raums - und die Frage einer nachhaltigen Verkehrsstruktur, Frau Berichterstatterin, die mir seit langem am Herzen liegt, insbesondere seit meiner Zeit als Umweltminister meines Landes, gehört für mich in den Bereich der Entwicklung des ländlichen Raums - und das zweite Prinzip ist die Chancengleichheit, insbesondere zwischen Frauen und Männern, sowie die europäische B</td>\n",
       "      <td>I particularly remember the time when I was Minister for the Environment in my own country. The second principle is that of equal opportunities, particularly for men and women, as well as the European strategy for employment and the context of econom</td>\n",
       "      <td>Die Leitlinien gehen im übrigen von zwei horizontalen Prinzipien aus:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 128; trg_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_tok_kwargs = {}\n",
    "    if (model_name == 'sshleifer/tiny-mbart'):\n",
    "        hf_tok_kwargs['src_lang'], hf_tok_kwargs['tgt_lang'] = \"de_DE\", \"en_XX\"\n",
    "            \n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      tokenizer_kwargs=hf_tok_kwargs)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "    \n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task='translation')\n",
    "    \n",
    "    def add_t5_prefix(inp): return f'translate German to English: {inp}' if (hf_arch == 't5') else inp\n",
    "    \n",
    "    before_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                      padding='max_length', \n",
    "                                                      max_length=inp_seq_sz, \n",
    "                                                      max_target_length=trg_seq_sz, \n",
    "                                                      text_gen_kwargs=text_gen_kwargs)\n",
    "    \n",
    "    blocks = (HF_Seq2SeqBlock(before_batch_tfm=before_batch_tfm), noop)\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=Pipeline([ColReader('de'), add_t5_prefix]), \n",
    "                   get_y=ColReader('en'), \n",
    "                   splitter=RandomSplitter())\n",
    "\n",
    "    dls = dblock.dataloaders(wmt_df, bs=bsz) \n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {}\n",
    "    \n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    fit_cbs = [\n",
    "        ShortEpochCallback(0.05, short_valid=True), \n",
    "        HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    ]\n",
    "\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=ranger,\n",
    "                    loss_func=HF_PreCalculatedLoss(),\n",
    "                    cbs=[HF_BaseModelCallback],\n",
    "                    splitter=partial(seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "    learn.create_opt() \n",
    "    learn.freeze()\n",
    "    \n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***\\n')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "#         print('*** TESTING One pass through the model ***')\n",
    "#         preds = learn.model(b[0])\n",
    "#         test_eq(preds[1].shape[0], bsz)\n",
    "#         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsmt</td>\n",
       "      <td>FSMTTokenizer</td>\n",
       "      <td>FSMTForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marian</td>\n",
       "      <td>MarianTokenizer</td>\n",
       "      <td>MarianMTModel</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental bits to use Blurr for translation tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
