{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp modeling.seq2seq.translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.seq2seq.translation\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... translation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, inspect, torch\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from datasets import load_metric as hf_load_metric, list_metrics as hf_list_metrics\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar,master_bar\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM, logging,\n",
    "    PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    ")\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.seq2seq.core import HF_Seq2SeqBlock, HF_Seq2SeqBeforeBatchTransform, default_text_gen_kwargs\n",
    "from blurr.modeling.core import HF_BaseModelWrapper, HF_BaseModelCallback, HF_PreCalculatedLoss, Blearner\n",
    "from blurr.modeling.seq2seq.core import HF_Seq2SeqMetricsCallback, seq2seq_splitter\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.7.1\n",
      "fastai: 2.5.2\n",
      "transformers: 4.9.2\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "import os, ast, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import list_datasets, load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions('torch fastai transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "Translation tasks attempt to convert text in one language into another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('wmt16', 'de-en', split='train[:1%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45489"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "wmt_df = pd.DataFrame(ds['translation'], columns=['de', 'en']); len(wmt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_df = wmt_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Resumption of the session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.</td>\n",
       "      <td>I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                           de  \\\n",
       "0                                                                                                                                                                                          Wiederaufnahme der Sitzungsperiode   \n",
       "1  Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.   \n",
       "\n",
       "                                                                                                                                                                                                                en  \n",
       "0                                                                                                                                                                                        Resumption of the session  \n",
       "1  I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmt_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('marian',\n",
       " transformers.models.marian.tokenization_marian.MarianTokenizer,\n",
       " transformers.models.marian.configuration_marian.MarianConfig,\n",
       " transformers.models.marian.modeling_marian.MarianMTModel)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (HF_Seq2SeqBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('de'), get_y=ColReader('en'), splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(wmt_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 141]), torch.Size([2, 83]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Angesichts▁dieser Situation▁muß▁aus dem▁Bericht, den das▁Parlament annimmt,▁klar▁hervorgehen,▁daß▁Maßnahmen▁notwendig▁sind, die▁eindeutig auf die▁Bekämpfung der relativen▁Armut und der Arbeitslosigkeit▁gerichtet▁sind.▁Maßnahmen▁wie die für diese▁Zwe</td>\n",
       "      <td>Given this situation, the report approved by Parliament must highlight the need for measures that aim unequivocally to fight relative poverty and unemployment: measures such as the appropriate use of structural funds for these purposes, which are oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Ich▁kann▁jetzt nicht▁alle▁nennen:▁Einführung von▁sektorübergreifenden▁Maßnahmen,▁effizientere▁Nutzung▁öffentlicher▁Gelder,▁Unterstützung der▁unterschiedlichen Partner▁bei der▁gemeinsamen▁Entwicklung von▁regionalen oder▁nationalen▁Programmen▁usw. Die</td>\n",
       "      <td>I shall not list them all, but they include implementing intersectoral policies, increasing efficiency in the use of public funds, assisting the various partners in drawing up regional or national programming together, etc. The Commission takes note</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "seq2seq_metrics = {\n",
    "    'bleu': { 'returns': \"bleu\" },\n",
    "    'meteor': { 'returns': \"meteor\" },\n",
    "    'sacrebleu': { 'returns': \"score\" }\n",
    "}\n",
    "\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                loss_func=CrossEntropyLossFlat(), #HF_PreCalculatedLoss()\n",
    "                cbs=learn_cbs,\n",
    "                splitter=partial(seq2seq_splitter, arch=hf_arch)) #.to_native_fp16() #.to_fp16()\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HF_BaseModelWrapper (Input shape: 2)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 83 x 512        \n",
       "Embedding                                 29747712   False     \n",
       "Embedding                                 29747712   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 512             \n",
       "MarianSinusoidalPositionalEmbedding                      262144     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 141 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 512        \n",
       "Embedding                                 29747712   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 512             \n",
       "MarianSinusoidalPositionalEmbedding                      262144     False     \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 512        \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 512        \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 512        \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 512        \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 512        \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 512        \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 83 x 58101      \n",
       "Linear                                    29747712   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 163,653,632\n",
       "Total trainable params: 25,236,480\n",
       "Total non-trainable params: 138,417,152\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7ff65d4c8af0>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - HF_BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = dls.one_batch()\n",
    "# preds = learn.model(b[0])\n",
    "\n",
    "# len(preds),preds['loss'].shape, preds['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 141]), 2, torch.Size([2, 83]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/fastai/callback/schedule.py:269: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.00012022644514217973, steep=9.12010818865383e-07, valley=9.120108734350652e-05, slide=4.365158383734524e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.292981</td>\n",
       "      <td>1.263649</td>\n",
       "      <td>0.320008</td>\n",
       "      <td>0.540354</td>\n",
       "      <td>31.188232</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aus▁diesem Grund▁ist es▁eines der▁wichtigsten und▁weitreichendsten▁Ziele, die wir▁uns in der▁Europäischen Union▁stellen▁sollten,▁Anstrengungen zur▁Schaffung▁neuer▁Arbeitsplätze in den▁ländlichen▁Gebieten▁außerhalb des▁Agrarsektors zu▁unternehmen,▁unter▁anderem in den▁Bereichen▁ländlicher▁Tourismus, Sport, Kultur,▁Sanierung der▁Ressourcen,▁Umstellung von▁Unternehmen,▁neue▁Technologien,▁Dienstleistungen▁usw.▁Doch▁obwohl die▁Landwirtschaft▁keine▁ausschließliche▁Rolle▁mehr▁spielt,▁ist▁sie▁weiterhin▁</td>\n",
       "      <td>For this reason, one of the most important and essential objectives which we should set in the European Union is to make efforts to create new jobs in rural areas, outside of the agricultural sector, in sectors such as rural tourism, sport, culture, heritage conservation, the conversion of businesses, new technologies, services, etc. However, even though the role of agriculture is not exclusive, it is still essential, not only to prevent economic and social disintegration and the creation of gho</td>\n",
       "      <td>For this reason, it is one of the most important and far-reaching objectives that we should set ourselves in the European Union to make efforts to create new jobs in rural areas outside the agricultural sector, including in the areas of rural tourism, sport, culture, rehabilitation of resources, conversion of businesses, new technologies, services, etc. However, although agriculture no longer plays an exclusive role, it is still important, not only to prevent the economic and social decline of r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Es▁muß▁daran▁erinnert▁werden,▁daß die▁globale▁Wettbewerbsfähigkeit der▁Europäischen Union▁gegenwärtig 81 % des▁Niveaus der▁Vereinigten▁Staaten von▁Amerika▁erreicht und▁daß diese▁Kennziffer sich▁nur▁dann▁verbessern▁wird,▁wenn sich die▁unserer wettbewerbsfähigen▁Wirtschaftseinheiten,▁nämlich der▁Regionen,▁verbessert, und das zu▁einem▁Zeitpunkt, da die▁technologische▁Entwicklung, die▁Globalisierung der Wirtschaft und▁unsere▁Probleme, die▁Erweiterung und die▁Einheitswährung, von den▁Regionen,▁aber▁a</td>\n",
       "      <td>It must be remembered that, currently, the European Union' s overall competitiveness is, in general terms, 81% of that of the United States of America and that this figure will only improve if the figure for our competitive units, that is the regions, also improves. Furthermore, this is at a time when technological development, economic globalisation and our problems, which are enlargement and the single currency, demand that the regions, as well as businesses and individuals, make more of an ef</td>\n",
       "      <td>It should be recalled that the European Union' s overall competitiveness is currently reaching 81% of the level of the United States of America and that this figure will only improve if our competitive economic units, namely the regions, improve, at a time when technological development, the globalisation of the economy and our problems, enlargement and the single currency, demand greater competition from the regions, but also from businesses and individuals.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      "I like to drink beer\n",
      "\n",
      "=== Prediction 2 ===\n",
      "I like to drink beer.\n",
      "\n",
      "=== Prediction 3 ===\n",
      "I like drinking beer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_de, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'translation_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlearnerForTranslation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTranslation(Blearner):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        dls: DataLoaders, \n",
    "        hf_model: PreTrainedModel, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "            \n",
    "    @classmethod\n",
    "    def get_model_cls(cls): \n",
    "        return AutoModelForSeq2SeqLM\n",
    "    \n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp, src_lang_name, trg_lang_name): \n",
    "        return f'translate {src_lang_name} to {trg_lang_name}: {inp}'\n",
    "    \n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\n",
    "            'bleu': { 'returns': \"bleu\" },\n",
    "            'meteor': { 'returns': \"meteor\" },\n",
    "            'sacrebleu': { 'returns': \"score\" }\n",
    "        }\n",
    "            \n",
    "        return HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls, \n",
    "        # Your raw dataset\n",
    "        data, \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name:str='English', \n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr:str='src_lang', \n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name:str='English',\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr:str='trg_lang', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = BLURR.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        if (hf_arch == 'mbart'): \n",
    "            hf_tok_kwargs = { **{'src_lang': 'en_XX', 'tgt_lang': 'en_XX'}, **hf_tok_kwargs }\n",
    "            \n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, \n",
    "                                                                          model_cls=model_cls, \n",
    "                                                                          tokenizer_kwargs=hf_tok_kwargs)\n",
    "        \n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if (preprocess_func):\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, text_attr, summary_attr)\n",
    "            \n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = { **text_gen_kwargs, **default_text_gen_kwargs(hf_config, hf_model, task='translation') }\n",
    "        \n",
    "        # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args: del text_gen_kwargs[k]\n",
    "                \n",
    "        # update our text generation kwargs for mbart\n",
    "        if (hf_arch == 'mbart'):\n",
    "            text_gen_kwargs = { **{'decoder_start_token_id': 'en_XX'}, **text_gen_kwargs }\n",
    "            \n",
    "        # build dblock, dls, and default metrics (optional)\n",
    "        if (isinstance(data, pd.DataFrame)):\n",
    "            get_x = Pipeline(funcs=[ColReader(src_lang_attr)])\n",
    "            get_y = ColReader(trg_lang_attr)\n",
    "        else:\n",
    "            get_x = Pipeline(funcs=[ItemGetter(src_lang_attr)])\n",
    "            get_y = ItemGetter(trg_lang_attr)\n",
    "                               \n",
    "        if (hf_arch == 't5'):\n",
    "            get_x.add(partial(cls._add_t5_prefix, src_lang_name=src_lang_name, trg_lang_name=trg_lang_name))\n",
    "            \n",
    "        before_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                          max_length=max_length, \n",
    "                                                          max_target_length=max_target_length, \n",
    "                                                          text_gen_kwargs=text_gen_kwargs)\n",
    "        \n",
    "        blocks = (HF_Seq2SeqBlock(before_batch_tfm=before_batch_tfm), noop)\n",
    "        dblock = DataBlock(blocks=blocks, \n",
    "                           get_x=get_x, \n",
    "                           get_y=get_y, \n",
    "                           splitter=dblock_splitter)\n",
    "        \n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "        \n",
    "        # return BLearner instance\n",
    "        learner_kwargs['splitter'] = learner_kwargs.pop('splitter', partial(seq2seq_splitter, arch=hf_arch))\n",
    "        learner_kwargs['loss_func'] = learner_kwargs.pop('loss_func', CrossEntropyLossFlat())\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls, \n",
    "        # Your pandas DataFrame\n",
    "        df, \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name:str='English', \n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr:str='src_lang', \n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name:str='English',\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr:str='trg_lang', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        return cls._create_learner(df, \n",
    "                                   pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                   preprocess_func=preprocess_func, \n",
    "                                   src_lang_name=src_lang_name, \n",
    "                                   src_lang_attr=src_lang_attr, \n",
    "                                   trg_lang_name=trg_lang_name, \n",
    "                                   trg_lang_attr=trg_lang_attr, \n",
    "                                   max_length=max_length, \n",
    "                                   max_target_length=max_target_length,  \n",
    "                                   dblock_splitter=dblock_splitter, \n",
    "                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "        \n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls, \n",
    "        # The path to your csv file\n",
    "        csv_file:Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name:str='English', \n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr:str='src_lang', \n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name:str='English',\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr:str='trg_lang', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        return cls.from_dataframe(df, \n",
    "                                  pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                  preprocess_func=preprocess_func, \n",
    "                                  src_lang_name=src_lang_name, \n",
    "                                  src_lang_attr=src_lang_attr, \n",
    "                                  trg_lang_name=trg_lang_name, \n",
    "                                  trg_lang_attr=trg_lang_attr, \n",
    "                                  max_length=max_length, \n",
    "                                  max_target_length=max_target_length,  \n",
    "                                  dblock_splitter=dblock_splitter, \n",
    "                                  hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                  dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls, \n",
    "        # A list of dictionaries\n",
    "        ds:List[Dict], \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name:str='English', \n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr:str='src_lang', \n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name:str='English',\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr:str='trg_lang', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        return cls._create_learner(ds, \n",
    "                                   pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                   preprocess_func=preprocess_func, \n",
    "                                   src_lang_name=src_lang_name, \n",
    "                                   src_lang_attr=src_lang_attr, \n",
    "                                   trg_lang_name=trg_lang_name, \n",
    "                                   trg_lang_attr=trg_lang_attr, \n",
    "                                   max_length=max_length, \n",
    "                                   max_target_length=max_target_length,  \n",
    "                                   dblock_splitter=dblock_splitter, \n",
    "                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTranslation.from_dataframe(wmt_df, 'Helsinki-NLP/opus-mt-de-en', \n",
    "                                              src_lang_name='German', src_lang_attr='de', \n",
    "                                              trg_lang_name='English', trg_lang_attr='en', \n",
    "                                              dblock_splitter=RandomSplitter(),\n",
    "                                              dl_kwargs={'bs':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.326087</td>\n",
       "      <td>1.324222</td>\n",
       "      <td>0.308548</td>\n",
       "      <td>0.511621</td>\n",
       "      <td>30.511772</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForTranslation.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Angesichts▁dieser Situation▁muß▁aus dem▁Bericht, den das▁Parlament annimmt,▁klar▁hervorgehen,▁daß▁Maßnahmen▁notwendig▁sind, die▁eindeutig auf die▁Bekämpfung der relativen▁Armut und der Arbeitslosigkeit▁gerichtet▁sind.▁Maßnahmen▁wie die für diese▁Zwecke▁angemessene▁Verwendung der▁Strukturfonds, die▁häufig▁unsachgemäß▁eingesetzt▁werden, und▁zwar mit▁zentralen▁staatlichen▁Politiken, die▁Modernisierung der▁Bereiche Telekommunikation und▁Kommunikation,▁indem man vor▁allem die am▁wenigsten▁entwickelt</td>\n",
       "      <td>Given this situation, the report approved by Parliament must highlight the need for measures that aim unequivocally to fight relative poverty and unemployment: measures such as the appropriate use of structural funds for these purposes, which are oft</td>\n",
       "      <td>In view of this situation, the report adopted by Parliament must clearly show the need for measures which are clearly aimed at combating relative poverty and unemployment, such as the use of the Structural Funds, which are often used improperly for t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Deshalb▁besteht der▁Vorschlag der▁Fraktion der▁Sozialdemokratischen▁Partei▁Europas, den Sie▁erwähnt▁haben,▁darin, den▁Mittwoch▁als▁Termin der▁Vorstellung des▁Programms der▁Kommission Prodi für die▁Wahlperiode▁beizubehalten, und in▁dieses▁Programm▁auch das▁Verwaltungsreformprojekt▁einzubeziehen, da wir▁andernfalls in eine paradoxe Situation▁geraten▁könnten: Mit der Ausrede, der▁Wortlaut liege nicht vor,▁wird▁einerseits dem▁Präsidenten der▁Kommission das▁Recht▁abgesprochen, in▁diesem▁Parlament zu</td>\n",
       "      <td>Therefore, the proposal of the Group of the Party of European Socialists, and which you have mentioned, is that the Prodi Commission present its legislative programme on Wednesday, including its proposed administrative reform, because, otherwise, we</td>\n",
       "      <td>That is why the proposal of the Group of the Party of European Socialists, which you have mentioned, is to maintain Wednesday as the date for the presentation of the Prodi Commission' s programme for the parliamentary term, and to include in this pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like to drink beer']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = 'translation_export'\n",
    "\n",
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **translation models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained translation models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ model_type for model_type in BLURR.get_models(task='ConditionalGeneration') \n",
    " if (not model_type.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'facebook/bart-base',\n",
    "    'facebook/wmt19-de-en',                      # FSMT\n",
    "    'Helsinki-NLP/opus-mt-de-en',                # MarianMT\n",
    "    #'sshleifer/tiny-mbart',\n",
    "    #'google/mt5-small',\n",
    "    't5-small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    }
   ],
   "source": [
    "path = Path('./')\n",
    "ds = load_dataset('wmt16', 'de-en', split='train[:1%]')\n",
    "wmt_df = pd.DataFrame(ds['translation'], columns=['de', 'en']); len(wmt_df)\n",
    "wmt_df = wmt_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nach meiner Ansicht würde diese zweite Hypothese einem Verzicht auf unsere Verantwortung als Parlament und darüber hinaus dem Aufwerfen einer originellen These, einer unbekannten Methode gleichkommen, die darin bestände, den Fraktionen die programmatische Rede der Kommission in schriftlicher Form eine Woche vorher - und nicht, wie vereinbart, am Tag zuvor -</td>\n",
       "      <td>In my opinion, this second hypothesis would imply the failure of Parliament in its duty as a Parliament, as well as introducing an original thesis, an unknown method which consists of making political groups aware, in writing, of a speech concerning</td>\n",
       "      <td>Nach meiner Ansicht würde diese zweite Hypothese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Es muß daran erinnert werden, daß die globale Wettbewerbsfähigkeit der Europäischen Union gegenwärtig 81 % des Niveaus der Vereinigten Staaten von Amerika erreicht und daß diese Kennziffer sich nur dann verbessern wird, wenn sich die unserer wettbewerbsfähigen Wirtschaftseinheiten, nämlich der Regionen, verbessert, und das zu einem</td>\n",
       "      <td>It must be remembered that, currently, the European Union' s overall competitiveness is, in general terms, 81% of that of the United States of America and that this figure will only improve if the figure for our competitive units, that is the region</td>\n",
       "      <td>Es muß daran erinnert werden, daß die globale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/wmt19-de-en ===\n",
      "\n",
      "architecture:\tfsmt\n",
      "tokenizer:\tFSMTTokenizer\n",
      "model:\t\tFSMTForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angesichts dessen müssen wir in diesem Parlament auf jeden Fall verlangen, daß die gemeinschaftlichen Förderkonzepte für den fraglichen Zeitraum in diesem Parlament vor ihrer Annahme geprüft und erörtert werden, und zwar anhand der Leitlinien, die wir heute vorlegen, denn wir halten sie für ganz besonders geeignet, Arbeitsplätze in den ärmsten oder am wenigsten entwickelten Regionen zu schaffen, und so tragen wir dazu bei, den negativen, zur Ungleichheit führenden Tendenzen in der europäischen G</td>\n",
       "      <td>Bearing this in mind, this House should, in any event, demand that, before the Community support frameworks for the period in question are approved, they be studied and submitted for debate in this Parliament, specifically in light of the guidelines</td>\n",
       "      <td>In view of this, we in this Parliament must, in any case, demand that the Community support frameworks for the period in question be examined and discussed in this Parliament before they are adopted, on the basis of the guidelines we are presenting t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die Lage ist ernst, denn es gibt heute sogar in der Europäischen Union einen offensichtlichen Zusammenhang zwischen Arbeitslosigkeit und Armut, wie die äußerst besorgniserregende Tatsache beweist, daß die Arbeitslosigkeit in den von diesem Problem am stärksten betroffenen Regionen durchschnittlich 23,7% erreicht, und diese Regionen decken sich mit Armutsgebieten, während in den 25 Regionen mit geringerer Arbeitslosigkeit, die den wohlhabenden Gebieten entsprechen, die Arbeitslosigkeit nur bei 4%</td>\n",
       "      <td>We have a serious situation in which in the European Union today, there is a genuine link between unemployment and poverty, as demonstrated by the very worrying fact that unemployment has reached, on average, 23.7% in the regions worst affected, regi</td>\n",
       "      <td>The situation is serious because, even in the European Union today, there is an obvious link between unemployment and poverty, as is shown by the extremely worrying fact that unemployment in the regions most affected by this problem reaches an averag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Helsinki-NLP/opus-mt-de-en ===\n",
      "\n",
      "architecture:\tmarian\n",
      "tokenizer:\tMarianTokenizer\n",
      "model:\t\tMarianMTModel\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Deshalb▁besteht der▁Vorschlag der▁Fraktion der▁Sozialdemokratischen▁Partei▁Europas, den Sie▁erwähnt▁haben,▁darin, den▁Mittwoch▁als▁Termin der▁Vorstellung des▁Programms der▁Kommission Prodi für die▁Wahlperiode▁beizubehalten, und in▁dieses▁Programm▁auch das▁Verwaltungsreformprojekt▁einzubeziehen, da wir▁andernfalls in eine paradoxe Situation▁geraten▁könnten: Mit der Ausrede, der▁Wortlaut liege nicht vor,▁wird▁einerseits dem▁Präsidenten der▁Kommission das▁Recht▁abgesprochen, in▁diesem▁Parlament zu</td>\n",
       "      <td>Therefore, the proposal of the Group of the Party of European Socialists, and which you have mentioned, is that the Prodi Commission present its legislative programme on Wednesday, including its proposed administrative reform, because, otherwise, we</td>\n",
       "      <td>That is why the proposal of the Group of the Party of European Socialists, which you have mentioned, is to maintain Wednesday as the date for the presentation of the Prodi Commission's programme for the parliamentary term, and to include in this prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die▁Verkehrssicherheit▁bestimmte in▁letzter Zeit▁häufig die▁Negativschlagzeilen: Das▁Eisenbahnunglück▁nahe dem▁Londoner▁Bahnhof Paddington, das▁furchtbare▁Eisenbahnunglück in▁Norwegen,▁zwei▁Flugzeugabstürze,▁bei▁denen EU-Bürger zu▁Schaden▁kamen, und die von der Erika vor der bretonischen▁Küste▁verursachte Naturkatastrophe▁sind▁Ereignisse, die▁allein in den▁letzten▁vier▁Monaten zu▁verzeichnen▁waren. Sie▁machen▁deutlich,▁daß▁Verkehrssicherheit▁keine▁Selbstverständlichkeit▁ist und▁daß▁diejenigen, d</td>\n",
       "      <td>Transport safety has sadly been in the news recently: the Paddington rail crash in London, the terrible rail crash in Norway, the two aviation crashes involving EU citizens and the natural disaster involving the Erika off Brittany - all within the la</td>\n",
       "      <td>In recent years, road safety has often defined the negative headlines: the railway accident near London's Paddington station, the terrible railway accident in Norway, two aircraft crashes causing damage to EU citizens, and the natural disaster caused</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate German to English: Angesichts dieser Situation muß aus dem Bericht, den das Parlament annimmt, klar hervorgehen, daß Maßnahmen notwendig sind, die eindeutig auf die Bekämpfung der relativen Armut und der Arbeitslosigkeit gerichtet sind. Maßnahmen wie die für diese Zwecke angemessene Verwendung der Strukturfonds, die häufig unsachgemäß eingesetzt werden, und zwar mit zentralen staatlichen Politiken, die Modernisierung der Bereiche Telekommunikation und Kommunikation, indem man vor allem</td>\n",
       "      <td>Given this situation, the report approved by Parliament must highlight the need for measures that aim unequivocally to fight relative poverty and unemployment: measures such as the appropriate use of structural funds for these purposes, which are oft</td>\n",
       "      <td>Angesichts dieser Situation muß aus dem Bericht, den das Parlament annimmt, klar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>translate German to English: Aufgrund meinen Vorstellungen vom Aufbau Europas und von regionaler Entwicklungspolitik im besonderen halte ich das für eine Situation, die ich nicht akzeptieren kann. Ich habe die Absicht, im Rahmen meiner Möglichkeiten und mit Ihrer Unterstützung sämtliche Mittel, für die ich Verantwortung trage, für eine verbesserte soziale, menschliche und territoriale Kohäsion zu verwenden, um zu verhindern, daß es, wie ich es vor diesem Hause nannte, ein Europa der zwei Geschwi</td>\n",
       "      <td>As far as I am concerned - taking into account my own concept of the construction of Europe and regional development policy in particular - this is a situation which I find unacceptable and I have every intention, as far as possible, with your suppor</td>\n",
       "      <td>Ich habe die Absicht, im Rahmen meiner Möglichkeiten und mit Ihrer Unterstützung s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 128; trg_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_tok_kwargs = {}\n",
    "    if (model_name == 'sshleifer/tiny-mbart'):\n",
    "        hf_tok_kwargs['src_lang'], hf_tok_kwargs['tgt_lang'] = \"de_DE\", \"en_XX\"\n",
    "            \n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      tokenizer_kwargs=hf_tok_kwargs)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "    \n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task='translation')\n",
    "    \n",
    "    def add_t5_prefix(inp): return f'translate German to English: {inp}' if (hf_arch == 't5') else inp\n",
    "    \n",
    "    before_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                      padding='max_length', \n",
    "                                                      max_length=inp_seq_sz, \n",
    "                                                      max_target_length=trg_seq_sz, \n",
    "                                                      text_gen_kwargs=text_gen_kwargs)\n",
    "    \n",
    "    blocks = (HF_Seq2SeqBlock(before_batch_tfm=before_batch_tfm), noop)\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=Pipeline([ColReader('de'), add_t5_prefix]), \n",
    "                   get_y=ColReader('en'), \n",
    "                   splitter=RandomSplitter())\n",
    "\n",
    "    dls = dblock.dataloaders(wmt_df, bs=bsz) \n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {}\n",
    "    \n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    fit_cbs = [\n",
    "        ShortEpochCallback(0.05, short_valid=True), \n",
    "        HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    ]\n",
    "\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=ranger,\n",
    "                    loss_func=HF_PreCalculatedLoss(),\n",
    "                    cbs=[HF_BaseModelCallback],\n",
    "                    splitter=partial(seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "    learn.create_opt() \n",
    "    learn.freeze()\n",
    "    \n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***\\n')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "#         print('*** TESTING One pass through the model ***')\n",
    "#         preds = learn.model(b[0])\n",
    "#         test_eq(preds[1].shape[0], bsz)\n",
    "#         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsmt</td>\n",
       "      <td>FSMTTokenizer</td>\n",
       "      <td>FSMTForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marian</td>\n",
       "      <td>MarianTokenizer</td>\n",
       "      <td>MarianMTModel</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental bits to use Blurr for translation tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
