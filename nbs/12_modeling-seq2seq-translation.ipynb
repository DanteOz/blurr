{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp modeling.seq2seq.translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.seq2seq.translation\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... translation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import inspect, torch\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from transformers import AutoModelForSeq2SeqLM, PreTrainedModel, logging \n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.seq2seq.core import Seq2SeqBatchTokenizeTransform, Seq2SeqTextBlock, default_text_gen_kwargs\n",
    "from blurr.modeling.core import BaseModelCallback, BaseModelWrapper, Blearner, PreCalculatedCrossEntropyLoss\n",
    "from blurr.modeling.seq2seq.core import Seq2SeqMetricsCallback, blurr_seq2seq_splitter\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import ast, os, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "The objective in translation is to generate a representation of a given text in another style. For example, we may want to translate German into English or modern English into old English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.</td>\n",
       "      <td>In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?</td>\n",
       "      <td>\"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    de  \\\n",
       "0            Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.   \n",
       "1  \"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?   \n",
       "\n",
       "                                                                                                                                                                                     en  \n",
       "0  In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.  \n",
       "1                                                                                    \"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16', 'de-en', split='train')\n",
    "dataset = dataset.shuffle(seed=32).select(range(1200))\n",
    "wmt_df = pd.DataFrame(dataset['translation'], columns=['de', 'en']); len(wmt_df)\n",
    "wmt_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('marian',\n",
       " transformers.models.marian.tokenization_marian.MarianTokenizer,\n",
       " transformers.models.marian.configuration_marian.MarianConfig,\n",
       " transformers.models.marian.modeling_marian.MarianMTModel)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('de'), get_y=ColReader('en'), splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(wmt_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 168]), torch.Size([2, 140]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In▁Erwägung▁nachstehender▁Gründe▁sollte das▁Europäische▁Parlament▁keinerlei▁Doppelmoral tolerieren. Indessen und um▁politischen Druck auf▁Journalisten▁auszuüben, die▁Korruptionsfälle aufdecken, die in▁Verbindung mit▁hochrangigen▁Beamten und▁regieren</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Abschließend▁muss▁darauf▁hingewiesen▁werden,▁dass die▁frühere▁Verordnung des Rates Nr. 2371/2002 (EG), auf die in▁diesem▁Dokument▁Bezug▁genommen▁wird,▁darauf▁abzielte,▁bei der▁Umsetzung▁grundlegender▁Reformen in der Fischereipolitik▁Vorsicht walten</td>\n",
       "      <td>In conclusion, it should be pointed out that the intention of the earlier Council Regulation 2371/2002 mentioned in the document dealt with in the opinion was to retain the precautionary principle in connection with the introduction of fundamental ch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "seq2seq_metrics = {\"bleu\": {\"returns\": \"bleu\"}, \"meteor\": {\"returns\": \"meteor\"}, \"sacrebleu\": {\"returns\": \"score\"}}\n",
    "\n",
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),  #CrossEntropyLossFlat()\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "# learn = learn.to_native_fp16() #.to_fp16()\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 140, 58101]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds), preds[\"loss\"].shape, preds[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 168]), 2, torch.Size([2, 140]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=2.7542287170945203e-07, steep=1.5848931980144698e-06, valley=0.0003981071640737355, slide=0.00015848931798245758)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.192671</td>\n",
       "      <td>2.027766</td>\n",
       "      <td>0.307353</td>\n",
       "      <td>0.540451</td>\n",
       "      <td>29.957392</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reyes Ruiz▁ist ein▁dummer Neuling, hat▁nur ein▁Narr in den▁Kopf,▁dass in▁einer \"rote\" Zone der▁Toleranz in▁diesen Momenten zu▁investieren,▁wenn Sie eine▁andere Art von▁Freizeiteinrichtungen für▁Jugendliche der Stadt,▁dass das▁Fehlen von▁Freizeit-Räume▁beginnen in▁Alkohol von▁einem▁frühen Alter,▁müssen wir▁Kinos,▁Einkaufszentren, etc,▁etwas▁gerichtet, um▁keinen▁Anreiz jovens▁Bereiche in▁denen die Prostitution yl▁Konsum▁alkoholischer▁Getränke, das▁ist▁mein▁Kommentar▁heute..</td>\n",
       "      <td>Reyes Ruiz is a stupid neophyte, only a fool has in his head that invest in a \"Red\" zone of tolerance in these moments when you need another type of recreational facilities for young people of the city that the lack of recreational spaces begin in alcohol from an early age, we need movie theaters, shopping malls, etc, something directed to jovens no incentive areas where prostitution yl consumption of alcoholic beverages, this is my comment today..</td>\n",
       "      <td>[Reyes Ruiz is a stupid novice who has just a fool in his head that in a \"red\" zone of tolerance to invest in these moments, if you have another type of leisure facilities for teens of the city that the lack of leisure spaces start in alcohol from an early age, we need cinemas, shopping malls, etc, something aimed at not encouraging jovens areas in which prostitution yl consumption of alcoholic beverages, that is my comment today .., (12) If, within the time limit laid down in paragraph 9, one or more competent national authority(s) cannot agree to the mutual recognition of the draft decision by the competent authority of the reference Member State, the procedure laid down in Article 35(2) of Directive 2001/83/EC or Article 39(2) of Directive 2001/82/EC shall apply.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "We add here `Learner.blurr_translate` method to bring the results inline with the format returned via Hugging Face's pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': ['I like to drink beer',\n",
       "   'I like to drink beer.',\n",
       "   'I like to drink']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_de, key=\"translation_texts\", num_return_sequences=3)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_translate(self: Learner, inp, **kwargs):\n",
    "    preds = learn.blurr_generate(inp, key=\"translation_texts\", **kwargs)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': ['I like to drink beer',\n",
       "   'I like to drink beer.',\n",
       "   'I like to drink']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_translate(test_de, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'translation_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_translate(test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForTranslation`\n",
    "\n",
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTranslation(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    def predict(self, text, **kwargs):\n",
    "        return self.blurr_translate(text, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(cls):\n",
    "        return AutoModelForSeq2SeqLM\n",
    "\n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp, src_lang_name, trg_lang_name):\n",
    "        return f\"translate {src_lang_name} to {trg_lang_name}: {inp}\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\"bleu\": {\"returns\": \"bleu\"}, \"meteor\": {\"returns\": \"meteor\"}, \"sacrebleu\": {\"returns\": \"score\"}}\n",
    "\n",
    "        return Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths \n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name: str = \"English\",\n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr: str = \"src_lang\",\n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name: str = \"English\",\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr: str = \"trg_lang\",\n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length: Union[int, str] = None,\n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length: Union[int, str] = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs: dict = {},\n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type  == 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': \n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type  == 'text/csv': \n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type  == 'application/json': \n",
    "                data = pd.read_json(data, orient='records')\n",
    "            else: \n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = BLURR.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        if hf_arch == \"mbart\":\n",
    "            hf_tok_kwargs = {**{\"src_lang\": \"en_XX\", \"tgt_lang\": \"en_XX\"}, **hf_tok_kwargs}\n",
    "\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs\n",
    "        )\n",
    "\n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = {**text_gen_kwargs, **default_text_gen_kwargs(hf_config, hf_model, task=\"translation\")}\n",
    "\n",
    "        # not all \"translation\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args:\n",
    "                del text_gen_kwargs[k]\n",
    "\n",
    "        # update our text generation kwargs for mbart\n",
    "        if hf_arch == \"mbart\":\n",
    "            text_gen_kwargs = {**{\"decoder_start_token_id\": \"en_XX\"}, **text_gen_kwargs}\n",
    "\n",
    "        # build dblock, dls, and default metrics (optional)\n",
    "        get_x = Pipeline(funcs=[ColReader(src_lang_attr)])\n",
    "        get_y = ItemGetter(trg_lang_attr)\n",
    "\n",
    "        if hf_arch == \"t5\":\n",
    "            get_x.add(partial(cls._add_t5_prefix, src_lang_name=src_lang_name, trg_lang_name=trg_lang_name))\n",
    "\n",
    "        batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            max_length=max_length,\n",
    "            max_target_length=max_target_length,\n",
    "            text_gen_kwargs=text_gen_kwargs,\n",
    "        )\n",
    "\n",
    "        blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        learner_kwargs[\"splitter\"] = learner_kwargs.pop(\"splitter\", partial(blurr_seq2seq_splitter, arch=hf_arch))\n",
    "        learner_kwargs[\"loss_func\"] = learner_kwargs.pop(\"loss_func\", PreCalculatedCrossEntropyLoss())\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTranslation.from_data(wmt_df, 'Helsinki-NLP/opus-mt-de-en', \n",
    "                                              src_lang_name='German', src_lang_attr='de', \n",
    "                                              trg_lang_name='English', trg_lang_attr='en',\n",
    "                                              dl_kwargs={'bs':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.135929</td>\n",
       "      <td>2.162880</td>\n",
       "      <td>0.294676</td>\n",
       "      <td>0.534788</td>\n",
       "      <td>28.069091</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForTranslation.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In▁Erwägung▁nachstehender▁Gründe▁sollte das▁Europäische▁Parlament▁keinerlei▁Doppelmoral tolerieren. Indessen und um▁politischen Druck auf▁Journalisten▁auszuüben, die▁Korruptionsfälle aufdecken, die in▁Verbindung mit▁hochrangigen▁Beamten und▁regierenden▁Politikern der▁Partei▁stehen, hat die▁ungarische Staatsverwaltung vor Kurzem▁Schritte▁eingeleitet, um▁Strafverfahren▁gegen▁derartige▁Vertreter der Medien▁anzustrengen -▁nämlich▁gegen▁Herrn Tamás Pindroch, den▁Journalisten von Magyar Hírlap -,▁wob</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>\n",
       "      <td>[\"The European Parliament should not tolerate any double standards, however, and in order to exert political pressure on journalists to expose corruption cases related to high-ranking officials and political leaders of the Party, the Hungarian State Administration has recently taken steps to bring criminal proceedings against such media representatives, namely Mr Tamás Pindroch, the journalist of Magyar Hírlap, taking particular account of the fact that criminal proceedings have been launched against the journalist who has been investigating scandals related to senior former members of the government and one of the candidates for the office of European Commissioner., To this end, it is important to revolutionise the methods in order to achieve a significantly higher reach and effectiveness than the policies of the past. The Member States of the European Union, but also the candidate countries, in cooperation with the European Commission, must take all appropriate measures to disseminate the best practice and adopt those new models which are the success of the leading states.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_translate(test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = 'translation_export'\n",
    "\n",
    "learn.metrics = None\n",
    "learn = learn.to_fp32()\n",
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **translation models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained translation models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ model_type for model_type in BLURR.get_models(task='ConditionalGeneration') \n",
    " if (not model_type.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'facebook/bart-base',\n",
    "    'facebook/wmt19-de-en',                      # FSMT\n",
    "    'Helsinki-NLP/opus-mt-de-en',                # MarianMT\n",
    "    #'sshleifer/tiny-mbart',\n",
    "    #'google/mt5-small',\n",
    "    't5-small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16', 'de-en', split='train')\n",
    "dataset = dataset.shuffle(seed=32).select(range(1200))\n",
    "wmt_df = pd.DataFrame(dataset['translation'], columns=['de', 'en']); len(wmt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zudem haben wir unser Augenmerk auf das Erfordernis einer größtmöglichen Harmonisierung der einzelstaatlichen Sozialvorschriften im Straßenverkehr, die sich dank der modernen Technologien bietenden Kontrollmöglichkeiten, die uns zur Verfügung stehenden statistischen Daten, die bereits geäußerten Ansichten des Europäischen Parlaments z</td>\n",
       "      <td>We also took account of the need for maximum possible harmonisation between social provisions in the field of road transport in the Member States, the opportunities offered by modern technology in connection with the subject of controls, the statist</td>\n",
       "      <td>[ Zudem haben wir unser Augenmerk auf das, Wenn wir uns den enormen Berg von Arbeit vor Augen hal]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/wmt19-de-en ===\n",
      "\n",
      "architecture:\tfsmt\n",
      "tokenizer:\tFSMTTokenizer\n",
      "model:\t\tFSMTForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In Erwägung nachstehender Gründe sollte das Europäische Parlament keinerlei Doppelmoral tolerieren. Indessen und um politischen Druck auf Journalisten auszuüben, die Korruptionsfälle aufdecken, die in Verbindung mit hochrangigen Beamten und regierenden Politikern der Partei stehen, hat die ungarische Staatsverwaltung vor Kurzem Schritte eingeleitet, um Strafverfahren gegen derartige Vertreter der Medien anzustrengen - nämlich gegen Herrn Tamás Pindroch, den Journalisten von Magyar Hírlap -, wob</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>\n",
       "      <td>[\"Considering the following reasons, the European Parliament should not tolerate any double standards. However, and in order to exert political pressure on journalists who expose cases of corruption linked to senior officials and ruling politicians of the party, the Hungarian State Administration has recently taken steps to bring criminal proceedings against such representatives of the media - namely against Mr Tamás Pindroch, the journalist of Magyar Hírlap - taking into account in particular the fact that criminal proceedings have been opened against the journalist who investigated scandals,, As the Portuguese Presidency has pointed out, the European Union needs to better reconcile its extremely important role as the world's largest donor with a leading and more active role in this movement for a renewal of development policy on an international scale and to develop its capacity for linking and coordinating, particularly with the United Nations system and the Bretton Woods system.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Helsinki-NLP/opus-mt-de-en ===\n",
      "\n",
      "architecture:\tmarian\n",
      "tokenizer:\tMarianTokenizer\n",
      "model:\t\tMarianMTModel\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Schließen die▁vorgeschlagenen▁Anwendungszwecke▁Empfehlungen über die▁Bekämpfung von oder den▁Schutz▁gegen▁Organismen ein, die▁unter den in der▁vorgesehenen▁Anwendungsregion▁herrschenden▁Bedingungen in▁bezug auf▁Landwirtschaft,▁Pflanzenschutz und Umwelt -▁einschließlich der▁Witterungsverhältnisse - nach den▁Erfahrungen und dem▁wissenschaftlichen▁Erkenntnisstand nicht▁als▁schädlich▁gelten, oder▁ist▁davon▁auszugehen,▁daß die▁anderen▁Wirkungen▁unter▁diesen▁Bedingungen den▁beabsichtigten▁Zweck nicht</td>\n",
       "      <td>Where relevant, yield response when the product is used and reduction of loss in storage must be quantitatively and/or qualitatively similar to those resulting from the use of suitable reference products. If no suitable reference product exists, the</td>\n",
       "      <td>[Where the proposed uses include recommendations on the control of or protection against organisms which are not considered harmful under the conditions prevailing in the intended application region in respect of agriculture, plant health and the environment, including climatic conditions, in the light of experience and scientific knowledge, or where it is considered that the other effects do not meet the intended purpose under these conditions, no authorisation shall be granted for such uses., This is by no means intended to deny the importance of traditional energy sources - and I could do so even less at the moment when Algerian gas comes to Spain and from Spain to Portugal and to the rest of Europe via such an important construction as the gas pipeline linking Algeria to our continent and our Union via Morocco, but of course the emphasis this report places on renewable and sustainable energy sources and energy saving is greatly appreciated.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate German to English: Ich habe das Glück hier zu stehen, als schwuler Mann - und wenn ich für mich beschlossen habe, schwul zu sein, ist es nicht interessant, dass jemand anderes offensichtlich für sich bestimmt, heterosexuell zu sein? - Kampf für die Gleichstellung, nicht nur für schwule Männer und Lesben und Bisexuelle und Transgender, sondern für Menschen auf Grund ihres Alters, ihrer Religion, ihres Glauben, ihres Geschlechts, alles, was als Unterschied wahrgenommen wird</td>\n",
       "      <td>I stand here fortunate, as a gay man - and if I chose to be gay, is it not interesting that one obviously therefore chooses to be heterosexual? - fighting for equality, not just for gay men and lesbians and bisexuals and transgender people, but for p</td>\n",
       "      <td>[Ich habe das Glück hier zu stehen, als schwuler Mann - und wenn , In der begrenzten Zeit, die mir gewährt wird, Herr Präsident,]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 128; trg_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_tok_kwargs = {}\n",
    "    if (model_name == 'sshleifer/tiny-mbart'):\n",
    "        hf_tok_kwargs['src_lang'], hf_tok_kwargs['tgt_lang'] = \"de_DE\", \"en_XX\"\n",
    "            \n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      tokenizer_kwargs=hf_tok_kwargs)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "    \n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task='translation')\n",
    "    \n",
    "    def add_t5_prefix(inp): return f'translate German to English: {inp}' if (hf_arch == 't5') else inp\n",
    "    \n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                      padding='max_length', \n",
    "                                                      max_length=inp_seq_sz, \n",
    "                                                      max_target_length=trg_seq_sz, \n",
    "                                                      text_gen_kwargs=text_gen_kwargs)\n",
    "    \n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=Pipeline([ColReader('de'), add_t5_prefix]), \n",
    "                   get_y=ColReader('en'), \n",
    "                   splitter=RandomSplitter())\n",
    "\n",
    "    dls = dblock.dataloaders(wmt_df, bs=bsz) \n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {}\n",
    "    \n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    fit_cbs = [\n",
    "        ShortEpochCallback(0.05, short_valid=True), \n",
    "        Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    ]\n",
    "\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=ranger,\n",
    "                    loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "                    cbs=[BaseModelCallback],\n",
    "                    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "    learn.create_opt() \n",
    "    learn.freeze()\n",
    "    \n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***\\n')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "#         print('*** TESTING One pass through the model ***')\n",
    "#         preds = learn.model(b[0])\n",
    "#         test_eq(preds[1].shape[0], bsz)\n",
    "#         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsmt</td>\n",
       "      <td>FSMTTokenizer</td>\n",
       "      <td>FSMTForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marian</td>\n",
       "      <td>MarianTokenizer</td>\n",
       "      <td>MarianMTModel</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental bits to use Blurr for translation tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
