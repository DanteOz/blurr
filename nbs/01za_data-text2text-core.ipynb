{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.text2text.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data.text2text.core\n",
    "\n",
    "> This module contains the core text2text (e.g., language modeling, summarization, translation) bits required to use the fastai DataBlock API and/or mid-level data processing pipelines to organize your data in a way modelable by huggingface transformer implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import reduce\n",
    "\n",
    "import torch, nlp,pdb\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.0\n",
      "Using fastai 2.1.5\n",
      "Using transformers 3.5.0\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base tokenization, batch transform, and DataBlock methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_Text2TextAfterBatchTransform(HF_AfterBatchTransform):\n",
    "    def decodes(self, encoded_samples):\n",
    "        input_ids = encoded_samples['input_ids'] if (isinstance(encoded_samples, dict)) else encoded_samples\n",
    "        return self.input_return_type(input_ids, hf_tokenizer=self.hf_tokenizer)\n",
    "    \n",
    "    \n",
    "class HF_Text2TextBlock(HF_TextBlock):\n",
    "    \n",
    "    def __init__(self, hf_arch=None, hf_tokenizer=None, before_batch_tfms=None, after_batch_tfms=None,\n",
    "                 max_length=None, padding=True, truncation=True, is_split_into_words=False, \n",
    "                 n_tok_inps=1, tok_kwargs={}, input_return_type=HF_BaseInput, dl_type=SortedDL, \n",
    "                 before_batch_kwargs={}, after_batch_kwargs={}, **kwargs):\n",
    "\n",
    "        if (after_batch_tfms is None): \n",
    "            after_batch_tfms = HF_Text2TextAfterBatchTransform(hf_tokenizer, input_return_type, \n",
    "                                                               **after_batch_kwargs.copy())\n",
    "            \n",
    "        return super().__init__(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer, \n",
    "                                before_batch_tfms=before_batch_tfms, after_batch_tfms=after_batch_tfms,\n",
    "                                max_length=max_length, padding=padding, truncation=truncation, \n",
    "                                is_split_into_words=is_split_into_words, n_tok_inps=n_tok_inps, \n",
    "                                tok_kwargs=tok_kwargs, input_return_type=input_return_type, dl_type=dl_type, \n",
    "                                before_batch_kwargs=before_batch_kwargs, after_batch_kwargs=after_batch_kwargs, \n",
    "                                **kwargs)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include a new batch `Transform` and `TransformBlock` specific to text-2-text tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01za_data-text2text-core.ipynb.\n",
      "Converted 01zb_data-text2text-language-modeling.ipynb.\n",
      "Converted 01zc_data-text2text-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02za_modeling-text2text-core.ipynb.\n",
      "Converted 02zb_modeling-text2text-language-modeling.ipynb.\n",
      "Converted 02zc_modeling-text2text-summarization.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
