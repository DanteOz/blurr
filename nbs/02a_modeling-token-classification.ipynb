{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.data.token_classification import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.1\n",
      "Using fastai 2.1.8\n",
      "Using transformers 4.1.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.models.bert.configuration_bert.BertConfig,\n",
       " transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                     is_split_into_words=True, \n",
    "                                                     tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O'), ('Standard', 'B-ORG'), ('Oil', 'I-ORG'), ('of', 'I-ORG'), ('New', 'I-ORG'), ('Jersey', 'I-ORG'), ('),', 'O'), ('die', 'O'), ('ausgesprochen', 'O'), ('„', 'O'), ('Esso', 'O'), ('ergeben', 'B-ORG'), ('(', 'O'), ('heute', 'O'), ('ExxonMobil', 'O'), (').', 'O'), (';', 'B-ORG'), ('Exxon', 'O'), (':', 'O'), ('Ein', 'O'), ('Name,', 'B-ORG'), ('der', 'O'), ('in', 'O'), ('den', 'O'), ('frühen', 'O'), ('1970ern', 'O'), ('von', 'O'), ('Esso', 'O'), ('erfunden', 'O'), ('wurde,', 'O'), ('um', 'O'), ('ein', 'B-ORG'), ('neutrales', 'O'), ('aber', 'O'), ('eindeutiges', 'O'), ('Markenzeichen', 'O'), ('für', 'O'), ('das', 'O'), ('Unternehmen', 'O'), ('zu', 'O'), ('haben.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('12', 'O'), (':', 'O'), ('25', 'B-LOC'), ('Uhr', 'O'), ('Berlin', 'B-ORG'), ('(', 'O'), ('dpa', 'O'), (')', 'O'), ('-', 'O'), ('Die', 'O'), ('Zahl', 'O'), ('der', 'O'), ('Anbieter', 'O'), ('von', 'O'), ('neuartigen', 'O'), ('Software', 'O'), ('-', 'O'), ('und', 'O'), ('Service', 'O'), ('-', 'O'), ('Angeboten', 'O'), ('über', 'O'), ('das', 'O'), ('Internet', 'O'), ('wird', 'B-PER'), ('sich', 'I-PER'), ('nach', 'O'), ('Einschätzung', 'O'), ('von', 'O'), ('Brad', 'B-ORG'), ('Smith,', 'O'), ('Chef', 'O'), ('-', 'O'), ('Justiziar', 'O'), ('von', 'O'), ('Microsoft,', 'O'), ('vorerst', 'O'), ('auf', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(filter(lambda el: isinstance(el, HF_TokenCategorize), learn.dls.tfms[1]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in learn.dls.tfms[1]: print(isinstance(x,HF_TokenCategorize), type(x), HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdf = HF_TokenCategorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isinstance(asdf,HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_blurr_tfm(learn.dls.tfms, tfm_class=HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassMetricsCallback(Callback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the HF_TokenClassBeforeBatchTransform\n",
    "        hf_before_batch_tfm = get_blurr_tfm(self.learn.dls.before_batch)\n",
    "        hf_tok_categorize_tfm = get_blurr_tfm(self.learn.dls.tfms[1], tfm_class=HF_TokenCategorize)\n",
    "        \n",
    "        self.hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = hf_tok_categorize_tfm.ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_before_batch_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        try:\n",
    "            self.learn.token_classification_report = calculate_token_class_metrics(targs, \n",
    "                                                                                   preds, \n",
    "                                                                                   'classification_report')\n",
    "        except ZeroDivisionError as err:\n",
    "            print(f'Couldn\\'t calcualte classification report: {err}')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_TokenClassMetricsCallback()]\n",
    "\n",
    "learn = Learner(dls, model,opt_func=partial(Adam),cbs=learn_cbs,splitter=hf_splitter)\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2, 62, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 62]), 2, torch.Size([2, 62]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124, 18]) torch.Size([124])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0009120108559727668, lr_steep=5.248074739938602e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.191001</td>\n",
       "      <td>0.196042</td>\n",
       "      <td>0.946744</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.151665</td>\n",
       "      <td>0.122821</td>\n",
       "      <td>0.964956</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.700441</td>\n",
       "      <td>0.689805</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>0.121095</td>\n",
       "      <td>0.969647</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.724280</td>\n",
       "      <td>0.737945</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.79      0.73      0.76        67\n",
      "    LOCderiv       0.77      0.80      0.79        30\n",
      "     LOCpart       0.00      0.00      0.00         0\n",
      "         ORG       0.85      0.67      0.75        42\n",
      "     ORGpart       0.43      0.75      0.55         4\n",
      "         OTH       0.58      0.50      0.54        36\n",
      "    OTHderiv       0.00      0.00      0.00         0\n",
      "     OTHpart       0.00      0.00      0.00         0\n",
      "         PER       0.95      0.84      0.89        64\n",
      "    PERderiv       0.00      0.00      0.00         0\n",
      "     PERpart       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.75      0.72      0.74       243\n",
      "   macro avg       0.40      0.39      0.39       243\n",
      "weighted avg       0.80      0.72      0.76       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner, \n",
    "                 ctxs=None, max_n=6, trunc_at=None, **kwargs):    \n",
    "    \n",
    "    hf_before_batch_tfm = get_blurr_tfm(learner.dls.before_batch)\n",
    "    hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "    ignore_token_id = hf_before_batch_tfm.ignore_token_id\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x, y, samples, outs):\n",
    "        # recontstruct the string and split on space to get back your pre-tokenized list of tokens\n",
    "        toks = hf_tokenizer.convert_ids_to_tokens(inp, skip_special_tokens=True)\n",
    "        pretokenized_toks =  hf_tokenizer.convert_tokens_to_string(toks).split()\n",
    "        \n",
    "        # get predictions for subtokens that aren't ignored (e.g. special toks and token parts)\n",
    "        pred_labels = [ pred_lbl for lbl_id, pred_lbl in zip(trg, ast.literal_eval(pred[0])) if lbl_id != -ignore_token_id ]\n",
    "        \n",
    "        trg_labels = ast.literal_eval(sample[1])\n",
    "        res.append([f'{[ (tok, trg, pred) for idx, (tok, pred, trg) in enumerate(zip(pretokenized_toks, pred_labels, trg_labels)) if (trunc_at is None or idx < trunc_at) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'B-PER'), ('al.', 'I-OTH', 'I-PER'), ('(', 'O', 'I-PER'), ('1994', 'O', 'O'), (')', 'O', 'I-PER'), ('S.', 'O', 'O'), ('593.', 'O', 'O'), ('Wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Erstmals', 'O', 'O'), ('Urkundlich', 'O', 'O'), ('erwähnt', 'O', 'O'), ('ist', 'O', 'O'), ('Nimburg', 'B-LOC', 'O'), ('bereits', 'O', 'O'), ('im', 'O', 'O'), ('Jahre', 'O', 'B-PER'), ('977.', 'O', 'I-PER'), ('Im', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\",)\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _blurr_predict_tokens(predict_func, items, hf_before_batch_tfm):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.blurr_predict` or `blurrONNX.predict.\n",
    "    Aligns the predicted labels, label ids, and probabilities with what you passed in excluding subword tokens\n",
    "    \"\"\"\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_before_batch_tfm.tok_kwargs\n",
    "    \n",
    "    if (isinstance(items[0], str)): items = [items]\n",
    "        \n",
    "    outs = []\n",
    "    for inp, res in zip(items, predict_func(items)):\n",
    "        # blurr_predict returns a list for each, we only doing one at a time so git first element of each\n",
    "        pred_lbls, pred_lbl_ids, probs = res[0][0], res[1][0], res[2][0]\n",
    "  \n",
    "        # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "        # return\n",
    "        subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "        # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "        # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "        # (e.g., [CLS], [SEP], etc...)\n",
    "        res = hf_tokenizer(inp, None, \n",
    "                           max_length=hf_before_batch_tfm.max_length,\n",
    "                           padding=hf_before_batch_tfm.padding,\n",
    "                           truncation=hf_before_batch_tfm.truncation,\n",
    "                           is_split_into_words=hf_before_batch_tfm.is_split_into_words,\n",
    "                           **tok_kwargs)\n",
    "\n",
    "        special_toks_msk = L(res['special_tokens_mask'])\n",
    "        actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "        # using the indexes to the actual tokens, get that info from the results returned above\n",
    "        pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "        actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "        actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "        actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "        # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "        # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "        offset = 0\n",
    "        raw_trg_idxs = []\n",
    "        for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "            raw_trg_idxs.append(idx+offset)\n",
    "            offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "            \n",
    "        outs.append((inp, \n",
    "                     actual_pred_lbls[raw_trg_idxs], \n",
    "                     actual_pred_lbl_ids[raw_trg_idxs], \n",
    "                     actual_probs[raw_trg_idxs]))\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, items, **kargs):\n",
    "    hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "    return _blurr_predict_tokens(self.blurr_predict, items, hf_before_batch_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`items`**, **\\*\\*`kargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\n",
    "txt2 = \"I wish covid was over so I could go to Germany and watch Bayern Munich play in the Bundesliga.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'O'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'I-ORG'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'tok_class_learn_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'O'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'I-ORG'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "\n",
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def predict_tokens(self:blurrONNX, items, **kargs):\n",
    "    hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "    return _blurr_predict_tokens(self.predict, items, hf_before_batch_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py:192: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  position_ids = self.position_ids[:, :seq_length]\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/modeling_utils.py:1757: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/torch/onnx/utils.py:244: UserWarning: We detected that you are modifying a dictionnary that is an input to your model. Note that dictionaries are allowed as inputs in ONNX but they should be handled with care. Usages of dictionaries is not recommended, and should not be used except for configuration use. Also note that the order and values of the keys must remain the same. \n",
      "  warnings.warn(warning)\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.blurr_to_onnx(export_fname, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "onnx_inf = blurrONNX(export_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "res = onnx_inf.predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the token classification training code above works for **all** pretrained token classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.models.albert.modeling_albert.AlbertForTokenClassification,\n",
       " transformers.models.auto.modeling_auto.AutoModelForTokenClassification,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification,\n",
       " transformers.models.camembert.modeling_camembert.CamembertForTokenClassification,\n",
       " transformers.models.distilbert.modeling_distilbert.DistilBertForTokenClassification,\n",
       " transformers.models.electra.modeling_electra.ElectraForTokenClassification,\n",
       " transformers.models.flaubert.modeling_flaubert.FlaubertForTokenClassification,\n",
       " transformers.models.funnel.modeling_funnel.FunnelForTokenClassification,\n",
       " transformers.models.layoutlm.modeling_layoutlm.LayoutLMForTokenClassification,\n",
       " transformers.models.longformer.modeling_longformer.LongformerForTokenClassification,\n",
       " transformers.models.mpnet.modeling_mpnet.MPNetForTokenClassification,\n",
       " transformers.models.mobilebert.modeling_mobilebert.MobileBertForTokenClassification,\n",
       " transformers.models.roberta.modeling_roberta.RobertaForTokenClassification,\n",
       " transformers.models.squeezebert.modeling_squeezebert.SqueezeBertForTokenClassification,\n",
       " transformers.models.albert.modeling_tf_albert.TFAlbertForTokenClassification,\n",
       " transformers.models.auto.modeling_tf_auto.TFAutoModelForTokenClassification,\n",
       " transformers.models.bert.modeling_tf_bert.TFBertForTokenClassification,\n",
       " transformers.models.camembert.modeling_tf_camembert.TFCamembertForTokenClassification,\n",
       " transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForTokenClassification,\n",
       " transformers.models.electra.modeling_tf_electra.TFElectraForTokenClassification,\n",
       " transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForTokenClassification,\n",
       " transformers.models.funnel.modeling_tf_funnel.TFFunnelForTokenClassification,\n",
       " transformers.models.longformer.modeling_tf_longformer.TFLongformerForTokenClassification,\n",
       " transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForTokenClassification,\n",
       " transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForTokenClassification,\n",
       " transformers.models.roberta.modeling_tf_roberta.TFRobertaForTokenClassification,\n",
       " transformers.models.xlm.modeling_tf_xlm.TFXLMForTokenClassification,\n",
       " transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForTokenClassification,\n",
       " transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForTokenClassification,\n",
       " transformers.models.xlm.modeling_xlm.XLMForTokenClassification,\n",
       " transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForTokenClassification,\n",
       " transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='TokenClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'google/electra-small-generator',\n",
    "    'flaubert/flaubert_small_cased',\n",
    "    'funnel-transformer/small-base',\n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'squeezebert/squeezebert-uncased',\n",
    "    'xlm-mlm-ende-1024',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.696206</td>\n",
       "      <td>1.577081</td>\n",
       "      <td>0.865971</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('standard', 'B-ORG', 'O'), ('oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'B-LOCpart'), ('new', 'I-ORG', 'B-LOCpart'), ('jersey', 'I-ORG', 'B-LOCpart'), (')', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('wie', 'O', 'O'), ('wenige', 'O', 'O'), ('wochen', 'O', 'O'), ('vor', 'O', 'O'), ('der', 'O', 'O'), ('bekanntgabe', 'O', 'O'), ('in', 'O', 'O'), ('einem', 'O', 'O'), ('interview', 'O', 'O'), ('angekundigt', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-multilingual-cased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.698982</td>\n",
       "      <td>1.465090</td>\n",
       "      <td>0.901168</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'B-ORG'), ('Standard', 'B-ORG', 'O'), ('Oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'O'), ('New', 'I-ORG', 'O'), ('Jersey', 'I-ORG', 'O'), ('),', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O'), ('„', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O', 'I-LOCderiv'), ('28', 'O', 'O'), ('-', 'O', 'O'), ('Jährige', 'O', 'O'), ('und', 'O', 'O'), ('sein', 'O', 'O'), ('Team,', 'O', 'O'), ('zu', 'O', 'O'), ('dem', 'O', 'O'), ('auch', 'B-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.406101</td>\n",
       "      <td>2.359243</td>\n",
       "      <td>0.888162</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Au&lt;unk&gt;erdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('Nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('Stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Die', 'O', 'O'), ('Fl&lt;unk&gt;gel', 'O', 'O'), ('Die', 'O', 'O'), ('ge&lt;unk&gt;ffneten', 'O', 'O'), ('Fl&lt;unk&gt;gel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('Szenen', 'O', 'O'), ('H&lt;unk&gt;hepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.817103</td>\n",
       "      <td>1.684866</td>\n",
       "      <td>0.897422</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al.', 'I-OTH', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s.', 'O', 'O'), ('593.', 'O', 'O'), ('wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('wie', 'O', 'O'), ('wenige', 'O', 'O'), ('wochen', 'O', 'O'), ('vor', 'O', 'O'), ('der', 'O', 'O'), ('bekanntgabe', 'O', 'O'), ('in', 'O', 'O'), ('einem', 'O', 'O'), ('interview', 'O', 'O'), ('angekundigt,', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/electra-small-generator ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.954948</td>\n",
       "      <td>1.779784</td>\n",
       "      <td>0.839473</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al.', 'I-OTH', 'B-PERderiv'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s.', 'O', 'B-LOCderiv'), ('593.', 'O', 'B-LOCderiv'), ('wink', 'O', 'O'), ('&amp;', 'B-OTH', 'B-PERderiv')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('senden', 'O', 'O'), ('exxon', 'B-ORG', 'O'), ('mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'B-PERderiv'), ('\"', 'O', 'B-PERderiv'), ('paris', 'B-LOC', 'O'), ('(', 'O', 'B-PERderiv'), ('aktiencheck.', 'B-ORG', 'O'), ('de', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.705193</td>\n",
       "      <td>1.426126</td>\n",
       "      <td>0.836717</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('NEWSru.ua', 'B-OTH', 'O'), ('/', 'O', 'O'), (':', 'O', 'O'), ('Политисполком', 'B-OTH', 'O'), ('СПУ', 'I-OTH', 'O'), ('отказал', 'I-OTH', 'O'), ('Морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'I-OTH', 'O'), ('Die', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Senden', 'O', 'O'), ('Exxon', 'B-ORG', 'O'), ('Mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('Paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.de', 'B-ORG', 'O'), ('AG', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== funnel-transformer/small-base ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.030285</td>\n",
       "      <td>0.788729</td>\n",
       "      <td>0.885645</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('jeder', 'O', 'O'), ('rest', 'O', 'O'), ('von', 'O', 'O'), ('darstellung,', 'O', 'O'), ('bildlich', 'O', 'O'), ('oder', 'O', 'O'), ('figurlich,', 'O', 'O'), ('wurde', 'O', 'O'), ('abgelehnt', 'O', 'O'), (':', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('anfangs', 'O', 'O'), ('unterstutzte', 'O', 'O'), ('bucharin', 'B-PER', 'O'), ('stalin', 'B-PER', 'O'), ('mit', 'O', 'O'), ('diesem', 'O', 'O'), ('kurs,', 'O', 'O'), ('doch', 'O', 'O'), ('spater', 'O', 'O'), ('als', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.160781</td>\n",
       "      <td>2.039784</td>\n",
       "      <td>0.872384</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('«', 'O', 'I-LOCderiv'), ('Wer', 'O', 'O'), ('Aids', 'O', 'O'), ('hat', 'O', 'O'), ('und', 'O', 'O'), ('sexuell', 'O', 'O'), ('aktiv', 'O', 'O'), ('ist', 'O', 'I-LOCderiv'), (',', 'O', 'O'), ('wer', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Im', 'O', 'I-LOCderiv'), ('Jahr', 'O', 'O'), ('2006', 'O', 'O'), ('brachte', 'O', 'O'), ('Helmut', 'B-PER', 'O'), ('Lotti', 'I-PER', 'O'), ('zusammen', 'O', 'O'), ('mit', 'O', 'O'), ('den', 'O', 'I-LOCderiv'), ('belgischen', 'B-LOCderiv', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.585038</td>\n",
       "      <td>0.030956</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('außerdem', 'O', 'B-LOC'), ('befindet', 'O', 'B-PERpart'), ('sich', 'O', 'I-LOC'), ('im', 'O', 'B-OTHpart'), ('nordwesten', 'O', 'I-OTH'), ('der', 'O', 'B-PER'), ('stadt', 'O', 'B-OTHpart'), ('(', 'O', 'B-PERderiv'), ('auf', 'O', 'I-LOC'), ('dem', 'O', 'B-ORG')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('mit', 'O', 'B-LOC'), ('der', 'O', 'B-ORG'), ('servicefrau', 'O', 'I-LOC'), ('verband', 'O', 'I-OTH'), ('bianca', 'B-PER', 'I-LOC'), ('offenbar', 'O', 'I-LOC'), ('eine', 'O', 'B-OTHpart'), ('art', 'O', 'I-LOC'), ('freundschaft', 'O', 'B-PERpart'), ('–', 'O', 'B-PERderiv')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.260875</td>\n",
       "      <td>2.188365</td>\n",
       "      <td>0.890113</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('Standard', 'B-ORG', 'O'), ('Oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'B-PER'), ('New', 'I-ORG', 'O'), ('Jersey', 'I-ORG', 'O'), (')', 'O', 'B-LOCderiv'), (',', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Mit', 'O', 'B-ORGpart'), ('der', 'O', 'O'), ('Servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('Bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('Art', 'O', 'O'), ('Freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.523364</td>\n",
       "      <td>2.463683</td>\n",
       "      <td>0.911442</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al.', 'I-OTH', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s.', 'O', 'O'), ('593.', 'O', 'O'), ('wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('mit', 'O', 'O'), ('der', 'O', 'O'), ('servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('art', 'O', 'O'), ('freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-ende-1024 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.489715</td>\n",
       "      <td>1.259143</td>\n",
       "      <td>0.902348</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'O'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s', 'O', 'O'), ('.', 'O', 'O'), ('593', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('nach', 'O', 'O'), ('seiner', 'O', 'O'), ('ruckkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.175863</td>\n",
       "      <td>2.106882</td>\n",
       "      <td>0.912456</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('NEWSru.ua', 'B-OTH', 'O'), ('/', 'O', 'O'), (':', 'O', 'O'), ('Политисполком', 'B-OTH', 'O'), ('СПУ', 'I-OTH', 'O'), ('отказал', 'I-OTH', 'O'), ('Морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'I-OTH', 'O'), ('Die', 'O', 'I-PER')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('\"', 'O', 'O'), ('Es', 'O', 'O'), ('ist', 'O', 'O'), ('beabsichtigt', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('Aktien', 'O', 'O'), ('im', 'O', 'O'), ('ersten', 'O', 'O'), ('Halbjahr', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.591090</td>\n",
       "      <td>0.603436</td>\n",
       "      <td>0.887721</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Außerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('Nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('Stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Senden', 'O', 'O'), ('Exxon', 'B-ORG', 'O'), ('Mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('Paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.de', 'B-ORG', 'O'), ('AG', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "bsz = 4\n",
    "seq_sz = 64\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.num_labels = len(labels)\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config=config)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n')\n",
    "    \n",
    "    before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                         max_length=seq_sz,\n",
    "                                                         padding='max_length',\n",
    "                                                         is_split_into_words=True, \n",
    "                                                         tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "    blocks = (\n",
    "        HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "        HF_TokenCategoryBlock(vocab=labels)\n",
    "    )\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('tokens'),\n",
    "                       get_y= lambda inp: [ \n",
    "                           (label, len(hf_tokenizer.tokenize(str(entity)))) \n",
    "                           for entity, label in zip(inp.tokens, inp.labels) \n",
    "                       ],\n",
    "                       splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(germ_eval_df, bs=bsz)\n",
    "\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter).to_fp16()\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), \n",
    "                            cbs=[HF_TokenClassMetricsCallback(tok_metrics=['accuracy'])])\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=10)\n",
    "        \n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "        \n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01za_data-seq2seq-core.ipynb.\n",
      "Converted 01zb_data-seq2seq-language-modeling.ipynb.\n",
      "Converted 01zc_data-seq2seq-summarization.ipynb.\n",
      "Converted 01zd_data-seq2seq-translation.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02za_modeling-seq2seq-core.ipynb.\n",
      "Converted 02zb_modeling-seq2seq-language-modeling.ipynb.\n",
      "Converted 02zc_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 02zc_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
