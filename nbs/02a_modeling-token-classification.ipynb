{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.data.token_classification import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.0\n",
      "Using fastai 2.1.5\n",
      "Using transformers 3.4.0\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_tokenizer, is_split_into_words=True, \n",
    "                                                     tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfms=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH'), ('et', 'I-OTH'), ('al', 'I-OTH'), ('.', 'O'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S', 'O'), ('.', 'O'), ('593', 'B-OTH'), ('.', 'I-OTH'), ('Wink', 'I-OTH'), ('&amp;', 'I-OTH'), ('Seibold', 'I-OTH'), ('et', 'O'), ('al', 'O'), ('.', 'O'), ('(', 'O'), ('1998', 'O'), (')', 'O'), ('S', 'O'), ('.', 'O'), ('32', 'O'), ('Inwieweit', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falken', 'O'), (',', 'B-LOCderiv'), ('wie', 'O'), ('der', 'O'), ('Afrikanische', 'O'), ('Baumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('cuvieri', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Malaienbaumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('serverus', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zuzuzählen', 'O'), ('sind', 'O'), (',', 'O'), ('ist', 'O'), ('Gegenstand', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Scenes', 'B-OTH'), ('of', 'I-OTH'), ('a', 'I-OTH'), ('Sexual', 'I-OTH'), ('Nature', 'I-OTH'), ('(', 'O'), ('GB', 'O'), ('2006', 'O'), (')', 'O'), ('-', 'O'), ('Regie', 'O'), (':', 'O'), ('Ed', 'B-PER'), ('Blum', 'I-PER'), ('Shortbus', 'B-OTH'), ('(', 'O'), ('USA', 'B-LOC'), ('2006', 'O'), (')', 'O'), ('-', 'O'), ('Regie', 'O'), (':', 'O'), ('John', 'B-PER'), ('Cameron', 'I-PER'), ('Mitchell', 'I-PER'), (':', 'O'), ('Film', 'O'), ('über', 'O'), ('den', 'O'), ('gleichnamigen', 'B-LOCderiv'), ('New', 'I-LOCderiv'), ('Yorker', 'O'), ('Club', 'O'), (',', 'O'), ('der', 'O'), ('verschiedensten', 'O'), ('Paaren', 'O'), ('eine', 'O'), ('Plattform', 'O'), ('zur', 'O'), ('Aufarbeitung', 'O'), ('ihrer', 'O'), ('Probleme', 'O'), ('bietet', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassCallback(HF_BaseModelCallback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.dls.before_batch[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        try:\n",
    "            self.learn.token_classification_report = calculate_token_class_metrics(targs, \n",
    "                                                                                   preds, \n",
    "                                                                                   'classification_report')\n",
    "        except ZeroDivisionError as err:\n",
    "            print(f'Couldn\\'t calcualte classification report: {err}')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2, 76, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 76]), 2, torch.Size([2, 76]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([152, 18]) torch.Size([152])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0005248074419796466, lr_steep=3.630780702224001e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.209931</td>\n",
       "      <td>0.159975</td>\n",
       "      <td>0.952798</td>\n",
       "      <td>0.580087</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.124946</td>\n",
       "      <td>0.108146</td>\n",
       "      <td>0.968178</td>\n",
       "      <td>0.658009</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.686230</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066819</td>\n",
       "      <td>0.100261</td>\n",
       "      <td>0.971891</td>\n",
       "      <td>0.722944</td>\n",
       "      <td>0.673387</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.68      0.49      0.57        51\n",
      "      PER       0.95      0.86      0.90        64\n",
      "      LOC       0.79      0.78      0.79        73\n",
      "  LOCpart       0.20      1.00      0.33         1\n",
      "      OTH       0.32      0.32      0.32        31\n",
      " LOCderiv       0.89      0.68      0.77        25\n",
      "  ORGpart       0.33      0.67      0.44         3\n",
      "\n",
      "micro avg       0.72      0.67      0.70       248\n",
      "macro avg       0.75      0.67      0.71       248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner, \n",
    "                 ctxs=None, max_n=6, trunc_at=None, **kwargs):    \n",
    "    # grab tokenizer\n",
    "    hf_textblock_tfm = learner.dls.before_batch[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x, y, samples, outs):\n",
    "        # recontstruct the string and split on space to get back your pre-tokenized list of tokens\n",
    "        toks = hf_tokenizer.convert_ids_to_tokens(inp, skip_special_tokens=True)\n",
    "        pretokenized_toks =  hf_tokenizer.convert_tokens_to_string(toks).split()\n",
    "        \n",
    "        # get predictions for subtokens that aren't ignored (e.g. special toks and token parts)\n",
    "        pred_labels = [ pred_lbl for lbl_id, pred_lbl in zip(trg, ast.literal_eval(pred[0])) if lbl_id != -100 ]\n",
    "        \n",
    "        trg_labels = ast.literal_eval(sample[1])\n",
    "        res.append([f'{[ (tok, trg, pred) for idx, (tok, pred, trg) in enumerate(zip(pretokenized_toks, pred_labels, trg_labels)) if (trunc_at is None or idx < trunc_at) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Rückkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'B-PER'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Erstmals', 'O', 'O'), ('Urkundlich', 'O', 'O'), ('erwähnt', 'O', 'O'), ('ist', 'O', 'O'), ('Nimburg', 'B-LOC', 'B-PER'), ('bereits', 'O', 'O'), ('im', 'O', 'O'), ('Jahre', 'O', 'O'), ('977', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.blurr_predict(inp)\n",
    "\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.before_batch[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.tok_kwargs\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    res = hf_tokenizer(inp, None, \n",
    "                       max_length=hf_textblock_tfm.max_length,\n",
    "                       padding=hf_textblock_tfm.padding,\n",
    "                       truncation=hf_textblock_tfm.truncation,\n",
    "                       is_split_into_words=hf_textblock_tfm.is_split_into_words,\n",
    "                       **tok_kwargs)\n",
    "\n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the token classification training code above works for **all** pretrained token classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.modeling_albert.AlbertForTokenClassification,\n",
       " transformers.modeling_auto.AutoModelForTokenClassification,\n",
       " transformers.modeling_bert.BertForTokenClassification,\n",
       " transformers.modeling_camembert.CamembertForTokenClassification,\n",
       " transformers.modeling_distilbert.DistilBertForTokenClassification,\n",
       " transformers.modeling_electra.ElectraForTokenClassification,\n",
       " transformers.modeling_flaubert.FlaubertForTokenClassification,\n",
       " transformers.modeling_funnel.FunnelForTokenClassification,\n",
       " transformers.modeling_layoutlm.LayoutLMForTokenClassification,\n",
       " transformers.modeling_longformer.LongformerForTokenClassification,\n",
       " transformers.modeling_mobilebert.MobileBertForTokenClassification,\n",
       " transformers.modeling_roberta.RobertaForTokenClassification,\n",
       " transformers.modeling_squeezebert.SqueezeBertForTokenClassification,\n",
       " transformers.modeling_xlm.XLMForTokenClassification,\n",
       " transformers.modeling_xlm_roberta.XLMRobertaForTokenClassification,\n",
       " transformers.modeling_xlnet.XLNetForTokenClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='TokenClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    #'<electra>', # currently no pre-trained electra model works for token classification\n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'xlm-mlm-ende-1024',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.397884</td>\n",
       "      <td>0.334202</td>\n",
       "      <td>0.924774</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.334728</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('auerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('berg', 'B-PER', 'B-LOC'), ('spricht', 'O', 'O'), ('hier', 'O', 'O'), ('als', 'O', 'O'), ('chef', 'O', 'O'), ('von', 'O', 'O'), ('microsoft', 'B-ORG', 'O'), ('deutschland', 'I-ORG', 'O'), ('auch', 'O', 'O'), ('fur', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-multilingual-cased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.188294</td>\n",
       "      <td>0.198280</td>\n",
       "      <td>0.949709</td>\n",
       "      <td>0.611354</td>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.632054</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'I-PER'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'I-PER'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('S', 'O', 'O'), ('.', 'O', 'O'), ('593', 'B-OTH', 'I-PER')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Außerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('Nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('Stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.835932</td>\n",
       "      <td>0.812578</td>\n",
       "      <td>0.899955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('NEWSru.ua', 'B-OTH', 'O'), ('/', 'O', 'O'), (':', 'O', 'O'), ('ооо', 'B-OTH', 'O'), ('оаа', 'I-OTH', 'O'), ('оо', 'I-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Nachdem', 'O', 'O'), ('die', 'O', 'O'), ('Einwohnerzahl', 'O', 'O'), ('in', 'O', 'O'), ('der', 'O', 'O'), ('ersten', 'O', 'O'), ('Hlfte', 'O', 'O'), ('des', 'O', 'O'), ('20.', 'O', 'O'), ('Jahrhu', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.307468</td>\n",
       "      <td>0.326979</td>\n",
       "      <td>0.920641</td>\n",
       "      <td>0.251337</td>\n",
       "      <td>0.297468</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('standard', 'B-ORG', 'B-ORG'), ('oil', 'I-ORG', 'B-ORG'), ('of', 'I-ORG', 'O'), ('new', 'I-ORG', 'I-PER'), ('jersey', 'I-ORG', 'B-LOC'), (')', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('sexual', 'I-OTH', 'O'), ('nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('gb', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.366306</td>\n",
       "      <td>0.355079</td>\n",
       "      <td>0.911318</td>\n",
       "      <td>0.143678</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.184502</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('Sexual', 'I-OTH', 'O'), ('Nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('GB', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('NEWSru.ua', 'B-OTH', 'O'), ('/', 'O', 'O'), (':', 'O', 'O'), ('Политисполком', 'B-OTH', 'O'), ('СПУ', 'I-OTH', 'O'), ('от', 'I-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.603670</td>\n",
       "      <td>0.873559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'B-LOC'), ('al', 'I-OTH', 'B-LOC'), ('.', 'O', 'B-ORG'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s', 'O', 'I-LOCderiv'), ('.', 'O', 'I-LOCderiv'), ('593', 'B-OTH', 'B-ORG')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('zugang', 'O', 'O'), ('und', 'O', 'O'), ('engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('netz', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.370285</td>\n",
       "      <td>0.360035</td>\n",
       "      <td>0.911419</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('Standard', 'B-ORG', 'O'), ('Oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'O'), ('New', 'I-ORG', 'O'), ('Jersey', 'I-ORG', 'O'), (')', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-ende-1024 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.514749</td>\n",
       "      <td>0.563311</td>\n",
       "      <td>0.896833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('sexual', 'I-OTH', 'O'), ('nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('gb', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('newsru.ua', 'B-OTH', 'O'), ('/', 'O', 'O'), (':', 'O', 'O'), ('политисполком', 'B-OTH', 'O'), ('спу', 'I-OTH', 'O'), ('отказал', 'I-OTH', 'O'), ('м', 'I-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.280242</td>\n",
       "      <td>0.223893</td>\n",
       "      <td>0.940957</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.532020</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'I-PER'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'O'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('S.', 'O', 'O'), ('593.', 'O', 'O'), ('Wink', 'B-OTH', 'I-PER')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Genaugenommen', 'O', 'O'), ('gibt', 'O', 'O'), ('es', 'O', 'O'), ('aber', 'O', 'O'), ('den', 'O', 'O'), ('Migrationshintergrund', 'O', 'O'), ('nicht', 'O', 'O'), (',', 'O', 'O'), ('sondern', 'O', 'O'), ('nur', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `mem_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.440073</td>\n",
       "      <td>0.343047</td>\n",
       "      <td>0.917049</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.087379</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Ruckkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Die', 'O', 'O'), ('Flugel', 'O', 'O'), ('Die', 'O', 'O'), ('geoffneten', 'O', 'O'), ('Flugel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('Szenen', 'O', 'O'), ('Hohepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "bsz = 2\n",
    "seq_sz = 32\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.num_labels = len(labels)\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config=config)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n')\n",
    "    \n",
    "    before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_tokenizer, \n",
    "                                                         max_length=seq_sz,\n",
    "                                                         padding='max_length',\n",
    "                                                         is_split_into_words=True, \n",
    "                                                         tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "    blocks = (\n",
    "        HF_TextBlock(before_batch_tfms=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "        HF_TokenCategoryBlock(vocab=labels)\n",
    "    )\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('tokens'),\n",
    "                       get_y= lambda inp: [ \n",
    "                           (label, len(hf_tokenizer.tokenize(str(entity)))) \n",
    "                           for entity, label in zip(inp.tokens, inp.labels) \n",
    "                       ],\n",
    "                       splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(germ_eval_df, bs=bsz)\n",
    "\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.unfreeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING One pass through the model ***')\n",
    "        preds = learn.model(b[0])\n",
    "        test_eq(len(preds[0]), bsz)\n",
    "        test_eq(preds[0].shape, torch.Size([bsz, seq_sz, len(labels)]))\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=10)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizer</td>\n",
       "      <td>AlbertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizer</td>\n",
       "      <td>BertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizer</td>\n",
       "      <td>CamembertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizer</td>\n",
       "      <td>DistilBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizer</td>\n",
       "      <td>LongformerForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizer</td>\n",
       "      <td>MobileBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>RobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizer</td>\n",
       "      <td>XLMRobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizer</td>\n",
       "      <td>XLNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01za_data-text2text-core.ipynb.\n",
      "Converted 01zb_data-text2text-language-modeling.ipynb.\n",
      "Converted 01zc_data-text2text-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02za_modeling-text2text-core.ipynb.\n",
      "Converted 02zb_modeling-text2text-language-modeling.ipynb.\n",
      "Converted 02zc_modeling-text2text-summarization.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
