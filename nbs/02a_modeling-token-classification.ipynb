{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.data.token_classification import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.1\n",
      "Using fastai 2.1.8\n",
      "Using transformers 4.0.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.models.bert.configuration_bert.BertConfig,\n",
       " transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_tokenizer, is_split_into_words=True, \n",
    "                                                     tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfms=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S.', 'O'), ('593.', 'O'), ('Wink', 'O'), ('&amp;', 'B-OTH'), ('Seibold', 'I-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'I-OTH'), ('1998', 'O'), (')', 'O'), ('S.', 'O'), ('32', 'O'), ('Inwieweit', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falken,', 'O'), ('wie', 'O'), ('der', 'O'), ('Afrikanische', 'O'), ('Baumfalke', 'O'), ('(', 'O'), ('Falco', 'B-LOCderiv'), ('cuvieri', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Malaienbaumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('serverus', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zuzuzählen', 'O'), ('sind,', 'O'), ('ist', 'O'), ('Gegenstand', 'O'), ('der', 'O'), ('Forschung.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Außerdem', 'O'), ('befindet', 'O'), ('sich', 'O'), ('im', 'O'), ('Nordwesten', 'O'), ('der', 'O'), ('Stadt', 'O'), ('(', 'O'), ('auf', 'O'), ('dem', 'O'), ('Gelände', 'O'), ('des', 'O'), ('ehemaligen', 'O'), ('Militärflughafens', 'O'), ('Butzweilerhof', 'B-LOC'), (')', 'O'), ('das', 'O'), ('Coloneum,', 'B-LOC'), ('Europas', 'O'), ('größter', 'B-LOC'), ('Studiokomplex', 'O'), ('mit', 'O'), ('einer', 'O'), ('Fläche', 'O'), ('von', 'O'), ('35', 'O'), ('ha', 'O'), ('und', 'O'), ('20', 'O'), ('Studios', 'O'), ('(', 'O'), ('25.', 'O'), ('000', 'O'), ('m²', 'O'), (')', 'O'), ('mit', 'O'), ('bis', 'O'), ('zu', 'O'), ('30', 'O'), ('Meter', 'O'), ('Deckenhöhe.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassCallback(HF_BaseModelCallback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.dls.before_batch[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        try:\n",
    "            self.learn.token_classification_report = calculate_token_class_metrics(targs, \n",
    "                                                                                   preds, \n",
    "                                                                                   'classification_report')\n",
    "        except ZeroDivisionError as err:\n",
    "            print(f'Couldn\\'t calcualte classification report: {err}')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2, 76, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 76]), 2, torch.Size([2, 76]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([152, 18]) torch.Size([152])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0007585775572806596, lr_steep=3.630780702224001e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.155291</td>\n",
       "      <td>0.237057</td>\n",
       "      <td>0.949459</td>\n",
       "      <td>0.580508</td>\n",
       "      <td>0.559184</td>\n",
       "      <td>0.569647</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.097618</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.967568</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.729614</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.035995</td>\n",
       "      <td>0.177488</td>\n",
       "      <td>0.965676</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.84      0.76      0.80        71\n",
      "    LOCderiv       0.88      0.82      0.85        28\n",
      "     LOCpart       0.29      1.00      0.44         2\n",
      "         ORG       0.53      0.69      0.60        35\n",
      "     ORGpart       1.00      1.00      1.00         4\n",
      "         OTH       0.50      0.58      0.54        26\n",
      "    OTHderiv       0.00      0.00      0.00         0\n",
      "     OTHpart       0.00      0.00      0.00         0\n",
      "         PER       0.84      0.80      0.82        54\n",
      "     PERpart       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.70      0.75      0.72       220\n",
      "   macro avg       0.49      0.56      0.51       220\n",
      "weighted avg       0.76      0.75      0.75       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner, \n",
    "                 ctxs=None, max_n=6, trunc_at=None, **kwargs):    \n",
    "    # grab tokenizer\n",
    "    hf_textblock_tfm = learner.dls.before_batch[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    ignore_token_id = hf_textblock_tfm.ignore_token_id\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x, y, samples, outs):\n",
    "        # recontstruct the string and split on space to get back your pre-tokenized list of tokens\n",
    "        toks = hf_tokenizer.convert_ids_to_tokens(inp, skip_special_tokens=True)\n",
    "        pretokenized_toks =  hf_tokenizer.convert_tokens_to_string(toks).split()\n",
    "        \n",
    "        # get predictions for subtokens that aren't ignored (e.g. special toks and token parts)\n",
    "        pred_labels = [ pred_lbl for lbl_id, pred_lbl in zip(trg, ast.literal_eval(pred[0])) if lbl_id != -ignore_token_id ]\n",
    "        \n",
    "        trg_labels = ast.literal_eval(sample[1])\n",
    "        res.append([f'{[ (tok, trg, pred) for idx, (tok, pred, trg) in enumerate(zip(pretokenized_toks, pred_labels, trg_labels)) if (trunc_at is None or idx < trunc_at) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Wie', 'O', 'O'), ('wenige', 'O', 'O'), ('Wochen', 'O', 'O'), ('vor', 'O', 'O'), ('der', 'O', 'O'), ('Bekanntgabe', 'O', 'O'), ('in', 'O', 'O'), ('einem', 'O', 'O'), ('Interview', 'O', 'O'), ('angekündigt,', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O', 'O'), ('notenbeste', 'O', 'O'), ('Zweitligaspieler', 'O', 'O'), ('(', 'O', 'O'), ('2,', 'O', 'O'), ('91', 'O', 'O'), ('),', 'O', 'O'), ('der', 'O', 'O'), ('seine', 'O', 'O'), ('persönliche', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\",)\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _blurr_predict_tokens(predict_func, items, hf_textblock_tfm):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.blurr_predict` or `blurrONNX.predict.\n",
    "    Aligns the predicted labels, label ids, and probabilities with what you passed in excluding subword tokens\n",
    "    \"\"\"\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.tok_kwargs\n",
    "    \n",
    "    if (isinstance(items[0], str)): items = [items]\n",
    "        \n",
    "    outs = []\n",
    "    for inp, res in zip(items, predict_func(items)):\n",
    "        # blurr_predict returns a list for each, we only doing one at a time so git first element of each\n",
    "        pred_lbls, pred_lbl_ids, probs = res[0][0], res[1][0], res[2][0]\n",
    "  \n",
    "        # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "        # return\n",
    "        subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "        # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "        # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "        # (e.g., [CLS], [SEP], etc...)\n",
    "        res = hf_tokenizer(inp, None, \n",
    "                           max_length=hf_textblock_tfm.max_length,\n",
    "                           padding=hf_textblock_tfm.padding,\n",
    "                           truncation=hf_textblock_tfm.truncation,\n",
    "                           is_split_into_words=hf_textblock_tfm.is_split_into_words,\n",
    "                           **tok_kwargs)\n",
    "\n",
    "        special_toks_msk = L(res['special_tokens_mask'])\n",
    "        actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "        # using the indexes to the actual tokens, get that info from the results returned above\n",
    "        pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "        actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "        actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "        actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "        # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "        # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "        offset = 0\n",
    "        raw_trg_idxs = []\n",
    "        for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "            raw_trg_idxs.append(idx+offset)\n",
    "            offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "            \n",
    "        outs.append((inp, \n",
    "                     actual_pred_lbls[raw_trg_idxs], \n",
    "                     actual_pred_lbl_ids[raw_trg_idxs], \n",
    "                     actual_probs[raw_trg_idxs]))\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, items, **kargs):\n",
    "    hf_textblock_tfm = self.dls.before_batch[0]\n",
    "    return _blurr_predict_tokens(self.blurr_predict, items, hf_textblock_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`items`**, **\\*\\*`kargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\n",
    "txt2 = \"I wish covid was over so I could go to Germany and watch Bayern Munich play in the Bundesliga.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'B-PER'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'I-ORG'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'tok_class_learn_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'B-PER'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'I-ORG'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "\n",
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def predict_tokens(self:blurrONNX, items, **kargs):\n",
    "    hf_textblock_tfm = self.dls.before_batch[0]\n",
    "    return _blurr_predict_tokens(self.predict, items, hf_textblock_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py:192: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  position_ids = self.position_ids[:, :seq_length]\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/modeling_utils.py:1673: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/torch/onnx/utils.py:244: UserWarning: We detected that you are modifying a dictionnary that is an input to your model. Note that dictionaries are allowed as inputs in ONNX but they should be handled with care. Usages of dictionaries is not recommended, and should not be used except for configuration use. Also note that the order and values of the keys must remain the same. \n",
      "  warnings.warn(warning)\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.blurr_to_onnx(export_fname, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "onnx_inf = blurrONNX(export_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "res = onnx_inf.predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the token classification training code above works for **all** pretrained token classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.models.albert.modeling_albert.AlbertForTokenClassification,\n",
       " transformers.models.auto.modeling_auto.AutoModelForTokenClassification,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification,\n",
       " transformers.models.camembert.modeling_camembert.CamembertForTokenClassification,\n",
       " transformers.models.distilbert.modeling_distilbert.DistilBertForTokenClassification,\n",
       " transformers.models.electra.modeling_electra.ElectraForTokenClassification,\n",
       " transformers.models.flaubert.modeling_flaubert.FlaubertForTokenClassification,\n",
       " transformers.models.funnel.modeling_funnel.FunnelForTokenClassification,\n",
       " transformers.models.layoutlm.modeling_layoutlm.LayoutLMForTokenClassification,\n",
       " transformers.models.longformer.modeling_longformer.LongformerForTokenClassification,\n",
       " transformers.models.mobilebert.modeling_mobilebert.MobileBertForTokenClassification,\n",
       " transformers.models.roberta.modeling_roberta.RobertaForTokenClassification,\n",
       " transformers.models.squeezebert.modeling_squeezebert.SqueezeBertForTokenClassification,\n",
       " transformers.models.xlm.modeling_xlm.XLMForTokenClassification,\n",
       " transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForTokenClassification,\n",
       " transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='TokenClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'google/electra-small-generator',\n",
    "    'flaubert/flaubert_small_cased',\n",
    "    'funnel-transformer/small-base',\n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'squeezebert/squeezebert-uncased',\n",
    "    'xlm-mlm-ende-1024',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.324757</td>\n",
       "      <td>1.175696</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('in', 'O', 'O'), ('einer', 'O', 'O'), ('fernsehdiskussion', 'O', 'O'), ('traf', 'O', 'O'), ('er', 'O', 'O'), ('auf', 'O', 'O'), ('den', 'O', 'O'), ('kritiker', 'O', 'O'), ('alexander', 'B-PER', 'O'), ('walker', 'I-PER', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('der', 'O', 'I-LOC'), ('28-jahrige', 'O', 'O'), ('und', 'O', 'O'), ('sein', 'O', 'O'), ('team', 'O', 'O'), (',', 'O', 'O'), ('zu', 'O', 'O'), ('dem', 'O', 'O'), ('auch', 'O', 'O'), ('karla', 'B-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-multilingual-cased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.946755</td>\n",
       "      <td>1.763072</td>\n",
       "      <td>0.897194</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('Sexual', 'I-OTH', 'O'), ('Nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('GB', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('NEWSru.', 'B-OTH', 'O'), ('ua', 'O', 'O'), ('/', 'O', 'O'), (':', 'B-OTH', 'O'), ('Политисполком', 'I-OTH', 'O'), ('СПУ', 'I-OTH', 'O'), ('отказал', 'I-OTH', 'O'), ('Морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.201380</td>\n",
       "      <td>2.163309</td>\n",
       "      <td>0.898993</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('NEWSru.ua', 'B-OTH', 'O'), ('/', 'O', 'O'), (':', 'O', 'O'), ('&lt;unk&gt;о&lt;unk&gt;о&lt;unk&gt;о&lt;unk&gt;', 'B-OTH', 'O'), ('&lt;unk&gt;', 'I-OTH', 'O'), ('о&lt;unk&gt;а&lt;unk&gt;а&lt;unk&gt;', 'I-OTH', 'O'), ('&lt;unk&gt;о&lt;unk&gt;о&lt;unk&gt;', 'I-OTH', 'O'), ('&lt;unk&gt;', 'I-OTH', 'O'), ('о&lt;unk&gt;а&lt;unk&gt;', 'I-OTH', 'O'), ('Die', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Mit', 'O', 'O'), ('der', 'O', 'O'), ('Servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('Bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('Art', 'O', 'O'), ('Freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.979540</td>\n",
       "      <td>1.829795</td>\n",
       "      <td>0.900538</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('zugang', 'O', 'O'), ('und', 'O', 'O'), ('engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('netz', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('senden', 'O', 'I-ORGpart'), ('exxon', 'B-ORG', 'I-ORGpart'), ('mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.', 'B-ORG', 'O'), ('de', 'I-ORG', 'B-PERpart')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/electra-small-generator ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.107633</td>\n",
       "      <td>1.996512</td>\n",
       "      <td>0.765800</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'I-ORG'), ('et', 'I-OTH', 'O'), ('al.', 'I-OTH', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s.', 'O', 'I-PER'), ('593.', 'O', 'O'), ('wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('der', 'O', 'I-ORG'), ('28', 'O', 'O'), ('-', 'O', 'O'), ('jahrige', 'O', 'O'), ('und', 'O', 'O'), ('sein', 'O', 'O'), ('team,', 'O', 'O'), ('zu', 'O', 'O'), ('dem', 'O', 'O'), ('auch', 'B-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.078753</td>\n",
       "      <td>1.900974</td>\n",
       "      <td>0.645744</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'B-ORG'), ('Standard', 'B-ORG', 'B-ORGpart'), ('Oil', 'I-ORG', 'B-ORG'), ('of', 'I-ORG', 'B-PERpart'), ('New', 'I-ORG', 'B-PER'), ('Jersey', 'I-ORG', 'I-LOCderiv'), (')', 'O', 'B-PERderiv'), (',', 'O', 'O'), ('die', 'O', 'B-ORG'), ('ausgesprochen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Senden', 'O', 'O'), ('Exxon', 'B-ORG', 'O'), ('Mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('Paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.de', 'B-ORG', 'O'), ('AG', 'I-ORG', 'B-ORG')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== funnel-transformer/small-base ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.335637</td>\n",
       "      <td>0.985243</td>\n",
       "      <td>0.906076</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('mit', 'O', 'O'), ('der', 'O', 'O'), ('servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('art', 'O', 'B-OTH'), ('freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('senden', 'O', 'O'), ('exxon', 'B-ORG', 'O'), ('mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.', 'B-ORG', 'O'), ('de', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.130319</td>\n",
       "      <td>2.025543</td>\n",
       "      <td>0.893773</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Mit', 'O', 'O'), ('der', 'O', 'O'), ('Servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('Bianca', 'B-PER', 'O'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('Art', 'O', 'O'), ('Freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.991805</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('mit', 'O', 'B-LOC'), ('der', 'O', 'B-PERderiv'), ('servicefrau', 'O', 'B-PERderiv'), ('verband', 'O', 'I-ORGpart'), ('bianca', 'B-PER', 'B-PERderiv'), ('offenbar', 'O', 'B-PERpart'), ('eine', 'O', 'I-ORGpart'), ('art', 'O', 'B-PERpart'), ('freundschaft', 'O', 'B-OTHderiv'), ('–', 'O', 'B-PERderiv')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('senden', 'O', 'B-LOC'), ('exxon', 'B-ORG', 'B-LOCpart'), ('mobil', 'I-ORG', 'I-LOCderiv'), ('\"', 'O', 'I-LOCderiv'), ('buy', 'O', 'I-PER'), ('\"', 'O', 'I-LOCderiv'), ('paris', 'B-LOC', 'I-LOCderiv'), ('(', 'O', 'I-ORG'), ('aktiencheck.', 'B-ORG', 'I-LOCderiv'), ('de', 'I-ORG', 'B-PERderiv')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.397810</td>\n",
       "      <td>2.310558</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'B-LOC'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'B-LOC'), ('Sexual', 'I-OTH', 'B-LOC'), ('Nature', 'I-OTH', 'B-LOC'), ('(', 'O', 'I-LOCderiv'), ('GB', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Das', 'O', 'B-LOC'), ('\"', 'O', 'O'), ('Torchwood', 'B-OTH', 'O'), ('\"', 'O', 'B-LOC'), ('-Team', 'O', 'I-LOCderiv'), ('besteht', 'O', 'O'), ('neben', 'O', 'O'), ('Captain', 'O', 'O'), ('Jack', 'B-PER', 'O'), ('Harkness', 'I-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.431872</td>\n",
       "      <td>2.369726</td>\n",
       "      <td>0.900418</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('die', 'O', 'O'), ('flugel', 'O', 'O'), ('die', 'O', 'O'), ('geoffneten', 'O', 'O'), ('flugel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('szenen', 'O', 'O'), ('hohepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('da', 'O', 'O'), ('ich', 'O', 'O'), ('mir', 'O', 'O'), ('als', 'O', 'O'), ('kleine', 'O', 'O'), ('rentnerin', 'O', 'O'), ('nicht', 'O', 'O'), ('sehr', 'O', 'O'), ('viel', 'O', 'O'), ('leisten', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-ende-1024 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.074983</td>\n",
       "      <td>0.758206</td>\n",
       "      <td>0.885355</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'O'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s', 'O', 'O'), ('.', 'O', 'O'), ('593', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('sexual', 'I-OTH', 'O'), ('nature', 'I-OTH', 'O'), ('(', 'O', 'O'), ('gb', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.409844</td>\n",
       "      <td>2.338723</td>\n",
       "      <td>0.063095</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'I-LOC'), ('seiner', 'O', 'I-LOC'), ('Rückkehr', 'O', 'I-LOC'), ('hielt', 'O', 'I-LOC'), ('Strummer', 'B-PER', 'I-LOC'), ('ein', 'O', 'I-LOC'), ('Bandmeeting', 'O', 'I-LOC'), ('ab', 'O', 'I-LOC'), (',', 'O', 'I-LOC'), ('in', 'O', 'I-LOC')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O', 'I-LOC'), ('28-Jährige', 'O', 'I-LOC'), ('und', 'O', 'I-LOC'), ('sein', 'O', 'I-LOC'), ('Team', 'O', 'I-LOC'), (',', 'O', 'I-LOC'), ('zu', 'O', 'I-LOC'), ('dem', 'O', 'I-LOC'), ('auch', 'O', 'I-LOC'), ('Karla', 'B-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.031753</td>\n",
       "      <td>0.944214</td>\n",
       "      <td>0.720143</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Senden', 'O', 'O'), ('Exxon', 'B-ORG', 'O'), ('Mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'B-ORG'), ('\"', 'O', 'B-LOCderiv'), ('Paris', 'B-LOC', 'O'), ('(', 'O', 'B-ORG'), ('aktiencheck.de', 'B-ORG', 'B-LOCderiv'), ('AG', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Da', 'O', 'O'), ('ich', 'O', 'B-LOCderiv'), ('mir', 'O', 'O'), ('als', 'O', 'O'), ('kleine', 'O', 'B-ORG'), ('Rentnerin', 'O', 'O'), ('nicht', 'O', 'B-ORG'), ('sehr', 'O', 'B-PERderiv'), ('viel', 'O', 'B-LOCderiv'), ('leisten', 'O', 'B-ORG')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "bsz = 4\n",
    "seq_sz = 64\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.num_labels = len(labels)\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config=config)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n')\n",
    "    \n",
    "    before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_tokenizer, \n",
    "                                                         max_length=seq_sz,\n",
    "                                                         padding='max_length',\n",
    "                                                         is_split_into_words=True, \n",
    "                                                         tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "    blocks = (\n",
    "        HF_TextBlock(before_batch_tfms=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "        HF_TokenCategoryBlock(vocab=labels)\n",
    "    )\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('tokens'),\n",
    "                       get_y= lambda inp: [ \n",
    "                           (label, len(hf_tokenizer.tokenize(str(entity)))) \n",
    "                           for entity, label in zip(inp.tokens, inp.labels) \n",
    "                       ],\n",
    "                       splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(germ_eval_df, bs=bsz)\n",
    "\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_TokenClassCallback(tok_metrics=['accuracy'])],\n",
    "                splitter=hf_splitter).to_fp16()\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=10)\n",
    "        \n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "        \n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01za_data-text2text-core.ipynb.\n",
      "Converted 01zb_data-text2text-language-modeling.ipynb.\n",
      "Converted 01zc_data-text2text-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02za_modeling-text2text-core.ipynb.\n",
      "Converted 02zb_modeling-text2text-language-modeling.ipynb.\n",
      "Converted 02zc_modeling-text2text-summarization.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
