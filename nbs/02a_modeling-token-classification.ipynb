{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.data.token_classification import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.1\n",
      "Using fastai 2.3.1\n",
      "Using transformers 4.5.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForTokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.models.bert.configuration_bert.BertConfig,\n",
       " transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=model_cls, \n",
    "                                                                  config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                     is_split_into_words=True, \n",
    "                                                     tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O'), ('und', 'O'), ('Engagement', 'O'), (':', 'O'), ('das', 'O'), ('eigentlich', 'O'), ('Neue', 'O'), ('an', 'O'), ('der', 'O'), ('Netz', 'O'), ('(', 'O'), ('werk', 'O'), (')', 'O'), ('kunst,', 'O'), ('in', 'O'), (':', 'O'), ('Medien', 'O'), ('Kunst', 'O'), ('Netz,', 'O'), ('2004,', 'O'), ('URL', 'O'), (':', 'O'), ('*', 'O'), ('Arns,', 'B-PER'), ('Inke', 'O'), (':', 'B-PER'), ('Netzkulturen,', 'O'), ('Hamburg', 'O'), ('(', 'O'), ('eva', 'B-LOC'), ('),', 'O'), ('2002,', 'O'), ('S.', 'O'), ('46', 'O'), ('und', 'O'), ('81', 'O'), ('*', 'O'), ('Armin', 'O'), ('Medosch', 'O'), (':', 'O'), ('Public', 'B-PER'), ('Netbase', 'I-PER'), ('Wien.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Scenes', 'B-OTH'), ('of', 'I-OTH'), ('a', 'I-OTH'), ('Sexual', 'I-OTH'), ('Nature', 'I-OTH'), ('(', 'O'), ('GB', 'O'), ('2006', 'O'), (')', 'O'), ('-', 'O'), ('Regie', 'O'), (':', 'O'), ('Ed', 'B-PER'), ('Blum', 'I-PER'), ('Shortbus', 'B-OTH'), ('(', 'O'), ('USA', 'B-LOC'), ('2006', 'O'), (')', 'O'), ('-', 'O'), ('Regie', 'O'), (':', 'O'), ('John', 'B-PER'), ('Cameron', 'I-PER'), ('Mitchell', 'I-PER'), (':', 'O'), ('Film', 'O'), ('über', 'O'), ('den', 'O'), ('gleichnamigen', 'B-LOCderiv'), ('New', 'I-LOCderiv'), ('Yorker', 'O'), ('Club,', 'O'), ('der', 'O'), ('verschiedensten', 'O'), ('Paaren', 'O'), ('eine', 'O'), ('Plattform', 'O'), ('zur', 'O'), ('Aufarbeitung', 'O'), ('ihrer', 'O'), ('Probleme', 'O'), ('bietet.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(filter(lambda el: isinstance(el, HF_TokenCategorize), learn.dls.tfms[1]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in learn.dls.tfms[1]: print(isinstance(x,HF_TokenCategorize), type(x), HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdf = HF_TokenCategorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isinstance(asdf,HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_blurr_tfm(learn.dls.tfms, tfm_class=HF_TokenCategorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassMetricsCallback(Callback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the HF_TokenClassBeforeBatchTransform\n",
    "        hf_before_batch_tfm = get_blurr_tfm(self.learn.dls.before_batch)\n",
    "        hf_tok_categorize_tfm = get_blurr_tfm(self.learn.dls.tfms[1], tfm_class=HF_TokenCategorize)\n",
    "        \n",
    "        self.hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = hf_tok_categorize_tfm.ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_before_batch_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        try:\n",
    "            self.learn.token_classification_report = calculate_token_class_metrics(targs, \n",
    "                                                                                   preds, \n",
    "                                                                                   'classification_report')\n",
    "        except ZeroDivisionError as err:\n",
    "            print(f'Couldn\\'t calcualte classification report: {err}')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_TokenClassMetricsCallback()]\n",
    "\n",
    "learn = Learner(dls, model, opt_func=partial(Adam),cbs=learn_cbs,splitter=hf_splitter)\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2, 61, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 61]), 2, torch.Size([2, 61]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([122, 18]) torch.Size([122])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0005248074419796466, lr_steep=1.737800812406931e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.213807</td>\n",
       "      <td>0.171633</td>\n",
       "      <td>0.953887</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>0.662100</td>\n",
       "      <td>0.614407</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.76      0.62      0.68        84\n",
      "    LOCderiv       0.52      0.69      0.59        16\n",
      "     LOCpart       0.00      0.00      0.00         0\n",
      "         ORG       0.53      0.49      0.51        47\n",
      "     ORGpart       0.00      0.00      0.00         0\n",
      "         OTH       0.11      0.75      0.19         4\n",
      "    OTHderiv       0.00      0.00      0.00         0\n",
      "     OTHpart       0.00      0.00      0.00         0\n",
      "         PER       0.84      0.82      0.83        68\n",
      "    PERderiv       0.00      0.00      0.00         0\n",
      "     PERpart       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.57      0.66      0.61       219\n",
      "   macro avg       0.25      0.31      0.26       219\n",
      "weighted avg       0.71      0.66      0.68       219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner, \n",
    "                 ctxs=None, max_n=6, trunc_at=None, **kwargs):    \n",
    "    \n",
    "    hf_before_batch_tfm = get_blurr_tfm(learner.dls.before_batch)\n",
    "    hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "    ignore_token_id = hf_before_batch_tfm.ignore_token_id\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x, y, samples, outs):\n",
    "        # recontstruct the string and split on space to get back your pre-tokenized list of tokens\n",
    "        toks = hf_tokenizer.convert_ids_to_tokens(inp, skip_special_tokens=True)\n",
    "        pretokenized_toks =  hf_tokenizer.convert_tokens_to_string(toks).split()\n",
    "        \n",
    "        # get predictions for subtokens that aren't ignored (e.g. special toks and token parts)\n",
    "        pred_labels = [ pred_lbl for lbl_id, pred_lbl in zip(trg, ast.literal_eval(pred[0])) if lbl_id != -ignore_token_id ]\n",
    "        \n",
    "        trg_labels = ast.literal_eval(sample[1])\n",
    "        res.append([f'{[ (tok, trg, pred) for idx, (tok, pred, trg) in enumerate(zip(pretokenized_toks, pred_labels, trg_labels)) if (trunc_at is None or idx < trunc_at) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'B-PER'), ('al.', 'I-OTH', 'I-PER'), ('(', 'O', 'B-PER'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('S.', 'O', 'O'), ('593.', 'O', 'O'), ('Wink', 'O', 'O'), ('&amp;', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('(', 'O', 'O'), ('Standard', 'B-ORG', 'O'), ('Oil', 'I-ORG', 'B-ORG'), ('of', 'I-ORG', 'B-ORG'), ('New', 'I-ORG', 'I-ORG'), ('Jersey', 'I-ORG', 'B-LOC'), ('),', 'O', 'B-LOC'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O'), ('„', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O']\",)\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _blurr_predict_tokens(predict_func, items, hf_before_batch_tfm):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.blurr_predict` or `blurrONNX.predict.\n",
    "    Aligns the predicted labels, label ids, and probabilities with what you passed in excluding subword tokens\n",
    "    \"\"\"\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_tokenizer = hf_before_batch_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_before_batch_tfm.tok_kwargs\n",
    "    \n",
    "    if (isinstance(items[0], str)): items = [items]\n",
    "        \n",
    "    outs = []\n",
    "    for inp, res in zip(items, predict_func(items)):\n",
    "        # blurr_predict returns a list for each, we only doing one at a time so git first element of each\n",
    "        pred_lbls, pred_lbl_ids, probs = res[0][0], res[1][0], res[2][0]\n",
    "  \n",
    "        # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "        # return\n",
    "        subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "        # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "        # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "        # (e.g., [CLS], [SEP], etc...)\n",
    "        res = hf_tokenizer(inp, None, \n",
    "                           max_length=hf_before_batch_tfm.max_length,\n",
    "                           padding=hf_before_batch_tfm.padding,\n",
    "                           truncation=hf_before_batch_tfm.truncation,\n",
    "                           is_split_into_words=hf_before_batch_tfm.is_split_into_words,\n",
    "                           **tok_kwargs)\n",
    "\n",
    "        special_toks_msk = L(res['special_tokens_mask'])\n",
    "        actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "        # using the indexes to the actual tokens, get that info from the results returned above\n",
    "        pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "        actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "        actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "        actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "        # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "        # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "        offset = 0\n",
    "        raw_trg_idxs = []\n",
    "        for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "            raw_trg_idxs.append(idx+offset)\n",
    "            offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "            \n",
    "        outs.append((inp, \n",
    "                     actual_pred_lbls[raw_trg_idxs], \n",
    "                     actual_pred_lbl_ids[raw_trg_idxs], \n",
    "                     actual_probs[raw_trg_idxs]))\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, items, **kargs):\n",
    "    hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "    return _blurr_predict_tokens(self.blurr_predict, items, hf_before_batch_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`items`**, **\\*\\*`kargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\n",
    "txt2 = \"I wish covid was over so I could go to Germany and watch Bayern Munich play in the Bundesliga.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'O'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'B-LOC'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'tok_class_learn_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n",
      "\n",
      "[('I', 'O'), ('wish', 'O'), ('covid', 'O'), ('was', 'O'), ('over', 'O'), ('so', 'O'), ('I', 'O'), ('could', 'O'), ('go', 'O'), ('to', 'O'), ('Germany', 'B-LOC'), ('and', 'O'), ('watch', 'O'), ('Bayern', 'B-ORG'), ('Munich', 'B-LOC'), ('play', 'O'), ('in', 'O'), ('the', 'O'), ('Bundesliga.', 'B-ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "\n",
    "res = learn.blurr_predict_tokens([txt.split(), txt2.split()])\n",
    "for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# @patch\n",
    "# def predict_tokens(self:blurrONNX, items, **kargs):\n",
    "#     hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "#     return _blurr_predict_tokens(self.predict, items, hf_before_batch_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# learn.blurr_to_onnx(export_fname, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# onnx_inf = blurrONNX(export_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# res = onnx_inf.predict_tokens(txt.split())\n",
    "# for r in res: print(f'{[(tok, lbl) for tok,lbl in zip(r[0],r[1]) ]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the token classification training code above works for **all** pretrained token classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.models.albert.modeling_albert.AlbertForTokenClassification,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification,\n",
       " transformers.models.big_bird.modeling_big_bird.BigBirdForTokenClassification,\n",
       " transformers.models.camembert.modeling_camembert.CamembertForTokenClassification,\n",
       " transformers.models.convbert.modeling_convbert.ConvBertForTokenClassification,\n",
       " transformers.models.deberta.modeling_deberta.DebertaForTokenClassification,\n",
       " transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2ForTokenClassification,\n",
       " transformers.models.distilbert.modeling_distilbert.DistilBertForTokenClassification,\n",
       " transformers.models.electra.modeling_electra.ElectraForTokenClassification,\n",
       " transformers.models.flaubert.modeling_flaubert.FlaubertForTokenClassification,\n",
       " transformers.models.funnel.modeling_funnel.FunnelForTokenClassification,\n",
       " transformers.models.ibert.modeling_ibert.IBertForTokenClassification,\n",
       " transformers.models.layoutlm.modeling_layoutlm.LayoutLMForTokenClassification,\n",
       " transformers.models.longformer.modeling_longformer.LongformerForTokenClassification,\n",
       " transformers.models.mpnet.modeling_mpnet.MPNetForTokenClassification,\n",
       " transformers.models.mobilebert.modeling_mobilebert.MobileBertForTokenClassification,\n",
       " transformers.models.roberta.modeling_roberta.RobertaForTokenClassification,\n",
       " transformers.models.squeezebert.modeling_squeezebert.SqueezeBertForTokenClassification,\n",
       " transformers.models.xlm.modeling_xlm.XLMForTokenClassification,\n",
       " transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForTokenClassification,\n",
       " transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ model_type for model_type in BLURR.get_models(task='TokenClassification') \n",
    " if (not model_type.__name__.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'google/electra-small-discriminator',\n",
    "    'flaubert/flaubert_small_cased',\n",
    "    'huggingface/funnel-small-base',\n",
    "    'allenai/longformer-base-4096',\n",
    "    'microsoft/mpnet-base',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'squeezebert/squeezebert-uncased',\n",
    "    'xlm-mlm-en-2048',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.867803</td>\n",
       "      <td>1.700121</td>\n",
       "      <td>0.856904</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'B-LOCpart'), ('a', 'I-OTH', 'I-LOCderiv'), ('sexual', 'I-OTH', 'B-LOC'), ('nature', 'I-OTH', 'B-LOC'), ('(', 'O', 'I-ORGpart'), ('gb', 'O', 'O'), ('2006', 'O', 'B-ORGpart'), (')', 'O', 'B-LOCderiv'), ('-', 'O', 'B-LOCderiv')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('auerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-multilingual-cased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.131197</td>\n",
       "      <td>1.936746</td>\n",
       "      <td>0.876088</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'I-LOC'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'I-LOCderiv'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('NEWSru.', 'B-OTH', 'O'), ('ua', 'O', 'O'), ('/', 'O', 'O'), (':', 'B-OTH', 'O'), ('Политисполком', 'I-OTH', 'O'), ('СПУ', 'I-OTH', 'I-LOCderiv'), ('отказал', 'I-OTH', 'I-LOCderiv'), ('Морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.502792</td>\n",
       "      <td>2.456090</td>\n",
       "      <td>0.890556</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Der', 'O', 'O'), ('28-J&lt;unk&gt;hrige', 'O', 'O'), ('und', 'O', 'O'), ('sein', 'O', 'O'), ('Team', 'O', 'O'), (',', 'O', 'O'), ('zu', 'O', 'O'), ('dem', 'O', 'O'), ('auch', 'O', 'O'), ('Karla', 'B-PER', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Ein', 'O', 'O'), ('wesentlicher', 'O', 'O'), ('Unterschied', 'O', 'O'), ('zu', 'O', 'O'), ('der', 'O', 'O'), ('Position', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('er', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.666550</td>\n",
       "      <td>1.532129</td>\n",
       "      <td>0.895601</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('zugang', 'O', 'O'), ('und', 'O', 'O'), ('engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('netz', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('newsru.', 'B-OTH', 'O'), ('ua', 'O', 'O'), ('/', 'O', 'O'), (':', 'B-OTH', 'O'), ('политисполком', 'I-OTH', 'O'), ('спу', 'I-OTH', 'O'), ('отказал', 'I-OTH', 'O'), ('морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/electra-small-discriminator ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.467775</td>\n",
       "      <td>2.386883</td>\n",
       "      <td>0.812186</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'B-OTHpart'), ('et', 'I-OTH', 'B-LOCderiv'), ('al.', 'I-OTH', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'B-PERderiv'), (')', 'O', 'B-PERderiv'), ('s.', 'O', 'B-PERderiv'), ('593.', 'O', 'I-LOCderiv'), ('wink', 'O', 'O'), ('&amp;', 'B-OTH', 'I-OTH')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('außerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'B-LOC'), ('im', 'O', 'O'), ('nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.757714</td>\n",
       "      <td>1.439240</td>\n",
       "      <td>0.848270</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'O'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('S.', 'O', 'O'), ('593', 'O', 'O'), ('.', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Rückkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== huggingface/funnel-small-base ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.478251</td>\n",
       "      <td>1.119604</td>\n",
       "      <td>0.852570</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('scenes', 'B-OTH', 'I-LOC'), ('of', 'I-OTH', 'O'), ('a', 'I-OTH', 'O'), ('sexual', 'I-OTH', 'O'), ('nature', 'I-OTH', 'O'), ('(', 'O', 'B-OTH'), ('gb', 'O', 'I-LOC'), ('2006', 'O', 'O'), (')', 'O', 'I-ORG'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('senden', 'O', 'I-LOC'), ('exxon', 'B-ORG', 'O'), ('mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.', 'B-ORG', 'O'), ('de', 'I-ORG', 'B-LOC')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.155993</td>\n",
       "      <td>2.050895</td>\n",
       "      <td>0.899391</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('NEWSru.ua', 'B-OTH', 'B-OTHderiv'), ('/', 'O', 'O'), (':', 'O', 'O'), ('Политисполком', 'B-OTH', 'O'), ('СПУ', 'I-OTH', 'I-OTH'), ('отказал', 'I-OTH', 'O'), ('Морозу', 'I-OTH', 'O'), ('в', 'I-OTH', 'O'), ('отставке', 'I-OTH', 'O'), ('Die', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/mpnet-base ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.417605</td>\n",
       "      <td>2.372653</td>\n",
       "      <td>0.884151</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('außerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('senden', 'O', 'O'), ('exxon', 'B-ORG', 'O'), ('mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.', 'B-ORG', 'O'), ('de', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.559236</td>\n",
       "      <td>3.090698</td>\n",
       "      <td>0.152509</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('zugang', 'O', 'B-LOC'), ('und', 'O', 'I-ORG'), ('engagement', 'O', 'O'), (':', 'O', 'B-PERpart'), ('das', 'O', 'O'), ('eigentlich', 'O', 'B-LOC'), ('neue', 'O', 'B-ORGpart'), ('an', 'O', 'I-ORG'), ('der', 'O', 'B-OTHderiv'), ('netz', 'O', 'I-ORG')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('da', 'O', 'B-LOC'), ('ich', 'O', 'I-ORGpart'), ('mir', 'O', 'I-PER'), ('als', 'O', 'I-ORG'), ('kleine', 'O', 'B-OTHderiv'), ('rentnerin', 'O', 'B-PER'), ('nicht', 'O', 'I-ORG'), ('sehr', 'O', 'I-PER'), ('viel', 'O', 'I-PER'), ('leisten', 'O', 'I-ORG')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.196666</td>\n",
       "      <td>2.086785</td>\n",
       "      <td>0.898848</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'I-OTH'), ('of', 'I-OTH', 'I-OTH'), ('a', 'I-OTH', 'I-OTH'), ('Sexual', 'I-OTH', 'I-OTH'), ('Nature', 'I-OTH', 'I-OTH'), ('(', 'O', 'O'), ('GB', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'O'), ('-', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Außerdem', 'O', 'I-OTH'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('Nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('Stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.486174</td>\n",
       "      <td>2.428443</td>\n",
       "      <td>0.903737</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('standard', 'B-ORG', 'O'), ('oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'B-PERpart'), ('new', 'I-ORG', 'O'), ('jersey', 'I-ORG', 'O'), ('),', 'O', 'I-OTH'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O'), ('„', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('zugang', 'O', 'O'), ('und', 'O', 'O'), ('engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('netz', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.978414</td>\n",
       "      <td>0.788048</td>\n",
       "      <td>0.873687</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'O'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s', 'O', 'O'), ('.', 'O', 'O'), ('593', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('nach', 'O', 'O'), ('seiner', 'O', 'O'), ('ruckkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.730763</td>\n",
       "      <td>2.689008</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH', 'B-OTH'), ('et', 'I-OTH', 'B-OTHpart'), ('al', 'I-OTH', 'B-OTH'), ('.', 'O', 'B-OTH'), ('(', 'O', 'B-OTHpart'), ('1994', 'O', 'B-OTH'), (')', 'O', 'B-OTH'), ('S.', 'O', 'B-OTH'), ('593.', 'O', 'B-OTHpart'), ('Wink', 'B-OTH', 'B-OTHpart')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Nach', 'O', 'B-OTH'), ('seiner', 'O', 'B-OTHpart'), ('Rückkehr', 'O', 'B-OTHpart'), ('hielt', 'O', 'B-OTHpart'), ('Strummer', 'B-PER', 'B-OTHpart'), ('ein', 'O', 'B-OTHpart'), ('Bandmeeting', 'O', 'B-OTH'), ('ab', 'O', 'B-OTHpart'), (',', 'O', 'B-OTH'), ('in', 'O', 'B-OTHpart')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.084521</td>\n",
       "      <td>0.844006</td>\n",
       "      <td>0.777818</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Scenes', 'B-OTH', 'I-LOC'), ('of', 'I-OTH', 'I-LOC'), ('a', 'I-OTH', 'I-LOC'), ('Sexual', 'I-OTH', 'I-LOC'), ('Nature', 'I-OTH', 'I-LOC'), ('(', 'O', 'B-OTH'), ('GB', 'O', 'B-OTH'), ('2006', 'O', 'B-OTH'), (')', 'O', 'O'), ('-', 'O', 'B-OTH')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('In', 'O', 'O'), ('einer', 'O', 'O'), ('Fernsehdiskussion', 'O', 'O'), ('traf', 'O', 'O'), ('er', 'O', 'O'), ('auf', 'O', 'O'), ('den', 'O', 'O'), ('Kritiker', 'O', 'O'), ('Alexander', 'B-PER', 'O'), ('Walker', 'I-PER', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "model_cls = AutoModelForTokenClassification\n",
    "bsz = 4\n",
    "seq_sz = 64\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.num_labels = len(labels)\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      config=config)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n')\n",
    "    \n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if (hf_tokenizer.pad_token is None): \n",
    "        hf_tokenizer.add_special_tokens({'pad_token': '<pad>'})  \n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()['<pad>']\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer)) \n",
    "    \n",
    "    before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                         max_length=seq_sz,\n",
    "                                                         padding='max_length',\n",
    "                                                         is_split_into_words=True, \n",
    "                                                         tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "    blocks = (\n",
    "        HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "        HF_TokenCategoryBlock(vocab=labels)\n",
    "    )\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('tokens'),\n",
    "                       get_y= lambda inp: [ \n",
    "                           (label, len(hf_tokenizer.tokenize(str(entity)))) \n",
    "                           for entity, label in zip(inp.tokens, inp.labels) \n",
    "                       ],\n",
    "                       splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(germ_eval_df, bs=bsz)\n",
    "\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter).to_fp16()\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8), \n",
    "                            cbs=[HF_TokenClassMetricsCallback(tok_metrics=['accuracy'])])\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=10)\n",
    "        \n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "        \n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01za_data-seq2seq-core.ipynb.\n",
      "Converted 01zb_data-seq2seq-language-modeling.ipynb.\n",
      "Converted 01zc_data-seq2seq-summarization.ipynb.\n",
      "Converted 01zd_data-seq2seq-translation.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02za_modeling-seq2seq-core.ipynb.\n",
      "Converted 02zb_modeling-seq2seq-language-modeling.ipynb.\n",
      "Converted 02zc_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 02zc_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
