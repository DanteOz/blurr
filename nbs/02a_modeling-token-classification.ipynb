{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.0\n",
      "Using fastai 2.1.3\n",
      "Using transformers 3.4.0\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_TokenClassBatchTransform(hf_arch, hf_tokenizer, is_split_into_words=True, \n",
    "                                           tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_batch_tfm=hf_batch_tfm), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH'), ('et', 'I-OTH'), ('al', 'I-OTH'), ('.', 'O'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S', 'O'), ('.', 'O'), ('593', 'B-OTH'), ('.', 'I-OTH'), ('Wink', 'I-OTH'), ('&amp;', 'I-OTH'), ('Seibold', 'I-OTH'), ('et', 'O'), ('al', 'O'), ('.', 'O'), ('(', 'O'), ('1998', 'O'), (')', 'O'), ('S', 'O'), ('.', 'O'), ('32', 'O'), ('Inwieweit', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falken', 'O'), (',', 'B-LOCderiv'), ('wie', 'O'), ('der', 'O'), ('Afrikanische', 'O'), ('Baumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('cuvieri', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Malaienbaumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('serverus', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zuzuzählen', 'O'), ('sind', 'O'), (',', 'O'), ('ist', 'O'), ('Gegenstand', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Außerdem', 'O'), ('befindet', 'O'), ('sich', 'O'), ('im', 'O'), ('Nordwesten', 'O'), ('der', 'O'), ('Stadt', 'O'), ('(', 'O'), ('auf', 'O'), ('dem', 'O'), ('Gelände', 'O'), ('des', 'O'), ('ehemaligen', 'O'), ('Militärflughafens', 'O'), ('Butzweilerhof', 'B-LOC'), (')', 'O'), ('das', 'O'), ('Coloneum', 'B-LOC'), (',', 'O'), ('Europas', 'B-LOC'), ('größter', 'O'), ('Studiokomplex', 'O'), ('mit', 'O'), ('einer', 'O'), ('Fläche', 'O'), ('von', 'O'), ('35', 'O'), ('ha', 'O'), ('und', 'O'), ('20', 'O'), ('Studios', 'O'), ('(', 'O'), ('25', 'O'), ('.', 'O'), ('000', 'O'), ('m²', 'O'), (')', 'O'), ('mit', 'O'), ('bis', 'O'), ('zu', 'O'), ('30', 'O'), ('Meter', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassCallback(HF_BaseModelCallback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.dls.before_batch[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        try:\n",
    "            self.learn.token_classification_report = calculate_token_class_metrics(targs, \n",
    "                                                                                   preds, \n",
    "                                                                                   'classification_report')\n",
    "        except ZeroDivisionError as err:\n",
    "            print(f'Couldn\\'t calcualte classification report: {err}')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2, 76, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 76]), 2, torch.Size([2, 76]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([152, 18]) torch.Size([152])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.005754399299621582, lr_steep=2.511886486900039e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.228155</td>\n",
       "      <td>0.191920</td>\n",
       "      <td>0.948042</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.614634</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.109316</td>\n",
       "      <td>0.123039</td>\n",
       "      <td>0.966057</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.060131</td>\n",
       "      <td>0.109717</td>\n",
       "      <td>0.971279</td>\n",
       "      <td>0.768707</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      " LOCderiv       0.89      0.75      0.81        32\n",
      "      OTH       0.62      0.65      0.63        31\n",
      "      LOC       0.88      0.83      0.85        69\n",
      "      ORG       0.73      0.64      0.68        70\n",
      "      PER       0.90      0.96      0.93        81\n",
      "  ORGpart       0.22      0.67      0.33         3\n",
      "\n",
      "micro avg       0.77      0.79      0.78       286\n",
      "macro avg       0.81      0.79      0.80       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner, \n",
    "                 ctxs=None, max_n=6, trunc_at=None, **kwargs):    \n",
    "    # grab tokenizer\n",
    "    hf_textblock_tfm = learner.dls.before_batch[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x, y, samples, outs):\n",
    "        # recontstruct the string and split on space to get back your pre-tokenized list of tokens\n",
    "        toks = hf_tokenizer.convert_ids_to_tokens(inp, skip_special_tokens=True)\n",
    "        pretokenized_toks =  hf_tokenizer.convert_tokens_to_string(toks).split()\n",
    "        \n",
    "        # get predictions for subtokens that aren't ignored (e.g. special toks and token parts)\n",
    "        pred_labels = [ pred_lbl for lbl_id, pred_lbl in zip(trg, ast.literal_eval(pred[0])) if lbl_id != -100 ]\n",
    "        \n",
    "        trg_labels = ast.literal_eval(sample[1])\n",
    "        res.append([f'{[ (tok, trg, pred) for idx, (tok, pred, trg) in enumerate(zip(pretokenized_toks, pred_labels, trg_labels)) if (trunc_at is None or idx < trunc_at) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Rückkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'B-PER'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('NEWSru', 'B-OTH', 'B-ORG'), ('.', 'O', 'O'), ('ua', 'O', 'O'), ('/', 'B-OTH', 'B-ORG'), (':', 'I-OTH', 'B-ORG'), ('Политисполком', 'I-OTH', 'O'), ('СПУ', 'I-OTH', 'B-PER'), ('отказал', 'I-OTH', 'O'), ('Морозу', 'I-OTH', 'O'), ('в', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.blurr_predict(inp)\n",
    "\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.before_batch[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.tok_kwargs\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    res = hf_tokenizer(inp, None, \n",
    "                       max_length=hf_textblock_tfm.max_length,\n",
    "                       padding=hf_textblock_tfm.padding,\n",
    "                       truncation=hf_textblock_tfm.truncation,\n",
    "                       is_split_into_words=hf_textblock_tfm.is_split_into_words,\n",
    "                       **tok_kwargs)\n",
    "\n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the token classification training code above works for **all** pretrained token classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.modeling_albert.AlbertForTokenClassification,\n",
       " transformers.modeling_auto.AutoModelForTokenClassification,\n",
       " transformers.modeling_bert.BertForTokenClassification,\n",
       " transformers.modeling_camembert.CamembertForTokenClassification,\n",
       " transformers.modeling_distilbert.DistilBertForTokenClassification,\n",
       " transformers.modeling_electra.ElectraForTokenClassification,\n",
       " transformers.modeling_flaubert.FlaubertForTokenClassification,\n",
       " transformers.modeling_funnel.FunnelForTokenClassification,\n",
       " transformers.modeling_layoutlm.LayoutLMForTokenClassification,\n",
       " transformers.modeling_longformer.LongformerForTokenClassification,\n",
       " transformers.modeling_mobilebert.MobileBertForTokenClassification,\n",
       " transformers.modeling_roberta.RobertaForTokenClassification,\n",
       " transformers.modeling_squeezebert.SqueezeBertForTokenClassification,\n",
       " transformers.modeling_xlm.XLMForTokenClassification,\n",
       " transformers.modeling_xlm_roberta.XLMRobertaForTokenClassification,\n",
       " transformers.modeling_xlnet.XLNetForTokenClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='TokenClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    #'<electra>', # currently no pre-trained electra model works for token classification\n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'xlm-mlm-ende-1024',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.359127</td>\n",
       "      <td>0.349751</td>\n",
       "      <td>0.916535</td>\n",
       "      <td>0.157609</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.231076</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('nach', 'O', 'O'), ('seiner', 'O', 'O'), ('ruckkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('das', 'O', 'O'), ('triebwerk', 'O', 'O'), ('des', 'O', 'O'), ('hydrogen', 'B-OTH', 'O'), ('7', 'I-OTH', 'O'), ('leistet', 'O', 'O'), ('letztendlich', 'O', 'O'), ('191', 'O', 'O'), ('kw', 'O', 'O'), ('(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-multilingual-cased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.198768</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.948605</td>\n",
       "      <td>0.562212</td>\n",
       "      <td>0.493927</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Senden', 'O', 'O'), ('Exxon', 'B-ORG', 'B-ORG'), ('Mobil', 'I-ORG', 'B-ORG'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('Paris', 'B-LOC', 'B-LOC'), ('(', 'O', 'O'), ('aktiencheck', 'B-ORG', 'B-ORG'), ('.', 'I-ORG', 'I-ORG')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O', 'O'), ('erste', 'O', 'O'), ('Versuch', 'O', 'O'), ('geht', 'O', 'O'), ('auf', 'O', 'O'), ('Enno', 'B-PER', 'B-PER'), ('Patalas', 'I-PER', 'I-PER'), ('zurück', 'O', 'O'), (',', 'O', 'O'), ('der', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.818358</td>\n",
       "      <td>0.899494</td>\n",
       "      <td>0.869604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('Standard', 'B-ORG', 'O'), ('Oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'O'), ('New', 'I-ORG', 'O'), ('Jersey', 'I-ORG', 'O'), (')', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Die', 'O', 'O'), ('Flgel', 'O', 'O'), ('Die', 'O', 'O'), ('geffneten', 'O', 'O'), ('Flgel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('Szenen', 'O', 'O'), ('Hhepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.350060</td>\n",
       "      <td>0.385536</td>\n",
       "      <td>0.905431</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.156028</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('der', 'O', 'O'), ('28', 'O', 'O'), ('-', 'O', 'O'), ('jahrige', 'O', 'O'), ('und', 'O', 'O'), ('sein', 'O', 'O'), ('team', 'O', 'O'), (',', 'O', 'O'), ('zu', 'O', 'O'), ('dem', 'B-PER', 'B-PER')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('das', 'O', 'O'), ('\"', 'O', 'O'), ('torchwood', 'B-OTH', 'O'), ('\"', 'O', 'O'), ('-', 'O', 'O'), ('team', 'O', 'O'), ('besteht', 'O', 'O'), ('neben', 'O', 'O'), ('captain', 'B-PER', 'B-PER'), ('jack', 'I-PER', 'B-PER')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.406710</td>\n",
       "      <td>0.372947</td>\n",
       "      <td>0.902790</td>\n",
       "      <td>0.207865</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Rückkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Mit', 'O', 'O'), ('der', 'O', 'O'), ('Servicefrau', 'O', 'O'), ('verband', 'O', 'O'), ('Bianca', 'B-PER', 'B-PER'), ('offenbar', 'O', 'O'), ('eine', 'O', 'O'), ('Art', 'O', 'O'), ('Freundschaft', 'O', 'O'), ('–', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.726828</td>\n",
       "      <td>0.680752</td>\n",
       "      <td>0.866618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'O'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s', 'O', 'O'), ('.', 'O', 'O'), ('593', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('scenes', 'B-OTH', 'O'), ('of', 'I-OTH', 'I-LOCderiv'), ('a', 'I-OTH', 'B-LOCpart'), ('sexual', 'I-OTH', 'I-LOCderiv'), ('nature', 'I-OTH', 'B-LOCpart'), ('(', 'O', 'I-OTH'), ('gb', 'O', 'O'), ('2006', 'O', 'O'), (')', 'O', 'B-PERpart'), ('-', 'O', 'B-OTH')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.383711</td>\n",
       "      <td>0.363825</td>\n",
       "      <td>0.910810</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Rückkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Senden', 'O', 'O'), ('Exxon', 'B-ORG', 'B-ORG'), ('Mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'B-LOC'), ('Paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.de', 'B-ORG', 'O'), ('AG', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-ende-1024 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.470875</td>\n",
       "      <td>0.558718</td>\n",
       "      <td>0.892681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('wie', 'O', 'O'), ('wenige', 'O', 'O'), ('wochen', 'O', 'O'), ('vor', 'O', 'O'), ('der', 'O', 'O'), ('bekanntgabe', 'O', 'O'), ('in', 'O', 'O'), ('einem', 'O', 'O'), ('interview', 'O', 'O'), ('angekundigt', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('\"', 'O', 'O'), ('wer', 'O', 'O'), ('aids', 'O', 'O'), ('hat', 'O', 'O'), ('und', 'O', 'O'), ('sexuell', 'O', 'O'), ('aktiv', 'O', 'O'), ('ist', 'O', 'O'), (',', 'O', 'O'), ('wer', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.278543</td>\n",
       "      <td>0.228344</td>\n",
       "      <td>0.943959</td>\n",
       "      <td>0.526570</td>\n",
       "      <td>0.473913</td>\n",
       "      <td>0.498856</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Durch', 'O', 'O'), ('die', 'O', 'O'), ('vielfache', 'O', 'O'), ('Verbindung', 'O', 'O'), ('mit', 'O', 'O'), ('anderen', 'O', 'O'), ('Spielarten', 'O', 'O'), ('des', 'O', 'O'), ('BDSM', 'O', 'O'), ('ist', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `mem_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.450207</td>\n",
       "      <td>0.423693</td>\n",
       "      <td>0.902627</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't calcualte classification report: Weights sum to zero, can't be normalized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Lehre', 'O', 'O'), ('Obwohl', 'O', 'O'), ('Longinos', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Zeitgenosse', 'O', 'O'), ('Plotins', 'B-PER', 'O'), ('und', 'O', 'O'), ('Schuler', 'O', 'O'), ('von', 'O', 'O'), ('dessen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "bsz = 2\n",
    "seq_sz = 32\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.num_labels = len(labels)\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config=config)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n')\n",
    "    \n",
    "    hf_batch_tfm = HF_TokenClassBatchTransform(hf_arch, hf_tokenizer, \n",
    "                                               max_length=seq_sz,\n",
    "                                               padding='max_length',\n",
    "                                               is_split_into_words=True, \n",
    "                                               tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "    blocks = (\n",
    "        HF_TextBlock(hf_batch_tfm=hf_batch_tfm), \n",
    "        HF_TokenCategoryBlock(vocab=labels)\n",
    "    )\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('tokens'),\n",
    "                       get_y= lambda inp: [ \n",
    "                           (label, len(hf_tokenizer.tokenize(str(entity)))) \n",
    "                           for entity, label in zip(inp.tokens, inp.labels) \n",
    "                       ],\n",
    "                       splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(germ_eval_df, bs=bsz)\n",
    "\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.unfreeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING One pass through the model ***')\n",
    "        preds = learn.model(b[0])\n",
    "        test_eq(len(preds[0]), bsz)\n",
    "        test_eq(preds[0].shape, torch.Size([bsz, seq_sz, len(labels)]))\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=10)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizer</td>\n",
       "      <td>AlbertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizer</td>\n",
       "      <td>BertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizer</td>\n",
       "      <td>CamembertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizer</td>\n",
       "      <td>DistilBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizer</td>\n",
       "      <td>LongformerForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizer</td>\n",
       "      <td>MobileBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>RobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizer</td>\n",
       "      <td>XLMRobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizer</td>\n",
       "      <td>XLNetForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 01z_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02e_modeling-summarization.ipynb.\n",
      "Converted 02z_modeling-language-modeling.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
