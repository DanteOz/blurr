{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.data.token_classification import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.1\n",
      "Using fastai 2.1.8\n",
      "Using transformers 4.0.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.models.bert.configuration_bert.BertConfig,\n",
       " transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_tokenizer, is_split_into_words=True, \n",
    "                                                     tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfms=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Helbig', 'B-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S.', 'O'), ('593.', 'O'), ('Wink', 'O'), ('&amp;', 'B-OTH'), ('Seibold', 'I-OTH'), ('et', 'I-OTH'), ('al.', 'I-OTH'), ('(', 'I-OTH'), ('1998', 'O'), (')', 'O'), ('S.', 'O'), ('32', 'O'), ('Inwieweit', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falken,', 'O'), ('wie', 'O'), ('der', 'O'), ('Afrikanische', 'O'), ('Baumfalke', 'O'), ('(', 'O'), ('Falco', 'B-LOCderiv'), ('cuvieri', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Malaienbaumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('serverus', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zuzuzählen', 'O'), ('sind,', 'O'), ('ist', 'O'), ('Gegenstand', 'O'), ('der', 'O'), ('Forschung.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Außerdem', 'O'), ('befindet', 'O'), ('sich', 'O'), ('im', 'O'), ('Nordwesten', 'O'), ('der', 'O'), ('Stadt', 'O'), ('(', 'O'), ('auf', 'O'), ('dem', 'O'), ('Gelände', 'O'), ('des', 'O'), ('ehemaligen', 'O'), ('Militärflughafens', 'O'), ('Butzweilerhof', 'B-LOC'), (')', 'O'), ('das', 'O'), ('Coloneum,', 'B-LOC'), ('Europas', 'O'), ('größter', 'B-LOC'), ('Studiokomplex', 'O'), ('mit', 'O'), ('einer', 'O'), ('Fläche', 'O'), ('von', 'O'), ('35', 'O'), ('ha', 'O'), ('und', 'O'), ('20', 'O'), ('Studios', 'O'), ('(', 'O'), ('25.', 'O'), ('000', 'O'), ('m²', 'O'), (')', 'O'), ('mit', 'O'), ('bis', 'O'), ('zu', 'O'), ('30', 'O'), ('Meter', 'O'), ('Deckenhöhe.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassCallback(HF_BaseModelCallback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.dls.before_batch[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        try:\n",
    "            self.learn.token_classification_report = calculate_token_class_metrics(targs, \n",
    "                                                                                   preds, \n",
    "                                                                                   'classification_report')\n",
    "        except ZeroDivisionError as err:\n",
    "            print(f'Couldn\\'t calcualte classification report: {err}')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2, 76, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 76]), 2, torch.Size([2, 76]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([152, 18]) torch.Size([152])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0005248074419796466, lr_steep=1.737800812406931e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.236967</td>\n",
       "      <td>0.162253</td>\n",
       "      <td>0.954620</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.645793</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.103329</td>\n",
       "      <td>0.096656</td>\n",
       "      <td>0.969293</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.728745</td>\n",
       "      <td>0.730223</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.057280</td>\n",
       "      <td>0.096278</td>\n",
       "      <td>0.970380</td>\n",
       "      <td>0.752033</td>\n",
       "      <td>0.719844</td>\n",
       "      <td>0.735586</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.87      0.82      0.84        71\n",
      "    LOCderiv       1.00      0.67      0.80        18\n",
      "     LOCpart       0.00      0.00      0.00         0\n",
      "         ORG       0.67      0.65      0.66        52\n",
      "     ORGpart       0.67      0.25      0.36         8\n",
      "         OTH       0.56      0.44      0.49        41\n",
      "     OTHpart       0.00      0.00      0.00         0\n",
      "         PER       0.88      0.91      0.90        67\n",
      "    PERderiv       0.00      0.00      0.00         0\n",
      "     PERpart       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.75      0.72      0.74       257\n",
      "   macro avg       0.46      0.37      0.41       257\n",
      "weighted avg       0.79      0.72      0.75       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner, \n",
    "                 ctxs=None, max_n=6, trunc_at=None, **kwargs):    \n",
    "    # grab tokenizer\n",
    "    hf_textblock_tfm = learner.dls.before_batch[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    ignore_token_id = hf_textblock_tfm.ignore_token_id\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x, y, samples, outs):\n",
    "        # recontstruct the string and split on space to get back your pre-tokenized list of tokens\n",
    "        toks = hf_tokenizer.convert_ids_to_tokens(inp, skip_special_tokens=True)\n",
    "        pretokenized_toks =  hf_tokenizer.convert_tokens_to_string(toks).split()\n",
    "        \n",
    "        # get predictions for subtokens that aren't ignored (e.g. special toks and token parts)\n",
    "        pred_labels = [ pred_lbl for lbl_id, pred_lbl in zip(trg, ast.literal_eval(pred[0])) if lbl_id != -ignore_token_id ]\n",
    "        \n",
    "        trg_labels = ast.literal_eval(sample[1])\n",
    "        res.append([f'{[ (tok, trg, pred) for idx, (tok, pred, trg) in enumerate(zip(pretokenized_toks, pred_labels, trg_labels)) if (trunc_at is None or idx < trunc_at) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Erstmals', 'O', 'O'), ('Urkundlich', 'O', 'O'), ('erwähnt', 'O', 'O'), ('ist', 'O', 'O'), ('Nimburg', 'B-LOC', 'O'), ('bereits', 'O', 'O'), ('im', 'O', 'O'), ('Jahre', 'O', 'B-LOC'), ('977.', 'O', 'I-LOC'), ('Im', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Anfangs', 'O', 'O'), ('unterstützte', 'O', 'O'), ('Bucharin', 'B-PER', 'O'), ('Stalin', 'B-PER', 'O'), ('mit', 'O', 'B-PER'), ('diesem', 'O', 'I-PER'), ('Kurs,', 'O', 'I-PER'), ('doch', 'O', 'O'), ('später', 'O', 'O'), ('als', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.blurr_predict(inp)\n",
    "\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.before_batch[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.tok_kwargs\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    res = hf_tokenizer(inp, None, \n",
    "                       max_length=hf_textblock_tfm.max_length,\n",
    "                       padding=hf_textblock_tfm.padding,\n",
    "                       truncation=hf_textblock_tfm.truncation,\n",
    "                       is_split_into_words=hf_textblock_tfm.is_split_into_words,\n",
    "                       **tok_kwargs)\n",
    "\n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the token classification training code above works for **all** pretrained token classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.models.albert.modeling_albert.AlbertForTokenClassification,\n",
       " transformers.models.auto.modeling_auto.AutoModelForTokenClassification,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification,\n",
       " transformers.models.camembert.modeling_camembert.CamembertForTokenClassification,\n",
       " transformers.models.distilbert.modeling_distilbert.DistilBertForTokenClassification,\n",
       " transformers.models.electra.modeling_electra.ElectraForTokenClassification,\n",
       " transformers.models.flaubert.modeling_flaubert.FlaubertForTokenClassification,\n",
       " transformers.models.funnel.modeling_funnel.FunnelForTokenClassification,\n",
       " transformers.models.layoutlm.modeling_layoutlm.LayoutLMForTokenClassification,\n",
       " transformers.models.longformer.modeling_longformer.LongformerForTokenClassification,\n",
       " transformers.models.mobilebert.modeling_mobilebert.MobileBertForTokenClassification,\n",
       " transformers.models.roberta.modeling_roberta.RobertaForTokenClassification,\n",
       " transformers.models.squeezebert.modeling_squeezebert.SqueezeBertForTokenClassification,\n",
       " transformers.models.xlm.modeling_xlm.XLMForTokenClassification,\n",
       " transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForTokenClassification,\n",
       " transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='TokenClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    #'<electra>', # currently no pre-trained electra model works for token classification\n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'xlm-mlm-ende-1024',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.367992</td>\n",
       "      <td>0.326250</td>\n",
       "      <td>0.920491</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.213953</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('(', 'O', 'O'), ('standard', 'B-ORG', 'O'), ('oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'O'), ('new', 'I-ORG', 'O'), ('jersey', 'I-ORG', 'O'), (')', 'O', 'B-LOC'), (',', 'O', 'B-LOC'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('die', 'O', 'O'), ('flugel', 'O', 'O'), ('die', 'O', 'O'), ('geoffneten', 'O', 'O'), ('flugel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('szenen', 'O', 'O'), ('hohepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-multilingual-cased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.190103</td>\n",
       "      <td>0.160484</td>\n",
       "      <td>0.960778</td>\n",
       "      <td>0.645933</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.653753</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Die', 'O', 'O'), ('Flügel', 'O', 'O'), ('Die', 'O', 'O'), ('geöffneten', 'O', 'O'), ('Flügel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('Szenen', 'O', 'O'), ('Höhepunkte', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.847636</td>\n",
       "      <td>0.801762</td>\n",
       "      <td>0.899558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Senden', 'O', 'O'), ('Exxon', 'B-ORG', 'O'), ('Mobil', 'I-ORG', 'O'), ('\"', 'O', 'O'), ('buy', 'O', 'O'), ('\"', 'O', 'O'), ('Paris', 'B-LOC', 'O'), ('(', 'O', 'O'), ('aktiencheck.de', 'B-ORG', 'O'), ('AG', 'I-ORG', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.373863</td>\n",
       "      <td>0.295222</td>\n",
       "      <td>0.933559</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.315353</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('außerdem', 'O', 'O'), ('befindet', 'O', 'O'), ('sich', 'O', 'O'), ('im', 'O', 'O'), ('nordwesten', 'O', 'O'), ('der', 'O', 'O'), ('stadt', 'O', 'O'), ('(', 'O', 'O'), ('auf', 'O', 'O'), ('dem', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('viele', 'O', 'O'), ('fragen', 'O', 'O'), ('der', 'O', 'O'), ('schiffstheorie,', 'O', 'O'), ('die', 'O', 'O'), ('euler', 'O', 'O'), ('schon', 'B-PER', 'O'), ('aufgeworfen', 'O', 'O'), ('und', 'O', 'O'), ('mit', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.265513</td>\n",
       "      <td>0.213798</td>\n",
       "      <td>0.946336</td>\n",
       "      <td>0.534591</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.537975</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Zugang', 'O', 'O'), ('und', 'O', 'O'), ('Engagement', 'O', 'O'), (':', 'O', 'O'), ('das', 'O', 'O'), ('eigentlich', 'O', 'O'), ('Neue', 'O', 'O'), ('an', 'O', 'O'), ('der', 'O', 'O'), ('Netz(', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Nach', 'O', 'O'), ('seiner', 'O', 'O'), ('Rückkehr', 'O', 'O'), ('hielt', 'O', 'O'), ('Strummer', 'B-PER', 'O'), ('ein', 'O', 'O'), ('Bandmeeting', 'O', 'O'), ('ab', 'O', 'O'), (',', 'O', 'O'), ('in', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.890067</td>\n",
       "      <td>0.043741</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('nach', 'O', 'B-LOC'), ('seiner', 'O', 'B-PER'), ('ruckkehr', 'O', 'I-LOC'), ('hielt', 'O', 'I-PER'), ('strummer', 'B-PER', 'B-ORG'), ('ein', 'O', 'B-OTHpart'), ('bandmeeting', 'O', 'O'), ('ab,', 'O', 'B-LOCpart'), ('in', 'O', 'B-PERderiv'), ('dem', 'O', 'B-PERpart')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('erstmals', 'O', 'B-LOC'), ('urkundlich', 'O', 'B-PERpart'), ('erwahnt', 'O', 'B-ORGpart'), ('ist', 'O', 'B-PERpart'), ('nimburg', 'B-LOC', 'B-PERpart'), ('bereits', 'O', 'B-PERpart'), ('im', 'O', 'I-LOCderiv'), ('jahre', 'O', 'B-LOCpart'), ('977.', 'O', 'B-PERpart'), ('im', 'O', 'B-PERpart')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.286866</td>\n",
       "      <td>0.267586</td>\n",
       "      <td>0.934183</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('In', 'O', 'O'), ('einer', 'O', 'O'), ('Fernsehdiskussion', 'O', 'O'), ('traf', 'O', 'O'), ('er', 'O', 'O'), ('auf', 'O', 'O'), ('den', 'O', 'O'), ('Kritiker', 'O', 'O'), ('Alexander', 'B-PER', 'O'), ('Walker', 'I-PER', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('\"', 'O', 'O'), ('Es', 'O', 'O'), ('ist', 'O', 'O'), ('beabsichtigt', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('Aktien', 'O', 'O'), ('im', 'O', 'O'), ('ersten', 'O', 'O'), ('Halbjahr', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-ende-1024 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.527271</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.909317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('helbig', 'B-OTH', 'O'), ('et', 'I-OTH', 'O'), ('al', 'I-OTH', 'O'), ('.', 'O', 'O'), ('(', 'O', 'O'), ('1994', 'O', 'O'), (')', 'O', 'O'), ('s', 'O', 'O'), ('.', 'O', 'O'), ('593', 'B-OTH', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('(', 'O', 'O'), ('standard', 'B-ORG', 'O'), ('oil', 'I-ORG', 'O'), ('of', 'I-ORG', 'O'), ('new', 'I-ORG', 'O'), ('jersey', 'I-ORG', 'O'), (')', 'O', 'O'), (',', 'O', 'O'), ('die', 'O', 'O'), ('ausgesprochen', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.223170</td>\n",
       "      <td>0.224713</td>\n",
       "      <td>0.936681</td>\n",
       "      <td>0.425234</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.431280</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='16' class='' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      4.00% [16/400 00:01<00:41 12.5560]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "bsz = 2\n",
    "seq_sz = 32\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    config.num_labels = len(labels)\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config=config)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n')\n",
    "    \n",
    "    before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_tokenizer, \n",
    "                                                         max_length=seq_sz,\n",
    "                                                         padding='max_length',\n",
    "                                                         is_split_into_words=True, \n",
    "                                                         tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "    blocks = (\n",
    "        HF_TextBlock(before_batch_tfms=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "        HF_TokenCategoryBlock(vocab=labels)\n",
    "    )\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('tokens'),\n",
    "                       get_y= lambda inp: [ \n",
    "                           (label, len(hf_tokenizer.tokenize(str(entity)))) \n",
    "                           for entity, label in zip(inp.tokens, inp.labels) \n",
    "                       ],\n",
    "                       splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(germ_eval_df, bs=bsz)\n",
    "\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter).to_fp16()\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.unfreeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "#         print('*** TESTING One pass through the model ***')\n",
    "#         preds = learn.model(b[0])\n",
    "#         test_eq(len(preds[0]), bsz)\n",
    "#         test_eq(preds[0].shape, torch.Size([bsz, seq_sz, len(labels)]))\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max= 3e-5, moms=(0.8,0.7,0.8))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=10)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForTokenClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForTokenClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>CUDA out of memory. Tried to allocate 734.00 MiB (GPU 1; 10.91 GiB total capacity; 9.05 GiB already allocated; 657.88 MiB free; 9.59 GiB reserved in total by PyTorch)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForTokenClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>CUDA out of memory. Tried to allocate 94.00 MiB (GPU 1; 10.91 GiB total capacity; 10.13 GiB already allocated; 3.88 MiB free; 10.22 GiB reserved in total by PyTorch)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01za_data-text2text-core.ipynb.\n",
      "Converted 01zb_data-text2text-language-modeling.ipynb.\n",
      "Converted 01zc_data-text2text-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02za_modeling-text2text-core.ipynb.\n",
      "Converted 02zb_modeling-text2text-language-modeling.ipynb.\n",
      "Converted 02zc_modeling-text2text-summarization.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
