{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.language_modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.language_modeling\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... for both causal and MLM language modeling tasks. This includes things like training BERT from scratch or fine-tuning a particular pre-trained LM on your own corpus.\n",
    "\n",
    "**This is currently a work in progress** - You've been warned : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import ast, gc, inspect, os\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import perplexity\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoModelForCausalLM, AutoModelForMaskedLM, logging, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.core import BlurrDataLoader, TextBlock, first_blurr_tfm\n",
    "from blurr.modeling.core import Blearner, PreCalculatedCrossEntropyLoss\n",
    "from blurr.data.language_modeling import (\n",
    "    BaseLMStrategy,\n",
    "    LMBatchTokenizeTransform,\n",
    "    LMPreprocessor,\n",
    "    LMType,\n",
    "    CausalLMTextInput,\n",
    "    CausalLMStrategy,\n",
    "    MLMTextInput,\n",
    "    BertMLMStrategy,\n",
    ")\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.modeling.core import BaseModelWrapper, BaseModelCallback, PreCalculatedLoss, blurr_splitter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this example, we'll use the `WIKITEXT_TINY` dataset available from fastai to demonstrate how to configure BLURR code for language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Big Boy ( song ) = \\n \\n \" Big Boy \" &lt;unk&gt; \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and &lt;unk&gt; composit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica &lt;unk&gt; and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will &lt;unk&gt; ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family &lt;unk&gt; . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf &lt;unk&gt; cup , &lt;unk&gt; &lt;unk&gt; cup , or pixie cup . The small , &lt;unk&gt; @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0  \\\n",
       "0   \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...   \n",
       "1   \\n = Big Boy ( song ) = \\n \\n \" Big Boy \" <unk> \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...   \n",
       "2   \\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and <unk> composit...   \n",
       "3   \\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica <unk> and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will <unk> ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...   \n",
       "4   \\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family <unk> . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf <unk> cup , <unk> <unk> cup , or pixie cup . The small , <unk> @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_path = untar_data(URLs.WIKITEXT_TINY)\n",
    "\n",
    "train_df = pd.read_csv(wiki_path / \"train.csv\", header=None)\n",
    "valid_df = pd.read_csv(wiki_path / \"test.csv\", header=None)\n",
    "\n",
    "train_df[\"is_valid\"] = False\n",
    "valid_df[\"is_valid\"] = True\n",
    "\n",
    "df = pd.concat([train_df, valid_df])\n",
    "\n",
    "print(len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LMMetricsCallback`\n",
    "\n",
    "In this section, we'll add helpful metrics for calculating accuracy and perplexity for both causal and masked language modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LMMetricsCallback(Callback):\n",
    "    \"\"\"A fastai friendly metric implemented as a callback so that we can handle use cases where we don't\n",
    "    want to count tokens marked to be ignored or else not count batches where there are no targs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.run_before = Recorder\n",
    "\n",
    "        self.custom_metrics_dict = {\"lm_accuracy\": None}\n",
    "        self.do_setup = True\n",
    "\n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if not self.do_setup:\n",
    "            return\n",
    "\n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "\n",
    "        self.do_setup = False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.setup()\n",
    "\n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        # do this only for validation set\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0]  # yb is TensorText tuple, item 0 is the data\n",
    "\n",
    "        msk = torch.where(targs != -100, 1, 0).bool()\n",
    "        preds = torch.masked_select(preds, msk).cpu()\n",
    "        targs = torch.masked_select(targs, msk).cpu()\n",
    "\n",
    "        if preds.shape[0] == 0:\n",
    "            return\n",
    "\n",
    "        self.results += [(res[0], res[1]) for res in zip(preds, targs)]\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self):\n",
    "        self.results = []\n",
    "\n",
    "    def after_validate(self):\n",
    "        if len(self.results) < 1:\n",
    "            return\n",
    "\n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        self.custom_metrics_dict[\"lm_accuracy\"] = accuracy_score(targs, preds)\n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key):\n",
    "        return self.custom_metrics_dict[metric_key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal Language Modeling\n",
    "\n",
    "In causal language modeling, we are attempting to predict the next token given those before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "model_cls = AutoModelForCausalLM\n",
    "\n",
    "pretrained_model_name = \"gpt2\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "if hf_tokenizer.pad_token is None:\n",
    "    hf_tokenizer.pad_token = \"[PAD]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\n",
    "proc_df = preprocessor.process_df(train_df, valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=CausalLMStrategy)\n",
    "blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=CausalLMTextInput), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 129]), torch.Size([2, 129]), torch.Size([2, 129]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>₹ 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = &lt;unk&gt; = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at &lt;unk&gt; police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from</td>\n",
       "      <td>�� 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = &lt;unk&gt; = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at &lt;unk&gt; police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unk&gt;. Another such cruise took place during 1 – 4 December. The typical routine of gunnery drills and squadron exercises occurred in January 1916. The fleet departed for a cruise in the North Sea on 26 February ; Jellicoe had intended to use the Harwich Force to sweep the &lt;unk&gt; Bight, but bad weather prevented operations in the southern North Sea. As a result, the operation was confined to the northern end of the sea. On the night of 25 March, Iron Duke and the rest of the fleet sailed from Sca</td>\n",
       "      <td>k&gt;. Another such cruise took place during 1 – 4 December. The typical routine of gunnery drills and squadron exercises occurred in January 1916. The fleet departed for a cruise in the North Sea on 26 February ; Jellicoe had intended to use the Harwich Force to sweep the &lt;unk&gt; Bight, but bad weather prevented operations in the southern North Sea. As a result, the operation was confined to the northern end of the sea. On the night of 25 March, Iron Duke and the rest of the fleet sailed from Scapa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "fit_cbs = [LMMetricsCallback()]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "    cbs=[BaseModelCallback],\n",
    "    metrics=[perplexity],\n",
    "    splitter=blurr_splitter,\n",
    ").to_fp16()\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = dls.one_batch()\n",
    "# preds = learn.model(b[0])\n",
    "# len(preds),preds[0], preds[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.004786301031708717, steep=6.309573450380412e-07, valley=0.0030199517495930195, slide=0.0014454397605732083)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.480516</td>\n",
       "      <td>3.166632</td>\n",
       "      <td>23.727434</td>\n",
       "      <td>0.417128</td>\n",
       "      <td>07:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=3e-3, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_CausalLMInput` typed inputs\n",
    "    x: CausalLMTextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):\n",
    "    # grab our tokenizer and ignore token to decode\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    ignore_token_id = tfm.ignore_token_id\n",
    "\n",
    "    res = L(\n",
    "        [\n",
    "            (\n",
    "                hf_tokenizer.decode(s[0], skip_special_tokens=True)[:trunc_at],\n",
    "                hf_tokenizer.decode(s[1][s[1] != ignore_token_id], skip_special_tokens=True)[:trunc_at],\n",
    "                hf_tokenizer.decode(pred[0], skip_special_tokens=True)[:trunc_at],\n",
    "            )\n",
    "            for s, pred in zip(samples, outs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"target\", \"prediction\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. \\n The German government has said that it does not consider Scientology a religion, but a \" commercial enterprise with a history of taking advantage of vulnerable individuals and an extreme dislike of any criticism \" whose \" totalitarian structure a</td>\n",
       "      <td>\\n The German government has said that it does not consider Scientology a religion, but a \" commercial enterprise with a history of taking advantage of vulnerable individuals and an extreme dislike of any criticism \" whose \" totalitarian structure an</td>\n",
       "      <td>&lt;\\n  &lt; army was been that the is not want the to threat, but that \" religion enterprise \" a religious of commercial advantage of the individuals \" the interest religious of the form of. \" &lt;ism \" political \" be a threat to the \"s national system \". ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. On 22 November, the &lt;unk&gt; came under fire for the first time near &lt;unk&gt;, and they subsequently forced their attackers to withdraw after inflicting significant casualties on them. \\n Following a series of minor victories, the British suffered a major</td>\n",
       "      <td>On 22 November, the &lt;unk&gt; came under fire for the first time near &lt;unk&gt;, and they subsequently forced their attackers to withdraw after inflicting significant casualties on them. \\n Following a series of minor victories, the British suffered a major</td>\n",
       "      <td>&lt; the August, the Britishunk&gt; &lt; to attack from a first time in theunk&gt;, and the were lost the way to retreat. a heavy damage. the. The\\n  the brief of attacks skirm, the &lt; forces heavy setback setback in thewater, the and 12 November,. when the casua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': ' Blurr is fun to work with because he was a former member of the original team , which included players including <unk> <unk> , former <unk> and ex- players from a band known as the New Kids on the Block .'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masked Language Modeling\n",
    "\n",
    "In masked language modeling (MLM), we are attempting to predict the ***masked*** tokens. In Blurr, these are encapsulated by classes implementing the `BaseLMStrategy` base class.\n",
    "\n",
    "For a list of some of the more common strategies, see table 3 of the [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) paper.  When fine-tuning a MLM model. you'll want to make sure you use the same approach as the model authors should you be looking to reproduce their results ... but our approach here makes it easy to play with different strategies regardless.\n",
    "\n",
    "In the example below, we'll tell Blurr we want to use the BERT-style masking strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForMaskedLM\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "if hf_tokenizer.pad_token is None:\n",
    "    hf_tokenizer.pad_token = \"[PAD]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\n",
    "proc_df = preprocessor.process_df(train_df, valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=BertMLMStrategy)\n",
    "blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=MLMTextInput), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 130]), torch.Size([2, 130]), torch.Size([2, 130]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>� � � &lt;mask&gt; &lt;mask&gt;  wanted  to  forcibly  retire  officers  with  more [ than]  25 &lt;mask&gt; &lt;mask&gt;  service ,  as  they  thought  them  to  be    and  ineffective &lt;mask&gt;  but  most  importantly ,  rivals  for  power &lt;mask&gt;  Most  of  the  older  officers  had &lt;mask&gt; &lt;mask&gt;  under  the  Vietnamese  National  Army  during  the &lt;mask&gt;  colonial  era ,  and  some  of  the [ younger]  men  saw  them  as  too  detached  from  the [matically]  situation &lt;mask&gt;  The  Young  Turks  had  quite  a  lot  of  influence  over  Kh án h ,  as  Th i  and  K &lt;mask&gt; � �  had  intervened  milit arily  to  save  him  from  a  coup  attempt  in  September &lt;mask&gt;  Gener als   [ V] � � n    and  D � &lt;mask&gt; � &lt;mask&gt; ng  V &lt;mask&gt; �</td>\n",
       "      <td>� � � [u] [ —]  wanted  to  forcibly  retire  officers  with  more [ than]  25 [ years] [ of]  service ,  as  they  thought  them  to  be    and  ineffective [,]  but  most  importantly ,  rivals  for  power [.]  Most  of  the  older  officers  had [ more] [ experience]  under  the  Vietnamese  National  Army  during  the [ French]  colonial  era ,  and  some  of  the [ younger]  men  saw  them  as  too  detached  from  the [ modern]  situation [.]  The  Young  Turks  had  quite  a  lot  of  influence  over  Kh án h ,  as  Th i  and  K [�] � �  had  intervened  milit arily  to  save  him  from  a  coup  attempt  in  September [ by]  Gener als   [ V] � � n    and  D � [�] � [�] ng  V [�] �</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;mask&gt;  line  25  : &lt;mask&gt; \\n &lt;mask&gt;  Walter  Jackson  B ate ,  the  use  of  sp ond ees  in  lines  31  –  34  creates  a  feeling  of  slow  flight ,  and [ surprise] &lt;mask&gt;  the &lt;mask&gt;  st anza . &lt;mask&gt; .  the  distinctive  use  of  scattered  sp ond ees , [ together]  with  initial   ,  lend  [ [ s]  ]  an  approximate  phon etic  suggestion  of &lt;mask&gt;  peculiar  spring &lt;mask&gt;  bounce [ of]  the  bird  in &lt;mask&gt;  flight .  \"   \\n   \\n  =  =  Po em  =  =   &lt;mask&gt;   \\n  My  heart   &lt;mask&gt; &lt;mask&gt;  a      pains   \\n  My  sense &lt;mask&gt; &lt;mask&gt;  though  of &lt;mask&gt; ml ock  I  had  drunk ,   \\n  Or  emptied  some</td>\n",
       "      <td>[ and]  line  25  : [ ] \\n [ To]  Walter  Jackson  B ate ,  the  use  of  sp ond ees  in  lines  31  –  34  creates  a  feeling  of  slow  flight ,  and [ \"] [ in]  the [ final]  st anza . [.] .  the  distinctive  use  of  scattered  sp ond ees , [ together]  with  initial   ,  lend  [ [ s]  ]  an  approximate  phon etic  suggestion  of [ the]  peculiar  spring [ and]  bounce [ of]  the  bird  in [ its]  flight .  \"   \\n   \\n  =  =  Po em  =  =   [\\n]   \\n  My  heart   [,] [ and]  a      pains   \\n  My  sense [,] [ as]  though  of [ he] ml ock  I  had  drunk ,   \\n  Or  emptied  some</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "fit_cbs = [LMMetricsCallback()]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam, decouple_wd=True),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "    cbs=[BaseModelCallback],\n",
    "    metrics=[perplexity],\n",
    "    splitter=blurr_splitter,\n",
    ").to_fp16()\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.0007585775572806596, steep=6.918309736647643e-06, valley=0.0008317637839354575, slide=0.04786301031708717)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.814517</td>\n",
       "      <td>1.805421</td>\n",
       "      <td>6.082534</td>\n",
       "      <td>0.638812</td>\n",
       "      <td>05:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-4, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_MLMInput` typed inputs\n",
    "    x: MLMTextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer and ignore token to decode\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    ignore_token_id = tfm.ignore_token_id\n",
    "\n",
    "    # grab our mask token id and do-not-mask token ids\n",
    "    mask_token_id = hf_tokenizer.mask_token_id\n",
    "\n",
    "    vocab = hf_tokenizer.get_vocab()\n",
    "    dnm_tok_ids = [vocab[tok] for tok in list(hf_tokenizer.special_tokens_map.values()) if vocab[tok] != mask_token_id]\n",
    "\n",
    "    res = L()\n",
    "    for s, t in zip(samples, outs):\n",
    "        # exclue dnm tokens from input\n",
    "        inps = [\n",
    "            hf_tokenizer.decode(tok_id) if (tok_id == mask_token_id or s[1][idx] == ignore_token_id) else f\"[{hf_tokenizer.decode(tok_id)}]\"\n",
    "            for idx, tok_id in enumerate(s[0])\n",
    "            if (tok_id not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        # replaced masked tokens with \"[{actual_token}]\"\n",
    "        trgs = [\n",
    "            hf_tokenizer.decode(s[0][idx]) if (tok_id == ignore_token_id) else f\"[{hf_tokenizer.decode(tok_id)}]\"\n",
    "            for idx, tok_id in enumerate(s[1])\n",
    "            if (s[0][idx] not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        # same as above except we replace the [MASK] with the PREDICTED token\n",
    "        preds = [\n",
    "            hf_tokenizer.decode(s[0][idx]) if (tok_id == ignore_token_id) else f\"[{hf_tokenizer.decode(t[0][idx])}]\"\n",
    "            for idx, tok_id in enumerate(s[1])\n",
    "            if (s[0][idx] not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        res.append((\" \".join(inps[:trunc_at]).strip(), \" \".join(trgs[:trunc_at]).strip(), \" \".join(preds[:trunc_at]).strip()))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"target\", \"prediction\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hostile &lt;mask&gt;  the  sett &lt;mask&gt;  ' &lt;mask&gt;  presence  led &lt;mask&gt;  competition  over  resources ,  and  to  the  occupation  of  the  indigenous  inhabitants  '  lands .  European  diseases  dec imated [ Aboriginal]  populations &lt;mask&gt;  and  the  occupation  or  destruction &lt;mask&gt; &lt;mask&gt;  and  food &lt;mask&gt;  sometimes  led  to &lt;mask&gt; &lt;mask&gt;  By  and  large  neither  the  British  nor  the [ ]  approached  the  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers  and  individual &lt;mask&gt;  rather  than  systematic  warfare .  At  times ,  however ,  the  frontier  wars [ did]  see  the  involvement  of  British  soldiers  and  later  mounted  police  units .  Not  all  Aboriginal  groups  resisted  white [mans] &lt;mask&gt;  on &lt;mask&gt;  lands , &lt;mask&gt;  many    served  in &lt;mask&gt;  police  units  and  were  involved  in</td>\n",
       "      <td>hostile [ when]  the  sett [ler]  ' [s]  presence  led [ to]  competition  over  resources ,  and  to  the  occupation  of  the  indigenous  inhabitants  '  lands .  European  diseases  dec imated [ Aboriginal]  populations [,]  and  the  occupation  or  destruction [ of] [ lands]  and  food [ resources]  sometimes  led  to [ starvation] [.]  By  and  large  neither  the  British  nor  the [ ]  approached  the  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers  and  individual [ tribes]  rather  than  systematic  warfare .  At  times ,  however ,  the  frontier  wars [ did]  see  the  involvement  of  British  soldiers  and  later  mounted  police  units .  Not  all  Aboriginal  groups  resisted  white [ encro] [achment]  on [ their]  lands , [ while]  many    served  in [ mounted]  police  units  and  were  involved  in</td>\n",
       "      <td>hostile [ to]  the  sett [ler]  ' [s]  presence  led [ to]  competition  over  resources ,  and  to  the  occupation  of  the  indigenous  inhabitants  '  lands .  European  diseases  dec imated [ Aboriginal]  populations [,]  and  the  occupation  or  destruction [ of] [ land]  and  food [ supplies]  sometimes  led  to [ starvation] [.]  By  and  large  neither  the  British  nor  the [ ]  approached  the  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers  and  individual [ tribes]  rather  than  systematic  warfare .  At  times ,  however ,  the  frontier  wars [ did]  see  the  involvement  of  British  soldiers  and  later  mounted  police  units .  Not  all  Aboriginal  groups  resisted  white [ inv] [achment]  on [ their]  lands , [ but]  many    served  in [ mounted]  police  units  and  were  involved  in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>voicing  their  complaints  about  the  treatment  of  Scient [ bargaining]  in  Germany ,  and  had  a  briefing  with  United  States  National  Security    Sandy  Berger , &lt;mask&gt;  Clinton  had &lt;mask&gt;  to &lt;mask&gt;  \" &lt;mask&gt;  administration &lt;mask&gt; s &lt;mask&gt; &lt;mask&gt;  person  \" .  The  German  ambassador  responded  with  a  letter [ to]  the   &lt;mask&gt;  that  the  German  government  had  come  to  the  conclusion  that  Scientology  ' s &lt;mask&gt; [ pseudo]  @ - @  scientific  courses  can &lt;mask&gt;  jeopard &lt;mask&gt;  individuals  '  mental  and  physical  health  and  that  it  exploits  its  members  \" ,  adding  that &lt;mask&gt;  membership  can  lead  to  psychological  and  physical  dependency ,  to  financial  ruin &lt;mask&gt;  and  even  to  suicide .  In  addition &lt;mask&gt;  there  are &lt;mask&gt;  that  Scientology  poses  a [ threat]  to</td>\n",
       "      <td>voicing  their  complaints  about  the  treatment  of  Scient [ologists]  in  Germany ,  and  had  a  briefing  with  United  States  National  Security    Sandy  Berger , [ whom]  Clinton  had [ assigned]  to [ be]  \" [ the]  administration [ '] s [ Scientology] [ point]  person  \" .  The  German  ambassador  responded  with  a  letter [ to]  the   [ stating]  that  the  German  government  had  come  to  the  conclusion  that  Scientology  ' s [ \"] [ pseudo]  @ - @  scientific  courses  can [ seriously]  jeopard [ize]  individuals  '  mental  and  physical  health  and  that  it  exploits  its  members  \" ,  adding  that [ \"]  membership  can  lead  to  psychological  and  physical  dependency ,  to  financial  ruin [,]  and  even  to  suicide .  In  addition [,]  there  are [ indications]  that  Scientology  poses  a [ threat]  to</td>\n",
       "      <td>voicing  their  complaints  about  the  treatment  of  Scient [ologists]  in  Germany ,  and  had  a  briefing  with  United  States  National  Security    Sandy  Berger , [ whom]  Clinton  had [ attempted]  to [ become]  \" [ the]  administration [ '] s [ most] [ private]  person  \" .  The  German  ambassador  responded  with  a  letter [ to]  the   [ stating]  that  the  German  government  had  come  to  the  conclusion  that  Scientology  ' s [ \"] [ pseudo]  @ - @  scientific  courses  can [ \"]  jeopard [ize]  individuals  '  mental  and  physical  health  and  that  it  exploits  its  members  \" ,  adding  that [ the]  membership  can  lead  to  psychological  and  physical  dependency ,  to  financial  ruin [,]  and  even  to  suicide .  In  addition [,]  there  are [ concerns]  that  Scientology  poses  a [ threat]  to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction\n",
    "\n",
    "While `Learner.blurr_generate` will work well for causal LMs designed for text generation, it won't for MLM models designed to predict masked tokens.  To accomodate the later, we add `Learner.blurr_fill_mask` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_fill_mask(\n",
    "    self: Learner,\n",
    "    # Your input_ids or raw text string with a `hf_tokenizer.mask_token`\n",
    "    inp: Union[List[int], str],\n",
    "    # The number of predictions you want to return for the [MASK]ed token\n",
    "    n_preds: int = 1,\n",
    "    # Any other keyword arguments you want applied to text generation\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"For MLM models\"\"\"\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    if isinstance(inp, str):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors=\"pt\", **tok_kwargs)\n",
    "    else:\n",
    "        # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "        input_ids = inp.as_subclass(Tensor)\n",
    "\n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    mask_token_index = torch.where(input_ids == hf_tokenizer.mask_token_id)[1]\n",
    "\n",
    "    outputs = self.model.hf_model(input_ids)\n",
    "    mask_token_logits = outputs.logits[0, mask_token_index, :]\n",
    "    preds = torch.topk(mask_token_logits, n_preds, dim=-1).indices[0].tolist()\n",
    "\n",
    "    outputs = [inp.replace(hf_tokenizer.mask_token, hf_tokenizer.decode([tok_id]).strip()) for tok_id in preds]\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best place on earth is here.',\n",
       " 'The best place on earth is there.',\n",
       " 'The best place on earth is home.',\n",
       " 'The best place on earth is not.',\n",
       " 'The best place on earth is America.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_fill_mask(f\"The best place on earth is {hf_tokenizer.mask_token}.\", n_preds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache(), gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForLM`\n",
    "\n",
    "We can use the `BlearnerForLM` for either Causal or Masked language models.  With one line of code, we get our DataBlock, DataLoaders, and Blearner with sensible defaults and ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForLM(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        kwargs[\"loss_func\"] = kwargs.get(\"loss_func\", PreCalculatedCrossEntropyLoss())\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self, lm_type):\n",
    "        return AutoModelForCausalLM if (lm_type == LMType.CAUSAL) else AutoModelForMaskedLM\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        return LMMetricsCallback()\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The language modeling strategy (or objective)\n",
    "        lm_strategy_cls: BaseLMStrategy = CausalLMStrategy,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # get our hf objects\n",
    "        lm_type = lm_strategy_cls.get_lm_type()\n",
    "        model_cls = cls.get_model_cls(lm_type=lm_type)\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, model_cls=model_cls)\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # define DataBlock and DataLoaders\n",
    "        bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=lm_strategy_cls)\n",
    "\n",
    "        input_return_type = CausalLMTextInput if (lm_type == LMType.CAUSAL) else MLMTextInput\n",
    "        blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=input_return_type), noop)\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=ItemGetter(text_attr), splitter=dblock_splitter)\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance with default metrics (optional)\n",
    "        learner_kwargs[\"metrics\"] = learner_kwargs.pop(\"metrics\", [perplexity])\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "learn = BlearnerForLM.from_data(df, \"gpt2\", text_attr=0, dl_kwargs={\"bs\": 2}).to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = Bob Dylan = \\n \\n Bob Dylan ( / &lt;unk&gt; / ; born Robert Allen Zimmerman, May 24, 1941 ) is an American singer @-@ songwriter, artist and writer. He has been influential in popular music and culture for more than five decades. Much of his most celebrated work dates from the 1960s when his songs chronicled social unrest, although Dylan repudiated suggestions from journalists that he was a spokesman for his generation. Nevertheless, early songs such as \" Blowin'in the Wind \" and \" The Times They A</td>\n",
       "      <td>\\n = Bob Dylan = \\n \\n Bob Dylan ( / &lt;unk&gt; / ; born Robert Allen Zimmerman, May 24, 1941 ) is an American singer @-@ songwriter, artist and writer. He has been influential in popular music and culture for more than five decades. Much of his most celebrated work dates from the 1960s when his songs chronicled social unrest, although Dylan repudiated suggestions from journalists that he was a spokesman for his generation. Nevertheless, early songs such as \" Blowin'in the Wind \" and \" The Times They Ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Condom = \\n \\n A condom is a sheath @-@ shaped barrier device that may be used during sexual intercourse to reduce the probability of pregnancy and decrease the risk of sexually transmitted infections ( STIs ) such as HIV / AIDS. It is rolled onto an erect penis before intercourse and blocks &lt;unk&gt; semen from entering the body of a sexual partner. Condoms are also used during &lt;unk&gt; and for collection of semen for use in infertility treatment. In the modern age, condoms are most often made from</td>\n",
       "      <td>\\n = Condom = \\n \\n A condom is a sheath @-@ shaped barrier device that may be used during sexual intercourse to reduce the probability of pregnancy and decrease the risk of sexually transmitted infections ( STIs ) such as HIV / AIDS. It is rolled onto an erect penis before intercourse and blocks &lt;unk&gt; semen from entering the body of a sexual partner. Condoms are also used during &lt;unk&gt; and for collection of semen for use in infertility treatment. In the modern age, condoms are most often made from</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.480263</td>\n",
       "      <td>3.104528</td>\n",
       "      <td>22.298697</td>\n",
       "      <td>0.429945</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=3e-3, cbs=[BlearnerForLM.get_metrics_cb()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = Military history of Australia = \\n \\n The military history of Australia spans the nation's 220 @-@ year modern history, from the early Australian frontier wars between &lt;unk&gt; and Europeans to the ongoing conflicts in Iraq and Afghanistan in the ear</td>\n",
       "      <td>\\n = Military history of Australia = \\n \\n The military history of Australia spans the nation's 220 @-@ year modern history, from the early Australian frontier wars between &lt;unk&gt; and Europeans to the ongoing conflicts in Iraq and Afghanistan in the earl</td>\n",
       "      <td>\\n\\n =\\n = the\\n\\n\\n =\\n = Australian history of Australia is the period froms history- 1@ years period era. from the early days military to to the 18&gt; Australia &lt; &lt; the early conflict between the and Afghanistan. the late 1980st century. The the history is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Air Rhodesia Flight &lt;unk&gt; = \\n \\n Air Rhodesia Flight &lt;unk&gt; was a scheduled passenger flight that was shot down by the Zimbabwe People's Revolutionary Army ( &lt;unk&gt; ) on 3 September 1978, during the Rhodesian Bush War. The aircraft involved, a Vick</td>\n",
       "      <td>\\n = Air Rhodesia Flight &lt;unk&gt; = \\n \\n Air Rhodesia Flight &lt;unk&gt; was a scheduled passenger flight that was shot down by the Zimbabwe People's Revolutionary Army ( &lt;unk&gt; ) on 3 September 1978, during the Rhodesian Bush War. The aircraft involved, a Vicke</td>\n",
       "      <td>\\n\\n = Forceia\\n\\n\\n&gt;\\n Air\\n =\\n = Rhodesia Flight &lt;unk&gt; = a flight flight flight from was scheduled down by a Sovietan'ss Liberation Army (Zunk&gt; ) on September August 1944. killing a liberationian civil War. The plane was was was civilian- aircraftickersou</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': \" Blurr is fun to work with because it's main theme is the idea. It's the first game in a series, and it's a great way to newbies looking at games and learning how to get their hands on them\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masked language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForLM.from_data(df, \"bert-base-cased\", lm_strategy_cls=BertMLMStrategy, text_attr=0, dl_kwargs={\"bs\": 2}).to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= Bob Dylan = Bob Dylan ( / &lt; un ##k &gt; / ; born Robert Allen Z ##immer ##man , May 24 , 1941 ) is [MASK] American [MASK] @ - @ [MASK] , artist [##》] writer . He [MASK] been influential in popular music and culture [Strings] more than five decades . Much of his most celebrated [MASK] [MASK] from the 1960s when his [MASK] chronicle ##d social unrest , although Dylan re ##pu ##dia ##ted suggestions from journalists that he [MASK] [MASK] spokesman for [MASK] generation . Nevertheless , early songs such as \" B [##low] [MASK] ' in the Wind \" and \" The Times They Are a @ - @ [MASK] un ##k [MASK] ' \" became anthem ##s for the American civil rights and anti @ [MASK] @ war movements . After he [MASK] [MASK] [MASK] base in the American [MASK] music revival , his six @ - [MASK] [MASK] single \" Like [MASK] Rolling Stone \" altered the range [MASK] popular music in 1965 . His mid [MASK] - [##lor] 1960s recordings , backed by rock musicians , [MASK] the top end of the United States music charts while also attracting &lt; un ##k &gt; and criticism from [MASK] in [MASK] folk [MASK] . [scrap] ' s lyrics have incorporated [MASK] political , social , [MASK] , and literary influences . [They] def ##ied [MASK] pop [MASK] conventions and appealed to [MASK] b [MASK] ##oning counter ##culture [MASK] Initially inspired by the performances</td>\n",
       "      <td>= Bob Dylan = Bob Dylan ( / &lt; un ##k &gt; / ; born Robert Allen Z ##immer ##man , May 24 , 1941 ) is [an] American [singer] @ - @ [songwriter] , artist [and] writer . He [has] been influential in popular music and culture [for] more than five decades . Much of his most celebrated [work] [dates] from the 1960s when his [songs] chronicle ##d social unrest , although Dylan re ##pu ##dia ##ted suggestions from journalists that he [was] [a] spokesman for [his] generation . Nevertheless , early songs such as \" B [##low] [##in] ' in the Wind \" and \" The Times They Are a @ - @ [&lt;] un ##k [&gt;] ' \" became anthem ##s for the American civil rights and anti @ [-] @ war movements . After he [left] [his] [initial] base in the American [folk] music revival , his six @ - [@] [minute] single \" Like [a] Rolling Stone \" altered the range [of] popular music in 1965 . His mid [@] - [@] 1960s recordings , backed by rock musicians , [reached] the top end of the United States music charts while also attracting &lt; un ##k &gt; and criticism from [others] in [the] folk [movement] . [Dylan] ' s lyrics have incorporated [various] political , social , [philosophical] , and literary influences . [They] def ##ied [existing] pop [music] conventions and appealed to [the] b [##urge] ##oning counter ##culture [.] Initially inspired by the performances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Missouri River [MASK] The Missouri River is the longest river in North America . Rising in the Rocky Mountains of [MASK] Montana , the Missouri [MASK] east and south [MASK] 2 @ [MASK] @ 34 [##1] [miles] ( [MASK] [MASK] , @ 76 ##7 km ) [MASK] [MASK] the Mississippi River north [MASK] St . Louis , [MASK] . The [MASK] takes drainage from a sparse ##ly populated [MASK] semi @ - @ arid watershed of more than half a million square miles ( 1 @ , @ [MASK] [MASK] , [Radar] 000 km ##2 ) , which includes parts of ten U . S . states [MASK] two [MASK] provinces . When combined with the lower Mississippi River , it [MASK] the world ' s fourth longest river system . For over 12 [MASK] , @ 000 years , people have depended on the Missouri River and its tributaries as a [MASK] of su ##sten ##ance and transportation . [MASK] [MASK] ten major [MASK] of Native [MASK] populated the watershed [,] most leading [MASK] nomadic lifestyle and [MASK] on enormous buffalo herd ##s that once r [##oam] ##ed through the Great Plains . The [MASK] [MASK] encountered the river in the late seventeenth century , and the region passed through Spanish and French hands before [MASK] becoming part [620] the United [regime] through the Louisiana P ##ur ##chase . [The] Missouri was long believed to be part of the Northwest [MASK] [–] a water route from the Atlantic</td>\n",
       "      <td>= Missouri River [=] The Missouri River is the longest river in North America . Rising in the Rocky Mountains of [western] Montana , the Missouri [flows] east and south [for] 2 @ [,] @ 34 [##1] [miles] ( [3] [@] , @ 76 ##7 km ) [before] [entering] the Mississippi River north [of] St . Louis , [Missouri] . The [river] takes drainage from a sparse ##ly populated [,] semi @ - @ arid watershed of more than half a million square miles ( 1 @ , @ [300] [@] , [@] 000 km ##2 ) , which includes parts of ten U . S . states [and] two [Canadian] provinces . When combined with the lower Mississippi River , it [forms] the world ' s fourth longest river system . For over 12 [@] , @ 000 years , people have depended on the Missouri River and its tributaries as a [source] of su ##sten ##ance and transportation . [More] [than] ten major [groups] of Native [Americans] populated the watershed [,] most leading [a] nomadic lifestyle and [dependent] on enormous buffalo herd ##s that once r [##oam] ##ed through the Great Plains . The [first] [Europeans] encountered the river in the late seventeenth century , and the region passed through Spanish and French hands before [finally] becoming part [of] the United [States] through the Louisiana P ##ur ##chase . [The] Missouri was long believed to be part of the Northwest [Passage] [–] a water route from the Atlantic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.658835</td>\n",
       "      <td>2.445236</td>\n",
       "      <td>11.533271</td>\n",
       "      <td>0.579787</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=6e-4, cbs=[BlearnerForLM.get_metrics_cb()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= Military history of [MASK] = The military history of Australia spans [MASK] [MASK] ' s 220 @ - @ year modern history , from [benefited] early Australian [frontier] wars between &lt; un [MASK] [MASK] and Europeans to [MASK] ongoing conflicts in Iraq and Afghanistan in the early 21st century . Although this history is short [Dam] compared to that of many other nations , Australia has been involved in [MASK] conflicts and wars , and war and military service [MASK] been significant influences on Australian society and national identity , including the [MASK] ##zac spirit . The relationship between war and Australian society has also been shaped by the enduring themes [MASK] [Australian] strategic culture and its unique security di ##lemma . As British &lt; un ##k &gt; [MASK] the Australian colonies participated in Britain ' s small wars of the 19th [century] , while later [MASK] a &lt; un ##k &gt; do ##mini ##on , and then an independent nation , Australia fought in [MASK] [MASK] [MASK] War and Second World War [MASK] as [MASK] as in the wars in Korea , Malaya , Borneo and Vietnam during the Cold [MASK] . In [MASK] Post @ - @ Vietnam era Australian forces [MASK] been [involved] in numerous international peace ##keeping missions , [MASK] the [MASK] Nations and other [MASK] , including in the [MASK] [MASK] Persian Gulf , &lt; un ##k &gt; , Somalia [MASK] East Timor and the Solomon Islands , [MASK] more recently they have also</td>\n",
       "      <td>= Military history of [Australia] = The military history of Australia spans [the] [nation] ' s 220 @ - @ year modern history , from [the] early Australian [frontier] wars between &lt; un [##k] [&gt;] and Europeans to [the] ongoing conflicts in Iraq and Afghanistan in the early 21st century . Although this history is short [when] compared to that of many other nations , Australia has been involved in [numerous] conflicts and wars , and war and military service [have] been significant influences on Australian society and national identity , including the [An] ##zac spirit . The relationship between war and Australian society has also been shaped by the enduring themes [of] [Australian] strategic culture and its unique security di ##lemma . As British &lt; un ##k &gt; [,] the Australian colonies participated in Britain ' s small wars of the 19th [century] , while later [as] a &lt; un ##k &gt; do ##mini ##on , and then an independent nation , Australia fought in [the] [First] [World] War and Second World War [,] as [well] as in the wars in Korea , Malaya , Borneo and Vietnam during the Cold [War] . In [the] Post @ - @ Vietnam era Australian forces [have] been [involved] in numerous international peace ##keeping missions , [through] the [United] Nations and other [agencies] , including in the [Sinai] [,] Persian Gulf , &lt; un ##k &gt; , Somalia [,] East Timor and the Solomon Islands , [while] more recently they have also</td>\n",
       "      <td>= Military history of [Australia] = The military history of Australia spans [Australia] [Australia] ' s 220 @ - @ year modern history , from [the] early Australian [frontier] wars between &lt; un [##k] [&gt;] and Europeans to [the] ongoing conflicts in Iraq and Afghanistan in the early 21st century . Although this history is short [lived] compared to that of many other nations , Australia has been involved in [numerous] conflicts and wars , and war and military service [have] been significant influences on Australian society and national identity , including the [An] ##zac spirit . The relationship between war and Australian society has also been shaped by the enduring themes [of] [Australian] strategic culture and its unique security di ##lemma . As British &lt; un ##k &gt; [and] the Australian colonies participated in Britain ' s small wars of the 19th [century] , while later [becoming] a &lt; un ##k &gt; do ##mini ##on , and then an independent nation , Australia fought in [the] [First] [World] War and Second World War [,] as [well] as in the wars in Korea , Malaya , Borneo and Vietnam during the Cold [War] . In [the] Post @ - @ Vietnam era Australian forces [have] been [involved] in numerous international peace ##keeping missions , [to] the [United] Nations and other [countries] , including in the [Persian] [,] Persian Gulf , &lt; un ##k &gt; , Somalia [,] East Timor and the Solomon Islands , [and] more recently they have also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Air Rhodesia [Flight] &lt; un ##k &gt; = Air Rhodesia [MASK] &lt; un ##k &gt; was a [MASK] passenger flight that was shot [MASK] by the Zimbabwe People ' s Revolutionary [MASK] ( &lt; un ##k &gt; ) on [MASK] September 1978 , [MASK] the Rhodesia ##n Bush War . The aircraft involved , a Vickers Viscount named the &lt; un ##k &gt; [MASK] was flying the last leg of Air Rhodesia ' s regular scheduled service [MASK] Victoria Falls to [MASK] [MASK] Salisbury , via the resort [MASK] [MASK] &lt; un ##k &gt; . Soon after Flight [&lt;] un ##k &gt; took off , [MASK] group [MASK] &lt; un [MASK] &gt; guerrilla ##s scored a direct hit on its star ##board wing with a Soviet @ - [MASK] made &lt; un ##k &gt; 2 surface @ - @ to @ - @ air infrared &lt; un [MASK] [&gt;] [MASK] , critically [MASK] the aircraft [and] forcing an [MASK] landing . An attempted belly landing in a [MASK] [payload] [MASK] west of &lt; un ##k &gt; [MASK] &lt; un ##k &gt; by an unseen ditch , which caused the plane to [MASK] ##wheel and break up . Of the 52 passengers and four crew [MASK] 38 died [MASK] [MASK] crash [MASK] the [MASK] then approached the wreckage , rounded up the 10 survivors they could see and massacre [##d] them with automatic gunfire . Three passengers survived by [MASK] in [MASK] surrounding bush , while a further [MASK] lived</td>\n",
       "      <td>= Air Rhodesia [Flight] &lt; un ##k &gt; = Air Rhodesia [Flight] &lt; un ##k &gt; was a [scheduled] passenger flight that was shot [down] by the Zimbabwe People ' s Revolutionary [Army] ( &lt; un ##k &gt; ) on [3] September 1978 , [during] the Rhodesia ##n Bush War . The aircraft involved , a Vickers Viscount named the &lt; un ##k &gt; [,] was flying the last leg of Air Rhodesia ' s regular scheduled service [from] Victoria Falls to [the] [capital] Salisbury , via the resort [town] [of] &lt; un ##k &gt; . Soon after Flight [&lt;] un ##k &gt; took off , [a] group [of] &lt; un [##k] &gt; guerrilla ##s scored a direct hit on its star ##board wing with a Soviet @ - [@] made &lt; un ##k &gt; 2 surface @ - @ to @ - @ air infrared &lt; un [##k] [&gt;] [missile] , critically [damaging] the aircraft [and] forcing an [emergency] landing . An attempted belly landing in a [cotton] [field] [just] west of &lt; un ##k &gt; [was] &lt; un ##k &gt; by an unseen ditch , which caused the plane to [cart] ##wheel and break up . Of the 52 passengers and four crew [,] 38 died [in] [this] crash [;] the [insurgents] then approached the wreckage , rounded up the 10 survivors they could see and massacre [##d] them with automatic gunfire . Three passengers survived by [hiding] in [the] surrounding bush , while a further [five] lived</td>\n",
       "      <td>= Air Rhodesia [Flight] &lt; un ##k &gt; = Air Rhodesia [Flight] &lt; un ##k &gt; was a [scheduled] passenger flight that was shot [down] by the Zimbabwe People ' s Revolutionary [Army] ( &lt; un ##k &gt; ) on [10] September 1978 , [during] the Rhodesia ##n Bush War . The aircraft involved , a Vickers Viscount named the &lt; un ##k &gt; [,] was flying the last leg of Air Rhodesia ' s regular scheduled service [from] Victoria Falls to [Darwin] [Port] Salisbury , via the resort [of] [the] &lt; un ##k &gt; . Soon after Flight [&lt;] un ##k &gt; took off , [a] group [of] &lt; un [##k] &gt; guerrilla ##s scored a direct hit on its star ##board wing with a Soviet @ - [@] made &lt; un ##k &gt; 2 surface @ - @ to @ - @ air infrared &lt; un [##k] [&gt;] [)] , critically [damaging] the aircraft [and] forcing an [emergency] landing . An attempted belly landing in a [small] [payload] [bay] west of &lt; un ##k &gt; [followed] &lt; un ##k &gt; by an unseen ditch , which caused the plane to [tail] ##wheel and break up . Of the 52 passengers and four crew [,] 38 died [in] [the] crash [;] the [police] then approached the wreckage , rounded up the 10 survivors they could see and massacre [##d] them with automatic gunfire . Three passengers survived by [drowning] in [the] surrounding bush , while a further [two] lived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfm = first_blurr_tfm(learn.dls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best place on earth is here.',\n",
       " 'The best place on earth is heaven.',\n",
       " 'The best place on earth is Egypt.',\n",
       " 'The best place on earth is India.',\n",
       " 'The best place on earth is America.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_fill_mask(f\"The best place on earth is {batch_tfm.hf_tokenizer.mask_token}.\", n_preds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Whether you're using the low, mid, or high-level APIs, the `modeling.language_modeling` provides everything you need to train causual and masked language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
