{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp text.modeling.core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text.modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your Hugging Face models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, inspect, mimetypes\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, CategoryBlock, MultiCategoryBlock, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import BCEWithLogitsLossFlat, CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import accuracy, F1Score, accuracy_multi, F1ScoreMulti\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from transformers import AutoModelForSequenceClassification, PreTrainedModel, logging\n",
    "\n",
    "from blurr.text.data.core import TextBlock, TextInput, first_blurr_tfm\n",
    "from blurr.text.utils import NLP\n",
    "from blurr.utils import PreCalculatedLoss, PreCalculatedBCELoss, PreCalculatedCrossEntropyLoss, PreCalculatedMSELoss, set_seed\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.text.data.core import TextDataLoader\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API\n",
    "\n",
    "Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `blurr_splitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def blurr_splitter(m: Module):\n",
    "    \"\"\"Splits the Hugging Face model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, \"hf_model\")) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "\n",
    "    groups = L([m for m_name, m in list(top_module.named_children())])\n",
    "    groups += L([m for m_name, m in root_modules[1:]])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"blurr_splitter\" class=\"doc_header\"><code>blurr_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>blurr_splitter</code>(**`m`**:`Module`)\n",
       "\n",
       "Splits the Hugging Face model based on various model architecture conventions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(blurr_splitter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BaseModelWrapper`\n",
    "\n",
    "Note that `BaseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModelWrapper(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your Hugging Face model\n",
    "        hf_model: PreTrainedModel,\n",
    "        # If True, hidden_states will be returned and accessed from Learner\n",
    "        output_hidden_states: bool = False,\n",
    "        # If True, attentions will be returned and accessed from Learner\n",
    "        output_attentions: bool = False,\n",
    "        # Any additional keyword arguments you want passed into your models forward method\n",
    "        hf_model_kwargs={},\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        store_attr()\n",
    "        self.hf_model = hf_model.cuda() if torch.cuda.is_available() else hf_model\n",
    "        self.hf_model_fwd_args = list(inspect.signature(self.hf_model.forward).parameters.keys())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for k in list(x):\n",
    "            if k not in self.hf_model_fwd_args:\n",
    "                del x[k]\n",
    "\n",
    "        return self.hf_model(\n",
    "            **x,\n",
    "            output_hidden_states=self.output_hidden_states,\n",
    "            output_attentions=self.output_attentions,\n",
    "            return_dict=True,\n",
    "            **self.hf_model_kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BaseModelCallback`\n",
    "\n",
    "We use a `Callback` for handling the [`ModelOutput`](https://huggingface.co/transformers/main_classes/output.html#transformers.file_utils.ModelOutput) returned by Hugging Face transformers. It allows us to associate anything we want from that object to our `Learner`.\n",
    "\n",
    "**Note** that your `Learner`'s loss will be set for you only if the Hugging Face model returns one *and* you are using the `PreCalculatedLoss` loss function.  \n",
    "\n",
    "Also note that anything else you asked the model to return (for example, last hidden state, etc..) will be available for you via the `blurr_model_outputs` property attached to your `Learner`. For example, assuming you are using BERT for a classification task ... if you have told your `BaseModelWrapper` instance to return attentions, you'd be able to access them via `learn.blurr_model_outputs['attentions']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModelCallback(Callback):\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Below demonstrates how to setup your pipeline for a sequence classification task (e.g., a model that requires a single text input) using the mid, high, and low-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e2e17df4c34ab8912630cb1034cb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-65b5588450d6b196.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie was horrible. I swear they didn't even write a script they just kinda winged it through out the whole movie. Ice-T was annoying as hell. *SPOILERS Phht more like reasons not to watch it* They sit down and eat breakfast for 20 minutes. he coulda been long gone. The ground was hard it would of been close to impossible to to track him with out dogs. And when ICE-T is on that Hill and uses that Spaz-15 Assault SHOTGUN like its a sniper rifle (and then cuts down a tree with eight shells?? It would take 1000's of shells to cut down a tree that size.) Shotguns and hand guns are conside...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this movie at the cinema many years ago, and one thing surprised me so negatively that I could not see any redeeming virtues in the movies: Dennis Quaid was cast as a policeman that never smiles or grin, while his smile and grin are two of his trademarks. Danny Glover was cast as the bad guy, but - again - most viewers' imagination could not go far enough as to believe him in that role. Also, Jared Leto was not believable as the former medicine student. The tension was just not there, since the killer was known very early. The finale was, again, neither dramatic nor tense: nobo...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a fantastic series first and foremost. It is very well done and very interesting. As a huge WWII buff, I had learned a lot before seeing this series. One of the best things this has going for it is all the interviews with past individuals back when the war was relatively fresh in their minds, comparatively speaking that is. It is nothing against the men that you see getting interviewed in the programs of today, it is just that most of these men weren't really involved in the upper echelons of what was happening then. One of the best parts is the narrating by Sir Laurence Oliver. I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kurosawa really blew it on this one. Every genius is allowed a failure. The concept is fine but the execution is badly blurred.&lt;br /&gt;&lt;br /&gt;There is an air of fantasy about this film making it something of an art film. The poverty stricken of Tokyo deserve a fairer and more realistic portrayal. Many of them have interesting stories to tell. A very disappointing film.</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGM were unsure of how to market Garbo when she first arrived in Hollywood. Mayer had a lot of faith in her and her appearance in \"Torrent\" justified that. She did not speak a word of English so she must have found it difficult to work, also Ricardo Cortez did not make it very easy for her.&lt;br /&gt;&lt;br /&gt;The torrent of the title is the river Juscar that winds through a sleepy little village in Spain. Leonora (Greta Garbo) hopes someday that her voice will bring great wealth and happiness to her struggling parents. Leonora and Don Rafael (Ricardo Cortez) are in love but he is under his mother'...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  This movie was horrible. I swear they didn't even write a script they just kinda winged it through out the whole movie. Ice-T was annoying as hell. *SPOILERS Phht more like reasons not to watch it* They sit down and eat breakfast for 20 minutes. he coulda been long gone. The ground was hard it would of been close to impossible to to track him with out dogs. And when ICE-T is on that Hill and uses that Spaz-15 Assault SHOTGUN like its a sniper rifle (and then cuts down a tree with eight shells?? It would take 1000's of shells to cut down a tree that size.) Shotguns and hand guns are conside...   \n",
       "1  I have seen this movie at the cinema many years ago, and one thing surprised me so negatively that I could not see any redeeming virtues in the movies: Dennis Quaid was cast as a policeman that never smiles or grin, while his smile and grin are two of his trademarks. Danny Glover was cast as the bad guy, but - again - most viewers' imagination could not go far enough as to believe him in that role. Also, Jared Leto was not believable as the former medicine student. The tension was just not there, since the killer was known very early. The finale was, again, neither dramatic nor tense: nobo...   \n",
       "2  This is a fantastic series first and foremost. It is very well done and very interesting. As a huge WWII buff, I had learned a lot before seeing this series. One of the best things this has going for it is all the interviews with past individuals back when the war was relatively fresh in their minds, comparatively speaking that is. It is nothing against the men that you see getting interviewed in the programs of today, it is just that most of these men weren't really involved in the upper echelons of what was happening then. One of the best parts is the narrating by Sir Laurence Oliver. I ...   \n",
       "3                                                                                                                                                                                                                                         Kurosawa really blew it on this one. Every genius is allowed a failure. The concept is fine but the execution is badly blurred.<br /><br />There is an air of fantasy about this film making it something of an art film. The poverty stricken of Tokyo deserve a fairer and more realistic portrayal. Many of them have interesting stories to tell. A very disappointing film.   \n",
       "4  MGM were unsure of how to market Garbo when she first arrived in Hollywood. Mayer had a lot of faith in her and her appearance in \"Torrent\" justified that. She did not speak a word of English so she must have found it difficult to work, also Ricardo Cortez did not make it very easy for her.<br /><br />The torrent of the title is the river Juscar that winds through a sleepy little village in Spain. Leonora (Greta Garbo) hopes someday that her voice will bring great wealth and happiness to her struggling parents. Leonora and Don Rafael (Ricardo Cortez) are in love but he is under his mother'...   \n",
       "\n",
       "   label  is_valid  \n",
       "0      0     False  \n",
       "1      0     False  \n",
       "2      1     False  \n",
       "3      0     False  \n",
       "4      1     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "raw_datasets[0] = raw_datasets[0].add_column(\"is_valid\", [False] * len(raw_datasets[0]))\n",
    "raw_datasets[1] = raw_datasets[1].add_column(\"is_valid\", [True] * len(raw_datasets[1]))\n",
    "\n",
    "final_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n",
    "imdb_df = pd.DataFrame(final_ds)\n",
    "imdb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[0].features[\"label\"].names\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "set_seed()\n",
    "blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, batch_tokenize_kwargs={\"labels\": labels}), CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=RandomSplitter(seed=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# dblock.summary(imdb_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anyone who visited drive-ins in the 1950s, 60s, and 70s, must have seen a film or two by American International Pictures, a distributor that resembled 1980s giant Cannon Films. Wherever movie-goers ventured, AIP would be right there to supply the latest en vogue titles - in the 50s came horror movies like 'Voodoo Woman' and 'The Undead;' in the 60s were Frankie Avalon-Annette Funicello beach comedies and biker flicks like 'The Glory Stompers;' and into the 70s, AIP churned out grindhouse-level</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*****WARNING, MAY CONTAIN SPOILERS WHICH WILL BE MORE ENTERTAINING THAN THIS TRIPE.**** &lt;br /&gt;&lt;br /&gt;Heres some good advise to anyone living in the U.K. Whenever Channel 5 has an old 80's comedy on late at night, read a book instead. I am currently in the process of recovering from a seizure, due to reading some of the comments on this film on here. I am actually shocked at the fact that someone actually said this film was realistic! All I can say is thank god the Cold War never escalated or els</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github.  Let's check that we can get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "model = BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(OptimWrapper, opt=torch.optim.Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat(),\n",
    "    metrics=[accuracy],\n",
    "    cbs=[BaseModelCallback],\n",
    "    splitter=blurr_splitter,\n",
    ")\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=7.585775847473997e-08, steep=0.007585775572806597, valley=0.00010964782268274575, slide=0.0012022644514217973)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.332286</td>\n",
       "      <td>0.246465</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `TextInput` typed inputs\n",
    "    x: TextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    # if we've included our labels list, we'll use it to look up the value of our target(s)\n",
    "    trg_labels = tfm.kwargs[\"labels\"] if (\"labels\" in tfm.kwargs) else None\n",
    "\n",
    "    res = L()\n",
    "    n_inp = learner.dls.n_inp\n",
    "\n",
    "    for idx, (input_ids, label, pred, sample) in enumerate(zip(x, y, outs, samples)):\n",
    "        if idx >= max_n:\n",
    "            break\n",
    "\n",
    "        # add in the input text\n",
    "        rets = [hf_tokenizer.decode(input_ids, skip_special_tokens=True)[:trunc_at]]\n",
    "        # add in the targets\n",
    "        for item in sample[n_inp:]:\n",
    "            if not torch.is_tensor(item):\n",
    "                trg = trg_labels[int(item)] if trg_labels else item\n",
    "            elif is_listy(item.tolist()):\n",
    "                trg = [trg_labels[idx] for idx, val in enumerate(label.numpy().tolist()) if (val == 1)] if (trg_labels) else label.numpy()\n",
    "            else:\n",
    "                trg = trg_labels[label.item()] if (trg_labels) else label.item()\n",
    "\n",
    "            rets.append(trg)\n",
    "        # add in the predictions\n",
    "        for item in pred:\n",
    "            if not torch.is_tensor(item):\n",
    "                p = trg_labels[int(item)] if trg_labels else item\n",
    "            elif is_listy(item.tolist()):\n",
    "                p = [trg_labels[idx] for idx, val in enumerate(item.numpy().tolist()) if (val == 1)] if (trg_labels) else item.numpy()\n",
    "            else:\n",
    "                p = trg_labels[item.item()] if (trg_labels) else item.item()\n",
    "\n",
    "            rets.append(p)\n",
    "\n",
    "        res.append(tuplify(rets))\n",
    "\n",
    "    cols = [\"text\"] + [\"target\" if (i == 0) else f\"target_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    cols += [\"prediction\" if (i == 0) else f\"prediction_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    display_df(pd.DataFrame(res, columns=cols)[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You don't need to read this review.&lt;br /&gt;&lt;br /&gt;An earlier review, by pninson of Seattle, has already identified all the main shortcomings of this production. I can only amplify its basic arguments.&lt;br /&gt;&lt;br /&gt;Bleak House was a relatively late Dickens novel and is much darker than his earlier work. This is taken too literally by the director, Ross Devenish, who piles on the gloom and fog too much. When Ada, Rick and Esther appear, half an hour into the opening episode, it is a relief just to be</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This TV production of 1970 starring Susannah York and George C. Scott is another proof of how difficult it is to adopt \"Jane Eyre\" to the screen, and how much can go wrong in doing so. It is true that the movie suffered in the transfer to DVD - some scenes which were complete in the original were shortened and so badly edited that there are striking continuity gaps and that even one crucial scene between Jane and Rochester starts in the middle of a sentence! But even if the editing were better,</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.275167</td>\n",
       "      <td>0.255125</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.223377</td>\n",
       "      <td>0.217043</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-7, 1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You don't need to read this review.&lt;br /&gt;&lt;br /&gt;An earlier review, by pninson of Seattle, has already identified all the main shortcomings of this production. I can only amplify its basic arguments.&lt;br /&gt;&lt;br /&gt;Bleak House was a relatively late Dickens novel and is much darker than his earlier work. This is taken too literally by the director, Ross Devenish, who piles on the gloom and fog too much. When Ada, Rick and Esther appear, half an hour into the opening episode, it is a relief just to be</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This TV production of 1970 starring Susannah York and George C. Scott is another proof of how difficult it is to adopt \"Jane Eyre\" to the screen, and how much can go wrong in doing so. It is true that the movie suffered in the transfer to DVD - some scenes which were complete in the original were shortened and so badly edited that there are striking continuity gaps and that even one crucial scene between Jane and Rochester starts in the middle of a sentence! But even if the editing were better,</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "We need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_predict(self: Learner, items, rm_type_tfms=None):\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "    trg_labels = tfm.kwargs[\"labels\"] if (\"labels\" in tfm.kwargs) else None\n",
    "\n",
    "    is_split_str = tfm.is_split_into_words and isinstance(items[0], str)\n",
    "    is_df = isinstance(items, pd.DataFrame)\n",
    "\n",
    "    if not is_df and (is_split_str or not is_listy(items)):\n",
    "        items = [items]\n",
    "\n",
    "    dl = self.dls.test_dl(items, rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "\n",
    "    with self.no_bar():\n",
    "        probs, _, decoded_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "\n",
    "    trg_tfms = self.dls.tfms[self.dls.n_inp :]\n",
    "\n",
    "    outs = []\n",
    "    is_multilabel = isinstance(self.loss_func, BCEWithLogitsLossFlat)\n",
    "    probs, decoded_preds = L(probs), L(decoded_preds)\n",
    "    for i in range(len(items)):\n",
    "        item_probs = probs.itemgot(i)\n",
    "        item_dec_preds = decoded_preds.itemgot(i)\n",
    "        item_dec_labels = tuplify([tfm.decode(item_dec_preds[tfm_idx]) for tfm_idx, tfm in enumerate(trg_tfms)])[0]\n",
    "        if trg_labels:\n",
    "            item_dec_labels = [trg_labels[int(lbl)] for item in item_dec_labels for lbl in item]\n",
    "\n",
    "        res = {}\n",
    "        if is_multilabel:\n",
    "            res[\"labels\"] = list(item_dec_labels)\n",
    "            msk = item_dec_preds[0]\n",
    "            res[\"scores\"] = item_probs[0][msk].tolist()\n",
    "            res[\"class_indices\"] = [int(val) for val in item_dec_preds[0]]\n",
    "        else:\n",
    "            res[\"label\"] = item_dec_labels[0]\n",
    "            res[\"score\"] = item_probs[0].tolist()[item_dec_preds[0]]\n",
    "            res[\"class_index\"] = item_dec_preds[0].item()\n",
    "\n",
    "        res[\"class_labels\"] = trg_labels if trg_labels else self.dls.vocab\n",
    "        res[\"probs\"] = item_probs[0].tolist()\n",
    "\n",
    "        outs.append(res)\n",
    "\n",
    "        # outs.append((item_dec_labels, [p.tolist() if p.dim() > 0 else p.item() for p in item_dec_preds], [p.tolist() for p in item_probs]))\n",
    "\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict\" class=\"doc_header\"><code>Learner.blurr_predict</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict</code>(**`items`**, **`rm_type_tfms`**=*`None`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'pos',\n",
       "  'score': 0.8974564671516418,\n",
       "  'class_index': 1,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.10254360735416412, 0.8974564671516418]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"I really liked the movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neg',\n",
       "  'score': 0.8034900426864624,\n",
       "  'class_index': 0,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.8034900426864624, 0.1965099722146988]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'pos',\n",
       "  'score': 0.8974562287330627,\n",
       "  'class_index': 1,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.10254369676113129, 0.8974562287330627]},\n",
       " {'label': 'neg',\n",
       "  'score': 0.7418527007102966,\n",
       "  'class_index': 0,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.7418527007102966, 0.2581472396850586]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict([\"I really liked the movie\", \"I really hated the movie\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text generation\n",
    "\n",
    "Though not useful in sequence classification, we will also add a `blurr_generate` method to `Learner` that uses Hugging Face's `PreTrainedModel.generate` for text generation tasks.  \n",
    "\n",
    "For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_generate(self: Learner, items, key=\"generated_texts\", **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text\n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    if not is_listy(items):\n",
    "        items = [items]\n",
    "\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    results = []\n",
    "    for idx, inp in enumerate(items):\n",
    "        if isinstance(inp, str):\n",
    "            input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors=\"pt\", **tok_kwargs)\n",
    "        else:\n",
    "            # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "            input_ids = inp.as_subclass(Tensor)\n",
    "\n",
    "        input_ids = input_ids.to(self.model.hf_model.device)\n",
    "\n",
    "        gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "        outputs = [hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) for txt in gen_texts]\n",
    "\n",
    "        if tfm.hf_arch == \"pegasus\":\n",
    "            outputs = [o.replace(\"<n>\", \" \") for o in outputs]\n",
    "\n",
    "        results.append({key: outputs[0] if len(outputs) == 1 else outputs})\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_generate\" class=\"doc_header\"><code>Learner.blurr_generate</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_generate</code>(**`items`**, **`key`**=*`'generated_texts'`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text\n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_generate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"seq_class_learn_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neg',\n",
       "  'score': 0.946750283241272,\n",
       "  'class_index': 0,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.946750283241272, 0.05324973911046982]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Blearner`\n",
    "\n",
    "Instead of constructing our low-level `Learner`, we can use the `Blearner` class which provides sensible defaults for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "class Blearner(Learner):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your fastai DataLoaders\n",
    "        dls: DataLoaders,\n",
    "        # Your pretrained Hugging Face transformer\n",
    "        hf_model: PreTrainedModel,\n",
    "        # Your `BaseModelCallback`\n",
    "        base_model_cb: BaseModelCallback = BaseModelCallback,\n",
    "        # Any kwargs you want to pass to your `BLearner`\n",
    "        **kwargs\n",
    "    ) -> Learner:\n",
    "        \"\"\"\n",
    "        Returns a Blurr friendly `Learner` ready for model training\n",
    "        \"\"\"\n",
    "        model = kwargs.get(\"model\", BaseModelWrapper(hf_model))\n",
    "        splitter = kwargs.pop(\"splitter\", blurr_splitter)\n",
    "        loss_func = kwargs.pop(\"loss_func\", dls.loss_func if hasattr(dls, \"loss_func\") else None)\n",
    "\n",
    "        # if we are letting the Hugging Face model calculate the loss for us (which is the default), we update\n",
    "        # our loss function here to simply used the correct `PrecalculatedLoss`\n",
    "        tfm = first_blurr_tfm(dls)\n",
    "        if hasattr(tfm, \"include_labels\") and tfm.include_labels:\n",
    "            if isinstance(loss_func, CrossEntropyLossFlat):\n",
    "                loss_func = PreCalculatedCrossEntropyLoss()\n",
    "            elif isinstance(loss_func, BCEWithLogitsLossFlat):\n",
    "                loss_func = PreCalculatedBCELoss()\n",
    "            elif isinstance(loss_func.func, nn.MSELoss):\n",
    "                loss_func = PreCalculatedMSELoss()\n",
    "\n",
    "        super().__init__(dls, model=model, loss_func=loss_func, splitter=splitter, **kwargs)\n",
    "\n",
    "        self.add_cb(base_model_cb)\n",
    "        self.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Blearner(dls, hf_model, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.358829</td>\n",
       "      <td>0.235570</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You don't need to read this review.&lt;br /&gt;&lt;br /&gt;An earlier review, by pninson of Seattle, has already identified all the main shortcomings of this production. I can only amplify its basic arguments.&lt;br /&gt;&lt;br /&gt;Bleak House was a relatively late Dickens novel and is much darker than his earlier work. This is taken too literally by the director, Ross Devenish, who piles on the gloom and fog too much. When Ada, Rick and Esther appear, half an hour into the opening episode, it is a relief just to be</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This TV production of 1970 starring Susannah York and George C. Scott is another proof of how difficult it is to adopt \"Jane Eyre\" to the screen, and how much can go wrong in doing so. It is true that the movie suffered in the transfer to DVD - some scenes which were complete in the original were shortened and so badly edited that there are striking continuity gaps and that even one crucial scene between Jane and Rochester starts in the middle of a sentence! But even if the editing were better,</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'pos',\n",
       "  'score': 0.8155084848403931,\n",
       "  'class_index': 1,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.18449150025844574, 0.8155084848403931]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neg',\n",
       "  'score': 0.9165473580360413,\n",
       "  'class_index': 0,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.9165473580360413, 0.08345270156860352]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `BlearnerForSequenceClassification`\n",
    "\n",
    "We also introduce a classification task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSequenceClassification(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    def predict(self, text):\n",
    "        return self.blurr_predict(text)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForSequenceClassification\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else tuple(r[inp] for inp in attr)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_y(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else [r[inp] for inp in attr]\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: Optional[int] = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if n_labels is None:\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                n_labels = len(label_attr) if (is_listy(label_attr)) else len(data[label_attr].unique())\n",
    "            else:\n",
    "                n_labels = len(label_attr) if (is_listy(label_attr)) else len(set([item[label_attr] for item in data]))\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=cls.get_model_cls(), config_kwargs={\"num_labels\": n_labels}\n",
    "        )\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # infer loss function and default metrics\n",
    "        if is_listy(label_attr):\n",
    "            trg_block = MultiCategoryBlock(encoded=True, vocab=label_attr)\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1ScoreMulti(), accuracy_multi])\n",
    "        else:\n",
    "            trg_block = CategoryBlock\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1Score(), accuracy])\n",
    "\n",
    "        # build our DataBlock and DataLoaders\n",
    "        blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), trg_block)\n",
    "        dblock = DataBlock(\n",
    "            blocks=blocks, get_x=partial(cls._get_x, attr=text_attr), get_y=partial(cls._get_y, attr=label_attr), splitter=dblock_splitter\n",
    "        )\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Mid-level API building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification.from_data(\n",
    "    imdb_df, \"distilroberta-base\", text_attr=\"text\", label_attr=\"label\", dl_kwargs={\"bs\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.319669</td>\n",
       "      <td>0.279372</td>\n",
       "      <td>0.893401</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As an ancient movie fan, I had heard much about the controversial movie CALIGULA assessed ambiguously as one of the most realistic epics by some and as one of the most disgusting porn movies by others. I decided to see it in the entire uncut version to evaluate it myself hoping to find something positive that would make justice to the many accusations towards the film. I sat down in my chair one autumn evening and started to watch. The beginning quotation from the New Testament shocked me a bit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Documentaries in which sons and daughters seek to understand a parent and, by the process, their own lives are not that uncommon. Also not uncommon are results that reflect lack of talent, a failure of introspection, an abundance of narcissism and, perhaps, an unsubtle quest for publicly-splashed revenge for countless past hurts, real and fantasized. What is unusual is a brilliant, fair and engrossing portrait of a fascinating parent and \"My Architect: A Son's Journey\" is that rare achievement.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '1',\n",
       "  'score': 0.8121861815452576,\n",
       "  'class_index': 1,\n",
       "  'class_labels': [0, 1],\n",
       "  'probs': [0.187813863158226, 0.8121861815452576]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '0',\n",
       "  'score': 0.9281742572784424,\n",
       "  'class_index': 0,\n",
       "  'class_labels': [0, 1],\n",
       "  'probs': [0.9281742572784424, 0.07182577252388]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Low-level API building blocks\n",
    "\n",
    "Thanks to the `TextDataLoader`, there isn't really anything you have to do to use plain ol' PyTorch or fast.ai `Dataset`s and `DataLoaders` with Blurr.  Let's take a look at fine-tuning a model against Glue's MRPC dataset ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build your Hugging Face objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e2d4789b164b06bace84b5b9311ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from blurr.text.data.core import preproc_hf_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f3774ba9358a732c.arrow\n",
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-84263331ad583603.arrow\n",
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b7fe644c800de3c0.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return hf_tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build your `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = raw_datasets[\"train\"].features[\"label\"].names\n",
    "\n",
    "trn_dl = TextDataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_decode_kwargs={\"labels\": label_names},\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "val_dl = TextDataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_decode_kwargs={\"labels\": label_names},\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define your `Blearner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification(dls, hf_model, loss_func=PreCalculatedCrossEntropyLoss())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=6.30957365501672e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>0.468044</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.519991</td>\n",
       "      <td>0.469563</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.478303</td>\n",
       "      <td>0.469889</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-8, 1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spansion products are to be available from both AMD and Fujitsu, AMD said. Spansion Flash memory solutions are available worldwide from AMD and Fujitsu.</td>\n",
       "      <td>equivalent</td>\n",
       "      <td>equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, EPA officials would not confirm the 20 percent figure. Only in the past few weeks have officials settled on the 20 percent figure.</td>\n",
       "      <td>not_equivalent</td>\n",
       "      <td>not_equivalent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlbertForSequenceClassification',\n",
       " 'BartForSequenceClassification',\n",
       " 'BertForSequenceClassification',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CanineForSequenceClassification',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'HubertForSequenceClassification',\n",
       " 'IBertForSequenceClassification',\n",
       " 'LEDForSequenceClassification',\n",
       " 'LayoutLMForSequenceClassification',\n",
       " 'LayoutLMv2ForSequenceClassification',\n",
       " 'LongformerForSequenceClassification',\n",
       " 'MBartForSequenceClassification',\n",
       " 'MPNetForSequenceClassification',\n",
       " 'MegatronBertForSequenceClassification',\n",
       " 'MobileBertForSequenceClassification',\n",
       " 'NystromformerForSequenceClassification',\n",
       " 'OpenAIGPTForSequenceClassification',\n",
       " 'PerceiverForSequenceClassification',\n",
       " 'ReformerForSequenceClassification',\n",
       " 'RemBertForSequenceClassification',\n",
       " 'RoFormerForSequenceClassification',\n",
       " 'RobertaForSequenceClassification',\n",
       " 'SEWDForSequenceClassification',\n",
       " 'SEWForSequenceClassification',\n",
       " 'SqueezeBertForSequenceClassification',\n",
       " 'TransfoXLForSequenceClassification',\n",
       " 'UniSpeechForSequenceClassification',\n",
       " 'UniSpeechSatForSequenceClassification',\n",
       " 'Wav2Vec2ForSequenceClassification',\n",
       " 'WavLMForSequenceClassification',\n",
       " 'XLMForSequenceClassification',\n",
       " 'XLMRobertaForSequenceClassification',\n",
       " 'XLNetForSequenceClassification',\n",
       " 'YosoForSequenceClassification']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "[model_type for model_type in NLP.get_models(task=\"SequenceClassification\") if (not model_type.startswith(\"TF\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "pretrained_model_names = [\n",
    "    \"hf-internal-testing/tiny-albert\",\n",
    "    \"hf-internal-testing/tiny-random-bart\",\n",
    "    \"hf-internal-testing/tiny-bert\",\n",
    "    \"google/bigbird-roberta-base\",\n",
    "    \"google/bigbird-pegasus-large-arxiv\",\n",
    "    \"hf-internal-testing/tiny-random-ctrl\",\n",
    "    \"camembert-base\",\n",
    "    \"hf-internal-testing/tiny-random-canine\",\n",
    "    \"YituTech/conv-bert-base\",\n",
    "    \"hf-internal-testing/tiny-deberta\",\n",
    "    \"hf-internal-testing/tiny-random-deberta-v2\",\n",
    "    \"hf-internal-testing/tiny-random-distilbert\",\n",
    "    \"hf-internal-testing/tiny-electra\",\n",
    "    \"google/fnet-base\",\n",
    "    \"hf-internal-testing/tiny-random-flaubert\",\n",
    "    \"hf-internal-testing/tiny-random-funnel\",\n",
    "    \"hf-internal-testing/tiny-random-gpt2\",\n",
    "    \"anton-l/gpt-j-tiny-random\",\n",
    "    \"hf-internal-testing/tiny-random-gpt_neo\",\n",
    "    \"kssteven/ibert-roberta-base\",\n",
    "    \"hf-internal-testing/tiny-random-led\",\n",
    "    \"hf-internal-testing/tiny-random-longformer\",\n",
    "    \"hf-internal-testing/tiny-random-mbart\",\n",
    "    \"hf-internal-testing/tiny-random-mpnet\",\n",
    "    # \"nvidia/megatron-bert-cased-345m\",                 could not test\n",
    "    \"hf-internal-testing/tiny-random-mobilebert\",\n",
    "    \"openai-gpt\",\n",
    "    \"google/reformer-crime-and-punishment\",\n",
    "    \"google/rembert\",\n",
    "    \"junnyu/roformer_chinese_sim_char_ft_small\",\n",
    "    \"roberta-base\",\n",
    "    \"squeezebert/squeezebert-uncased\",\n",
    "    \"hf-internal-testing/tiny-random-transfo-xl\",\n",
    "    \"xlm-mlm-en-2048\",\n",
    "    \"xlm-roberta-base\",\n",
    "    \"xlnet-base-cased\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37139db9c44c4e22a8a236857f465d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-bb082f8a90ea273a.arrow\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-5a941c558a0690b2.arrow\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "raw_datasets = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "raw_datasets[0] = raw_datasets[0].add_column(\"is_valid\", [False] * len(raw_datasets[0]))\n",
    "raw_datasets[1] = raw_datasets[1].add_column(\"is_valid\", [True] * len(raw_datasets[1]))\n",
    "\n",
    "final_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n",
    "imdb_df = pd.DataFrame(final_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-albert ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \"big trail\" director raoul walsh's first</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tartbr /br /date of review - 5/26/02b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-bart ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First off, the editing of this film consisted of one major flaw which I don't underst</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-bert ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date of review - 5 / 26 / 02 &lt; br / &gt; &lt; br / &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/bigbird-roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbig_bird\n",
      "tokenizer:\tBigBirdTokenizerFast\n",
      "model:\t\tBigBirdForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/bigbird-pegasus-large-arxiv ===\n",
      "\n",
      "architecture:\tbigbird_pegasus\n",
      "tokenizer:\tPegasusTokenizerFast\n",
      "model:\t\tBigBirdPegasusForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tartbr /&gt;br /&gt;Date of review - 5/26/02br /&gt;br /&gt;Year of movie - 2001br</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-ctrl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/transformers/models/ctrl/modeling_ctrl.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / d_model_size)\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tctrl\n",
      "tokenizer:\tCTRLTokenizer\n",
      "model:\t\tCTRLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat inaccurate but wholly exhilarating biography of cavalry officer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie -</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, esp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-canine ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tcanine\n",
      "tokenizer:\tCanineTokenizer\n",
      "model:\t\tCanineForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered consi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YituTech/conv-bert-base ===\n",
      "\n",
      "architecture:\tconvbert\n",
      "tokenizer:\tConvBertTokenizerFast\n",
      "model:\t\tConvBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray charles, has much in common with</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-deberta ===\n",
      "\n",
      "architecture:\tdeberta\n",
      "tokenizer:\tDebertaTokenizerFast\n",
      "model:\t\tDebertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-deberta-v2 ===\n",
      "\n",
      "architecture:\tdeberta_v2\n",
      "tokenizer:\tDebertaV2Tokenizer\n",
      "model:\t\tDebertaV2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001&lt;br /&gt;&lt;br</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-distilbert ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of bi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-electra ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul wal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the monkees, surprisingly, are a big favorite of mine. yes, they might have</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/fnet-base ===\n",
      "\n",
      "architecture:\tfnet\n",
      "tokenizer:\tFNetTokenizerFast\n",
      "model:\t\tFNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-flaubert ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \" Big Trail \" director Raoul Walsh' s first-rate western \" Th</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, especially the really</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-funnel ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "model:\t\tFunnelForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-gpt2 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt2\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPT2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== anton-l/gpt-j-tiny-random ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgptj\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPTJForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, especially the really bad ones. So I wouldn't call it naive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-gpt_neo ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt_neo\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPTNeoForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== kssteven/ibert-roberta-base ===\n",
      "\n",
      "architecture:\tibert\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tIBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story of Ray Charles, has much in common with \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-led ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-longformer ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell mo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mpnet ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "model:\t\tMPNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mobilebert ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of bi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== openai-gpt ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\topenai\n",
      "tokenizer:\tOpenAIGPTTokenizerFast\n",
      "model:\t\tOpenAIGPTForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on, \" a somewhat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray charles, has much in common with \" walk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/reformer-crime-and-punishment ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\treformer\n",
      "tokenizer:\tReformerTokenizerFast\n",
      "model:\t\tReformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/rembert ===\n",
      "\n",
      "architecture:\trembert\n",
      "tokenizer:\tRemBertTokenizerFast\n",
      "model:\t\tRemBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001&lt;br /&gt;&lt;br</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== junnyu/roformer_chinese_sim_char_ft_small ===\n",
      "\n",
      "architecture:\troformer\n",
      "tokenizer:\tRoFormerTokenizerFast\n",
      "model:\t\tRoFormerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul w</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "model:\t\tSqueezeBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first off, the editing of this film consisted of one major flaw which i don't understand how was missed - you consistently see the overhead microphones</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-transfo-xl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\ttransfo_xl\n",
      "tokenizer:\tTransfoXLTokenizer\n",
      "model:\t\tTransfoXLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat inaccurate</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray,\" the story of Ray Charles, has much in common with \"Walk the Line</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first-rate western \" they died with their boots on, \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray, \" the story of ray charles, has much in common with \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Die</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story of Ray Charles, has much in common with</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "bsz = 2\n",
    "seq_sz = 32\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    # 1. get/configure our Hugging Face objects\n",
    "    tok_class = RobertaTokenizer if (\"/ibert\" in model_name) else None\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(\n",
    "        model_name, model_cls=model_cls, tokenizer_cls=tok_class, config_kwargs={\"num_labels\": 2}\n",
    "    )\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if hf_tokenizer.pad_token is None:\n",
    "        hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "    try:\n",
    "        learn = None\n",
    "\n",
    "        # 2. get our DataLoaders\n",
    "        blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=seq_sz, padding=\"max_length\"), CategoryBlock)\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=ColSplitter(col=\"is_valid\"))\n",
    "\n",
    "        dls = dblock.dataloaders(imdb_df, bs=bsz)\n",
    "\n",
    "        # 3. configure our Learner\n",
    "        model = BaseModelWrapper(hf_model)\n",
    "        learn = Learner(\n",
    "            dls,\n",
    "            model,\n",
    "            opt_func=partial(Adam),\n",
    "            loss_func=CrossEntropyLossFlat(),\n",
    "            metrics=[accuracy],\n",
    "            cbs=[BaseModelCallback],\n",
    "            splitter=blurr_splitter,\n",
    "        )\n",
    "\n",
    "        learn.freeze()\n",
    "\n",
    "        b = dls.one_batch()\n",
    "\n",
    "        # 4. train\n",
    "        print(\"*** TESTING DataLoaders ***\")\n",
    "        test_eq(len(b), bsz)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(len(preds[0]), bsz)\n",
    "        #         test_eq(preds[0].shape, torch.Size([bsz, 2]))\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=ShortEpochCallback(pct=0.2, short_valid=True))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        if learn:\n",
    "            del learn\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big_bird</td>\n",
       "      <td>BigBirdTokenizerFast</td>\n",
       "      <td>BigBirdForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigbird_pegasus</td>\n",
       "      <td>PegasusTokenizerFast</td>\n",
       "      <td>BigBirdPegasusForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>CTRLTokenizer</td>\n",
       "      <td>CTRLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>canine</td>\n",
       "      <td>CanineTokenizer</td>\n",
       "      <td>CanineForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>convbert</td>\n",
       "      <td>ConvBertTokenizerFast</td>\n",
       "      <td>ConvBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deberta</td>\n",
       "      <td>DebertaTokenizerFast</td>\n",
       "      <td>DebertaForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mat1 and mat2 shapes cannot be multiplied (2x32 and 768x768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deberta_v2</td>\n",
       "      <td>DebertaV2Tokenizer</td>\n",
       "      <td>DebertaV2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fnet</td>\n",
       "      <td>FNetTokenizerFast</td>\n",
       "      <td>FNetForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>forward() got an unexpected keyword argument 'output_attentions'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPT2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gptj</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPTJForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt_neo</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPTNeoForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ibert</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>IBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>openai</td>\n",
       "      <td>OpenAIGPTTokenizerFast</td>\n",
       "      <td>OpenAIGPTForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>reformer</td>\n",
       "      <td>ReformerTokenizerFast</td>\n",
       "      <td>ReformerForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>If training, make sure that config.axial_pos_shape factors: (512, 1024) multiply to sequence length. Got prod((512, 1024)) != sequence_length: 32. You might want to consider padding your sequence length to 524288 or changing config.axial_pos_shape.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rembert</td>\n",
       "      <td>RemBertTokenizerFast</td>\n",
       "      <td>RemBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>roformer</td>\n",
       "      <td>RoFormerTokenizerFast</td>\n",
       "      <td>RoFormerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>TransfoXLTokenizer</td>\n",
       "      <td>TransfoXLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 10.91 GiB total capacity; 8.84 GiB already allocated; 7.25 MiB free; 9.18 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=[\"arch\", \"tokenizer\", \"model\", \"result\", \"error\"])\n",
    "display_df(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental building blocks for training using `BLURR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
