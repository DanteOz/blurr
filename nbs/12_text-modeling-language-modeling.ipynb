{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp text.modeling.language_modeling\n",
    "#|default_cls_lvl 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text.modeling.language_modeling\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... for both causal and MLM language modeling tasks. This includes things like training BERT from scratch or fine-tuning a particular pre-trained LM on your own corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import ast, gc, inspect, os\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import perplexity\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoModelForCausalLM, AutoModelForMaskedLM, logging, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "\n",
    "from blurr.text.data.core import TextDataLoader, TextBlock, first_blurr_tfm\n",
    "from blurr.text.data.language_modeling import (\n",
    "    BaseLMStrategy,\n",
    "    LMBatchTokenizeTransform,\n",
    "    LMPreprocessor,\n",
    "    LMType,\n",
    "    CausalLMTextInput,\n",
    "    CausalLMStrategy,\n",
    "    MLMTextInput,\n",
    "    BertMLMStrategy,\n",
    ")\n",
    "\n",
    "from blurr.text.modeling.core import Blearner\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.6\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "#|hide_input\n",
    "import pdb\n",
    "\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.text.modeling.core import BaseModelWrapper, BaseModelCallback, blurr_splitter\n",
    "from blurr.text.utils import BlurrText\n",
    "\n",
    "NLP = BlurrText()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this example, we'll use the `WIKITEXT_TINY` dataset available from fastai to demonstrate how to configure BLURR code for language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Big Boy ( song ) = \\n \\n \" Big Boy \" &lt;unk&gt; \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and &lt;unk&gt; composit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica &lt;unk&gt; and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will &lt;unk&gt; ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family &lt;unk&gt; . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf &lt;unk&gt; cup , &lt;unk&gt; &lt;unk&gt; cup , or pixie cup . The small , &lt;unk&gt; @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0  \\\n",
       "0   \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...   \n",
       "1   \\n = Big Boy ( song ) = \\n \\n \" Big Boy \" <unk> \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...   \n",
       "2   \\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and <unk> composit...   \n",
       "3   \\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica <unk> and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will <unk> ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...   \n",
       "4   \\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family <unk> . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf <unk> cup , <unk> <unk> cup , or pixie cup . The small , <unk> @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_path = untar_data(URLs.WIKITEXT_TINY)\n",
    "\n",
    "train_df = pd.read_csv(wiki_path / \"train.csv\", header=None)\n",
    "valid_df = pd.read_csv(wiki_path / \"test.csv\", header=None)\n",
    "\n",
    "train_df[\"is_valid\"] = False\n",
    "valid_df[\"is_valid\"] = True\n",
    "\n",
    "df = pd.concat([train_df, valid_df])\n",
    "\n",
    "print(len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LMMetricsCallback` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LMMetricsCallback(Callback):\n",
    "    \"\"\"A fastai friendly metric implemented as a callback so that we can handle use cases where we don't\n",
    "    want to count tokens marked to be ignored or else not count batches where there are no targs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.run_before = Recorder\n",
    "\n",
    "        self.custom_metrics_dict = {\"lm_accuracy\": None}\n",
    "        self.do_setup = True\n",
    "\n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if not self.do_setup:\n",
    "            return\n",
    "\n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "\n",
    "        self.do_setup = False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.setup()\n",
    "\n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        # do this only for validation set\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0]  # yb is TensorText tuple, item 0 is the data\n",
    "\n",
    "        msk = torch.where(targs != -100, 1, 0).bool()\n",
    "        preds = torch.masked_select(preds, msk).cpu()\n",
    "        targs = torch.masked_select(targs, msk).cpu()\n",
    "\n",
    "        if preds.shape[0] == 0:\n",
    "            return\n",
    "\n",
    "        self.results += [(res[0], res[1]) for res in zip(preds, targs)]\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self):\n",
    "        self.results = []\n",
    "\n",
    "    def after_validate(self):\n",
    "        if len(self.results) < 1:\n",
    "            return\n",
    "\n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        self.custom_metrics_dict[\"lm_accuracy\"] = accuracy_score(targs, preds)\n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key):\n",
    "        return self.custom_metrics_dict[metric_key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll add helpful metrics for calculating accuracy and perplexity for both causal and masked language modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal Language Modeling\n",
    "\n",
    "In causal language modeling, we are attempting to predict the next token given those before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "model_cls = AutoModelForCausalLM\n",
    "\n",
    "pretrained_model_name = \"gpt2\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "if hf_tokenizer.pad_token is None:\n",
    "    hf_tokenizer.pad_token = \"[PAD]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\n",
    "proc_df = preprocessor.process_df(train_df, valid_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=CausalLMStrategy)\n",
    "blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=CausalLMTextInput), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 129]), torch.Size([2, 129]), torch.Size([2, 129]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>₹ 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = &lt;unk&gt; = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at &lt;unk&gt; police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from</td>\n",
       "      <td>�� 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = &lt;unk&gt; = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at &lt;unk&gt; police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n &lt;|endoftext|&gt;  Wins, L \\n = Losses, T = \\n &lt;|endoftext|&gt;  \\n = New York State Route 164 = \\n \\n New York State Route 164 ( NY 164 ) is a short state highway located entirely in the town of Patterson in northeastern Putnam County, New York, in the United States. It is a short, two @-@ lane back road that does not pass through any major populated areas and serves primarily as a connector between NY 311 and NY 22. NY 164 also allows for faster passage from Interstate 84 ( I @-@ 84 ) to the Putnam Lak</td>\n",
       "      <td>\\n   Wins, L \\n = Losses, T = \\n   \\n = New York State Route 164 = \\n \\n New York State Route 164 ( NY 164 ) is a short state highway located entirely in the town of Patterson in northeastern Putnam County, New York, in the United States. It is a short, two @-@ lane back road that does not pass through any major populated areas and serves primarily as a connector between NY 311 and NY 22. NY 164 also allows for faster passage from Interstate 84 ( I @-@ 84 ) to the Putnam Lake area via NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "fit_cbs = [LMMetricsCallback()]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "    cbs=[BaseModelCallback],\n",
    "    metrics=[perplexity],\n",
    "    splitter=blurr_splitter,\n",
    ").to_fp16()\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaseModelWrapper (Input shape: 2 x 129)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 129 x 768       \n",
       "Embedding                                 38597376   False     \n",
       "Embedding                                 786432     False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 2304      \n",
       "Conv1D                                    1771776    False     \n",
       "Conv1D                                    590592     False     \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 3072      \n",
       "Conv1D                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 768       \n",
       "Conv1D                                    2360064    False     \n",
       "Dropout                                                        \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 129 x 50257     \n",
       "Linear                                    38597376   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 163,037,184\n",
       "Total trainable params: 38,400\n",
       "Total non-trainable params: 162,998,784\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7f11a241a160>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #4\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - BaseModelCallback\n",
       "  - MixedPrecision\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide_output\n",
    "learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = dls.one_batch()\n",
    "# preds = learn.model(b[0])\n",
    "# len(preds),preds[0], preds[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.0033113110810518267, steep=2.0892961401841603e-05, valley=0.0014454397605732083, slide=0.0020892962347716093)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.501945</td>\n",
       "      <td>3.165918</td>\n",
       "      <td>23.710508</td>\n",
       "      <td>0.417112</td>\n",
       "      <td>24:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=3e-3, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_CausalLMInput` typed inputs\n",
    "    x: CausalLMTextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):\n",
    "    # grab our tokenizer and ignore token to decode\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    ignore_token_id = tfm.ignore_token_id\n",
    "\n",
    "    res = L(\n",
    "        [\n",
    "            (\n",
    "                hf_tokenizer.decode(s[0], skip_special_tokens=True)[:trunc_at],\n",
    "                hf_tokenizer.decode(s[1][s[1] != ignore_token_id], skip_special_tokens=True)[:trunc_at],\n",
    "                hf_tokenizer.decode(pred[0], skip_special_tokens=True)[:trunc_at],\n",
    "            )\n",
    "            for s, pred in zip(samples, outs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"target\", \"prediction\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. \\n The German government has said that it does not consider Scientology a religion, but a \" commercial enterprise with a history of taking advantage of vulnerable individuals and an extreme dislike of any criticism \" whose \" totalitarian structure a</td>\n",
       "      <td>\\n The German government has said that it does not consider Scientology a religion, but a \" commercial enterprise with a history of taking advantage of vulnerable individuals and an extreme dislike of any criticism \" whose \" totalitarian structure an</td>\n",
       "      <td>&lt;\\n  &lt; &lt; was been that the will not want the to threat, but that \" cult \" \" a religious of religious advantage of the individuals \" families interest form of the form of. \" &lt; \" \" political \" be a threat to the \"s national system \". , the government g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>security concerns — has ensured that Australian strategic policy has often been defined by relations with its allies. Regardless, a tendency towards strategic &lt;unk&gt; has also been evident, with Australians often reluctant to think about defence issue</td>\n",
       "      <td>concerns — has ensured that Australian strategic policy has often been defined by relations with its allies. Regardless, a tendency towards strategic &lt;unk&gt; has also been evident, with Australians often reluctant to think about defence issues or to &lt;</td>\n",
       "      <td>and. including been that the troops planners is been been based by the between the allies. The of the strong to a isolationunk&gt; has been been evident in with Australia increasingly preferring to engage that the policy. the considerunk&gt; their. they n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': ' Blurr is fun to work with because of the high probability of a problem solving approach , a trait common to many of the early problems of physics . \" The concept of \" \\' abstract \\' problems \" may be the first to describe what is meant'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masked Language Modeling\n",
    "\n",
    "In masked language modeling (MLM), we are attempting to predict the ***masked*** tokens. In Blurr, these are encapsulated by classes implementing the `BaseLMStrategy` base class.\n",
    "\n",
    "For a list of some of the more common strategies, see table 3 of the [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) paper.  When fine-tuning a MLM model. you'll want to make sure you use the same approach as the model authors should you be looking to reproduce their results ... but our approach here makes it easy to play with different strategies regardless.\n",
    "\n",
    "In the example below, we'll tell Blurr we want to use the BERT-style masking strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForMaskedLM\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "if hf_tokenizer.pad_token is None:\n",
    "    hf_tokenizer.pad_token = \"[PAD]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\n",
    "proc_df = preprocessor.process_df(train_df, valid_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=BertMLMStrategy)\n",
    "blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=MLMTextInput), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 130]), torch.Size([2, 130]), torch.Size([2, 130]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;mask&gt; � � u  — &lt;mask&gt;  to &lt;mask&gt;  retire  officers  with  more  than  25  years [ of]  service ,  as  they  thought  them  to  be    and  ineffective , [ Oliv]  most  importantly ,  rivals  for  power [.]  Most  of &lt;mask&gt;  older  officers  had  more  experience  under  the  Vietnamese  National  Army &lt;mask&gt;  the  French  colonial  era ,  and  some  of  the  younger  men  saw  them  as  too  detached  from  the  modern  situation .  The  Young  Turks  had  quite  a &lt;mask&gt;  of  influence  over  Kh &lt;mask&gt; h ,  as  Th i  and  K � � �  had  intervened  milit arily  to  save &lt;mask&gt;  from  a &lt;mask&gt;  attempt  in  September  by &lt;mask&gt; als    V [�] � n &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; � � � � &lt;mask&gt;  V &lt;mask&gt; �</td>\n",
       "      <td>[ �] � � u  — [ wanted]  to [ forcibly]  retire  officers  with  more  than  25  years [ of]  service ,  as  they  thought  them  to  be    and  ineffective , [ but]  most  importantly ,  rivals  for  power [.]  Most  of [ the]  older  officers  had  more  experience  under  the  Vietnamese  National  Army [ during]  the  French  colonial  era ,  and  some  of  the  younger  men  saw  them  as  too  detached  from  the  modern  situation .  The  Young  Turks  had  quite  a [ lot]  of  influence  over  Kh [án] h ,  as  Th i  and  K � � �  had  intervened  milit arily  to  save [ him]  from  a [ coup]  attempt  in  September  by [ Gener] als    V [�] � n [ ] [ and] [ D] � � � � [ng]  V [�] �</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;mask&gt; \\n  During  the &lt;mask&gt;  1990 s , &lt;mask&gt;  major &lt;mask&gt;  were  disbanded  and  a &lt;mask&gt;  of  equipment [ was]  phased  out  or  scrapped &lt;mask&gt;  to  a  severe  shortage  of  funds .  The  whole  land  forces  structure &lt;mask&gt;  re organized &lt;mask&gt; &lt;mask&gt;  into  territorial [ corps] ,  and  from [ reg] iments  into  batt alions .  In  the  mid  @ - @  1990 s ,  the  situation  of  the &lt;mask&gt;  forces  was  critical  : [ FM]  military  budget &lt;mask&gt;  three  times  lower  than  in  1989  (    million  dollars  ) ,  50  %  of  the  equipment  was  older  than  30  years ,  and  60  %  of  the  armoured  vehicles  and  85  %  of &lt;mask&gt;  missile  units  were  non &lt;mask&gt; - @  operational &lt;mask&gt;  Due &lt;mask&gt;  lack  of</td>\n",
       "      <td>[ ] \\n  During  the [ early]  1990 s , [ some]  major [ units]  were  disbanded  and  a [ lot]  of  equipment [ was]  phased  out  or  scrapped [ due]  to  a  severe  shortage  of  funds .  The  whole  land  forces  structure [ was]  re organized [ from] [ armies]  into  territorial [ corps] ,  and  from [ reg] iments  into  batt alions .  In  the  mid  @ - @  1990 s ,  the  situation  of  the [ land]  forces  was  critical  : [ the]  military  budget [ was]  three  times  lower  than  in  1989  (    million  dollars  ) ,  50  %  of  the  equipment  was  older  than  30  years ,  and  60  %  of  the  armoured  vehicles  and  85  %  of [ the]  missile  units  were  non [ @] - @  operational [.]  Due [ to]  lack  of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "fit_cbs = [LMMetricsCallback()]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam, decouple_wd=True),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "    cbs=[BaseModelCallback],\n",
    "    metrics=[perplexity],\n",
    "    splitter=blurr_splitter,\n",
    ").to_fp16()\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaseModelWrapper (Input shape: 2 x 130)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 130 x 768       \n",
       "Embedding                                 38603520   False     \n",
       "Embedding                                 394752     False     \n",
       "Embedding                                 768        False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "LayerNorm                                 1536       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 130 x 50265     \n",
       "Linear                                    38653785   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 120,773,721\n",
       "Total trainable params: 612,096\n",
       "Total non-trainable params: 120,161,625\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7f11a241a160>, decouple_wd=True)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - BaseModelCallback\n",
       "  - MixedPrecision\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide_output\n",
    "learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.0005248074419796466, steep=1.3182567499825382e-06, valley=0.0003311311302240938, slide=0.0004786300996784121)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.898339</td>\n",
       "      <td>1.804883</td>\n",
       "      <td>6.079262</td>\n",
       "      <td>0.642062</td>\n",
       "      <td>44:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-4, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_MLMInput` typed inputs\n",
    "    x: MLMTextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer and ignore token to decode\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    ignore_token_id = tfm.ignore_token_id\n",
    "\n",
    "    # grab our mask token id and do-not-mask token ids\n",
    "    mask_token_id = hf_tokenizer.mask_token_id\n",
    "\n",
    "    vocab = hf_tokenizer.get_vocab()\n",
    "    dnm_tok_ids = [vocab[tok] for tok in list(hf_tokenizer.special_tokens_map.values()) if vocab[tok] != mask_token_id]\n",
    "\n",
    "    res = L()\n",
    "    for s, t in zip(samples, outs):\n",
    "        # exclue dnm tokens from input\n",
    "        inps = [\n",
    "            hf_tokenizer.decode(tok_id) if (tok_id == mask_token_id or s[1][idx] == ignore_token_id) else f\"[{hf_tokenizer.decode(tok_id)}]\"\n",
    "            for idx, tok_id in enumerate(s[0])\n",
    "            if (tok_id not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        # replaced masked tokens with \"[{actual_token}]\"\n",
    "        trgs = [\n",
    "            hf_tokenizer.decode(s[0][idx]) if (tok_id == ignore_token_id) else f\"[{hf_tokenizer.decode(tok_id)}]\"\n",
    "            for idx, tok_id in enumerate(s[1])\n",
    "            if (s[0][idx] not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        # same as above except we replace the [MASK] with the PREDICTED token\n",
    "        preds = [\n",
    "            hf_tokenizer.decode(s[0][idx]) if (tok_id == ignore_token_id) else f\"[{hf_tokenizer.decode(t[0][idx])}]\"\n",
    "            for idx, tok_id in enumerate(s[1])\n",
    "            if (s[0][idx] not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        res.append((\" \".join(inps[:trunc_at]).strip(), \" \".join(trgs[:trunc_at]).strip(), \" \".join(preds[:trunc_at]).strip()))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"target\", \"prediction\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;mask&gt;  when  the  sett ler  ' s  presence  led  to  competition  over  resources &lt;mask&gt;  and  to  the  occupation  of  the [ indigenous]  inhabitants  '  lands .  European  diseases  dec imated  Aboriginal  populations ,  and  the  occupation &lt;mask&gt; &lt;mask&gt;  of  lands &lt;mask&gt;  food  resources  sometimes &lt;mask&gt;  to  starvation . &lt;mask&gt;  and  large  neither  the  British  nor &lt;mask&gt;    approached  the  conflict  in  an  organised  sense  and  conflict &lt;mask&gt;  between  groups  of &lt;mask&gt;  and  individual  tribes  rather &lt;mask&gt;  systematic  warfare .  At  times &lt;mask&gt;  however ,  the  frontier  wars  did  see  the  involvement  of  British  soldiers  and [ Roe]  mounted  police [ units] .  Not  all  Aboriginal &lt;mask&gt;  resisted  white [ encro] achment  on  their  lands ,  while  many   &lt;mask&gt; &lt;mask&gt;  mounted  police  units  and  were  involved  in</td>\n",
       "      <td>[ hostile]  when  the  sett ler  ' s  presence  led  to  competition  over  resources [,]  and  to  the  occupation  of  the [ indigenous]  inhabitants  '  lands .  European  diseases  dec imated  Aboriginal  populations ,  and  the  occupation [ or] [ destruction]  of  lands [ and]  food  resources  sometimes [ led]  to  starvation . [ By]  and  large  neither  the  British  nor [ the]    approached  the  conflict  in  an  organised  sense  and  conflict [ occurred]  between  groups  of [ settlers]  and  individual  tribes  rather [ than]  systematic  warfare .  At  times [,]  however ,  the  frontier  wars  did  see  the  involvement  of  British  soldiers  and [ later]  mounted  police [ units] .  Not  all  Aboriginal [ groups]  resisted  white [ encro] achment  on  their  lands ,  while  many   [ served] [ in]  mounted  police  units  and  were  involved  in</td>\n",
       "      <td>[,]  when  the  sett ler  ' s  presence  led  to  competition  over  resources [,]  and  to  the  occupation  of  the [ indigenous]  inhabitants  '  lands .  European  diseases  dec imated  Aboriginal  populations ,  and  the  occupation [ of] [ control]  of  lands [ and]  food  resources  sometimes [ led]  to  starvation . [ By]  and  large  neither  the  British  nor [ the]    approached  the  conflict  in  an  organised  sense  and  conflict [ was]  between  groups  of [ settlers]  and  individual  tribes  rather [ than]  systematic  warfare .  At  times [,]  however ,  the  frontier  wars  did  see  the  involvement  of  British  soldiers  and [ mounted]  mounted  police [ units] .  Not  all  Aboriginal [ Australians]  resisted  white [ encro] achment  on  their  lands ,  while  many   [ were] [ mounted]  mounted  police  units  and  were  involved  in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,  at  the  junction  of  the   &lt;mask&gt;  and  the   &lt;mask&gt; ,  which  included [ a]  heavy  Japanese  artillery  bombardment .  Australian  patrols  were  resumed  in  late  July  and  continued  into  August &lt;mask&gt;  These  attacks  proved  very  costly , [Fil]  amongst  the  Australian  engineers  that &lt;mask&gt; &lt;mask&gt;  with  rebuilding  the  bridges  and  roads  that  had  been  destroyed  in &lt;mask&gt;  flooding .   \\n [ Fighting] &lt;mask&gt;  the  northern &lt;mask&gt;  continued  during &lt;mask&gt;  time  also ,  and  although  preparations  in  the  south  for  the  final &lt;mask&gt; &lt;mask&gt;    continued  into  August ,  combat  operations  on  the &lt;mask&gt;  ceased &lt;mask&gt;  the &lt;mask&gt; [ came]  to  an  end  before  these  were  completed .  As  a  result ,  the  final  Australian  operations  on   &lt;mask&gt;  place</td>\n",
       "      <td>,  at  the  junction  of  the   [ River]  and  the   [ Road] ,  which  included [ a]  heavy  Japanese  artillery  bombardment .  Australian  patrols  were  resumed  in  late  July  and  continued  into  August [.]  These  attacks  proved  very  costly , [ particularly]  amongst  the  Australian  engineers  that [ were] [ tasked]  with  rebuilding  the  bridges  and  roads  that  had  been  destroyed  in [ the]  flooding .   \\n [ Fighting] [ in]  the  northern [ sector]  continued  during [ this]  time  also ,  and  although  preparations  in  the  south  for  the  final [ advance] [ towards]    continued  into  August ,  combat  operations  on  the [ island]  ceased [ as]  the [ war] [ came]  to  an  end  before  these  were  completed .  As  a  result ,  the  final  Australian  operations  on   [ took]  place</td>\n",
       "      <td>,  at  the  junction  of  the   [ River]  and  the   [ River] ,  which  included [ a]  heavy  Japanese  artillery  bombardment .  Australian  patrols  were  resumed  in  late  July  and  continued  into  August [.]  These  attacks  proved  very  costly , [ particularly]  amongst  the  Australian  engineers  that [ were] [ tasked]  with  rebuilding  the  bridges  and  roads  that  had  been  destroyed  in [ the]  flooding .   \\n [ Fighting] [ on]  the  northern [ beaches]  continued  during [ this]  time  also ,  and  although  preparations  in  the  south  for  the  final [ battles] [ on]    continued  into  August ,  combat  operations  on  the [ mainland]  ceased [ and]  the [ attacks] [ came]  to  an  end  before  these  were  completed .  As  a  result ,  the  final  Australian  operations  on   [ took]  place</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction\n",
    "\n",
    "While `Learner.blurr_generate` will work well for causal LMs designed for text generation, it won't for MLM models designed to predict masked tokens.  To accomodate the later, we add `Learner.blurr_fill_mask` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def blurr_fill_mask(\n",
    "    self: Learner,\n",
    "    # Your input_ids or raw text string with a `hf_tokenizer.mask_token`\n",
    "    inp: Union[List[int], str],\n",
    "    # The number of predictions you want to return for the [MASK]ed token\n",
    "    n_preds: int = 1,\n",
    "    # Any other keyword arguments you want applied to text generation\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"For MLM models\"\"\"\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    if isinstance(inp, str):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors=\"pt\", **tok_kwargs)\n",
    "    else:\n",
    "        # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "        input_ids = inp.as_subclass(Tensor)\n",
    "\n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    mask_token_index = torch.where(input_ids == hf_tokenizer.mask_token_id)[1]\n",
    "\n",
    "    outputs = self.model.hf_model(input_ids)\n",
    "    mask_token_logits = outputs.logits[0, mask_token_index, :]\n",
    "    preds = torch.topk(mask_token_logits, n_preds, dim=-1).indices[0].tolist()\n",
    "\n",
    "    outputs = [inp.replace(hf_tokenizer.mask_token, hf_tokenizer.decode([tok_id]).strip()) for tok_id in preds]\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best place on earth is here.',\n",
       " 'The best place on earth is America.',\n",
       " 'The best place on earth is Antarctica.',\n",
       " 'The best place on earth is mine.',\n",
       " 'The best place on earth is there.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_fill_mask(f\"The best place on earth is {hf_tokenizer.mask_token}.\", n_preds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache(), gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForLM` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForLM(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        kwargs[\"loss_func\"] = kwargs.get(\"loss_func\", PreCalculatedCrossEntropyLoss())\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self, lm_type):\n",
    "        return AutoModelForCausalLM if (lm_type == LMType.CAUSAL) else AutoModelForMaskedLM\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        return LMMetricsCallback()\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The language modeling strategy (or objective)\n",
    "        lm_strategy_cls: BaseLMStrategy = CausalLMStrategy,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # get our hf objects\n",
    "        lm_type = lm_strategy_cls.get_lm_type()\n",
    "        model_cls = cls.get_model_cls(lm_type=lm_type)\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name_or_path, model_cls=model_cls)\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # define DataBlock and DataLoaders\n",
    "        bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=lm_strategy_cls)\n",
    "\n",
    "        input_return_type = CausalLMTextInput if (lm_type == LMType.CAUSAL) else MLMTextInput\n",
    "        blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=input_return_type), noop)\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=ItemGetter(text_attr), splitter=dblock_splitter)\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance with default metrics (optional)\n",
    "        learner_kwargs[\"metrics\"] = learner_kwargs.pop(\"metrics\", [perplexity])\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `BlearnerForLM` for either Causal or Masked language models.  With one line of code, we get our DataBlock, DataLoaders, and Blearner with sensible defaults and ready for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "learn = BlearnerForLM.from_data(df, \"gpt2\", text_attr=0, dl_kwargs={\"bs\": 2}).to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = Bob Dylan = \\n \\n Bob Dylan ( / &lt;unk&gt; / ; born Robert Allen Zimmerman, May 24, 1941 ) is an American singer @-@ songwriter, artist and writer. He has been influential in popular music and culture for more than five decades. Much of his most celebrated work dates from the 1960s when his songs chronicled social unrest, although Dylan repudiated suggestions from journalists that he was a spokesman for his generation. Nevertheless, early songs such as \" Blowin'in the Wind \" and \" The Times They A</td>\n",
       "      <td>\\n = Bob Dylan = \\n \\n Bob Dylan ( / &lt;unk&gt; / ; born Robert Allen Zimmerman, May 24, 1941 ) is an American singer @-@ songwriter, artist and writer. He has been influential in popular music and culture for more than five decades. Much of his most celebrated work dates from the 1960s when his songs chronicled social unrest, although Dylan repudiated suggestions from journalists that he was a spokesman for his generation. Nevertheless, early songs such as \" Blowin'in the Wind \" and \" The Times They Ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Ireland = \\n \\n Ireland ( / &lt;unk&gt; / ; Irish : &lt;unk&gt; [ &lt;unk&gt; ] ; Ulster @-@ Scots : &lt;unk&gt; [ &lt;unk&gt; ] ) is an island in the North Atlantic. It is separated from Great Britain to its east by the North Channel, the Irish Sea, and St George's Channel. Ireland is the second @-@ largest island of the British Isles, the third @-@ largest in Europe, and the twentieth @-@ largest on Earth. \\n &lt;unk&gt;, Ireland is divided between the Republic of Ireland ( officially named Ireland ), which covers five @-@ &lt;un</td>\n",
       "      <td>\\n = Ireland = \\n \\n Ireland ( / &lt;unk&gt; / ; Irish : &lt;unk&gt; [ &lt;unk&gt; ] ; Ulster @-@ Scots : &lt;unk&gt; [ &lt;unk&gt; ] ) is an island in the North Atlantic. It is separated from Great Britain to its east by the North Channel, the Irish Sea, and St George's Channel. Ireland is the second @-@ largest island of the British Isles, the third @-@ largest in Europe, and the twentieth @-@ largest on Earth. \\n &lt;unk&gt;, Ireland is divided between the Republic of Ireland ( officially named Ireland ), which covers five @-@ &lt;unk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.519682</td>\n",
       "      <td>3.112483</td>\n",
       "      <td>22.476774</td>\n",
       "      <td>0.427281</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=3e-3, cbs=[BlearnerForLM.get_metrics_cb()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = Military history of Australia = \\n \\n The military history of Australia spans the nation's 220 @-@ year modern history, from the early Australian frontier wars between &lt;unk&gt; and Europeans to the ongoing conflicts in Iraq and Afghanistan in the ear</td>\n",
       "      <td>\\n = Military history of Australia = \\n \\n The military history of Australia spans the nation's 220 @-@ year modern history, from the early Australian frontier wars between &lt;unk&gt; and Europeans to the ongoing conflicts in Iraq and Afghanistan in the earl</td>\n",
       "      <td>\\n\\n =\\n = the\\n\\n\\n =\\n = Australian history of Australia is the period froms history years 1@ period period era. including the early days colonies to to the 18&gt; Australia &lt; &lt; the early conflict between the and Afghanistan. the 1980 1980st century. The the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Air Rhodesia Flight &lt;unk&gt; = \\n \\n Air Rhodesia Flight &lt;unk&gt; was a scheduled passenger flight that was shot down by the Zimbabwe People's Revolutionary Army ( &lt;unk&gt; ) on 3 September 1978, during the Rhodesian Bush War. The aircraft involved, a Vick</td>\n",
       "      <td>\\n = Air Rhodesia Flight &lt;unk&gt; = \\n \\n Air Rhodesia Flight &lt;unk&gt; was a scheduled passenger flight that was shot down by the Zimbabwe People's Revolutionary Army ( &lt;unk&gt; ) on 3 September 1978, during the Rhodesian Bush War. The aircraft involved, a Vicke</td>\n",
       "      <td>\\n\\n =planes\\n\\n\\n\\n&gt;\\n Air\\n =\\n = Rhodesia Flight &lt;unk&gt; = a flight flight flight from was scheduled down by a Sovietan'ss Liberation Army (Zunk&gt; ) on September August 1944. killing a liberationian civil War. The plane was in was civilian- Airickersount,'Air</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': ' Blurr is fun to work with because you be able to find easy to work with the toolkit as well as your own own personal tools.\\n\\nIf you want to take the time to you need to know that the'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masked language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForLM.from_data(df, \"bert-base-cased\", lm_strategy_cls=BertMLMStrategy, text_attr=0, dl_kwargs={\"bs\": 2}).to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= Bob [MASK] = Bob Dylan ( / &lt; un ##k &gt; / ; born Robert Allen [MASK] ##immer [MASK] , May 24 [##ott] 1941 ) is an American singer @ - @ songwriter , artist and writer . He has been influential in popular [MASK] and culture for more than five decades . Much of his most [MASK] work dates from the 1960s when his songs chronicle ##d social unrest [MASK] [Freiburg] Dylan [Chrysler] ##pu ##dia ##ted suggestions from journalists that he [MASK] a [MASK] [MASK] his generation . Nevertheless , early songs such [MASK] \" [MASK] ##low ##in ' in the Wind \" [MASK] [MASK] The Times They Are a [MASK] - @ &lt; un ##k &gt; ' \" [MASK] anthem [IS] for the American civil rights [MASK] [anti] @ - [MASK] war movements [MASK] After he left his initial base in the American folk music revival , his six @ [MASK] @ minute single [MASK] Like a [MASK] [MASK] \" altered the range of popular [MASK] in [MASK] . His mid @ - @ 1960s [MASK] , backed by rock musicians , reached [MASK] [MASK] end of the United States music charts while also attracting &lt; un ##k &gt; and criticism from others in [MASK] folk [MASK] [MASK] Dylan ' s lyrics [have] [MASK] various political , [MASK] , philosophical , and literary [MASK] . They def ##ied existing pop [MASK] conventions [MASK] appealed to the b ##urge ##oning counter [MASK] [tugging] Initially inspired by the performances</td>\n",
       "      <td>= Bob [Dylan] = Bob Dylan ( / &lt; un ##k &gt; / ; born Robert Allen [Z] ##immer [##man] , May 24 [,] 1941 ) is an American singer @ - @ songwriter , artist and writer . He has been influential in popular [music] and culture for more than five decades . Much of his most [celebrated] work dates from the 1960s when his songs chronicle ##d social unrest [,] [although] Dylan [re] ##pu ##dia ##ted suggestions from journalists that he [was] a [spokesman] [for] his generation . Nevertheless , early songs such [as] \" [B] ##low ##in ' in the Wind \" [and] [\"] The Times They Are a [@] - @ &lt; un ##k &gt; ' \" [became] anthem [##s] for the American civil rights [and] [anti] @ - [@] war movements [.] After he left his initial base in the American folk music revival , his six @ [-] @ minute single [\"] Like a [Rolling] [Stone] \" altered the range of popular [music] in [1965] . His mid @ - @ 1960s [recordings] , backed by rock musicians , reached [the] [top] end of the United States music charts while also attracting &lt; un ##k &gt; and criticism from others in [the] folk [movement] [.] Dylan ' s lyrics [have] [incorporated] various political , [social] , philosophical , and literary [influences] . They def ##ied existing pop [music] conventions [and] appealed to the b ##urge ##oning counter [##culture] [.] Initially inspired by the performances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Mortimer Wheeler = Sir Robert [MASK] Mortimer [MASK] CH , &lt; un ##k &gt; , MC [MASK] &lt; un ##k &gt; , &lt; [##and] ##k &gt; , F [Hopkins] , [MASK] un ##k &gt; ( 10 September 1890 – [MASK] July 1976 ) was a British [MASK] and officer in the British Army . [MASK] [MASK] course [MASK] his career , he served as [MASK] of both the National Museum of Wales and London Museum , [Director] @ - @ General of the Archaeological Survey of India , and the founder and Honorary Director of the [MASK] of [MASK] [MASK] [MASK] , further writing [MASK] @ - @ [four] books on archaeological subjects . Born in Glasgow to a middle [@] - @ class family , Wheeler was [Divinity] largely in Yorkshire before re ##locating to [MASK] in [##SC] [Maurice] years . After studying Classics [MASK] [MASK] College London ( UC ##L ) [MASK] he [began] working professionally in archaeology [pendant] [MASK] in the Romano @ - @ British period . During World War I he volunteered for [MASK] in [MASK] [MASK] Artillery , [MASK] stationed on the [MASK] Front , where he rose to the [MASK] of major and was awarded the Military Cross . Returning to [MASK] , he obtained his doctorate from UC ##L before taking on [MASK] [MASK] at the National Museum of Wales [MASK] [MASK] as Keeper [MASK] Archaeology and then [MASK] Director , during which time he oversaw [MASK] [MASK] the Roman forts</td>\n",
       "      <td>= Mortimer Wheeler = Sir Robert [Eric] Mortimer [Wheeler] CH , &lt; un ##k &gt; , MC [,] &lt; un ##k &gt; , &lt; [un] ##k &gt; , F [##RS] , [&lt;] un ##k &gt; ( 10 September 1890 – [22] July 1976 ) was a British [archaeologist] and officer in the British Army . [Over] [the] course [of] his career , he served as [Director] of both the National Museum of Wales and London Museum , [Director] @ - @ General of the Archaeological Survey of India , and the founder and Honorary Director of the [Institute] of [Archaeology] [in] [London] , further writing [twenty] @ - @ [four] books on archaeological subjects . Born in Glasgow to a middle [@] - @ class family , Wheeler was [raised] largely in Yorkshire before re ##locating to [London] in [his] [teenage] years . After studying Classics [at] [University] College London ( UC ##L ) [,] he [began] working professionally in archaeology [,] [specializing] in the Romano @ - @ British period . During World War I he volunteered for [service] in [the] [Royal] Artillery , [being] stationed on the [Western] Front , where he rose to the [rank] of major and was awarded the Military Cross . Returning to [Britain] , he obtained his doctorate from UC ##L before taking on [a] [position] at the National Museum of Wales [,] [first] as Keeper [of] Archaeology and then [as] Director , during which time he oversaw [excavation] [at] the Roman forts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.644017</td>\n",
       "      <td>2.414341</td>\n",
       "      <td>11.182396</td>\n",
       "      <td>0.575588</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=6e-4, cbs=[BlearnerForLM.get_metrics_cb()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= Military [MASK] of Australia = The military history of Australia spans [MASK] nation ' [MASK] 220 @ - [MASK] year modern history [cliffs] from the [MASK] [MASK] frontier wars between &lt; un ##k &gt; and Europeans to the ongoing conflicts [MASK] Iraq and Afghanistan in the early 21st [MASK] . Although this history is short [when] compared to that of many [MASK] nations , Australia has been involved in numerous conflicts [MASK] wars , and [MASK] and military service have been significant influences on Australian society and national identity [MASK] including the An [MASK] [MASK] . The relationship [MASK] war and Australian society has also been shaped by [MASK] enduring [MASK] of Australian [MASK] culture and its unique [MASK] di ##lemma . As British &lt; un ##k &gt; , the Australian colonies participated in Britain ' s small wars of [supporter] 19th century , while later as a &lt; un [MASK] &gt; do ##mini ##on , and [MASK] an independent nation , Australia fought in the First World War and Second World War [MASK] [as] well as in the [wars] in [MASK] , Malaya , Borneo and Vietnam during the [MASK] War . In the [MASK] @ - @ Vietnam era Australian forces have been involved in numerous [MASK] peace ##keeping missions , through [the] United Nations and other agencies , including in the Sinai , Persian Gulf , &lt; [un] ##k [MASK] [MASK] Somalia , East [MASK] and the Solomon Islands , [MASK] [MASK] recently they have also</td>\n",
       "      <td>= Military [history] of Australia = The military history of Australia spans [the] nation ' [s] 220 @ - [@] year modern history [,] from the [early] [Australian] frontier wars between &lt; un ##k &gt; and Europeans to the ongoing conflicts [in] Iraq and Afghanistan in the early 21st [century] . Although this history is short [when] compared to that of many [other] nations , Australia has been involved in numerous conflicts [and] wars , and [war] and military service have been significant influences on Australian society and national identity [,] including the An [##zac] [spirit] . The relationship [between] war and Australian society has also been shaped by [the] enduring [themes] of Australian [strategic] culture and its unique [security] di ##lemma . As British &lt; un ##k &gt; , the Australian colonies participated in Britain ' s small wars of [the] 19th century , while later as a &lt; un [##k] &gt; do ##mini ##on , and [then] an independent nation , Australia fought in the First World War and Second World War [,] [as] well as in the [wars] in [Korea] , Malaya , Borneo and Vietnam during the [Cold] War . In the [Post] @ - @ Vietnam era Australian forces have been involved in numerous [international] peace ##keeping missions , through [the] United Nations and other agencies , including in the Sinai , Persian Gulf , &lt; [un] ##k [&gt;] [,] Somalia , East [Timor] and the Solomon Islands , [while] [more] recently they have also</td>\n",
       "      <td>= Military [history] of Australia = The military history of Australia spans [the] nation ' [s] 220 @ - [@] year modern history [,] from the [pre] [and] frontier wars between &lt; un ##k &gt; and Europeans to the ongoing conflicts [in] Iraq and Afghanistan in the early 21st [century] . Although this history is short [when] compared to that of many [other] nations , Australia has been involved in numerous conflicts [and] wars , and [political] and military service have been significant influences on Australian society and national identity [,] including the An [##zac] [era] . The relationship [between] war and Australian society has also been shaped by [the] enduring [nature] of Australian [military] culture and its unique [political] di ##lemma . As British &lt; un ##k &gt; , the Australian colonies participated in Britain ' s small wars of [the] 19th century , while later as a &lt; un [##k] &gt; do ##mini ##on , and [as] an independent nation , Australia fought in the First World War and Second World War [,] [as] well as in the [wars] in [Afghanistan] , Malaya , Borneo and Vietnam during the [Vietnam] War . In the [220] @ - @ Vietnam era Australian forces have been involved in numerous [international] peace ##keeping missions , through [the] United Nations and other agencies , including in the Sinai , Persian Gulf , &lt; [un] ##k [&gt;] [,] Somalia , East [Timor] and the Solomon Islands , [and] [more] recently they have also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= [Air] [MASK] Flight &lt; un ##k &gt; = Air Rhodesia [Flight] &lt; un ##k &gt; was a scheduled passenger flight [PA] was [MASK] [MASK] by the Zimbabwe People ' s Revolutionary [Army] ( [MASK] [MASK] ##k &gt; ) on 3 September 1978 , during the Rhodesia [MASK] Bush [MASK] . The aircraft involved , a Vickers [MASK] named the [&lt;] un [MASK] &gt; , was flying the last leg of Air Rhodesia [MASK] s regular [MASK] service from Victoria Falls to the [MASK] Salisbury , via the resort [MASK] of &lt; un ##k &gt; . Soon after Flight [MASK] un [##k] &gt; [MASK] off , a group of &lt; un ##k &gt; guerrilla ##s scored a direct hit on its star ##board wing [with] a Soviet @ - @ made &lt; un [MASK] &gt; [Sounds] [MASK] @ [MASK] [MASK] [MASK] @ - @ air infrared &lt; un ##k [&gt;] missile , [may] [MASK] [MASK] aircraft and forcing an emergency landing . An attempted belly landing in a cotton field just west of &lt; un ##k &gt; was &lt; un ##k &gt; by [MASK] unseen ditch , which caused the plane to cart ##wheel and break [MASK] [MASK] [MASK] the 52 [MASK] and four crew , 38 [MASK] in this crash ; the insurgents then approached the wreckage , rounded up the 10 survivors they could see and massacre ##d them with automatic gunfire . Three passengers survived by [hiding] in the surrounding bush , while a further five lived</td>\n",
       "      <td>= [Air] [Rhodesia] Flight &lt; un ##k &gt; = Air Rhodesia [Flight] &lt; un ##k &gt; was a scheduled passenger flight [that] was [shot] [down] by the Zimbabwe People ' s Revolutionary [Army] ( [&lt;] [un] ##k &gt; ) on 3 September 1978 , during the Rhodesia [##n] Bush [War] . The aircraft involved , a Vickers [Viscount] named the [&lt;] un [##k] &gt; , was flying the last leg of Air Rhodesia ['] s regular [scheduled] service from Victoria Falls to the [capital] Salisbury , via the resort [town] of &lt; un ##k &gt; . Soon after Flight [&lt;] un [##k] &gt; [took] off , a group of &lt; un ##k &gt; guerrilla ##s scored a direct hit on its star ##board wing [with] a Soviet @ - @ made &lt; un [##k] &gt; [2] [surface] @ [-] [@] [to] @ - @ air infrared &lt; un ##k [&gt;] missile , [critically] [damaging] [the] aircraft and forcing an emergency landing . An attempted belly landing in a cotton field just west of &lt; un ##k &gt; was &lt; un ##k &gt; by [an] unseen ditch , which caused the plane to cart ##wheel and break [up] [.] [Of] the 52 [passengers] and four crew , 38 [died] in this crash ; the insurgents then approached the wreckage , rounded up the 10 survivors they could see and massacre ##d them with automatic gunfire . Three passengers survived by [hiding] in the surrounding bush , while a further five lived</td>\n",
       "      <td>= [Air] [Rhodesia] Flight &lt; un ##k &gt; = Air Rhodesia [Flight] &lt; un ##k &gt; was a scheduled passenger flight [that] was [operated] [operated] by the Zimbabwe People ' s Revolutionary [Army] ( [&lt;] [un] ##k &gt; ) on 3 September 1978 , during the Rhodesia [##n] Bush [War] . The aircraft involved , a Vickers [Viscount] named the [&lt;] un [##k] &gt; , was flying the last leg of Air Rhodesia ['] s regular [scheduled] service from Victoria Falls to the [capital] Salisbury , via the resort [town] of &lt; un ##k &gt; . Soon after Flight [&lt;] un [##k] &gt; [took] off , a group of &lt; un ##k &gt; guerrilla ##s scored a direct hit on its star ##board wing [with] a Soviet @ - @ made &lt; un [##k] &gt; [@] [of] @ [-] [-] [&gt;] @ - @ air infrared &lt; un ##k [&gt;] missile , [which] [destroying] [the] aircraft and forcing an emergency landing . An attempted belly landing in a cotton field just west of &lt; un ##k &gt; was &lt; un ##k &gt; by [an] unseen ditch , which caused the plane to cart ##wheel and break [.] [.] [killed] the 52 [passengers] and four crew , 38 [injured] in this crash ; the insurgents then approached the wreckage , rounded up the 10 survivors they could see and massacre ##d them with automatic gunfire . Three passengers survived by [hiding] in the surrounding bush , while a further five lived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfm = first_blurr_tfm(learn.dls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best place on earth is here.',\n",
       " 'The best place on earth is heaven.',\n",
       " 'The best place on earth is Earth.',\n",
       " 'The best place on earth is paradise.',\n",
       " 'The best place on earth is Egypt.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_fill_mask(f\"The best place on earth is {batch_tfm.hf_tokenizer.mask_token}.\", n_preds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_text-examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
