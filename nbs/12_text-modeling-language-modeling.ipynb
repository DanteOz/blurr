{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp text.modeling.language_modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text.modeling.language_modeling\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... for both causal and MLM language modeling tasks. This includes things like training BERT from scratch or fine-tuning a particular pre-trained LM on your own corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import ast, gc, inspect, os\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import perplexity\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoModelForCausalLM, AutoModelForMaskedLM, logging, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "\n",
    "from blurr.text.data.core import TextDataLoader, TextBlock, first_blurr_tfm\n",
    "from blurr.text.data.language_modeling import (\n",
    "    BaseLMStrategy,\n",
    "    LMBatchTokenizeTransform,\n",
    "    LMPreprocessor,\n",
    "    LMType,\n",
    "    CausalLMTextInput,\n",
    "    CausalLMStrategy,\n",
    "    MLMTextInput,\n",
    "    BertMLMStrategy,\n",
    ")\n",
    "from blurr.text.modeling.core import Blearner\n",
    "from blurr.text.utils import NLP\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.text.modeling.core import BaseModelWrapper, BaseModelCallback, blurr_splitter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this example, we'll use the `WIKITEXT_TINY` dataset available from fastai to demonstrate how to configure BLURR code for language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Big Boy ( song ) = \\n \\n \" Big Boy \" &lt;unk&gt; \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and &lt;unk&gt; composit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica &lt;unk&gt; and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will &lt;unk&gt; ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family &lt;unk&gt; . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf &lt;unk&gt; cup , &lt;unk&gt; &lt;unk&gt; cup , or pixie cup . The small , &lt;unk&gt; @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0  \\\n",
       "0   \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...   \n",
       "1   \\n = Big Boy ( song ) = \\n \\n \" Big Boy \" <unk> \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...   \n",
       "2   \\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and <unk> composit...   \n",
       "3   \\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica <unk> and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will <unk> ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...   \n",
       "4   \\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family <unk> . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf <unk> cup , <unk> <unk> cup , or pixie cup . The small , <unk> @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_path = untar_data(URLs.WIKITEXT_TINY)\n",
    "\n",
    "train_df = pd.read_csv(wiki_path / \"train.csv\", header=None)\n",
    "valid_df = pd.read_csv(wiki_path / \"test.csv\", header=None)\n",
    "\n",
    "train_df[\"is_valid\"] = False\n",
    "valid_df[\"is_valid\"] = True\n",
    "\n",
    "df = pd.concat([train_df, valid_df])\n",
    "\n",
    "print(len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LMMetricsCallback`\n",
    "\n",
    "In this section, we'll add helpful metrics for calculating accuracy and perplexity for both causal and masked language modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LMMetricsCallback(Callback):\n",
    "    \"\"\"A fastai friendly metric implemented as a callback so that we can handle use cases where we don't\n",
    "    want to count tokens marked to be ignored or else not count batches where there are no targs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.run_before = Recorder\n",
    "\n",
    "        self.custom_metrics_dict = {\"lm_accuracy\": None}\n",
    "        self.do_setup = True\n",
    "\n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if not self.do_setup:\n",
    "            return\n",
    "\n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "\n",
    "        self.do_setup = False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.setup()\n",
    "\n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        # do this only for validation set\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0]  # yb is TensorText tuple, item 0 is the data\n",
    "\n",
    "        msk = torch.where(targs != -100, 1, 0).bool()\n",
    "        preds = torch.masked_select(preds, msk).cpu()\n",
    "        targs = torch.masked_select(targs, msk).cpu()\n",
    "\n",
    "        if preds.shape[0] == 0:\n",
    "            return\n",
    "\n",
    "        self.results += [(res[0], res[1]) for res in zip(preds, targs)]\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self):\n",
    "        self.results = []\n",
    "\n",
    "    def after_validate(self):\n",
    "        if len(self.results) < 1:\n",
    "            return\n",
    "\n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        self.custom_metrics_dict[\"lm_accuracy\"] = accuracy_score(targs, preds)\n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key):\n",
    "        return self.custom_metrics_dict[metric_key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal Language Modeling\n",
    "\n",
    "In causal language modeling, we are attempting to predict the next token given those before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "model_cls = AutoModelForCausalLM\n",
    "\n",
    "pretrained_model_name = \"gpt2\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "if hf_tokenizer.pad_token is None:\n",
    "    hf_tokenizer.pad_token = \"[PAD]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\n",
    "proc_df = preprocessor.process_df(train_df, valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=CausalLMStrategy)\n",
    "blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=CausalLMTextInput), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 129]), torch.Size([2, 129]), torch.Size([2, 129]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>₹ 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = &lt;unk&gt; = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at &lt;unk&gt; police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from</td>\n",
       "      <td>�� 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = &lt;unk&gt; = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at &lt;unk&gt; police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unk&gt; ul @-@ &lt;unk&gt; holiday, was meant to show different views of Islam ; however, it has also been interpreted as a critique of the current Muhammadiyah leadership. It was seen in theatres by over 1 million people – the only Indonesian film of 2010 to do so. It also received favourable critical reception, winning the 2011 Bandung Film Festival after being refused a nomination at the 2010 Indonesian Film Festival. However, some Muslim critics decried it as being too liberal. \\n \\n = = Plot = = \\n \\n</td>\n",
       "      <td>k&gt; ul @-@ &lt;unk&gt; holiday, was meant to show different views of Islam ; however, it has also been interpreted as a critique of the current Muhammadiyah leadership. It was seen in theatres by over 1 million people – the only Indonesian film of 2010 to do so. It also received favourable critical reception, winning the 2011 Bandung Film Festival after being refused a nomination at the 2010 Indonesian Film Festival. However, some Muslim critics decried it as being too liberal. \\n \\n = = Plot = = \\n \\n Muh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "fit_cbs = [LMMetricsCallback()]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "    cbs=[BaseModelCallback],\n",
    "    metrics=[perplexity],\n",
    "    splitter=blurr_splitter,\n",
    ").to_fp16()\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = dls.one_batch()\n",
    "# preds = learn.model(b[0])\n",
    "# len(preds),preds[0], preds[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.0015848932787775993, steep=1.3182567499825382e-06, valley=0.0030199517495930195, slide=0.0020892962347716093)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwjklEQVR4nO3deXzU5bn//9eVnSwkIQkkECCAIKuBEBVUFIq4AmIVl9Jaq6cea6tirT/tT+tRj57T7/dQ69aKtlW6uMcVQUvtwYorkLDvO2SDJGTfl+v7x0xiCElISGbLXM/HI4/MfLZ5z6Bz5f7cn899i6pijDHGfwV4OoAxxhjPskJgjDF+zgqBMcb4OSsExhjj56wQGGOMn7NCYIwxfi7I0wG6Kz4+XlNSUjwdwxhjfEpmZmahqia0t87nCkFKSgrr16/3dAxjjPEpInKoo3V2asgYY/ycFQJjjPFzVgiMMcbP+VwfQXvq6+vJzs6mpqbG01F8XlhYGMnJyQQHB3s6ijHGTfpEIcjOziYqKoqUlBRExNNxfJaqUlRURHZ2NiNGjPB0HGOMm/SJU0M1NTXExcVZEeghESEuLs5aVsb4mT5RCAArAr3EPkdjvNOqbfnsK6hwybH7TCHwBR988AG//vWvO90mNzeXa6+91k2JjDG+oKlJ+emrWWRkZrvk+H2ij6DbNr8J/3wMSrMhOhlmPwxnXefyl50/fz7z58/vdJvBgweTkZHh8izGGN9RUFFLfaMyOKafS47vfy2CzW/C8rug9Aigjt/L73Is74GDBw8yduxYbr75ZsaMGcOiRYv45JNPOP/88xk9ejRr165l2bJl/OxnPwPg5ptv5q677uK8885j5MiRLV/+Bw8eZOLEiQAsW7aMBQsWMGfOHFJSUnjuued48sknmTJlCtOmTeP48eMAzJw5s+Vu68LCQpqH4Ojq/sYY75ZTUg1AshWCXvLPx6C++sRl9dWO5T20d+9e7r33Xnbu3MnOnTt59dVX+fzzz1myZAn/9V//ddL2eXl5fP7553z44Yc88MAD7R5z69atvPPOO6xbt44HH3yQ8PBwNmzYwPTp0/nLX/5yykw93d8Y43m5zkJgLYLeUtrBObaOlnfDiBEjmDRpEgEBAUyYMIHZs2cjIkyaNImDBw+etP2CBQsICAhg/PjxHD16tN1jzpo1i6ioKBISEoiOjmbevHkAHR6zt/c3xnheTnFzIQhzyfH9rxBEJ3dveTeEhoa2PA4ICGh5HhAQQENDQ6fbq+ppHzMoKIimpiaAky797G4mY4z3yS2pJiosiKgw19zo6X+FYPbDENymeRXcz7HcR6WkpJCZmQlgHc3G9EE5JTUMcdFpIfDHQnDWdTDvGYgeCojj97xn3HLVkKv84he/4Pnnn2fKlCkUFhZ6Oo4xppfllFS7tBBIR6ckvFV6erq2nY9gx44djBs3zkOJ+h77PI3xLqmPrmJ+6mD+c8HE0z6GiGSqanp76/yvRWCMMT6koraB0up6l10xBC4sBCJypohsbPVTJiKL22wzU0RKW23juyfqjTHGBfKcl44OiXVdIXDZncWquguYDCAigUAO8G47m65R1bmuymGMMb4su7kQuOjSUXDfqaHZwD5V7XDOTGOMMSdz9c1k4L5CcAPwWgfrpovIJhH5SEQmuCmPMcb4hNySaoIChIFRPtwiEJEQYD7wVjurs4DhqpoKPAu818ExbhOR9SKyvqCgwGVZjTHG2+QUV5MYHUZggOuGiHdHi+ByIEtVTxpDQVXLVLXC+XglECwi8e1s96KqpqtqekJCgusT95KnnnqKqqoqT8cwxviw3JIal54WAvcUghvp4LSQiCSKcyYUETnHmafI1YFW7F/BJRmXcNafz+KSjEtYsX+FS17HCoExpqdcfTMZuLgQiEgEMAd4p9Wy20XkdufTa4GtIrIJeAa4QV18h9uK/St45MtHyKvMQ1HyKvN45MtHelwMKisrufLKK0lNTWXixIk8+uij5ObmMmvWLGbNmgXAqlWrmD59OmlpaSxcuJCKCsdsQ5mZmVx00UVMnTqVSy+9lLy8PMAxvPTdd9/N5MmTmThxImvXru3ZmzfG+JTGJiW/zLXDS4CLC4GqVqpqnKqWtlq2VFWXOh8/p6oTVDVVVaep6peuzAPwdNbT1DSeODBbTWMNT2c93aPjfvzxxwwePJhNmzaxdetWFi9ezODBg1m9ejWrV6+msLCQxx9/nE8++YSsrCzS09N58sknqa+v58477yQjI4PMzExuueUWHnzwwZbjVlVVsXHjRn7/+99zyy239CijMca3HC2robHJdRPSNPO7GcryK/O7tbyrJk2axL333sv999/P3LlzmTFjxgnrv/76a7Zv3875558PQF1dHdOnT2fXrl1s3bqVOXPmANDY2EhSUlLLfjfeeCMAF154IWVlZZSUlBATE9OjrMYY3/DtpaOuu2II/LAQJEYkkleZ1+7ynhgzZgxZWVmsXLmShx56iNmzZ5+wXlWZM2cOr712YnfJli1bmDBhAl999VW7x207mbxNLm+M/8hpuZnMh08NeaO70+4mLPDE6hoWGMbdaXf36Li5ubmEh4fz/e9/n/vuu4+srCyioqIoLy8HYNq0aXzxxRfs3bsXcPQp7N69mzPPPJOCgoKWQlBfX8+2bdtajvvGG28A8PnnnxMdHU10dHSPchpjfEeOG24mAz9sEVw58krA0VeQX5lPYkQid6fd3bL8dG3ZsoX77ruPgIAAgoODef755/nqq6+47LLLWvoKli1bxo033khtbS0Ajz/+OGPGjCEjI4O77rqL0tJSGhoaWLx4MRMmOO6tCwsLY8qUKdTX1/PSSy/17M0bY3xKbkk1MeHBRIS69qvahqH2YjNnzmTJkiWkp7c7cqzL9NXP0xhfc8uydeSX1rDy7hmn3vgUbBhqY4zxQbkl1S4/LQR+eGrIl3z66aeejmCM8aCc4mqmjYxz+etYi8AYY7xQWU095bUNLr90FKwQGGOMV2q+hyAp2vWnhqwQGGOMFyood1xdmBhtLQJjjPFLRRV1AMRFhLj8tawQeEBkZCQABw8eZOLEiR5OY4zxRoUVjhZBXGSoy1/LLwtB6fLl7PnObHaMG8+e78ymdPlyT0cyxpgTFFbUERwo9A9z/cWdflcISpcvJ+9XD9OQmwuqNOTmkverh3tUDB544AF+97vftTx/5JFHePzxx5k9ezZpaWlMmjSJ999/v9NjNDY2ct9993H22Wdz1lln8cILLwBw00038d5777Vst2jRolMeyxjj+4oqaomLCHXL+GJ+VwiO/fYptObEYai1poZjv33qtI95/fXX8+abb7Y8f/PNN/nhD3/Iu+++S1ZWFqtXr+bee++ls7u4//SnPxEdHc26detYt24df/jDHzhw4AC33nory5YtA6C0tJQvv/ySK6/s2XAYxhjvV1RZR1yk6/sHwA9vKGvIO3nk0c6Wd8WUKVM4duwYubm5FBQUEBsbS2JiIvfccw+fffYZAQEB5OTkcPToURIT2x/ldNWqVWzevJmMjAzA8aW/Z88eLrnkEu644w4KCgp4++23ueaaawgK8rt/NmP8TlFFLfFu6B8APywEQUlJjtNC7SzviYULF5KRkUF+fj7XX389r7zyCgUFBWRmZhIcHExKSgo1bVoirakqzz77LJdeeulJ62666Sb+9re/8frrr/Pyyy/3KKcxxjcUVtQxamCkW17L704NDbxnMRJ24nW5EhbGwHsW9+i4119/Pa+//joZGRksXLiQ0tJSBg4cSHBwMKtXr+bQoUOd7n/ppZfy/PPPU19fD8Du3buprKwE4Oabb+app54CYPz48T3KaYzxfqpKUaW1CFwmet48wNFX0JCXR1BSEgPvWdyy/HRNmDCB8vJyhgwZQlJSEosWLWLevHlMmjSJ9PR0xo4d2+n+//Zv/8bBgwdJS0tDVUlISGjpJB40aBDjxo1jwYIFPcpojPENlXWN1NQ3ueUeArBhqH1CVVUVkyZNIisryy0T0/T1z9MYb3eoqJKL/udTlixM5dqpyb1yTI8MQy0iZ4rIxlY/ZSKyuM02IiLPiMheEdksImmuyuOrPvnkE8aNG8edd95ps5MZ4ycKm+8q9vWrhlR1FzAZQEQCgRzg3TabXQ6Mdv6cCzzv/G2cLr744lP2Lxhj+pYi513F8RHu6SNwV2fxbGCfqrb9RrsK+Is6fA3EiEjPLt8xxhgfV1Tp3haBuwrBDcBr7SwfAhxp9TzbuewEInKbiKwXkfUFBQUuimiMMd6hqGWcoT5SCEQkBJgPvHW6x1DVF1U1XVXTExISei+cMcZ4ocKKOqLCgggNCnTL67mjRXA5kKWqR9tZlwMMbfU82bnMGGP8VqEb7yoG9xSCG2n/tBDAB8BNzquHpgGlqnr6Yz14mZkzZ9J8qesVV1xBSUnJSds88sgjLFmyxM3JjDHerKiizm33EICLbygTkQhgDvDvrZbdDqCqS4GVwBXAXqAK+JEr8zTb/U0+X72/j4rjtUQOCGX6VaMYc277YwD1lpUrV7r0+MaYvqOospYR8RFuez2XtghUtVJV41S1tNWypc4igPNqoZ+q6ihVnaSq6zs+Wu/Y/U0+q1/ZScVxR2dMxfFaVr+yk93f5PfouJWVlVx55ZWkpqYyceJE3njjjRPWp6SkUFhYCMATTzzBmDFjuOCCC9i1a1fLNvv27eOyyy5j6tSpzJgxg507d/YokzHGNxVV1LllQppmfjfW0Ffv76OhrumEZQ11TXz1/r4eHffjjz9m8ODBbNq0ia1bt3LZZZe1u11mZiavv/46GzduZOXKlaxbt65l3W233cazzz5LZmYmS5Ys4Y477uhRJmOM72lsUo5X1RHfV04NeaPmlkBXl3fVpEmTuPfee7n//vuZO3cuM2bMaHe7NWvWcPXVVxMeHg7A/PnzHa9fUcGXX37JwoULW7atre1ZJmOM7ymuqkMV4qPc1yLwu0IQOSC03S/9yAE9+9DHjBlDVlYWK1eu5KGHHmL27Nnd2r+pqYmYmBg2btzYoxzGGN/27aT1dmrIZaZfNYqgkBPfdlBIANOvGtWj4+bm5hIeHs73v/997rvvPrKystrd7sILL+S9996jurqa8vJyljunyOzfvz8jRozgrbcct1uoKps2bepRJmOM7yl0881k4IeFYMy5icxaNLalBRA5IJRZi8b2+KqhLVu2cM455zB58mQeffRRHnrooXa3S0tL4/rrryc1NZXLL7+cs88+u2XdK6+8wp/+9CdSU1OZMGGCzU1sjB9qLgTxbiwENgy1OYl9nsZ4zkufH+CxD7ez4VdziO3FDmOPDENtjDGm+4oqawkMEKL7BbvtNa0QGGOMFymqqGNARAgBAeK217RCYIwxXqSwos6t4wxBHyoEvtbX4a3sczTGsxyT1ruvoxj6SCEICwujqKjIvsR6SFUpKioiLCzM01GM8VuFFbVuHXAO+sgNZcnJyWRnZ2OT1vRcWFgYycm9M1m2Mab73D3OEPSRQhAcHMyIESM8HcMYY3qkqq6BqrpGt95MBn3k1JAxxvQFzcNLuGvS+mZWCIwxxku4e9L6ZlYIjDHGSxS1DC9hLQJjjPFLLSOPWovAGGP8U3ZxFQFiLQJjjPFb2/PKGZkQSVhwoFtf1wqBMcZ4iZ35ZYxL6u/213VpIRCRGBHJEJGdIrJDRKa3WT9TREpFZKPz52FX5jHGGG9VVlNPdnE1YxOj3P7arr6h7GngY1W9VkRCgPB2tlmjqnNdnMMYY7zazrxyAMZ7oEXgskIgItHAhcDNAKpaB9S56vWMMcaX7cgrA+hzp4ZGAAXAyyKyQUT+KCIR7Ww3XUQ2ichHIjKhvQOJyG0isl5E1tt4QsaYvmhnfhmx4cEM6u/eK4bAtYUgCEgDnlfVKUAl8ECbbbKA4aqaCjwLvNfegVT1RVVNV9X0hIQEF0Y2xhjP2J5Xzrik/oi4b0KaZq4sBNlAtqp+43yegaMwtFDVMlWtcD5eCQSLSLwLMxljjNdpbFJ25ZcxNtH9p4XAhYVAVfOBIyJypnPRbGB7621EJFGc5U9EznHmKXJVJmOM8UYHiyqpqW9iXJL7rxgC1181dCfwivOKof3Aj0TkdgBVXQpcC/xERBqAauAGtdlljDF+pvmKIU90FIOLC4GqbgTS2yxe2mr9c8BzrsxgjDHebkdeGYEBwuhBkR55fbuz2BhjPGxHXhmjEiIIDXLv0BLNrBAYY4yH7cjzzNASzawQGGOMB5VW1ZNbWmOFwBhj/NWOfM/dUdzMCoExxnhQy9ASHhhsrpkVAmOM8aAdeWXERYSQEOX+oSWaWSEwxhgP2uHBoSWaWSEwxhgPaWhsYtfRcsYP9lz/AFghMMYYjzlQWEldg+eGlmhmhcAYYzxkuwfnIGjNCoExxnjI9rwyQgIDGJXgmaElmlkhMMYYD9meW8boQZEEB3r2q9gKgTHGeEjzFUOeZoXAGGM84Fh5DYUVtR6ZrL6tLhUCEYkQkQDn4zEiMl9Egl0bzRhj+q4dHp6DoLWutgg+A8JEZAiwCvgBsMxVoYwxpq9rHlrCZ1oEgKhqFfBd4PequhCY4LpYxhjTt23PLWNITD+iwz1/cqXLhUBEpgOLgBXOZZ6ZQcEYY/oAxxwEnr2RrFlXC8Fi4JfAu6q6TURGAqtdlsoYY/qwmvpG9hVUeEX/AHRxzmJV/RfwLwBnp3Ghqt7lymDGGNNX7T5aTpN6R/8AdP2qoVdFpL+IRABbge0icl8X9osRkQwR2SkiO5ynl1qvFxF5RkT2ishmEUk7vbdhjDG+Y3uudwwt0ayrp4bGq2oZsAD4CBiB48qhU3ka+FhVxwKpwI426y8HRjt/bgOe72IeY4zxWTvyyogICWTYgHBPRwG6XgiCnfcNLAA+UNV6QDvbQUSigQuBPwGoap2qlrTZ7CrgL+rwNRAjIkndyG+MMT5nR145Y5P6ExDguTkIWutqIXgBOAhEAJ+JyHCg7BT7jAAKgJdFZIOI/NF5aqm1IcCRVs+znctOICK3ich6EVlfUFDQxcjGGON9GpuU7XllXtM/AF0sBKr6jKoOUdUrnH+9HwJmnWK3ICANeF5VpwCVwAOnE1JVX1TVdFVNT0hIOJ1DGGOMV9hzrJyK2gYmD43xdJQWXe0sjhaRJ5v/KheR3+BoHXQmG8hW1W+czzNwFIbWcoChrZ4nO5cZY0yflHWoBIC04bGeDdJKV08NvQSUA9c5f8qAlzvbQVXzgSMicqZz0Wxge5vNPgBucl49NA0oVdW8roY3xhhfk3W4mAERIaTEeUdHMXTxPgJglKpe0+r5oyKysQv73Qm8IiIhwH7gRyJyO4CqLgVWAlcAe4Eq4EddDW6MMb4o63AxU4bGeHSy+ra6WgiqReQCVf0cQETOB6pPtZOqbgTS2yxe2mq9Aj/tYgZjjPFpJVV17C+o5Jq0ZE9HOUFXC8HtwF+cl4QCFAM/dE0kY4zpmzYcLgEgbZj39A9A14eY2ASkikh/5/MyEVkMbHZhNmOM6VOyDhcTGCCkDo0+9cZu1K0ZylS1zHmHMcDPXZDHGGP6rKzDxYxNjCI8pKsnY9yjJ1NVek9PhzHGeLnGJmXj4RKvOy0EPSsEnQ4xYYwx5lu78suprGskbXiMp6OcpNP2iYiU0/4XvgD9XJLIGGP6oKzDxYD3dRTDKQqBqnrH9DnGGOPjsg4XExcR4jUjjrbWk1NDxhhjumjD4RKmDIv1qhvJmlkhMMYYFyuqqOVAYaVX9g+AFQJjjHG5v287CsCMM7xz9GQrBMYY42LvZGUzemAkE4d4zxwErVkhMMYYFzpUVMn6Q8V8Ny3ZK/sHwAqBMca41DtZOYjAgimDPR2lQ1YIjDHGRVSVdzfkcN6oOJKivffWKysExhjjIpmHijl8vIrvTvGuYafbskJgjDEu8nZWDv2CA7lsYqKno3TKCoExxrhATX0jH27O5fKJiUSEetdoo21ZITDGGBdYvfMY5TUNXJ02xNNRTskKgTHGuMCnuwroHxbE9JFxno5ySlYIjDGml6kqa/YUcP4Z8QQFev/XrEsTishBEdkiIhtFZH0762eKSKlz/UYRediVeYwxxh32FVSSW1rDjNHeOaREW+7owZilqoWdrF+jqnPdkMMYY9xizZ4CAGaMjvdwkq7x/jaLMcb4mDV7ChkRH8FQL5x7oD2uLgQKrBKRTBG5rYNtpovIJhH5SEQmtLeBiNwmIutFZH1BQYHr0hpjTA/VNjTy1b4in2kNgOtPDV2gqjkiMhD4h4jsVNXPWq3PAoaraoWIXAG8B4xuexBVfRF4ESA9Pd3mSjbGeK2sQyVU1zf6TP8AuLhFoKo5zt/HgHeBc9qsL1PVCufjlUCwiPhOGTXGmDbW7CkgKECYNnKAp6N0mcsKgYhEiEhU82PgEmBrm20SxTkuq4ic48xT5KpMxhjjamv2FJI2LJaosGBPR+kyV54aGgS86/yeDwJeVdWPReR2AFVdClwL/EREGoBq4AZVtVM/xhifVFRRy9bcUn5+8RhPR+kWlxUCVd0PpLazfGmrx88Bz7kqgzHGuNMX+4pQhRljfKd/AOzyUWOM6TWf7jxGdL9gJg2J9nSUbrFCYIwxvaCytoGPt+Vz+cREAgO8c0rKjlghMMaYXvDR1nyq6hq5Zqp3T0LTHisExhjTC97OzGZ4XDjpw2M9HaXbrBAYY0wPHTlexVf7i7gmLRnnlZI+xQqBMcb00LsbcgD4rg9MQtMeKwTGGNMDqsrbWdlMHxlHcqxvDDLXlhUCY4zpgfWHijlUVMW1PthJ3MwKgTHG9MDbmdmEhwRy2cRET0c5bVYIjDHmNOWUVPPexhzmnpVERKg75vlyDSsExhhzmn790U5U4W4fG1uoLSsExhhzGtYeOM7yTbncftEohsT083ScHrFCYIwx3dTUpDz24TaSosO4/aJRno7TY1YIjDGmmzIys9maU8YDl4+lX0igp+P0mBUCY4zphtKqev7v33eRPjyW+amDPR2nV1ghMMaYLlJV/v/3tlBSVccj8yf45HAS7bFCYIwxXfROVg4rNudxz5wxTPSxOQc6Y4XAGGO64MjxKv7jg22cM2JAn+ggbs0KgTHGnEJDYxOL39iICDx5XarPTTxzKr57K5wxxriBqvLo8u1kHirm6Rsm++zAcp1xaYtARA6KyBYR2Sgi69tZLyLyjIjsFZHNIpLmyjzGGNNdT/5jN3/9+hD/fuFIrprsm8NMn4o7WgSzVLWwg3WXA6OdP+cCzzt/G2OMx/1xzX6e/d+93HD2UB64fKyn47iMp/sIrgL+og5fAzEikuThTMYYw9uZ2Ty+YgdXTkriiasn9ZlLRdvj6kKgwCoRyRSR29pZPwQ40up5tnPZCUTkNhFZLyLrCwoKXBTVGGMcsg4X88t3tnDeqDh+e/3kPtc53JarC8EFqpqG4xTQT0XkwtM5iKq+qKrpqpqekJDQuwmNMaaVo2U13P7XTBKjw/j9ojRCgjx94sT1XPoOVTXH+fsY8C5wTptNcoChrZ4nO5cZY4zb1dQ3cttfM6mobeAPN6UTEx7i6Uhu4bJCICIRIhLV/Bi4BNjaZrMPgJucVw9NA0pVNc9VmYwxpiOqykPvbWXTkRKevG4yZyZGeTqS27jyqqFBwLvODpYg4FVV/VhEbgdQ1aXASuAKYC9QBfzIhXmMMaZDf/7yIBmZ2dw1e7RPTzt5OlxWCFR1P5DazvKlrR4r8FNXZTDGmK74al8R/7liBxePG8Ti2aM9Hcft+n4viDHGdCKnpJqfvppFSlw4v70+lYA+foVQe6wQGGP8Vm1DI7f/NZP6hiZevCmdqLBgT0fyCBtryBjjt55ctZstOaW8+IOpjEqI9HQcj7EWgTHGL32zv4gX1+znxnOGcckE/+ocbssKgTHG75TX1PPzNzcxbEA4D105ztNxPM5ODRlj/M6jy7eTV1rNW7efR0SofQ1ai8AY41f+vi2fjMxs7ph5BlOHx3o6jlewQmCM8RtFFbU8+O4Wxif15y4/vF+gI9YmMsb4heYhJMqqG/jbv6X6xWByXWWfhDHGL3ywKZePtuZzz5wxjE3s7+k4XsUKgTGmzztaVsPD729jyrAYbrtwpKfjeB0rBMaYPk1Vuf/tzdQ2NPKbhal9fpKZ02GFwBjTp7229gif7irgl5ePY6Qf3z3cGSsExpg+61BRJY+v2M4FZ8Tzg2nDPR3Ha/lVIWhqUk9HMMa4SWOTcu+bmwgMEP7vtWf55aiiXeU3heBfuwv4zm8+pbCitlv7WfEwxjf9Yc1+1h8q5rGrJjA4pp+n43g1vykEybH9OFJczTP/3NOl7WvqG3novS2c9egqPtyc6+J0xpjetCu/nCdX7eayCYksmDzE03G8nt8UglEJkXzvnGG88s1h9hVUdLrtwcJKrnn+S/729WEGRITws1c38Ow/9+CYUM0Y483qG5v4xVubiAoL4omrJ+KcLtd0wm8KAcDdF4+mX3Ag/+ejne2uL6mq46XPDzD32c/JLq7mjzels+qeC7l6yhB+84/d/PzNTVTWNrg5tTGmO57/dB9bckp5fMFE4iJDPR3HJ/jVEBPxkaHcftFIlqzazdoDxzlnxABUlS/3FfHa2sOs2naUusYmzhkxgCevSyU5NhyAJ69LZWR8BL/5x25W7zrGzeelcPN5KcSEh3j4HRljWtuWW8oz/9zD/NTBXD4pydNxfIa4+nSHiAQC64EcVZ3bZt3NwP8AOc5Fz6nqHzs7Xnp6uq5fv/6081TXNTJryacM6h/K984dxkufH2TX0XJiwoNZMHkIC9OTmTA4ut19Nxwu5ner9/HJjqNEhARy7dRkvnfucM5MjDrtPMaY3pFXWs0PX1pLcVU9qxZfSGyE/aHWmohkqmp6u+vcUAh+DqQD/TsoBOmq+rOuHq+nhQDgrfVHuC9jMwBjE6O49YIRzEsdTFhwYJf235lfxgv/2s+KzXnUNTYxdXgst180ijnjB/Uol+m+45V1bM8tY1tuKQcKKymsqKOospbK2gZS4iIYl9SfcUlRpMRHMDQ2vGXs+eq6RvJKq6mpb2JQ/1Biw0Ps8kIf9sn2o/wiYxN1DU288IOpzBid4OlIXsdjhUBEkoE/A08AP/eWQtDYpLz8xQHGD+7P9JFxp92ZdLyyjneysnnlm8McKKzkF5eM4aezzvDrzilVpbS6noYmZUAnX65NTcrBoko2Hilh45ESNhwuobiqjoiQICJCAwkMEEqq6imuqqO0uh4AESHQ+dkqiirUNjS1HDM+MoSEqDDiI0MICw5kX0EFBwsraX0F8ICIEJpUKamqPyFPcKCQEBlKZFgQ4SFB9AsOpFGV2oYmausbSY7txzkjBnDOiDgmDO5PcKBfda95rbqGJn790U5e+uIA45P689z3ptjdwx3wZCHIAP4biAJ+0UEh+G+gANgN3KOqR9o5zm3AbQDDhg2beujQIZdlPh11DU3c//Zm3t2Qww1nD+U/F0z0+S8KVSW3tIadeWWU1dST2L8fSdFhJEaHndByOlZWw6rtR/lkx1H2F1RytKym5cs5OFAY1D+MQf3DiOkXTHR4MP2CA9lzrILtuWVUODveI0ICOSs5hsToMKrqGqisbaShqYnY8BBiI0KI7heMAI2qNDVpS6EVHF/sEwZHM35wfwa0cyqguq6RvccqOHS8ksPHqzhyvJoAgcExjvcTFhzIsbIa8stqKSivdbx+XSPVdQ0EBgghQYGEBAr7CyvZX1DZ8r6GxoaTEh/BsAHhDI5xvMeBUWEEBQqNTUqTKqMSIhnUP8y1/1B+rKymnp/8LZMv9hbxw+nD+eUV47rcqvdHHikEIjIXuEJV7xCRmbRfCOKAClWtFZF/B65X1e90dtzeaBG4gqry5D928+z/7uWCM+J58MpxjEvy3qFuq+sayS6uYs2eQj7bU8A3+48DEBUWRGRoEAUVtZTXtH+FVGRoEAMiQugXHMjuY+WoQkpcOJOHxji+EPuHESiQX1bL0bIajpXXUFJVT0lVPZV1DYyIj2Di4GgmDulP6tAYRg+M8omBwI6V17D2wHG255ZxsKiSA4VVHC6qpLKuscN9Jg7pz3fGDuLslFhnsQh1FDY/bjX2hpySan708lr2F1Ty62vO4tqpyZ6O5PU8VQj+G/gB0ACEAf2Bd1T1+x1sHwgcV9X2e2qdvLUQNHt97WEe+3A7VXWNXDgmgVsvGMH4pP7EhgcT1M1Wwor9K3g662nyK/NJjEjk7rS7uXLklZ3uU9fQRNbhYvYcq+BQYSUHi6ooqaqjur6RmvpGKmsbKa6qO+GUysj4CM4/I56w4ADKaxoor2kgJjy45fx6dL8QjpXVkFdaQ35ZDUXO8/Bl1fVMGRbLZRMTGT0w0i+/3FSV8toGjpbWcKy8FlUICAAUNmaXsHrnMTIPFZ9weio0KIDhceEMj4tgZEIEs52For3Pb/c3+Xz1/j4qjtcSOSCU6VeNYsy5ie57g15oa04ptyxbR3V9I0u/P5Xzz4j3dCSf4NHOYmeAmbTfIkhS1Tzn46uB+1V1WmfH8vZCAI77EV755jDLvjxIQfm3Q1rEhAczdVgs81IHc/H4QUS2mTT7cFEVa/YWsC23DA3P5B8Fv6O2saZlfVhgGI+c98hJxeBYWQ2rdx3jf3ce4/M9hS1/oTZ/4cRFhNIvJJCw4AAiQoKIjQghJjyYgVFhnDtiAEMHhLvw0zDFlXXsOlrOsfJax2mo0hoOHa/iUFElBwurqGtsIjm2H1dPGUJ6ygCGxIQxOKYf2RsKWf3KThrqvi3aQSEBzFo0ljHnJlK6fDnHfvsUDXl5BCUlMfCexUTPm+fBd+p6q3cd46evZBEbHsLLPzqbMYPsir2u8qpCICKPAetV9QNnq2E+jlbDceAnqtr+3V5OvlAImtU2NPKvXQUtf0UfK6/h010F5JXWEBoUwNjEKEQEESiqqOPw8SoAwkMCkaFPEBBSctIxkyKSWHXtKvJLa3hj3RH+ufMom7NLARgcHcassQOZeeZAJg2JZmBUqF0J4+Uqaxv4+7Z83t2Qwxd7C09oOfykPIzIxpP//SIHhLJg+nHyfvUwWvPtHwoSFkbSfz7WZ4vBa2sP89B7WxmbGMVLN59t/S/d5PFC0Jt8qRC0p6lJyTpczPJNuRwoqmoZtiI8JJBpI+OYMTqeUQmRpP4lFeXkfxtBuO/M5fyfj3ZSWdfA5KExXDxuEN8ZO7ClsBjfVFRRy/7CSnJLqskurkbfOEx7/5oKnJ31MP3Lik5aVxWbwOYlfyY+MpSosCDqGpqobWgiQITzRsX53LX1TU3KuoPHeXN9Nm9nZXPRmAR+tyjtpNa0ObXOCoF9mm4WECCkpwwgPWVAp9slRiSSV5l30vLAplh+9d5WLjgjnieunsjwuAhXRTVuFhcZesKQCH/+x1Eqjp88Wm5VIES1UwQAwooLeHT59nbXBQUIF45JYF5qEpdPTPLqK2zKa+p54V/7eTsrm7zSGvoFB3LL+SP45RVjff6KPG9khcBL3Z12N498+Qg1rfoIaAqmoegylixM5Zq0IfbXfx83/apR7fYRLFg0FtkxmIbck0fFDUlKIutXcyh0XvUVGhTQchHAx9vy+XBTHv+78xhPrNjBLReM4AfThhMVFuzOt9UpVeWDTbk8sWIHBRW1fOfMgTxw+VjmjB9EeIh9XbmKnRryYm2vGvrxhJ9yScoVRPfznv9xjWt1dNVQ6fLlp9VH0NSkfH2giKX/2s9nuwuICgti7lmDmTo8lrRhMYyIj+j8D4zNb8I/H4PSbIhOhtkPw1nX9fh9Hi6q4vO9hby3MYe1B45zVnI0j101kclDY3p8bONgfQTG9EE9vWpoS3YpSz/bx2e7C1ruGWl9P0d4cCBzU5NYdO5wJg6JdhSB5XdBfXXLNk1B/dg/7b84NmI+qqAKQYFCcKAQHBjAwKiwky5aqK5rZF9BBRsOF7PhcAlrDx4nu9hxzKToMH72nTO44exhPnFviS+xQmCM6VBTk7KvoILMQ8UcPl6FiOOihNzSalZuyaOmvonU5GheLrmFAQ1HT9o/uymeC+qe6fD4wYFCYnQYTU2OYVmq67+9AS8+MpS0YTGcf0Y8558Rz6iEU7RIzGmzzmJjTIcCAoTRg6IY3c41+f8xdwJvZ2Xz/sYcYhqOtbv/kIAiXvvxtJa/4BuammhodIzTdLSshpySanJLqgkMEOIiQhgQEUpybD+mDIthSEw/++L3AlYIjDEdig4P5pYLRnDLBSPgt8lQetJQYEh0MtNHxXkgnektdh2WMaZrZj8MwW0mgQ/u51hufJoVAmNM15x1Hcx7BqKHAuL4Pe+ZXrlqyHiWnRoyxnTdWdfZF38fZC0CY4zxc1YIjDHGz1khMMYYP2eFwBhj/JwVAmOM8XM+N8SEiBQAzbPXRwOlnTxuuywYKOzmS7Y+RlfWtV3W1YzNv+O7mdFd+ZqX2WfoXfl8IaO35+tJxs6WedtnOFxVE9o9uqr67A/wYmeP2y7DMTPaab9GV9a1XdbVjK1+dyuju/LZZ+id+Xwho7fn60nGU2T1qs+wsx9fPzW0/BSPO1p/uq/RlXVtl3U1o7fnO9VrdcY+w1O/TmdOtZ+3Z/T2fB2t70rGUy3rDld/hh3yuVNDPSEi67WD0fe8hbdn9PZ84P0ZvT0feH9Gb88HvpGxma+3CLrrRU8H6AJvz+jt+cD7M3p7PvD+jN6eD3wjI+BnLQJjjDEn87cWgTHGmDasEBhjjJ+zQmCMMX7OCoGTiMwQkaUi8kcR+dLTedojIgEi8oSIPCsiP/R0nrZEZKaIrHF+jjM9nac9IhIhIutFZK6ns7RHRMY5P78MEfmJp/O0R0QWiMgfROQNEbnE03naEpGRIvInEcnwdJZmzv/u/uz83BZ5Ok9bfaIQiMhLInJMRLa2WX6ZiOwSkb0i8kBnx1DVNap6O/Ah8GdvzAhcBSQD9UC2F+ZToAII89J8APcDb/Zmtt7MqKo7nP8dXgec76UZ31PVHwO3A9d7Yb79qnprb+ZqTzezfhfIcH5u812drdu6c+ebt/4AFwJpwNZWywKBfcBIIATYBIwHJuH4sm/9M7DVfm8CUd6YEXgA+HfnvhlemC/Aud8g4BUvzDcHuAG4GZjrjf/Gzn3mAx8B3/PWjM79fgOkeXG+Xv1/pIdZfwlMdm7zqitznc5Pn5ihTFU/E5GUNovPAfaq6n4AEXkduEpV/xto97SAiAwDSlW13Bszikg2UOd82uht+VopBkK9LZ/zdFUEjv8xq0Vkpao2eVNG53E+AD4QkRXAq72Vr7cyiogAvwY+UtUsb8vnLt3JiqOFnAxsxAvPxPSJQtCBIcCRVs+zgXNPsc+twMsuS3Sy7mZ8B3hWRGYAn7kymFO38onId4FLgRjgOZcmc+hWPlV9EEBEbgYKe7MIdKK7n+FMHKcRQoGVrgzWSnf/O7wTuBiIFpEzVHWpK8PR/c8wDngCmCIiv3QWDHfpKOszwHMiciWnPwSFy/TlQtBtqvofns7QGVWtwlGsvJKqvoOjWHk1VV3m6QwdUdVPgU89HKNTqvoMji82r6SqRTj6L7yGqlYCP/J0jo54XROlF+UAQ1s9T3Yu8ybentHy9Zxl7Dlvz9eaL2Vt0ZcLwTpgtIiMEJEQHJ2EH3g4U1ventHy9Zxl7Dlvz9eaL2X9lqd7q3vjB3gNyOPbyypvdS6/AtiNoxf/Qcto+Syjd2f09ny+mvVUPzbonDHG+Lm+fGrIGGNMF1ghMMYYP2eFwBhj/JwVAmOM8XNWCIwxxs9ZITDGGD9nhcD0CSJS4ebX65U5K8Qxh0OpiGwUkZ0isqQL+ywQkfG98frGgBUCY9olIp2Ow6Wq5/Xiy61R1cnAFGCuiJxqHoIFOEZQNaZXWCEwfZaIjBKRj0UkUxwzp411Lp8nIt+IyAYR+UREBjmXPyIifxWRL4C/Op+/JCKfish+Ebmr1bErnL9nOtdnOP+if8U5TDMicoVzWaaIPCMiH3aWV1WrcQxTPMS5/49FZJ2IbBKRt0UkXETOwzFfwf84WxGjOnqfxnSVFQLTl70I3KmqU4FfAL93Lv8cmKaqU4DXgf+v1T7jgYtV9Ubn87E4htY+B/gPEQlu53WmAIud+44EzheRMOAF4HLn6yecKqyIxAKj+XaI8XdU9WxVTQV24BjC4EscY9fcp6qTVXVfJ+/TmC6xYahNnyQikcB5wFvOP9Dh28lykoE3RCQJxyxSB1rt+oHzL/NmK1S1FqgVkWM4Zl9rOw3nWlXNdr7uRiAFx5Sd+1W1+divAbd1EHeGiGzCUQSeUtV85/KJIvI4jvkdIoG/d/N9GtMlVghMXxUAlDjPvbf1LPCkqn7gnAjmkVbrKttsW9vqcSPt/z/TlW06s0ZV54rICOBrEXlTVTcCy4AFqrrJOZnOzHb27ex9GtMldmrI9EmqWgYcEJGF4JheUURSnauj+XaM+B+6KMIuYGSrqQxPOcm7s/Xwa+B+56IoIM95OmpRq03LnetO9T6N6RIrBKavCBeR7FY/P8fx5Xmr87TLNhxzx4KjBfCWiGQCha4I4zy9dAfwsfN1yoHSLuy6FLjQWUB+BXwDfAHsbLXN68B9zs7uUXT8Po3pEhuG2hgXEZFIVa1wXkX0O2CPqv7W07mMactaBMa4zo+dncfbcJyOesGzcYxpn7UIjDHGz1mLwBhj/JwVAmOM8XNWCIwxxs9ZITDGGD9nhcAYY/ycFQJjjPFz/w8c4OMkn57ceQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.490997</td>\n",
       "      <td>3.167573</td>\n",
       "      <td>23.749784</td>\n",
       "      <td>0.417016</td>\n",
       "      <td>08:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=3e-3, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_CausalLMInput` typed inputs\n",
    "    x: CausalLMTextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):\n",
    "    # grab our tokenizer and ignore token to decode\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    ignore_token_id = tfm.ignore_token_id\n",
    "\n",
    "    res = L(\n",
    "        [\n",
    "            (\n",
    "                hf_tokenizer.decode(s[0], skip_special_tokens=True)[:trunc_at],\n",
    "                hf_tokenizer.decode(s[1][s[1] != ignore_token_id], skip_special_tokens=True)[:trunc_at],\n",
    "                hf_tokenizer.decode(pred[0], skip_special_tokens=True)[:trunc_at],\n",
    "            )\n",
    "            for s, pred in zip(samples, outs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"target\", \"prediction\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. \\n The German government has said that it does not consider Scientology a religion, but a \" commercial enterprise with a history of taking advantage of vulnerable individuals and an extreme dislike of any criticism \" whose \" totalitarian structure a</td>\n",
       "      <td>\\n The German government has said that it does not consider Scientology a religion, but a \" commercial enterprise with a history of taking advantage of vulnerable individuals and an extreme dislike of any criticism \" whose \" totalitarian structure an</td>\n",
       "      <td>&lt;\\n  &lt; army was been that the will not want the to threat, but that \" &lt; \" \" a religious of commercial advantage of the individuals \" families interest social of the form of. \" &lt; \" \" political \" be a threat to the \"s national system \". , the governmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901 = = = \\n \\n From 1870 until 1901, each of the six colonial governments was responsible for their own defence. The colonies had gained responsible government between 1855 and 1890, and while the Colonial Office in London retained control of some a</td>\n",
       "      <td>= = = \\n \\n From 1870 until 1901, each of the six colonial governments was responsible for their own defence. The colonies had gained responsible government between 1855 and 1890, and while the Colonial Office in London retained control of some affair</td>\n",
       "      <td>and 18 = =\\n \\n  the to 18, the of the four provinces colonies in responsible for the own development of The British were a independence status status 1871 and 18, and the the British Government was London was control of the of, the British General th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': ' Blurr is fun to work with because they can work with a number of different individuals . I would call him a hard hat @-@ , but that may be the reason <unk> <unk> . He is an exceptional @-@'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masked Language Modeling\n",
    "\n",
    "In masked language modeling (MLM), we are attempting to predict the ***masked*** tokens. In Blurr, these are encapsulated by classes implementing the `BaseLMStrategy` base class.\n",
    "\n",
    "For a list of some of the more common strategies, see table 3 of the [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) paper.  When fine-tuning a MLM model. you'll want to make sure you use the same approach as the model authors should you be looking to reproduce their results ... but our approach here makes it easy to play with different strategies regardless.\n",
    "\n",
    "In the example below, we'll tell Blurr we want to use the BERT-style masking strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForMaskedLM\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "if hf_tokenizer.pad_token is None:\n",
    "    hf_tokenizer.pad_token = \"[PAD]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\n",
    "proc_df = preprocessor.process_df(train_df, valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=BertMLMStrategy)\n",
    "blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=MLMTextInput), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 130]), torch.Size([2, 130]), torch.Size([2, 130]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>� � � &lt;mask&gt;  —  wanted  to  forcibly  retire [ officers]  with  more  than  25  years  of  service ,  as  they &lt;mask&gt;  them  to  be    and  ineffective ,  but  most  importantly ,  rivals  for  power . &lt;mask&gt;  of  the  older  officers  had  more  experience  under  the  Vietnamese [ National] &lt;mask&gt;  during  the  French  colonial  era ,  and  some  of  the  younger  men  saw  them  as &lt;mask&gt;  detached  from  the  modern  situation .  The  Young  Turks  had &lt;mask&gt; [ a]  lot &lt;mask&gt;  influence  over  Kh án h &lt;mask&gt;  as &lt;mask&gt; i  and  K � � � [ prog]  intervened &lt;mask&gt; arily  to  save  him  from  a  coup  attempt  in  September &lt;mask&gt;  Gener als &lt;mask&gt;  V � &lt;mask&gt; n    and &lt;mask&gt; � &lt;mask&gt; � � ng  V � �</td>\n",
       "      <td>� � � [u]  —  wanted  to  forcibly  retire [ officers]  with  more  than  25  years  of  service ,  as  they [ thought]  them  to  be    and  ineffective ,  but  most  importantly ,  rivals  for  power . [ Most]  of  the  older  officers  had  more  experience  under  the  Vietnamese [ National] [ Army]  during  the  French  colonial  era ,  and  some  of  the  younger  men  saw  them  as [ too]  detached  from  the  modern  situation .  The  Young  Turks  had [ quite] [ a]  lot [ of]  influence  over  Kh án h [,]  as [ Th] i  and  K � � � [ had]  intervened [ milit] arily  to  save  him  from  a  coup  attempt  in  September [ by]  Gener als [ ]  V � [�] n    and [ D] � [�] � � ng  V � �</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It  couldn  ' &lt;mask&gt;  happen &lt;mask&gt; [.]  Internal &lt;mask&gt;  Boards  would  not  permit  the  use &lt;mask&gt;  a  live  virus  in [ human]  subjects &lt;mask&gt;  they  really  understood  what  was  going  to  happen  to  them .  And  I  doubt  that  even  if  they &lt;mask&gt;  what  the  risk  was ,  that  an  Internal  Review  Board  in  any  academic &lt;mask&gt;  would  consent  to  that  kind &lt;mask&gt;  experimental  work .   \\n  The    research  was  instrumental  in &lt;mask&gt; &lt;mask&gt;  virus &lt;mask&gt;  responsible  for  the  disease  and  that  it  is  transmitted  through &lt;mask&gt;   , [ foster] [ and]  drinking &lt;mask&gt; .   &lt;mask&gt;    :  During  the &lt;mask&gt;  1940 s ,  qu in ine  was  the  chief  anti  @ - @    drug .  Made</td>\n",
       "      <td>It  couldn  ' [t]  happen [ today] [.]  Internal [ Review]  Boards  would  not  permit  the  use [ of]  a  live  virus  in [ human]  subjects [ unless]  they  really  understood  what  was  going  to  happen  to  them .  And  I  doubt  that  even  if  they [ knew]  what  the  risk  was ,  that  an  Internal  Review  Board  in  any  academic [ institution]  would  consent  to  that  kind [ of]  experimental  work .   \\n  The    research  was  instrumental  in [ determining] [ a]  virus [ is]  responsible  for  the  disease  and  that  it  is  transmitted  through [ human]   , [ ] [ and]  drinking [ water] .   [\\n]    :  During  the [ early]  1940 s ,  qu in ine  was  the  chief  anti  @ - @    drug .  Made</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "fit_cbs = [LMMetricsCallback()]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam, decouple_wd=True),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "    cbs=[BaseModelCallback],\n",
    "    metrics=[perplexity],\n",
    "    splitter=blurr_splitter,\n",
    ").to_fp16()\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=7.585775847473997e-08, steep=2.75422871709452e-06, valley=0.0004786300996784121, slide=0.0010000000474974513)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.950741</td>\n",
       "      <td>1.804249</td>\n",
       "      <td>6.075405</td>\n",
       "      <td>0.639451</td>\n",
       "      <td>05:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-4, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_MLMInput` typed inputs\n",
    "    x: MLMTextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer and ignore token to decode\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    ignore_token_id = tfm.ignore_token_id\n",
    "\n",
    "    # grab our mask token id and do-not-mask token ids\n",
    "    mask_token_id = hf_tokenizer.mask_token_id\n",
    "\n",
    "    vocab = hf_tokenizer.get_vocab()\n",
    "    dnm_tok_ids = [vocab[tok] for tok in list(hf_tokenizer.special_tokens_map.values()) if vocab[tok] != mask_token_id]\n",
    "\n",
    "    res = L()\n",
    "    for s, t in zip(samples, outs):\n",
    "        # exclue dnm tokens from input\n",
    "        inps = [\n",
    "            hf_tokenizer.decode(tok_id) if (tok_id == mask_token_id or s[1][idx] == ignore_token_id) else f\"[{hf_tokenizer.decode(tok_id)}]\"\n",
    "            for idx, tok_id in enumerate(s[0])\n",
    "            if (tok_id not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        # replaced masked tokens with \"[{actual_token}]\"\n",
    "        trgs = [\n",
    "            hf_tokenizer.decode(s[0][idx]) if (tok_id == ignore_token_id) else f\"[{hf_tokenizer.decode(tok_id)}]\"\n",
    "            for idx, tok_id in enumerate(s[1])\n",
    "            if (s[0][idx] not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        # same as above except we replace the [MASK] with the PREDICTED token\n",
    "        preds = [\n",
    "            hf_tokenizer.decode(s[0][idx]) if (tok_id == ignore_token_id) else f\"[{hf_tokenizer.decode(t[0][idx])}]\"\n",
    "            for idx, tok_id in enumerate(s[1])\n",
    "            if (s[0][idx] not in dnm_tok_ids)\n",
    "        ]\n",
    "\n",
    "        res.append((\" \".join(inps[:trunc_at]).strip(), \" \".join(trgs[:trunc_at]).strip(), \" \".join(preds[:trunc_at]).strip()))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"target\", \"prediction\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hostile  when  the  sett ler  ' s  presence  led  to  competition &lt;mask&gt;  resources , &lt;mask&gt;  to [ the]  occupation  of  the  indigenous  inhabitants &lt;mask&gt;  lands . &lt;mask&gt;  diseases &lt;mask&gt; imated  Aboriginal  populations ,  and  the  occupation [ or]  destruction  of  lands  and  food  resources  sometimes  led  to  starvation &lt;mask&gt; &lt;mask&gt;  and [vine]  neither &lt;mask&gt;  British  nor  the    approached &lt;mask&gt;  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers &lt;mask&gt;  individual  tribes  rather  than  systematic  warfare .  At  times &lt;mask&gt;  however ,  the  frontier  wars  did  see  the  involvement  of  British  soldiers  and  later  mounted  police  units .  Not  all  Aboriginal  groups  resisted  white  encro achment  on  their  lands [,]  while  many   &lt;mask&gt; &lt;mask&gt;  mounted  police &lt;mask&gt;  and  were &lt;mask&gt;  in</td>\n",
       "      <td>hostile  when  the  sett ler  ' s  presence  led  to  competition [ over]  resources , [ and]  to [ the]  occupation  of  the  indigenous  inhabitants [ ']  lands . [ European]  diseases [ dec] imated  Aboriginal  populations ,  and  the  occupation [ or]  destruction  of  lands  and  food  resources  sometimes  led  to  starvation [.] [ By]  and [ large]  neither [ the]  British  nor  the    approached [ the]  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers [ and]  individual  tribes  rather  than  systematic  warfare .  At  times [,]  however ,  the  frontier  wars  did  see  the  involvement  of  British  soldiers  and  later  mounted  police  units .  Not  all  Aboriginal  groups  resisted  white  encro achment  on  their  lands [,]  while  many   [ served] [ in]  mounted  police [ units]  and  were [ involved]  in</td>\n",
       "      <td>hostile  when  the  sett ler  ' s  presence  led  to  competition [ for]  resources , [ leading]  to [ the]  occupation  of  the  indigenous  inhabitants [ of]  lands . [ Chronic]  diseases [ dec] imated  Aboriginal  populations ,  and  the  occupation [ or]  destruction  of  lands  and  food  resources  sometimes  led  to  starvation [.] [,]  and [ so]  neither [ the]  British  nor  the    approached [ the]  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers [ and]  individual  tribes  rather  than  systematic  warfare .  At  times [,]  however ,  the  frontier  wars  did  see  the  involvement  of  British  soldiers  and  later  mounted  police  units .  Not  all  Aboriginal  groups  resisted  white  encro achment  on  their  lands [,]  while  many   [ ] [ also]  mounted  police [ units]  and  were [ involved]  in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pursue  an  aggressive  campaign [ newcomers]  clear  the &lt;mask&gt;  from    in  order  to  free  their  troops  for  subsequent  operations &lt;mask&gt; ,  rather  than  maintaining  the  defensive  posture  the  US  forces  had &lt;mask&gt; .  However , &lt;mask&gt;  estimates  of &lt;mask&gt; [ strength]  were  later [ found]  to  be  grossly  inaccurate  and  after  the  war &lt;mask&gt;  was  found &lt;mask&gt;  the [ number]  of  Japanese  on  the  island  at  this  time  was  closer  to  40  @ &lt;mask&gt; @  000 .   \\n  The  campaign  that  Australian  planners &lt;mask&gt;  ent &lt;mask&gt; &lt;mask&gt;  separate  drives  :  in  the  north ,  it  was  planned  that  Japanese &lt;mask&gt;  would &lt;mask&gt;  forced  into  the  narrow    Peninsula  and &lt;mask&gt;  ;  in  the  centre  the  seizure  of  Pearl  Ridge  would &lt;mask&gt;  the  Australians  control  of</td>\n",
       "      <td>pursue  an  aggressive  campaign [ to]  clear  the [ Japanese]  from    in  order  to  free  their  troops  for  subsequent  operations [ elsewhere] ,  rather  than  maintaining  the  defensive  posture  the  US  forces  had [ adopted] .  However , [ Allied]  estimates  of [ Japanese] [ strength]  were  later [ found]  to  be  grossly  inaccurate  and  after  the  war [ it]  was  found [ that]  the [ number]  of  Japanese  on  the  island  at  this  time  was  closer  to  40  @ [,] @  000 .   \\n  The  campaign  that  Australian  planners [ developed]  ent [ailed] [ three]  separate  drives  :  in  the  north ,  it  was  planned  that  Japanese [ forces]  would [ be]  forced  into  the  narrow    Peninsula  and [ contained]  ;  in  the  centre  the  seizure  of  Pearl  Ridge  would [ give]  the  Australians  control  of</td>\n",
       "      <td>pursue  an  aggressive  campaign [ to]  clear  the [ island]  from    in  order  to  free  their  troops  for  subsequent  operations [ there] ,  rather  than  maintaining  the  defensive  posture  the  US  forces  had [ assumed] .  However , [ Australian]  estimates  of [ Japanese] [ strength]  were  later [ found]  to  be  grossly  inaccurate  and  after  the  war [ it]  was  found [,]  the [ number]  of  Japanese  on  the  island  at  this  time  was  closer  to  40  @ [-] @  000 .   \\n  The  campaign  that  Australian  planners [ undertook]  ent [ailed] [ two]  separate  drives  :  in  the  north ,  it  was  planned  that  Japanese [ forces]  would [ be]  forced  into  the  narrow    Peninsula  and [ south]  ;  in  the  centre  the  seizure  of  Pearl  Ridge  would [ give]  the  Australians  control  of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction\n",
    "\n",
    "While `Learner.blurr_generate` will work well for causal LMs designed for text generation, it won't for MLM models designed to predict masked tokens.  To accomodate the later, we add `Learner.blurr_fill_mask` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_fill_mask(\n",
    "    self: Learner,\n",
    "    # Your input_ids or raw text string with a `hf_tokenizer.mask_token`\n",
    "    inp: Union[List[int], str],\n",
    "    # The number of predictions you want to return for the [MASK]ed token\n",
    "    n_preds: int = 1,\n",
    "    # Any other keyword arguments you want applied to text generation\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"For MLM models\"\"\"\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    if isinstance(inp, str):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors=\"pt\", **tok_kwargs)\n",
    "    else:\n",
    "        # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "        input_ids = inp.as_subclass(Tensor)\n",
    "\n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    mask_token_index = torch.where(input_ids == hf_tokenizer.mask_token_id)[1]\n",
    "\n",
    "    outputs = self.model.hf_model(input_ids)\n",
    "    mask_token_logits = outputs.logits[0, mask_token_index, :]\n",
    "    preds = torch.topk(mask_token_logits, n_preds, dim=-1).indices[0].tolist()\n",
    "\n",
    "    outputs = [inp.replace(hf_tokenizer.mask_token, hf_tokenizer.decode([tok_id]).strip()) for tok_id in preds]\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best place on earth is here.',\n",
       " 'The best place on earth is Antarctica.',\n",
       " 'The best place on earth is America.',\n",
       " 'The best place on earth is there.',\n",
       " 'The best place on earth is home.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_fill_mask(f\"The best place on earth is {hf_tokenizer.mask_token}.\", n_preds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache(), gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForLM`\n",
    "\n",
    "We can use the `BlearnerForLM` for either Causal or Masked language models.  With one line of code, we get our DataBlock, DataLoaders, and Blearner with sensible defaults and ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForLM(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        kwargs[\"loss_func\"] = kwargs.get(\"loss_func\", PreCalculatedCrossEntropyLoss())\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self, lm_type):\n",
    "        return AutoModelForCausalLM if (lm_type == LMType.CAUSAL) else AutoModelForMaskedLM\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        return LMMetricsCallback()\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The language modeling strategy (or objective)\n",
    "        lm_strategy_cls: BaseLMStrategy = CausalLMStrategy,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # get our hf objects\n",
    "        lm_type = lm_strategy_cls.get_lm_type()\n",
    "        model_cls = cls.get_model_cls(lm_type=lm_type)\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(pretrained_model_name_or_path, model_cls=model_cls)\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # define DataBlock and DataLoaders\n",
    "        bbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=lm_strategy_cls)\n",
    "\n",
    "        input_return_type = CausalLMTextInput if (lm_type == LMType.CAUSAL) else MLMTextInput\n",
    "        blocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=input_return_type), noop)\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=ItemGetter(text_attr), splitter=dblock_splitter)\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance with default metrics (optional)\n",
    "        learner_kwargs[\"metrics\"] = learner_kwargs.pop(\"metrics\", [perplexity])\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "learn = BlearnerForLM.from_data(df, \"gpt2\", text_attr=0, dl_kwargs={\"bs\": 2}).to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = Bob Dylan = \\n \\n Bob Dylan ( / &lt;unk&gt; / ; born Robert Allen Zimmerman, May 24, 1941 ) is an American singer @-@ songwriter, artist and writer. He has been influential in popular music and culture for more than five decades. Much of his most celebrated work dates from the 1960s when his songs chronicled social unrest, although Dylan repudiated suggestions from journalists that he was a spokesman for his generation. Nevertheless, early songs such as \" Blowin'in the Wind \" and \" The Times They A</td>\n",
       "      <td>\\n = Bob Dylan = \\n \\n Bob Dylan ( / &lt;unk&gt; / ; born Robert Allen Zimmerman, May 24, 1941 ) is an American singer @-@ songwriter, artist and writer. He has been influential in popular music and culture for more than five decades. Much of his most celebrated work dates from the 1960s when his songs chronicled social unrest, although Dylan repudiated suggestions from journalists that he was a spokesman for his generation. Nevertheless, early songs such as \" Blowin'in the Wind \" and \" The Times They Ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Track and field = \\n \\n Track and field is a sport which includes athletic contests established on the skills of running, jumping, and throwing. The name is derived from the sport's typical venue : a stadium with an oval running track enclosing a grass field where the throwing and jumping events take place. Track and field is categorised under the umbrella sport of athletics, which also includes road running, cross country running, and race walking. \\n The running events, which include sprints</td>\n",
       "      <td>\\n = Track and field = \\n \\n Track and field is a sport which includes athletic contests established on the skills of running, jumping, and throwing. The name is derived from the sport's typical venue : a stadium with an oval running track enclosing a grass field where the throwing and jumping events take place. Track and field is categorised under the umbrella sport of athletics, which also includes road running, cross country running, and race walking. \\n The running events, which include sprints,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.521133</td>\n",
       "      <td>3.112241</td>\n",
       "      <td>22.471352</td>\n",
       "      <td>0.428322</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=3e-3, cbs=[BlearnerForLM.get_metrics_cb()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = Military history of Australia = \\n \\n The military history of Australia spans the nation's 220 @-@ year modern history, from the early Australian frontier wars between &lt;unk&gt; and Europeans to the ongoing conflicts in Iraq and Afghanistan in the ear</td>\n",
       "      <td>\\n = Military history of Australia = \\n \\n The military history of Australia spans the nation's 220 @-@ year modern history, from the early Australian frontier wars between &lt;unk&gt; and Europeans to the ongoing conflicts in Iraq and Afghanistan in the earl</td>\n",
       "      <td>\\n\\n =\\n = the\\n\\n\\n =\\n = Australian history of Australia is the period froms history- 1year years period era. including the early days colonial to to the 18&gt; Australia &lt; &lt; the early conflict between the and Afghanistan. the late 1980st century. The the hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Air Rhodesia Flight &lt;unk&gt; = \\n \\n Air Rhodesia Flight &lt;unk&gt; was a scheduled passenger flight that was shot down by the Zimbabwe People's Revolutionary Army ( &lt;unk&gt; ) on 3 September 1978, during the Rhodesian Bush War. The aircraft involved, a Vick</td>\n",
       "      <td>\\n = Air Rhodesia Flight &lt;unk&gt; = \\n \\n Air Rhodesia Flight &lt;unk&gt; was a scheduled passenger flight that was shot down by the Zimbabwe People's Revolutionary Army ( &lt;unk&gt; ) on 3 September 1978, during the Rhodesian Bush War. The aircraft involved, a Vicke</td>\n",
       "      <td>\\n\\n =planes\\n\\n\\n\\n&gt;\\n Air\\n =\\n = Rhodesia Flight &lt;unk&gt; = a flight flight flight from was scheduled down by a Sovietan'ss Liberation Army (Zunk&gt; ) in September August 1944. killing a liberationian civil War. The plane was in was civilian- Airickersount, \" A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': ' Blurr is fun to work with because you get to the first number while in the game. Your first number is the number where he is in your game and your first string is the number where you are in the game.'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masked language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForLM.from_data(df, \"bert-base-cased\", lm_strategy_cls=BertMLMStrategy, text_attr=0, dl_kwargs={\"bs\": 2}).to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= Bob Dylan = Bob Dylan [MASK] / &lt; un ##k [MASK] / ; born Robert Allen [MASK] ##immer ##man [,] May 24 , 1941 ) [MASK] an American [MASK] @ [MASK] @ songwriter , artist and writer . [MASK] has been influential in popular [MASK] and culture for more than five decades . Much of his most [laugh] work dates from the 1960s when [MASK] songs [MASK] ##d social unrest , although Dylan re [MASK] [MASK] [MASK] suggestions from journalists that he was a spokesman for [cannabis] generation . [MASK] , early songs such as \" B ##low ##in ' in the [MASK] \" and \" The [MASK] They Are a @ - @ [MASK] un ##k &gt; ' \" became anthem [MASK] for the American civil [MASK] and [anti] [MASK] - @ war movements . After he left his initial base in the American folk music revival , his six @ - @ minute single \" Like a Rolling [Stone] \" altered the range of popular [MASK] [Shooting] 1965 . His mid @ - [MASK] 1960s recordings , backed by rock [MASK] , reached the top end of the United [MASK] music charts while also attracting &lt; un ##k &gt; and criticism from others in the folk movement . Dylan ' s lyrics have incorporated various political , social , [MASK] , and literary influences . They def ##ied existing [MASK] music conventions and appealed to the b ##urge ##oning counter ##culture . Initially inspired [MASK] the performances</td>\n",
       "      <td>= Bob Dylan = Bob Dylan [(] / &lt; un ##k [&gt;] / ; born Robert Allen [Z] ##immer ##man [,] May 24 , 1941 ) [is] an American [singer] @ [-] @ songwriter , artist and writer . [He] has been influential in popular [music] and culture for more than five decades . Much of his most [celebrated] work dates from the 1960s when [his] songs [chronicle] ##d social unrest , although Dylan re [##pu] [##dia] [##ted] suggestions from journalists that he was a spokesman for [his] generation . [Nevertheless] , early songs such as \" B ##low ##in ' in the [Wind] \" and \" The [Times] They Are a @ - @ [&lt;] un ##k &gt; ' \" became anthem [##s] for the American civil [rights] and [anti] [@] - @ war movements . After he left his initial base in the American folk music revival , his six @ - @ minute single \" Like a Rolling [Stone] \" altered the range of popular [music] [in] 1965 . His mid @ - [@] 1960s recordings , backed by rock [musicians] , reached the top end of the United [States] music charts while also attracting &lt; un ##k &gt; and criticism from others in the folk movement . Dylan ' s lyrics have incorporated various political , social , [philosophical] , and literary influences . They def ##ied existing [pop] music conventions and appealed to the b ##urge ##oning counter ##culture . Initially inspired [by] the performances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Guitar Hero = [MASK] Guitar Hero [MASK] ( [sometimes] referred to as the Hero [series] [MASK] is a series of music rhythm games first published in 2005 by [MASK] ##O [MASK] ##ane and [Ha] ##rmon ##ix , and distributed [MASK] Act [MASK] , in which players use a guitar @ - @ shaped [MASK] controller to [##pted] ##mu [MASK] playing lead , bass guitar , and rhythm guitar across [MASK] rock music [MASK] . Players match notes that scroll on @ - @ screen [MASK] colored f [MASK] buttons on the [MASK] , [MASK] ##tr ##um ##ming the controller in time to the music in order to score points [MASK] and keep the virtual audience excited . The [games] attempt to mimic many features of playing a real guitar , [MASK] the use [MASK] fast @ - @ finger ##ing hammer @ - @ &lt; un ##k &gt; and pull @ - @ offs [MASK] the [use] of the w ##ham ##my bar to alter the pitch of notes . Most games support single player modes , typically a Career mode to play through all the [MASK] [MASK] the game , and both competitive and cooperative multiplayer modes . With [MASK] introduction of Guitar Hero World Tour in 2008 , [colloquially] game includes support for [MASK] four @ - @ player band [MASK] vocals and [MASK] . The series initially used mostly cover versions of [songs] created by &lt; un ##k &gt; Sound , but most recent titles feature</td>\n",
       "      <td>= Guitar Hero = [The] Guitar Hero [series] ( [sometimes] referred to as the Hero [series] [)] is a series of music rhythm games first published in 2005 by [Red] ##O [##ct] ##ane and [Ha] ##rmon ##ix , and distributed [by] Act [##ivision] , in which players use a guitar @ - @ shaped [game] controller to [si] ##mu [##late] playing lead , bass guitar , and rhythm guitar across [numerous] rock music [songs] . Players match notes that scroll on @ - @ screen [to] colored f [##ret] buttons on the [controller] , [s] ##tr ##um ##ming the controller in time to the music in order to score points [,] and keep the virtual audience excited . The [games] attempt to mimic many features of playing a real guitar , [including] the use [of] fast @ - @ finger ##ing hammer @ - @ &lt; un ##k &gt; and pull @ - @ offs [and] the [use] of the w ##ham ##my bar to alter the pitch of notes . Most games support single player modes , typically a Career mode to play through all the [songs] [in] the game , and both competitive and cooperative multiplayer modes . With [the] introduction of Guitar Hero World Tour in 2008 , [the] game includes support for [a] four @ - @ player band [including] vocals and [drums] . The series initially used mostly cover versions of [songs] created by &lt; un ##k &gt; Sound , but most recent titles feature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>lm_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.618286</td>\n",
       "      <td>2.440292</td>\n",
       "      <td>11.476390</td>\n",
       "      <td>0.583707</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=6e-4, cbs=[BlearnerForLM.get_metrics_cb()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= Military history of Australia = The [MASK] [MASK] of Australia spans the [nation] [MASK] s 220 @ - @ year modern history , from the early Australian frontier wars between &lt; un ##k &gt; and Europeans to the [MASK] conflicts [MASK] Iraq and Afghanistan in the early 21st century . Although this history is short when compared to that of many other nations , Australia has been involved in [MASK] [DNA] and wars , [and] war [MASK] military service [MASK] been significant influences on Australian society and national identity [MASK] including the An [MASK] spirit . The relationship [between] [MASK] and [MASK] society [MASK] [MASK] been [MASK] by the enduring themes of Australian [MASK] culture and its unique security di [MASK] . As [MASK] [MASK] un ##k &gt; , the Australian colonies participated in Britain ' s small wars [MASK] the 19th [MASK] , while later as a &lt; un [MASK] &gt; [do] ##mini [MASK] , [MASK] then an independent nation , Australia fought in the First [MASK] War and Second World War , [##bang] well as in the wars in Korea , Malaya , Borneo [infamous] Vietnam during the Cold War [MASK] In the Post @ - [MASK] Vietnam era Australian [MASK] have been involved in numerous international peace ##keeping missions , through the United Nations and other agencies , including in the Sinai , Persian [Allan] , [&lt;] un ##k &gt; , Somalia , East Timor and the Solomon Islands , while [MASK] recently they have also</td>\n",
       "      <td>= Military history of Australia = The [military] [history] of Australia spans the [nation] ['] s 220 @ - @ year modern history , from the early Australian frontier wars between &lt; un ##k &gt; and Europeans to the [ongoing] conflicts [in] Iraq and Afghanistan in the early 21st century . Although this history is short when compared to that of many other nations , Australia has been involved in [numerous] [conflicts] and wars , [and] war [and] military service [have] been significant influences on Australian society and national identity [,] including the An [##zac] spirit . The relationship [between] [war] and [Australian] society [has] [also] been [shaped] by the enduring themes of Australian [strategic] culture and its unique security di [##lemma] . As [British] [&lt;] un ##k &gt; , the Australian colonies participated in Britain ' s small wars [of] the 19th [century] , while later as a &lt; un [##k] &gt; [do] ##mini [##on] , [and] then an independent nation , Australia fought in the First [World] War and Second World War , [as] well as in the wars in Korea , Malaya , Borneo [and] Vietnam during the Cold War [.] In the Post @ - [@] Vietnam era Australian [forces] have been involved in numerous international peace ##keeping missions , through the United Nations and other agencies , including in the Sinai , Persian [Gulf] , [&lt;] un ##k &gt; , Somalia , East Timor and the Solomon Islands , while [more] recently they have also</td>\n",
       "      <td>= Military history of Australia = The [Military] [history] of Australia spans the [nation] ['] s 220 @ - @ year modern history , from the early Australian frontier wars between &lt; un ##k &gt; and Europeans to the [major] conflicts [in] Iraq and Afghanistan in the early 21st century . Although this history is short when compared to that of many other nations , Australia has been involved in [both] [wars] and wars , [and] war [and] military service [have] been significant influences on Australian society and national identity [,] including the An [##zac] spirit . The relationship [between] [Australia] and [Australian] society [has] [also] been [shaped] by the enduring themes of Australian [popular] culture and its unique security di [##lemma] . As [a] [&lt;] un ##k &gt; , the Australian colonies participated in Britain ' s small wars [in] the 19th [century] , while later as a &lt; un [##k] &gt; [do] ##mini [##on] , [and] then an independent nation , Australia fought in the First [World] War and Second World War , [as] well as in the wars in Korea , Malaya , Borneo [and] Vietnam during the Cold War [.] In the Post @ - [@] Vietnam era Australian [soldiers] have been involved in numerous international peace ##keeping missions , through the United Nations and other agencies , including in the Sinai , Persian [Gulf] , [&lt;] un ##k &gt; , Somalia , East Timor and the Solomon Islands , while [more] recently they have also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Air Rhodesia Flight &lt; un ##k &gt; [MASK] Air Rhodesia [Flight] &lt; un ##k &gt; was [MASK] scheduled passenger flight that was shot down by the Zimbabwe People ' s Revolutionary [Army] ( &lt; un ##k &gt; ) on 3 September 1978 , during the [MASK] ##n Bush War . The aircraft involved , a Vickers Viscount [MASK] the &lt; un ##k [X] , was flying the last [leg] of Air Rhodesia ' s regular [MASK] [Baton] from Victoria Falls to the capital Salisbury , via [MASK] resort town [MASK] &lt; un ##k &gt; . Soon after Flight &lt; [MASK] ##k &gt; took off , a group of &lt; un ##k &gt; guerrilla ##s scored a direct [MASK] on its star ##board wing with a Soviet @ - @ [MASK] &lt; un ##k &gt; 2 surface @ - @ [##ssent] @ - @ air [MASK] [MASK] un ##k &gt; missile , critically damaging the aircraft and forcing an emergency landing [MASK] An attempted belly landing [Marissa] a cotton field just west of &lt; un ##k &gt; was &lt; [un] [MASK] &gt; by an unseen ditch , which caused the plane to [MASK] [MASK] and break up [MASK] Of the 52 passengers [MASK] [MASK] [MASK] , 38 died in this [MASK] ; the insurgents then approached the wreckage , rounded up the 10 survivors [MASK] could see and massacre ##d them with automatic [MASK] . Three [MASK] [Cooke] by hiding in the surrounding bush , while a [MASK] five lived</td>\n",
       "      <td>= Air Rhodesia Flight &lt; un ##k &gt; [=] Air Rhodesia [Flight] &lt; un ##k &gt; was [a] scheduled passenger flight that was shot down by the Zimbabwe People ' s Revolutionary [Army] ( &lt; un ##k &gt; ) on 3 September 1978 , during the [Rhodesia] ##n Bush War . The aircraft involved , a Vickers Viscount [named] the &lt; un ##k [&gt;] , was flying the last [leg] of Air Rhodesia ' s regular [scheduled] [service] from Victoria Falls to the capital Salisbury , via [the] resort town [of] &lt; un ##k &gt; . Soon after Flight &lt; [un] ##k &gt; took off , a group of &lt; un ##k &gt; guerrilla ##s scored a direct [hit] on its star ##board wing with a Soviet @ - @ [made] &lt; un ##k &gt; 2 surface @ - @ [to] @ - @ air [infrared] [&lt;] un ##k &gt; missile , critically damaging the aircraft and forcing an emergency landing [.] An attempted belly landing [in] a cotton field just west of &lt; un ##k &gt; was &lt; [un] [##k] &gt; by an unseen ditch , which caused the plane to [cart] [##wheel] and break up [.] Of the 52 passengers [and] [four] [crew] , 38 died in this [crash] ; the insurgents then approached the wreckage , rounded up the 10 survivors [they] could see and massacre ##d them with automatic [gunfire] . Three [passengers] [survived] by hiding in the surrounding bush , while a [further] five lived</td>\n",
       "      <td>= Air Rhodesia Flight &lt; un ##k &gt; [=] Air Rhodesia [Flight] &lt; un ##k &gt; was [a] scheduled passenger flight that was shot down by the Zimbabwe People ' s Revolutionary [Army] ( &lt; un ##k &gt; ) on 3 September 1978 , during the [Rhodesia] ##n Bush War . The aircraft involved , a Vickers Viscount [and] the &lt; un ##k [&gt;] , was flying the last [leg] of Air Rhodesia ' s regular [Flying] [flight] from Victoria Falls to the capital Salisbury , via [the] resort town [of] &lt; un ##k &gt; . Soon after Flight &lt; [un] ##k &gt; took off , a group of &lt; un ##k &gt; guerrilla ##s scored a direct [hit] on its star ##board wing with a Soviet @ - @ [-] &lt; un ##k &gt; 2 surface @ - @ [-] @ - @ air [&lt;] [&lt;] un ##k &gt; missile , critically damaging the aircraft and forcing an emergency landing [.] An attempted belly landing [in] a cotton field just west of &lt; un ##k &gt; was &lt; [un] [##k] &gt; by an unseen ditch , which caused the plane to [crash] [over] and break up [.] Of the 52 passengers [aboard] [the] [crash] , 38 died in this [crash] ; the insurgents then approached the wreckage , rounded up the 10 survivors [who] could see and massacre ##d them with automatic [weapons] . Three [escaped] [died] by hiding in the surrounding bush , while a [further] five lived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfm = first_blurr_tfm(learn.dls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best place on earth is here.',\n",
       " 'The best place on earth is heaven.',\n",
       " 'The best place on earth is everywhere.',\n",
       " 'The best place on earth is Egypt.',\n",
       " 'The best place on earth is India.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_fill_mask(f\"The best place on earth is {batch_tfm.hf_tokenizer.mask_token}.\", n_preds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Whether you're using the low, mid, or high-level APIs, the `text.modeling.language_modeling` provides everything you need to train causual and masked language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
