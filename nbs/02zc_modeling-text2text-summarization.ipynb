{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.text2text.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.text2text.summarization\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, inspect, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.data.text2text.core import *\n",
    "from blurr.data.text2text.summarization import *\n",
    "from blurr.modeling.core import *\n",
    "from blurr.modeling.text2text.core import *\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.0\n",
      "Using fastai 2.1.5\n",
      "Using transformers 3.5.0\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv'); len(cnndm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>\n",
       "      <td>John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>\n",
       "      <td>NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  (CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...   \n",
       "1  (CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              highlights  \\\n",
       "0  John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"   \n",
       "1                                                                                          NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "# pretrained_model_name = \"t5-small\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "#                                                                                model_cls=T5ForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"google/pegasus-cnn_dailymail\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "#                                                                                model_cls=PegasusForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "#                                                                                model_cls=BartForConditionalGeneration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.configuration_bart.BartConfig,\n",
       " transformers.tokenization_bart.BartTokenizer,\n",
       " transformers.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_SummarizationBeforeBatchTransform(hf_arch, hf_tokenizer, max_length=[256, 130])\n",
    "blocks = (HF_Text2TextBlock(before_batch_tfms=before_batch_tfm, input_return_type=HF_SummarizationInput), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('article'), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 256]), torch.Size([2, 68]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan Condon believes in recycling. Just not when it comes to his hotel towels. Condon composts when he's at home in Boulder, Colorado. He eats local, organic and fair-trade food and drives a Honda CR-Z hybrid sports car. You might call him green. Except he's not so green when he travels for his work at an education nonprofit and stays in a hotel, which happens about 10 weeks per year. There, he uses a new towel every day. And don't try to bribe him with a drink or dessert coupon to get him to reuse the same one. \"I could care less about rewards for environmentally conscious behavior unless it's miles,\" Condon wrote in an e-mail. If hotels can't convince a hybrid-driving recycling enthusiast like Condon to go green while traveling, how can they possibly convince everyone else? 9 glamorous movie-star hotels. That's the problem of hotels trying to \"green\" your hotel stay. After guests have paid a pretty penny for a night at the inn, even the most environmental guests may want to treat themselves to fresh towels every day and those little bottles of sweet-smelling shampoo. Despite the fact that most people describe themselves in surveys as environmentally conscious and as preferring green products,</td>\n",
       "      <td>Hotel guests who \"go green\" are happier with their stay.\\nIncreasing water and energy costs are pushing hotels to cut costs wherever they can.\\nMany hotels find that guests don't mind using the same towels and sheets every night.\\nTripAdvisor will be adding a green label for hotels listed on its site.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington (CNN) -- Few answers have emerged to the myriad questions about the Boston Marathon bombing and its aftermath, but that didn't stop political leaders from clashing about what happened and why it did on Sunday talk shows. Republican members of Congress played up a possible connection to global terrorists and said the lone surviving suspect should be designated an enemy combatant to allow unfettered questioning and unlimited detention. Democratic legislators called for handling the 19-year-old suspect as a crime suspect rather than a war enemy, allowing the U.S. citizen the right to legal representation under federal law that could impose the death penalty. A closer look at their statements and arguments showed how politicians blend facts, conjecture and spin to push their side's agenda while countering arguments from across the aisle. The facts so far tell a still-convoluted story. Tamerlan and Dzhokhar Tsarnaev, brothers of northern Caucasus origin who had lived in the United States for years, allegedly set off two bombs near the finish line of Monday's Boston Marathon, killing three people and injuring more than 170. Graham: 'Ball was dropped' in probe of Tamerlan. After the FBI released video footage and photos of the pair on Thursday, they allegedly shot to death a university police officer and</td>\n",
       "      <td>Partisan posturing emerges over Boston bombings on Sunday talk shows.\\nDespite little evidence, Republicans hint of possible international terror ties.\\nDemocrats argue against designating the suspect an enemy combatant.\\nAuthors of immigration reform reject conservative calls to put off the issue.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for summarization tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_rouge(predicted_txts, reference_txts, rouge_keys=[\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True):\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_keys, use_stemmer=use_stemmer)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "\n",
    "    for ref_text, pred_txt in zip(reference_txts, predicted_txts):\n",
    "        scores = scorer.score(ref_text, pred_txt)\n",
    "        aggregator.add_scores(scores)\n",
    "\n",
    "    result = aggregator.aggregate()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here we create a summarization specific subclass of `HF_BaseModelCallback` in order to include custom, summarization specific, metrics, and also handle the pre-calculated loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_SummarizationModelCallback(HF_BaseModelCallback):  \n",
    "    def __init__(self, rouge_metrics=[\"rouge1\", \"rouge2\", \"rougeL\"], \n",
    "                 ignore_token_id=CrossEntropyLossFlat().ignore_index,\n",
    "                 text_gen_kwargs={}, **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='rouge_metrics, ignore_token_id, text_gen_kwargs, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in rouge_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.learn.dls.before_batch[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.tok_kwargs = hf_textblock_tfm.tok_kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "        \n",
    "        \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # grab predicted and reference ids for any metrics that need them\n",
    "        input_ids, attention_mask = self.xb[0]['input_ids'], self.xb[0]['attention_mask']\n",
    "        gen_ids = self.learn.model.hf_model.generate(input_ids=input_ids, \n",
    "                                                     attention_mask=attention_mask, \n",
    "                                                     use_cache=True,\n",
    "                                                     **self.text_gen_kwargs)\n",
    "        \n",
    "        \n",
    "        self.generated_ids += gen_ids.tolist()\n",
    "        self.refernce_ids += [ seq[seq != self.ignore_token_id].tolist()  for seq in self.yb[0] ]\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.generated_ids, self.refernce_ids = [], []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        # are there rouge metrics to calculate?\n",
    "        if (self.rouge_metrics is not None and len(self.rouge_metrics) > 0):\n",
    "            gen_texts = self.hf_tokenizer.batch_decode(self.generated_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            ref_texts = self.hf_tokenizer.batch_decode(self.refernce_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            rouge_results = calculate_rouge(gen_texts, ref_texts, rouge_keys=self.rouge_metrics)\n",
    "            \n",
    "            for rouge_key, scores in rouge_results.items(): \n",
    "                self.custom_metrics_dict[rouge_key] = scores.mid.fmeasure\n",
    "                \n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a custom param splitter to give us a bit more depth in applying discriminative learning rates for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def summarization_splitter(m, arch):\n",
    "    \"\"\"Custom param splitter for summarization models\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    \n",
    "    if arch in ['bart', 'pegasus']:     \n",
    "        embeds = nn.Sequential(\n",
    "            model.model.shared, \n",
    "            model.model.encoder.embed_positions, \n",
    "            model.model.encoder.embed_tokens,\n",
    "            model.model.decoder.embed_positions, \n",
    "            model.model.decoder.embed_tokens\n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.model.encoder, model.model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    if arch in['t5']:\n",
    "        embeds = nn.Sequential(\n",
    "            model.shared, \n",
    "            model.encoder.embed_tokens,\n",
    "            model.decoder.embed_tokens\n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.encoder, model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    raise ValueError('Invalid architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"summarization_splitter\" class=\"doc_header\"><code>summarization_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>summarization_splitter</code>(**`m`**, **`arch`**)\n",
       "\n",
       "Custom param splitter for summarization models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(summarization_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': True,\n",
       " 'length_penalty': 2.0,\n",
       " 'max_length': 130,\n",
       " 'min_length': 30,\n",
       " 'no_repeat_ngram_size': 3,\n",
       " 'num_beams': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen_kwargs = { **hf_config.task_specific_params['summarization'], **{'max_length': 130, 'min_length': 30} }\n",
    "text_gen_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': True,\n",
       " 'length_penalty': 2.0,\n",
       " 'max_length': 130,\n",
       " 'min_length': 30,\n",
       " 'no_repeat_ngram_size': 3,\n",
       " 'num_beams': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "for k in text_gen_kwargs:\n",
    "    if k not in generate_func_args: del text_gen_kwargs[k]\n",
    "        \n",
    "text_gen_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "model_cb = HF_SummarizationModelCallback(text_gen_kwargs=text_gen_kwargs)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                loss_func=CrossEntropyLossFlat(), #HF_PreCalculatedLoss()\n",
    "                cbs=[model_cb],\n",
    "                splitter=partial(summarization_splitter, arch=hf_arch)) #.to_native_fp16() #.to_fp16()\n",
    "\n",
    "learn.create_opt() \n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([]), torch.Size([2, 77, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds['loss'].shape, preds['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, torch.Size([2, 256]), 2, torch.Size([2, 77]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.00010000000474974513, lr_steep=2.0892961401841603e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.912652</td>\n",
       "      <td>1.809375</td>\n",
       "      <td>0.375766</td>\n",
       "      <td>0.157390</td>\n",
       "      <td>0.255853</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max=4e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to take advantage of huggingface's `PreTrainedModel.generate` model, which can be used to easily implement beam search, top-k/nucleous sampling, etc... so that we get more human sounding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10 10About 10 men robbed with pistols and machine machine guns raid a casino in Switzerland and made off\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict(test_article)\n",
    "print(hf_tokenizer.decode(res[0][:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look much like a human-generated summary.  Let's use huggingface's `PreTrainedModel.generate` method to create something more human-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target ===\n",
      " Mexico hosts to up to 10 percent of all known species on Earth.\n",
      "It is home to 502 types of mammals, 290 bird species and 26,000 types of plants.\n",
      "Human development and climate change is placing a big strain on its biodiversity.\n",
      "The Golden Eagle is under threat in spite of being the country's national symbol.\n",
      "\n",
      "=== Prediction ===\n",
      " Climate change and human encroachment on natural environments threaten Mexico's rich wildlife.\n",
      "Mexico is home to 502 types of mammals, 290 species of birds, 1,150 varieties of birds and 26,000 classifications of plants.\n",
      "Some 574 out of 717 reptile species found in Mexico -- the most in any country -- can only be encountered within its borders.\n",
      "Pronatura, a non-profit organization, has selected six species it says symbolize the problems faced by the country.\n"
     ]
    }
   ],
   "source": [
    "b = dls.valid.one_batch()\n",
    "\n",
    "b_before_batch_tfm = dls.before_batch[0]\n",
    "b_hf_tokenizer = before_batch_tfm.hf_tokenizer\n",
    "b_ignore_token_id = before_batch_tfm.ignore_token_id\n",
    "\n",
    "test_input_ids = b[0]['input_ids'][0].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "test_trg_ids = b[1][0].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "test_trg_ids = [ trg[trg != b_ignore_token_id] for trg in test_trg_ids ]\n",
    "\n",
    "gen_text = learn.model.hf_model.generate(test_input_ids, num_beams=4, max_length=130, min_length=30)\n",
    "\n",
    "print('=== Target ===')\n",
    "print(f'{b_hf_tokenizer.decode(test_trg_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)}\\n')\n",
    "\n",
    "print('=== Prediction ===')\n",
    "print(b_hf_tokenizer.decode(gen_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add a `blurr_summarize` method to `Learner` that uses huggingface's `PreTrainedModel.generate` to create our predictions.  For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summarize(self:Learner, inp, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text \n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = self.cbs.filter(lambda el: isinstance(el, HF_SummarizationModelCallback) )[0].text_gen_kwargs\n",
    "    text_gen_kwargs = { **text_gen_kwargs, **kwargs}\n",
    "    \n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.before_batch[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.tok_kwargs\n",
    "\n",
    "    if (isinstance(inp, str)):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors='pt', **tok_kwargs)\n",
    "    else:\n",
    "        # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "        input_ids = inp.as_subclass(Tensor)\n",
    "        \n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    \n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [ hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) \n",
    "               for txt in gen_texts ]\n",
    "    \n",
    "    if hf_textblock_tfm.hf_arch == 'pegasus':\n",
    "        outputs = [o.replace('<n>', ' ') for o in outputs]\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_summarize\" class=\"doc_header\"><code>Learner.blurr_summarize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_summarize</code>(**`inp`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text \n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved, police officer says .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles and was beaten to death .\n",
      "Swiss authorities are working closely with French authorities, police chief says .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved, police officer says .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles and was beaten to death .\n",
      "Swiss authorities are working closely with French authorities, an officer says.\n",
      "\n",
      "=== Prediction 3 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved, police officer says .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles and was beaten to death .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_summarize(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much nicer!!! Now, we can update our @typedispatched `show_results` to use this new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_SummarizationInput, y, samples, outs, learner, ctxs=None, max_n=6, \n",
    "                 input_trunc_at=None, target_trunc_at=None, **kwargs):  \n",
    "    \n",
    "    before_batch_tfm = learner.dls.before_batch[0]\n",
    "    hf_tokenizer = before_batch_tfm.hf_tokenizer\n",
    "    ignore_token_id = before_batch_tfm.ignore_token_id\n",
    "    \n",
    "    gen_text_txts = learner.blurr_summarize(x)\n",
    "    res = L([(\n",
    "        hf_tokenizer.decode(s[0], skip_special_tokens=True)[:input_trunc_at], \n",
    "        hf_tokenizer.decode(s[1][s[1] != ignore_token_id], skip_special_tokens=True)[:target_trunc_at], \n",
    "        gen_txt[:target_trunc_at]\n",
    "    ) for s, gen_txt in zip(samples, gen_text_txts) ])          \n",
    "    \n",
    "    display_df(pd.DataFrame(res, columns=['text', 'target', 'prediction'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Home to up to 10 percent of all known species, Mexico is recognized as one of the most biodiverse regions on the planet. The twin threats of climate change and human encroachment on natural environments are, however, threatening the existence of the country's rich wildlife. And there is a great deal to lose. In the United Nations Environment Program (UNEP) World Conservation Monitoring Centre's list of megadiverse countries Mexico ranks 11th. The list represents a group of 17 countries</td>\n",
       "      <td>Mexico hosts to up to 10 percent of all known species on Earth.\\nIt is home to 502 types of mammals, 290 bird species and 26,000 types of plants.\\nHuman development and climate change is placing a big strain on its biodiversity.\\nThe Golden Eagle is un</td>\n",
       "      <td>Climate change and human encroachment on natural environments threaten Mexico's rich wildlife .\\nMexico is home to 502 types of mammals, 290 species of birds, 1,150 varieties of birds and 26,000 classifications of plants .\\nSome 574 out of 717 reptile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN Student News) -- Parents and Teachers: Watch with your students or record \"Gary + Tony Have a Baby\" when it airs on CNN on Thursday, June 24 at 8 p.m. ET. By recording the documentary, you agree that you will use the program for educational viewing purposes for a one-year period only. No other rights of any kind or nature whatsoever are granted, including, without limitation, any rights to sell, publish, distribute, post online or distribute in any other medium or forum, or use for any com</td>\n",
       "      <td>\"Gary + Tony Have a Baby\" is a documentary that follows the journey of a gay couple as they attempt to become parents.\\nParents and educators can use this guide to initiate discussion with students about the documentary.</td>\n",
       "      <td>\"Gary + Tony Have a Baby\" is a documentary that follows the journey of a gay couple as they attempt to become parents .\\nWe recommend that you preview this program and determine whether it is appropriate before showing it to students .\\nBy recording t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='summarize_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nThere were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved, police officer says .\\nA woman driving by unknowingly blocked the robbers' vehicles and was beaten to death .\\nSwiss authorities are working closely with French authorities, police chief says .\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='summarize_export.pkl')\n",
    "inf_learn.blurr_summarize(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained summarization models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.modeling_bart.BartForConditionalGeneration,\n",
       " transformers.modeling_blenderbot.BlenderbotForConditionalGeneration,\n",
       " transformers.modeling_fsmt.FSMTForConditionalGeneration,\n",
       " transformers.modeling_mbart.MBartForConditionalGeneration,\n",
       " transformers.modeling_pegasus.PegasusForConditionalGeneration,\n",
       " transformers.modeling_prophetnet.ProphetNetForConditionalGeneration,\n",
       " transformers.modeling_t5.T5ForConditionalGeneration,\n",
       " transformers.modeling_xlm_prophetnet.XLMProphetNetForConditionalGeneration]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='ConditionalGeneration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    ('facebook/bart-large-cnn',BartForConditionalGeneration),\n",
    "    ('t5-small', T5ForConditionalGeneration),\n",
    "    #('google/pegasus-cnn_dailymail', PegasusForConditionalGeneration), ... don't fit on my 1080TI :(\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-large-cnn ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizer\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.905564</td>\n",
       "      <td>2.675347</td>\n",
       "      <td>0.279706</td>\n",
       "      <td>0.117743</td>\n",
       "      <td>0.215063</td>\n",
       "      <td>01:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Home to up to 10 percent of all known species, Mexico is recognized as one of the most biodiverse regions on the planet. The twin threats of climate change and human encroachment on natural environments are, however, threatening the existence of the country's rich wildlife. And there is a great deal to lose. In the United Nations Environment Program (UNEP) World Conservation Monitoring Centre's list of megadiverse countries Mexico ranks 11th. The list represents a group of 17 countries</td>\n",
       "      <td>Mexico hosts to up to 10 percent of all known species on Earth.\\nIt is home to 502 types of mammals, 290 bird species and 26,000 types of plants.\\nHuman development and climate change is placing a big strain on its biodiversity.\\nThe Golden Eagle is un</td>\n",
       "      <td>Mexico is one of the most biodiverse region on the planet .\\nIt is home to up to 10 percent of all known species .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dan Condon believes in recycling. Just not when it comes to his hotel towels. Condon composts when he's at home in Boulder, Colorado. He eats local, organic and fair-trade food and drives a Honda CR-Z hybrid sports car. You might call him green. Except he's not so green when he travels for his work at an education nonprofit and stays in a hotel, which happens about 10 weeks per year. There, he uses a new towel every day. And don't try to bribe him with a drink or dessert coupon to get him to re</td>\n",
       "      <td>Hotel guests who \"go green\" are happier with their stay.\\nIncreasing water and energy costs are pushing hotels to cut costs wherever they can.\\nMany hotels find that guests don't mind using the same towels and sheets every night.\\nTripAdvisor will be a</td>\n",
       "      <td>Dan Condon composts when he's at home in Boulder, Colorado .\\nWhen he travels for work, he uses a new towel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5Tokenizer\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.919514</td>\n",
       "      <td>2.680419</td>\n",
       "      <td>0.266945</td>\n",
       "      <td>0.103067</td>\n",
       "      <td>0.202842</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarize: London (CNN) -- In 1948, a hospital outside London witnessed the birth of the Paralympic movement, as a Jewish doctor who had fled Nazi Germany sought to change the lives of patients with spinal injuries -- and inspire new hope in them through sport. The first \"Stoke Mandeville Games\" were organized in 1948 to coincide with the London Olympics, the second to be held in Britain. Named for the hospital in Buckinghamshire where Prof. Ludwig Guttmann's pioneering spinal injuries unit was</td>\n",
       "      <td>Paralympic movement was born in Stoke Mandeville, outside London, in 1948. 2012 Games will be the biggest yet, with 4,200 competitors from 165 countries. In an echo of the first, post-World War II Games, injured veterans are among the athletes. They</td>\n",
       "      <td>In 1948, a hospital outside London witnessed the birth of the Paralympic movement . The first \"Stoke Mandeville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summarize: (CNN) -- Wondering where to go for your next holiday? Experts explain which destinations we should be checking out in 2014. Brazil: The World Cup. The modern game of football, or soccer, may have been born in England's public schools, but many will claim its soul has settled in Brazil. It has the world's most successful international team, winning the World Cup five times. It calls what many claim to be the world's greatest player, Pele, one of its own. And company managers and bosses</td>\n",
       "      <td>New Zealand government threw $50 million into the construction of the Nga Haerenga cycle trails. Nosara in Costa Rica recently awarded a Blue Flag -- a certification awarded to world's best beaches. First few months of 2014 best period for Northern L</td>\n",
       "      <td>Brazil has the world's most successful international team, winning the World Cup five times . Experts explain which destinations we should be checking out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "bsz = 2\n",
    "inp_seq_sz = 128; trg_seq_sz = 130\n",
    "\n",
    "test_results = []\n",
    "for model_name, model_cls in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   model_cls=model_cls)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "    \n",
    "    # 1. build your DataBlock\n",
    "    def add_t5_prefix(inp): return f'summarize: {inp}' if (hf_arch == 't5') else inp\n",
    "    \n",
    "    before_batch_tfm = HF_SummarizationBeforeBatchTransform(hf_arch, hf_tokenizer, \n",
    "                                                            max_length=[inp_seq_sz, trg_seq_sz])\n",
    "    \n",
    "    blocks = (\n",
    "        HF_Text2TextBlock(before_batch_tfms=before_batch_tfm, input_return_type=HF_SummarizationInput), \n",
    "        noop\n",
    "    )\n",
    "    \n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=Pipeline([ColReader('article'), add_t5_prefix]), \n",
    "                       get_y=ColReader('highlights'), \n",
    "                       splitter=RandomSplitter())\n",
    "\n",
    "    dls = dblock.dataloaders(cnndm_df, bs=bsz)\n",
    "\n",
    "    # 2. build your Learner\n",
    "    text_gen_kwargs = {}\n",
    "    if (hf_arch in ['bart', 't5']):\n",
    "        text_gen_kwargs = { \n",
    "            **hf_config.task_specific_params['summarization'], \n",
    "            **{'max_length': 30, 'min_length': 10} \n",
    "        }\n",
    "    \n",
    "    # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "    generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "    for k in text_gen_kwargs.copy():\n",
    "        if k not in generate_func_args: del text_gen_kwargs[k]\n",
    "    \n",
    "    \n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    model_cb = HF_SummarizationModelCallback(text_gen_kwargs=text_gen_kwargs)\n",
    "\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=ranger,\n",
    "                    loss_func=HF_PreCalculatedLoss(),\n",
    "                    cbs=[model_cb],\n",
    "                    splitter=partial(summarization_splitter, arch=hf_arch))\n",
    "\n",
    "    learn.create_opt() \n",
    "    learn.freeze()\n",
    "    \n",
    "    # 3. Run your tests\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***\\n')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING One pass through the model ***')\n",
    "        preds = learn.model(b[0])\n",
    "        test_eq(preds[1].shape[0], bsz)\n",
    "        test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizer</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5Tokenizer</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01za_data-text2text-core.ipynb.\n",
      "Converted 01zb_data-text2text-language-modeling.ipynb.\n",
      "Converted 01zc_data-text2text-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02za_modeling-text2text-core.ipynb.\n",
      "Converted 02zb_modeling-text2text-language-modeling.ipynb.\n",
      "Converted 02zc_modeling-text2text-summarization.ipynb.\n",
      "Converted 99a_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
