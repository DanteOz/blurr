{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your Hugging Face models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, CategoryBlock, MultiCategoryBlock, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import accuracy, F1Score, accuracy_multi, F1ScoreMulti\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from transformers import AutoModelForSequenceClassification, logging, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "\n",
    "from blurr.utils import BLURR, set_seed\n",
    "from blurr.data.core import HF_TextBlock, HF_BaseInput, first_blurr_tfm\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.7.1\n",
      "fastai: 2.5.3\n",
      "transformers: 4.13.0\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.data.core import BlurrDataLoader\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hf_splitter(m: Module):\n",
    "    \"\"\"Splits the Hugging Face model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, \"hf_model\")) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "\n",
    "    groups = L([m for m_name, m in list(top_module.named_children())])\n",
    "    groups += L([m for m_name, m in root_modules[1:]])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"hf_splitter\" class=\"doc_header\"><code>hf_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>hf_splitter</code>(**`m`**:`Module`)\n",
       "\n",
       "Splits the Hugging Face model based on various model architecture conventions\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`m`** : *`<class 'fastai.torch_core.Module'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(hf_splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_BaseModelWrapper(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your Hugging Face model\n",
    "        hf_model: PreTrainedModel,\n",
    "        # If True, hidden_states will be returned and accessed from Learner\n",
    "        output_hidden_states: bool = False,\n",
    "        # If True, attentions will be returned and accessed from Learner\n",
    "        output_attentions: bool = False,\n",
    "        # Any additional keyword arguments you want passed into your models forward method\n",
    "        hf_model_kwargs={},\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        store_attr(self=self, names=\"output_hidden_states, output_attentions, hf_model_kwargs\")\n",
    "        self.hf_model = hf_model.cuda() if torch.cuda.is_available() else hf_model\n",
    "\n",
    "        self.hf_model_fwd_args = list(inspect.signature(self.hf_model.forward).parameters.keys())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for k in list(x):\n",
    "            if k not in self.hf_model_fwd_args:\n",
    "                del x[k]\n",
    "\n",
    "        return self.hf_model(\n",
    "            **x,\n",
    "            output_hidden_states=self.output_hidden_states,\n",
    "            output_attentions=self.output_attentions,\n",
    "            return_dict=True,\n",
    "            **self.hf_model_kwargs\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `HF_BaseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_PreCalculatedLoss:\n",
    "    def __call__(self, inp, targ, **kwargs):\n",
    "        return tensor(0.0)\n",
    "\n",
    "    def decodes(self, x):\n",
    "        return x.argmax(dim=-1)\n",
    "\n",
    "    def activation(self, x):\n",
    "        return F.softmax(x, dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to let your Hugging Face model calculate the loss for you, make sure you include the `labels` argument in your inputs and use `HF_PreCalculatedLoss` as your loss function. Even though we don't really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a `decodes` and `activation` methods).  Why?  Because these methods will get called in methods like `show_results` to get the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_BaseModelCallback(Callback):\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, HF_PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `Callback` for handling what is returned from the Hugging Face model. The return type is (`ModelOutput`)[https://huggingface.co/transformers/main_classes/output.html#transformers.file_utils.ModelOutput] which makes it easy to return all the goodies we asked for.\n",
    "\n",
    "Note that your `Learner`'s loss will be set for you only if the Hugging Face model returns one *and* you are using the `HF_PreCalculatedLoss` loss function.  \n",
    "\n",
    "Also note that anything else you asked the model to return (for example, last hidden state, etc..) will be available for you via the `blurr_model_outputs` property attached to your `Learner`. For example, assuming you are using BERT for a classification task ... if you have told your `HF_BaseModelWrapper` instance to return attentions, you'd be able to access them via `learn.blurr_model_outputs['attentions']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a sequence classification task (e.g., a model that requires a single text input) using the mid, high, and low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the mid-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "imdb_df = pd.read_csv(path / \"texts.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "2  Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...   \n",
       "3  Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...   \n",
       "4  This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "set_seed()\n",
    "blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=RandomSplitter(seed=42))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# dblock.summary(imdb_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "We'll also add in custom summary methods for blurr learners/models that work with dictionary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(OptimWrapper, opt=torch.optim.Adam),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=[accuracy],\n",
    "    cbs=[HF_BaseModelCallback],\n",
    "    splitter=hf_splitter,\n",
    ")\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github.  Let's check that we can get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.348139</td>\n",
       "      <td>0.286452</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "0\t0.324516\t0.294210\t0.885000\t00:11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a @typedispatched implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_BaseInput` typed inputs\n",
    "    x: HF_BaseInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    trg_labels = None\n",
    "    if hasattr(learner.dls, \"label_names\"):\n",
    "        trg_labels = learner.dls.label_names\n",
    "\n",
    "    res = L()\n",
    "    n_inp = learner.dls.n_inp\n",
    "\n",
    "    for idx, (input_ids, label, pred, sample) in enumerate(zip(x, y, outs, samples)):\n",
    "        if idx >= max_n:\n",
    "            break\n",
    "\n",
    "        # add in the input text\n",
    "        rets = [hf_tokenizer.decode(input_ids, skip_special_tokens=True)[:trunc_at]]\n",
    "        # add in the targets\n",
    "        for item in sample[n_inp:]:\n",
    "            if not torch.is_tensor(item):\n",
    "                trg = item\n",
    "            elif is_listy(item.tolist()):\n",
    "                trg = [trg_labels[idx] for idx, val in enumerate(label.numpy().tolist()) if (val == 1)] if (trg_labels) else label.item()\n",
    "            else:\n",
    "                trg = trg_labels[label.item()] if (trg_labels) else label.item()\n",
    "\n",
    "            rets.append(trg)\n",
    "        # add in the predictions\n",
    "        for item in pred:\n",
    "            if not torch.is_tensor(item):\n",
    "                p = item\n",
    "            elif is_listy(item.tolist()):\n",
    "                p = [trg_labels[idx] for idx, val in enumerate(item.numpy().tolist()) if (val == 1)] if (trg_labels) else item.item()\n",
    "            else:\n",
    "                p = trg_labels[item.item()] if (trg_labels) else item.item()\n",
    "\n",
    "            rets.append(p)\n",
    "\n",
    "        res.append(tuplify(rets))\n",
    "\n",
    "    cols = [\"text\"] + [\"target\" if (i == 0) else f\"target_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    cols += [\"prediction\" if (i == 0) else f\"prediction_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    display_df(pd.DataFrame(res, columns=cols)[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Written by the writer who penned the excellent Murder Rooms series which chronicled ACD's adventures with Doctor Joseph Bell, I was looking forward to this and I wasn't disappointed. It was quite slow moving, with a lot of emphasis on Doyle's frustration at Sherlock Holmes which was very accurate and excellently portrayed. It was an interesting character study and very well shot ( on digital video, unusual for a period piece ). The acting was excellent all round, particularly Tim McInnery and B</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was the first movie I ever saw Ashley Judd in and the first film of Victor Nunez' that I ever say, and boy am I glad I did. Its' quiet tone, its' relaxed pace, its' realistic depiction of a young woman just starting out in life, its' fine depiction of the struggles she has to go through to make her mark in life, the decisions she makes based on real things, the people she meets - there is nothing wrong with this movie. It is as close to movie magic as I have ever seen outside of the \" Star</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_predict(self: Learner, items, rm_type_tfms=None):\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    is_split_str = tfm.is_split_into_words and isinstance(items[0], str)\n",
    "    is_df = isinstance(items, pd.DataFrame)\n",
    "\n",
    "    if not is_df and (is_split_str or not is_listy(items)):\n",
    "        items = [items]\n",
    "    dl = self.dls.test_dl(items, rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "\n",
    "    with self.no_bar():\n",
    "        probs, _, decoded_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "\n",
    "    trg_tfms = self.dls.tfms[self.dls.n_inp :]\n",
    "\n",
    "    outs = []\n",
    "    probs, decoded_preds = L(probs), L(decoded_preds)\n",
    "    for i in range(len(items)):\n",
    "        item_probs = probs.itemgot(i)\n",
    "        item_dec_preds = decoded_preds.itemgot(i)\n",
    "        item_dec_labels = tuplify([tfm.decode(item_dec_preds[tfm_idx]) for tfm_idx, tfm in enumerate(trg_tfms)])\n",
    "\n",
    "        outs.append((item_dec_labels, item_dec_preds, item_probs))\n",
    "\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict\" class=\"doc_header\"><code>Learner.blurr_predict</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict</code>(**`items`**, **`rm_type_tfms`**=*`None`*)\n",
       "\n",
       "\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`items`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`rm_type_tfms`** : *`<class 'NoneType'>`*, *optional*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.1104, 0.8896])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"I really liked the movie\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.1104, 0.8896])]),\n",
       " (('negative',), (#1) [tensor(0)], (#1) [tensor([0.5803, 0.4197])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict([\"I really liked the movie\", \"I really hated the movie\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though not useful in sequence classification, we will also add a `blurr_generate` method to `Learner` that uses Hugging Face's `PreTrainedModel.generate` for text generation tasks.  \n",
    "\n",
    "For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_generate(self: Learner, inp, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text \n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    if isinstance(inp, str):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors=\"pt\", **tok_kwargs)\n",
    "    else:\n",
    "        # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "        input_ids = inp.as_subclass(Tensor)\n",
    "\n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "\n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) for txt in gen_texts]\n",
    "\n",
    "    if tfm.hf_arch == \"pegasus\":\n",
    "        outputs = [o.replace(\"<n>\", \" \") for o in outputs]\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_generate\" class=\"doc_header\"><code>Learner.blurr_generate</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_generate</code>(**`inp`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text \n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`inp`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_generate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.261777</td>\n",
       "      <td>0.250683</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.270926</td>\n",
       "      <td>0.258984</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-7, 1e-4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "0\t0.263290\t0.272322\t0.895000\t00:18\n",
    "1\t0.218568\t0.263317\t0.910000\t00:18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Written by the writer who penned the excellent Murder Rooms series which chronicled ACD's adventures with Doctor Joseph Bell, I was looking forward to this and I wasn't disappointed. It was quite slow moving, with a lot of emphasis on Doyle's frustration at Sherlock Holmes which was very accurate and excellently portrayed. It was an interesting character study and very well shot ( on digital video, unusual for a period piece ). The acting was excellent all round, particularly Tim McInnery and B</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was the first movie I ever saw Ashley Judd in and the first film of Victor Nunez' that I ever say, and boy am I glad I did. Its' quiet tone, its' relaxed pace, its' realistic depiction of a young woman just starting out in life, its' fine depiction of the struggles she has to go through to make her mark in life, the decisions she makes based on real things, the people she meets - there is nothing wrong with this movie. It is as close to movie magic as I have ever seen outside of the \" Star</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.1539, 0.8461])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negative',), (#1) [tensor(0)], (#1) [tensor([0.9367, 0.0633])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"seq_class_learn_export\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negative',), (#1) [tensor(0)], (#1) [tensor([0.9371, 0.0629])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the high-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of constructing our low-level `Learner`, we can use the `Blearner` class which provides sensible defaults for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "class Blearner(Learner):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your fast.ai DataLoaders\n",
    "        dls: DataLoaders,\n",
    "        # Your pretrained Hugging Face transformer\n",
    "        hf_model: PreTrainedModel,\n",
    "        # Your `HF_BaseModelCallback`\n",
    "        base_model_cb: HF_BaseModelCallback = HF_BaseModelCallback,\n",
    "        # Any kwargs you want to pass to your `BLearner`\n",
    "        **kwargs\n",
    "    ):\n",
    "        model = kwargs.get(\"model\", HF_BaseModelWrapper(hf_model))\n",
    "        loss_func = kwargs.pop(\"loss_func\", dls.loss_func if hasattr(dls, \"loss_func\") else None)\n",
    "        splitter = kwargs.pop(\"splitter\", hf_splitter)\n",
    "\n",
    "        super().__init__(dls, model=model, loss_func=loss_func, splitter=splitter, **kwargs)\n",
    "\n",
    "        self.add_cb(base_model_cb)\n",
    "        self.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Blearner(dls, hf_model, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.369877</td>\n",
       "      <td>0.285627</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After gorging myself on a variety of seemingly immature movies purchased on ex-rental DVDs, I figured that the time was right for a little serious drama and who better to provide it than Sam Mendes? For a number of reasons, \"American Beauty\" doesn't appeal to me as much as this film which is easily the darkest thing that Tom Hanks has ever done and probably one of the most underrated films of the last decade. For this is not a simple gangster tale lifted from its graphic novel origins, and is s</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George Cukor directs a brooding and cynical classic. The distinctive Ronald Coleman is at his best in this piece of Noir about an actor who loses himself in his roles. The acclaimed Anthony John(Colman)has driven his wife Brita(Signe Hasso)away with his highly fueled temper and erratic behavior. But the two manage to continue working together to please their audiences. Things begin to change as John is becoming bored with his career; he reluctantly agrees to play Othello. He gets deep into char</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.2342, 0.7658])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negative',), (#1) [tensor(0)], (#1) [tensor([0.8425, 0.1575])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BlearnerForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSequenceClassification(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForSequenceClassification\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else tuple(r[inp] for inp in attr)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_y(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else [r[inp] for inp in attr]\n",
    "\n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls,\n",
    "        # Your raw dataset\n",
    "        data,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = 2,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=cls.get_model_cls(), config_kwargs={\"num_labels\": n_labels}\n",
    "        )\n",
    "\n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if preprocess_func:\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, text_attr, label_attr)\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # defin our input/target getters\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            get_x = ColReader(text_attr)\n",
    "            get_y = ColReader(label_attr)\n",
    "        else:\n",
    "            get_x = partial(cls._get_x, attr=text_attr)\n",
    "            get_y = partial(cls._get_y, attr=label_attr)\n",
    "\n",
    "        # infer loss function and default metrics\n",
    "        if is_listy(label_attr):\n",
    "            trg_block = MultiCategoryBlock(encoded=True, vocab=label_attr)\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1ScoreMulti(), accuracy_multi])\n",
    "        else:\n",
    "            trg_block = CategoryBlock\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1Score(), accuracy])\n",
    "\n",
    "        # build our DataBlock and DataLoaders\n",
    "        blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), trg_block)\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls,\n",
    "        # Your pandas DataFrame\n",
    "        df: pd.DataFrame,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if n_labels is None:\n",
    "            n_labels = len(label_attr) if (is_listy(label_attr)) else len(df[label_attr].unique())\n",
    "\n",
    "        return cls._create_learner(\n",
    "            df, pretrained_model_name_or_path, preprocess_func, text_attr, label_attr, n_labels, dblock_splitter, dl_kwargs, learner_kwargs\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls,\n",
    "        # The path to your csv file\n",
    "        csv_file: Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        return cls.from_dataframe(\n",
    "            df,\n",
    "            pretrained_model_name_or_path=pretrained_model_name_or_path,\n",
    "            preprocess_func=preprocess_func,\n",
    "            text_attr=text_attr,\n",
    "            label_attr=label_attr,\n",
    "            n_labels=n_labels,\n",
    "            dblock_splitter=dblock_splitter,\n",
    "            dl_kwargs=dl_kwargs,\n",
    "            learner_kwargs=learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls,\n",
    "        # A list of dictionaries\n",
    "        ds: List[Dict],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if n_labels is None:\n",
    "            n_labels = len(label_attr) if (is_listy(label_attr)) else len(set([item[label_attr] for item in ds]))\n",
    "\n",
    "        return cls._create_learner(\n",
    "            ds, pretrained_model_name_or_path, preprocess_func, text_attr, label_attr, n_labels, dblock_splitter, dl_kwargs, learner_kwargs\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification.from_dataframe(\n",
    "    imdb_df, \"distilroberta-base\", text_attr=\"text\", label_attr=\"label\", dl_kwargs={\"bs\": 4}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.345587</td>\n",
       "      <td>0.303959</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forget the campy'religious' movies that have monopolized the television/film market... this movie has a real feel to it. While it may be deemed as a movie that has cheap emotional draws, it also has that message of forgiveness, and overall good morals. However, I did not like the lighting in this movie... for a movie dealing with such subject matter, it was too bright. I felt it took away from the overall appeal of the movie, which is almost an unforgivable sin, but the recognizable cast, and t</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I watched it some years ago. I remembered it as very mysterious situations, and a mixture of melancholic things, like the fate of Dorothy and the personal future of Bogdanovich.&lt;br /&gt;&lt;br /&gt;I turn to watch on my VHS copy and then I was reviewing it more and more. Nowadays I am waiting for the DVD version, at any price, please!&lt;br /&gt;&lt;br /&gt;The country and easy listening music is very well chosen from the very first second, a bit of blueish, but also happy.&lt;br /&gt;&lt;br /&gt;All the characters are great t</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.2718, 0.7282])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negative',), (#1) [tensor(0)], (#1) [tensor([0.9160, 0.0840])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the `BlurrDataLoader`, there isn't really anything you have to do to use plain ol' PyTorch or fast.ai `Dataset`s and `DataLoaders` with Blurr.  Let's take a look at fine-tuning a model against Glue's MRPC dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from blurr.data.core import preproc_hf_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a7ee3b44b1486b82804d75b75b2ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eef8ea1f6e5457dadc508a165dd59d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7861dd03c4604a63b5cca9dca3588cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return hf_tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = raw_datasets[\"train\"].features[\"label\"].names\n",
    "\n",
    "trn_dl = BlurrDataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    label_names=label_names,\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "val_dl = BlurrDataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    label_names=label_names,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with our fast.ai `DataLoaders` in hand, we can train our model's using the high or low-level Blurr API.  The `BlurrDataLoader` class sets up everything so that we can use our objects just as if we built our `DataLoaders` with the mid-level `DataBlock` API.  This means we get back methods like `one_batch`, `show_batch`, `show_results`, etc... with all levels of Blurr's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification(dls, hf_model, loss_func=CrossEntropyLossFlat())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0014454397605732083)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.698624</td>\n",
       "      <td>0.706874</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.637104</td>\n",
       "      <td>0.679274</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.678463</td>\n",
       "      <td>0.671297</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-8, 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Because of the accounting charge, the company now says it lost $ 1.04 billion, or 32 cents a share, in the quarter ended June 30. Including the charge, the Santa Clara, Calif.-based company said Monday it lost $ 1.04 billion, or 32 cents per share, in the period ending June 30.</td>\n",
       "      <td>equivalent</td>\n",
       "      <td>not_equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The airline also said it has the option to buy 380 more airplanes, orders that would be split evenly between the two manufacturers. The airline has the option to buy 380 more, split evenly between the two manufacturers.</td>\n",
       "      <td>equivalent</td>\n",
       "      <td>equivalent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlbertForSequenceClassification',\n",
       " 'BartForSequenceClassification',\n",
       " 'BertForSequenceClassification',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CanineForSequenceClassification',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'HubertForSequenceClassification',\n",
       " 'IBertForSequenceClassification',\n",
       " 'LEDForSequenceClassification',\n",
       " 'LayoutLMForSequenceClassification',\n",
       " 'LayoutLMv2ForSequenceClassification',\n",
       " 'LongformerForSequenceClassification',\n",
       " 'MBartForSequenceClassification',\n",
       " 'MPNetForSequenceClassification',\n",
       " 'MegatronBertForSequenceClassification',\n",
       " 'MobileBertForSequenceClassification',\n",
       " 'OpenAIGPTForSequenceClassification',\n",
       " 'PerceiverForSequenceClassification',\n",
       " 'ReformerForSequenceClassification',\n",
       " 'RemBertForSequenceClassification',\n",
       " 'RoFormerForSequenceClassification',\n",
       " 'RobertaForSequenceClassification',\n",
       " 'SEWDForSequenceClassification',\n",
       " 'SEWForSequenceClassification',\n",
       " 'SqueezeBertForSequenceClassification',\n",
       " 'TransfoXLForSequenceClassification',\n",
       " 'UniSpeechForSequenceClassification',\n",
       " 'UniSpeechSatForSequenceClassification',\n",
       " 'Wav2Vec2ForSequenceClassification',\n",
       " 'XLMForSequenceClassification',\n",
       " 'XLMRobertaForSequenceClassification',\n",
       " 'XLNetForSequenceClassification']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "[model_type for model_type in BLURR.get_models(task=\"SequenceClassification\") if (not model_type.startswith(\"TF\"))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "pretrained_model_names = [\n",
    "    \"albert-base-v1\",\n",
    "    \"facebook/bart-base\",\n",
    "    \"bert-base-uncased\",\n",
    "    \"google/bigbird-roberta-base\",\n",
    "    \"sshleifer/tiny-ctrl\",\n",
    "    \"camembert-base\",\n",
    "    \"sarnikowski/convbert-medium-small-da-cased\",\n",
    "    \"microsoft/deberta-base\",\n",
    "    \"microsoft/deberta-v2-xlarge\",\n",
    "    \"distilbert-base-uncased\",\n",
    "    \"monologg/electra-small-finetuned-imdb\",\n",
    "    \"flaubert/flaubert_small_cased\",\n",
    "    \"huggingface/funnel-small-base\",\n",
    "    \"gpt2\",\n",
    "    \"kssteven/ibert-roberta-base\",\n",
    "    \"allenai/led-base-16384\",\n",
    "    \"microsoft/layoutlm-base-uncased\",\n",
    "    \"allenai/longformer-base-4096\",\n",
    "    \"sshleifer/tiny-mbart\",\n",
    "    \"microsoft/mpnet-base\",\n",
    "    \"google/mobilebert-uncased\",\n",
    "    \"openai-gpt\",\n",
    "    #'reformer-enwik8',                  # (see model card; does not work with/require a tokenizer so no bueno here)\n",
    "    \"roberta-base\",\n",
    "    \"squeezebert/squeezebert-uncased\",\n",
    "    #'google/tapas-base',                # (requires pip install torch-scatter)\n",
    "    \"transfo-xl-wt103\",\n",
    "    \"xlm-mlm-en-2048\",\n",
    "    \"xlm-roberta-base\",\n",
    "    \"xlnet-base-cased\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "imdb_df = pd.read_csv(path / \"texts.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolutely awful movie. utter waste of time.br /br /background music is so loud that you cannot understand speech.</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i've read a lot of comments about the film and how it's so hard for people to believe that it is a sequel to henry fool</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really wanted to like this movie - the location shots were mostly filmed in Pittsburgh and the trailer had some wonderful photography. But, even for a filmed</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The first one was different and funny. This attempt should have never left the studio. This movie does not make you laugh. It is a weak attempt</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-uncased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>december holiday specials, like the original frosty, ought to be richly - produced with quality music and a wholesome, yet lighthearted storyline. they</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neil simon's the odd couple set up a model for many of his later plays. felix unger and oscar madison were the unsuitably paired</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/bigbird-roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbig_bird\n",
      "tokenizer:\tBigBirdTokenizerFast\n",
      "model:\t\tBigBirdForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Things to Come is that rarity of rarities, a film about ideas. Many films present a vision of the future, but few attempt to show us</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is one of the most wildly distorted portrayals of history. Horribly inaccurate, this movie does nothing to honor the hundreds of thousands of Dutch</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/tiny-ctrl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tctrl\n",
      "tokenizer:\tCTRLTokenizer\n",
      "model:\t\tCTRLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again the same familiar story about a man (writer here) who sell his soul to the devil in order to have his most desired ambition in life: success. Unfunny</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No plot, crappy acting, and pointless gore....&lt;br /&gt;&lt;br /&gt;This is supposed to be a horror movie? There's no fear, or suspense,</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As far as cinematography goes, this film was pretty good for the mid 50's. There were</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This one is a little better than the first one. It still relies on a lot of its humor which bas</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sarnikowski/convbert-medium-small-da-cased ===\n",
      "\n",
      "architecture:\tconvbert\n",
      "tokenizer:\tConvBertTokenizerFast\n",
      "model:\t\tConvBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really liked this movie, and went back to see it two times more within a week. &lt; br / &gt; &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After high - school graduation, best friends Alice and Darlene, decide to take a trip to Thailand. Wh</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/deberta-base ===\n",
      "\n",
      "architecture:\tdeberta\n",
      "tokenizer:\tDebertaTokenizerFast\n",
      "model:\t\tDebertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tigerland is one of the finest films that i have seen, and in my opinion it outdoes even full metal jacket, a film of similar</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I never like to comment on a good film but when it comes to a bad movie, I gotta come really hard on it. Talking about Vivah</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/deberta-v2-xlarge ===\n",
      "\n",
      "architecture:\tdeberta_v2\n",
      "tokenizer:\tDebertaV2Tokenizer\n",
      "model:\t\tDebertaV2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The \"movie aimed at adults\" is a rare thing these days, but Moonstruck does it well, and is still a better than average movie,</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A compelling, honest, daring, and unforgettable psychological horror film that touches on the painful experiences of pain caused by rape - \"Descent\" is a</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what i think i'll probably like best about the new star wars film, \" phantom menace \", is that it will likely blow \" titanic \"</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well \" wayne's world \" is long gone and the years since then have been hard for snl off - shoot movies. from such cinematic off</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== monologg/electra-small-finetuned-imdb ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saw this saturday night at the provincetown film festival, and it's a stick - to - your - bones movie - - it's really</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a beautiful shopgirl in london is swept off her feet by a millionaire tea plantation owner and soon finds herself married and living with him at his villa in</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I couldn' t believe that this movie dates from 2007, it had all the looks of a below-average seventies</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I watched it some years ago. I remembered it as very mysterious situations, and a mixture of melancho</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== huggingface/funnel-small-base ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "model:\t\tFunnelForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in order to hold the public's attention for three hours, we were treated not so much to a family's romp through four generations and</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>franco proves, once again, that he is the prince of surreal &amp; erotic cinema. true, much of his work can be viewed as entertaining slea</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== gpt2 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt2\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPT2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bonanza had a great cast of wonderful actors. Lorne Greene, Pernell Whitaker, Michael Landon, Dan Blocker, and even Guy Williams</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...that seem to be fooling people into seeing qualities in this film that are just not there.&lt;br /&gt;&lt;br /&gt;Near Dark covered the same territory but</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== kssteven/ibert-roberta-base ===\n",
      "\n",
      "architecture:\tibert\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tIBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 17th Century Japan, there lived a samurai who would set the standard for the ages. His name was Mayeda. He is sent on an</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We've all been there, sitting with some friends watching a bad movie, laughing at how terribly it was made and how poor the acting was; eventually</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/led-base-16384 ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This has to be the cheapest film made in 21st century. It is all the way low quality, but at the end it falls below... everything</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is horrible- in a'so bad it's good' kind of way.&lt;br /&gt;&lt;br /&gt;The storyline is rehashed from</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/layoutlm-base-uncased ===\n",
      "\n",
      "architecture:\tlayoutlm\n",
      "tokenizer:\tLayoutLMTokenizerFast\n",
      "model:\t\tLayoutLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" in april 1946, the university of chicago agreed to operate argonne national laboratory, with an association of midwestern universities offering to sponsor the research</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am starting this review with a big giant spoiler about this film. don't read further... here it comes, avert your eyes</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really wanted to like this movie - the location shots were mostly filmed in Pittsburgh and the trailer had some wonderful photography. But, even for a filmed</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prom Night is shot with the artistic eye someone gives while finely crafting a Lifetime original film. You know the one. This October, Lifetime takes a break</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/tiny-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Lopez never caught my interest in his stand up comedy and he still doesn't. But this show is a work of art. It's</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merry madcaps in London stage a treasure hunt, with one young woman inadvertently fixing up her married politician father</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/mpnet-base ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "model:\t\tMPNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it seems evident from this adaptation that he did not. not only did he leave the plot behind, he made up his own! the things that he</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am sick and tired of all these little weenies going on about how this movie \" rocked \". it is pure cg over - acted crap</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weaker entry in the bulldog drummond series, with john howard in the role. usual funny banter and antics, but not much plot. barrymore gets</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of the elements that make this the best at this point, i have to say # 1 is christine mcintire. shemp's scene when</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== openai-gpt ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\topenai\n",
      "tokenizer:\tOpenAIGPTTokenizerFast\n",
      "model:\t\tOpenAIGPTForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i like movies about ufos, which is why i recently decided to rewatch eyes behind the stars after seeing it when i was a kid back in the</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in order to hold the public's attention for three hours, we were treated not so much to a family's romp through four generations and 120 years of</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was a terrible film. There was no story line whatsoever. To top it all off, when they couldn't explain the blood and gore (the</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Loulou' delights in the same way an expensive, high quality French wine does. It leaves you with a very fine aftertaste</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "model:\t\tSqueezeBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i saw this movie once as a kid on the late - late show and fell in love with it. &lt; br / &gt; &lt; br / &gt; it</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of the three titles from jess franco to find their way onto the official dpp video nasty list ( devil hunter, bloody moon and women behind bars )</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== transfo-xl-wt103 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\ttransfo_xl\n",
      "tokenizer:\tTransfoXLTokenizer\n",
      "model:\t\tTransfoXLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is a must-see movie for all. Congress should see this truthful documentary from the point-of-view of the soldier, as should everyone in</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I couldn't believe that this movie dates from 2007, it had all the looks of a below-average seventies horror-flick. Didn't they have any knowledge</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as a long time fan of peter o 'donnell's greatest creation, i watched this film on dvd with no great hopes of enjoyment ; indeed i expected to</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i watched this movie with some friends a couple months ago, i still laugh today thinking about some of the utter stupidity. the first few scenes alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weaker entry in the Bulldog Drummond series, with John Howard in the role. Usual funny banter and antics, but not much</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I watched this film a few times in the 90's and nearly split my sides laughing each time. I love Eddie Murphy as an actor</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"How To Lose Friends &amp; Alienate People\" is not based on Tiger Woods' infidelities. It is a mediocre romantic</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Highly enjoyable, very imaginative, and filmic fairytale all rolled into one, Stardust tells the story of a young man living outside a fantasy</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "bsz = 2\n",
    "seq_sz = 32\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    # 1. get/configure our Hugging Face objects\n",
    "    tok_class = RobertaTokenizer if (\"/ibert\" in model_name) else None\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
    "        model_name, model_cls=model_cls, tokenizer_cls=tok_class, config_kwargs={\"num_labels\": 2}\n",
    "    )\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if hf_tokenizer.pad_token is None:\n",
    "        hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "    # 2. get our DataLoaders\n",
    "    blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=seq_sz, padding=\"max_length\"), CategoryBlock)\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=ColSplitter(col=\"is_valid\"))\n",
    "\n",
    "    dls = dblock.dataloaders(imdb_df, bs=bsz)\n",
    "\n",
    "    # 3. configure our Learner\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=partial(Adam),\n",
    "        loss_func=CrossEntropyLossFlat(),\n",
    "        metrics=[accuracy],\n",
    "        cbs=[HF_BaseModelCallback],\n",
    "        splitter=hf_splitter,\n",
    "    )\n",
    "\n",
    "    learn.freeze()\n",
    "\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 4. train\n",
    "    try:\n",
    "        print(\"*** TESTING DataLoaders ***\")\n",
    "        test_eq(len(b), bsz)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(len(preds[0]), bsz)\n",
    "        #         test_eq(preds[0].shape, torch.Size([bsz, 2]))\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=ShortEpochCallback(pct=0.2, short_valid=True))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big_bird</td>\n",
       "      <td>BigBirdTokenizerFast</td>\n",
       "      <td>BigBirdForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>CTRLTokenizer</td>\n",
       "      <td>CTRLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>convbert</td>\n",
       "      <td>ConvBertTokenizerFast</td>\n",
       "      <td>ConvBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deberta</td>\n",
       "      <td>DebertaTokenizerFast</td>\n",
       "      <td>DebertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deberta_v2</td>\n",
       "      <td>DebertaV2Tokenizer</td>\n",
       "      <td>DebertaV2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPT2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ibert</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>IBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>layoutlm</td>\n",
       "      <td>LayoutLMTokenizerFast</td>\n",
       "      <td>LayoutLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>openai</td>\n",
       "      <td>OpenAIGPTTokenizerFast</td>\n",
       "      <td>OpenAIGPTForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>TransfoXLTokenizer</td>\n",
       "      <td>TransfoXLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=[\"arch\", \"tokenizer\", \"model\", \"result\", \"error\"])\n",
    "display_df(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental building blocks for training using Blurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
