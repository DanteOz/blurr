{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your Hugging Face models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, CategoryBlock, MultiCategoryBlock, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import accuracy, F1Score, accuracy_multi, F1ScoreMulti\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from transformers import AutoModelForSequenceClassification, logging, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "\n",
    "from blurr.utils import BLURR, set_seed\n",
    "from blurr.data.core import HF_TextBlock, HF_BaseInput, first_blurr_tfm\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.15.0\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.data.core import BlurrDataLoader\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `hf_splitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hf_splitter(m: Module):\n",
    "    \"\"\"Splits the Hugging Face model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, \"hf_model\")) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "\n",
    "    groups = L([m for m_name, m in list(top_module.named_children())])\n",
    "    groups += L([m for m_name, m in root_modules[1:]])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"hf_splitter\" class=\"doc_header\"><code>hf_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>hf_splitter</code>(**`m`**:`Module`)\n",
       "\n",
       "Splits the Hugging Face model based on various model architecture conventions\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`m`** : *`<class 'fastai.torch_core.Module'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(hf_splitter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `HF_BaseModelWrapper`\n",
    "\n",
    "Note that `HF_BaseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_BaseModelWrapper(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your Hugging Face model\n",
    "        hf_model: PreTrainedModel,\n",
    "        # If True, hidden_states will be returned and accessed from Learner\n",
    "        output_hidden_states: bool = False,\n",
    "        # If True, attentions will be returned and accessed from Learner\n",
    "        output_attentions: bool = False,\n",
    "        # Any additional keyword arguments you want passed into your models forward method\n",
    "        hf_model_kwargs={},\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        store_attr(self=self, names=\"output_hidden_states, output_attentions, hf_model_kwargs\")\n",
    "        self.hf_model = hf_model.cuda() if torch.cuda.is_available() else hf_model\n",
    "\n",
    "        self.hf_model_fwd_args = list(inspect.signature(self.hf_model.forward).parameters.keys())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for k in list(x):\n",
    "            if k not in self.hf_model_fwd_args:\n",
    "                del x[k]\n",
    "\n",
    "        return self.hf_model(\n",
    "            **x,\n",
    "            output_hidden_states=self.output_hidden_states,\n",
    "            output_attentions=self.output_attentions,\n",
    "            return_dict=True,\n",
    "            **self.hf_model_kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `HF_PreCalculatedLoss`\n",
    "\n",
    "If you want to let your Hugging Face model calculate the loss for you, make sure you include the `labels` argument in your inputs and use `HF_PreCalculatedLoss` as your loss function. Even though we don't really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a `decodes` and `activation` methods).  Why?  Because these methods will get called in methods like `show_results` to get the actual predictions.\n",
    "\n",
    "**Note**: The Hugging Face models ***will always*** calculate the loss for you ***if*** you pass a `labels` dictionary along with your other inputs (so only include it if that is what you intend to happen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_PreCalculatedLoss:\n",
    "    def __call__(self, inp, targ, **kwargs):\n",
    "        return tensor(0.0)\n",
    "\n",
    "    def decodes(self, x):\n",
    "        return x.argmax(dim=-1)\n",
    "\n",
    "    def activation(self, x):\n",
    "        return F.softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `HF_BaseModelCallback`\n",
    "\n",
    "We use a `Callback` for handling what is returned from the Hugging Face model. The return type is (`ModelOutput`)[https://huggingface.co/transformers/main_classes/output.html#transformers.file_utils.ModelOutput] which makes it easy to return all the goodies we asked for.\n",
    "\n",
    "Note that your `Learner`'s loss will be set for you only if the Hugging Face model returns one *and* you are using the `HF_PreCalculatedLoss` loss function.  \n",
    "\n",
    "Also note that anything else you asked the model to return (for example, last hidden state, etc..) will be available for you via the `blurr_model_outputs` property attached to your `Learner`. For example, assuming you are using BERT for a classification task ... if you have told your `HF_BaseModelWrapper` instance to return attentions, you'd be able to access them via `learn.blurr_model_outputs['attentions']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_BaseModelCallback(Callback):\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, HF_PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a sequence classification task (e.g., a model that requires a single text input) using the mid, high, and low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the mid-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47392403d0774d208f007d475c163482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-65b5588450d6b196.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie was horrible. I swear they didn't even write a script they just kinda winged it through out the whole movie. Ice-T was annoying as hell. *SPOILERS Phht more like reasons not to watch it* They sit down and eat breakfast for 20 minutes. he coulda been long gone. The ground was hard it would of been close to impossible to to track him with out dogs. And when ICE-T is on that Hill and uses that Spaz-15 Assault SHOTGUN like its a sniper rifle (and then cuts down a tree with eight shells?? It would take 1000's of shells to cut down a tree that size.) Shotguns and hand guns are conside...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this movie at the cinema many years ago, and one thing surprised me so negatively that I could not see any redeeming virtues in the movies: Dennis Quaid was cast as a policeman that never smiles or grin, while his smile and grin are two of his trademarks. Danny Glover was cast as the bad guy, but - again - most viewers' imagination could not go far enough as to believe him in that role. Also, Jared Leto was not believable as the former medicine student. The tension was just not there, since the killer was known very early. The finale was, again, neither dramatic nor tense: nobo...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a fantastic series first and foremost. It is very well done and very interesting. As a huge WWII buff, I had learned a lot before seeing this series. One of the best things this has going for it is all the interviews with past individuals back when the war was relatively fresh in their minds, comparatively speaking that is. It is nothing against the men that you see getting interviewed in the programs of today, it is just that most of these men weren't really involved in the upper echelons of what was happening then. One of the best parts is the narrating by Sir Laurence Oliver. I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kurosawa really blew it on this one. Every genius is allowed a failure. The concept is fine but the execution is badly blurred.&lt;br /&gt;&lt;br /&gt;There is an air of fantasy about this film making it something of an art film. The poverty stricken of Tokyo deserve a fairer and more realistic portrayal. Many of them have interesting stories to tell. A very disappointing film.</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGM were unsure of how to market Garbo when she first arrived in Hollywood. Mayer had a lot of faith in her and her appearance in \"Torrent\" justified that. She did not speak a word of English so she must have found it difficult to work, also Ricardo Cortez did not make it very easy for her.&lt;br /&gt;&lt;br /&gt;The torrent of the title is the river Juscar that winds through a sleepy little village in Spain. Leonora (Greta Garbo) hopes someday that her voice will bring great wealth and happiness to her struggling parents. Leonora and Don Rafael (Ricardo Cortez) are in love but he is under his mother'...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  This movie was horrible. I swear they didn't even write a script they just kinda winged it through out the whole movie. Ice-T was annoying as hell. *SPOILERS Phht more like reasons not to watch it* They sit down and eat breakfast for 20 minutes. he coulda been long gone. The ground was hard it would of been close to impossible to to track him with out dogs. And when ICE-T is on that Hill and uses that Spaz-15 Assault SHOTGUN like its a sniper rifle (and then cuts down a tree with eight shells?? It would take 1000's of shells to cut down a tree that size.) Shotguns and hand guns are conside...   \n",
       "1  I have seen this movie at the cinema many years ago, and one thing surprised me so negatively that I could not see any redeeming virtues in the movies: Dennis Quaid was cast as a policeman that never smiles or grin, while his smile and grin are two of his trademarks. Danny Glover was cast as the bad guy, but - again - most viewers' imagination could not go far enough as to believe him in that role. Also, Jared Leto was not believable as the former medicine student. The tension was just not there, since the killer was known very early. The finale was, again, neither dramatic nor tense: nobo...   \n",
       "2  This is a fantastic series first and foremost. It is very well done and very interesting. As a huge WWII buff, I had learned a lot before seeing this series. One of the best things this has going for it is all the interviews with past individuals back when the war was relatively fresh in their minds, comparatively speaking that is. It is nothing against the men that you see getting interviewed in the programs of today, it is just that most of these men weren't really involved in the upper echelons of what was happening then. One of the best parts is the narrating by Sir Laurence Oliver. I ...   \n",
       "3                                                                                                                                                                                                                                         Kurosawa really blew it on this one. Every genius is allowed a failure. The concept is fine but the execution is badly blurred.<br /><br />There is an air of fantasy about this film making it something of an art film. The poverty stricken of Tokyo deserve a fairer and more realistic portrayal. Many of them have interesting stories to tell. A very disappointing film.   \n",
       "4  MGM were unsure of how to market Garbo when she first arrived in Hollywood. Mayer had a lot of faith in her and her appearance in \"Torrent\" justified that. She did not speak a word of English so she must have found it difficult to work, also Ricardo Cortez did not make it very easy for her.<br /><br />The torrent of the title is the river Juscar that winds through a sleepy little village in Spain. Leonora (Greta Garbo) hopes someday that her voice will bring great wealth and happiness to her struggling parents. Leonora and Don Rafael (Ricardo Cortez) are in love but he is under his mother'...   \n",
       "\n",
       "   label  is_valid  \n",
       "0      0     False  \n",
       "1      0     False  \n",
       "2      1     False  \n",
       "3      0     False  \n",
       "4      1     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "raw_datasets[0] = raw_datasets[0].add_column(\"is_valid\", [False] * len(raw_datasets[0]))\n",
    "raw_datasets[1] = raw_datasets[1].add_column(\"is_valid\", [True] * len(raw_datasets[1]))\n",
    "\n",
    "final_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n",
    "imdb_df = pd.DataFrame(final_ds)\n",
    "imdb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[0].features[\"label\"].names\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "set_seed()\n",
    "blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, before_batch_kwargs={\"labels\": labels}), CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=RandomSplitter(seed=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# dblock.summary(imdb_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "We'll also add in custom summary methods for blurr learners/models that work with dictionary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(OptimWrapper, opt=torch.optim.Adam),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=[accuracy],\n",
    "    cbs=[HF_BaseModelCallback],\n",
    "    splitter=hf_splitter,\n",
    ")\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github.  Let's check that we can get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=3.311311302240938e-05, steep=0.015848932787775993, valley=0.0005754399462603033, slide=0.0012022644514217973)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.334854</td>\n",
       "      <td>0.266978</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "0\t0.324516\t0.294210\t0.885000\t00:11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a @typedispatched implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_BaseInput` typed inputs\n",
    "    x: HF_BaseInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    # if we've included our labels list, we'll use it to look up the value of our target(s)\n",
    "    trg_labels = tfm.kwargs[\"labels\"] if (\"labels\" in tfm.kwargs) else None\n",
    "\n",
    "    res = L()\n",
    "    n_inp = learner.dls.n_inp\n",
    "\n",
    "    for idx, (input_ids, label, pred, sample) in enumerate(zip(x, y, outs, samples)):\n",
    "        if idx >= max_n:\n",
    "            break\n",
    "\n",
    "        # add in the input text\n",
    "        rets = [hf_tokenizer.decode(input_ids, skip_special_tokens=True)[:trunc_at]]\n",
    "        # add in the targets\n",
    "        for item in sample[n_inp:]:\n",
    "            if not torch.is_tensor(item):\n",
    "                trg = trg_labels[int(item)] if trg_labels else item\n",
    "            elif is_listy(item.tolist()):\n",
    "                trg = [trg_labels[idx] for idx, val in enumerate(label.numpy().tolist()) if (val == 1)] if (trg_labels) else label.item()\n",
    "            else:\n",
    "                trg = trg_labels[label.item()] if (trg_labels) else label.item()\n",
    "\n",
    "            rets.append(trg)\n",
    "        # add in the predictions\n",
    "        for item in pred:\n",
    "            if not torch.is_tensor(item):\n",
    "                p = trg_labels[int(item)] if trg_labels else item\n",
    "            elif is_listy(item.tolist()):\n",
    "                p = [trg_labels[idx] for idx, val in enumerate(item.numpy().tolist()) if (val == 1)] if (trg_labels) else item.item()\n",
    "            else:\n",
    "                p = trg_labels[item.item()] if (trg_labels) else item.item()\n",
    "\n",
    "            rets.append(p)\n",
    "\n",
    "        res.append(tuplify(rets))\n",
    "\n",
    "    cols = [\"text\"] + [\"target\" if (i == 0) else f\"target_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    cols += [\"prediction\" if (i == 0) else f\"prediction_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    display_df(pd.DataFrame(res, columns=cols)[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You don't need to read this review.&lt;br /&gt;&lt;br /&gt;An earlier review, by pninson of Seattle, has already identified all the main shortcomings of this production. I can only amplify its basic arguments.&lt;br /&gt;&lt;br /&gt;Bleak House was a relatively late Dickens novel and is much darker than his earlier work. This is taken too literally by the director, Ross Devenish, who piles on the gloom and fog too much. When Ada, Rick and Esther appear, half an hour into the opening episode, it is a relief just to be</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This TV production of 1970 starring Susannah York and George C. Scott is another proof of how difficult it is to adopt \"Jane Eyre\" to the screen, and how much can go wrong in doing so. It is true that the movie suffered in the transfer to DVD - some scenes which were complete in the original were shortened and so badly edited that there are striking continuity gaps and that even one crucial scene between Jane and Rochester starts in the middle of a sentence! But even if the editing were better,</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.286210</td>\n",
       "      <td>0.270811</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.239452</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-7, 1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You don't need to read this review.&lt;br /&gt;&lt;br /&gt;An earlier review, by pninson of Seattle, has already identified all the main shortcomings of this production. I can only amplify its basic arguments.&lt;br /&gt;&lt;br /&gt;Bleak House was a relatively late Dickens novel and is much darker than his earlier work. This is taken too literally by the director, Ross Devenish, who piles on the gloom and fog too much. When Ada, Rick and Esther appear, half an hour into the opening episode, it is a relief just to be</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This TV production of 1970 starring Susannah York and George C. Scott is another proof of how difficult it is to adopt \"Jane Eyre\" to the screen, and how much can go wrong in doing so. It is true that the movie suffered in the transfer to DVD - some scenes which were complete in the original were shortened and so badly edited that there are striking continuity gaps and that even one crucial scene between Jane and Rochester starts in the middle of a sentence! But even if the editing were better,</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_predict(self: Learner, items, rm_type_tfms=None):\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "    trg_labels = tfm.kwargs[\"labels\"] if (\"labels\" in tfm.kwargs) else None\n",
    "\n",
    "    is_split_str = tfm.is_split_into_words and isinstance(items[0], str)\n",
    "    is_df = isinstance(items, pd.DataFrame)\n",
    "\n",
    "    if not is_df and (is_split_str or not is_listy(items)):\n",
    "        items = [items]\n",
    "    dl = self.dls.test_dl(items, rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "\n",
    "    with self.no_bar():\n",
    "        probs, _, decoded_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "\n",
    "    trg_tfms = self.dls.tfms[self.dls.n_inp :]\n",
    "\n",
    "    outs = []\n",
    "    probs, decoded_preds = L(probs), L(decoded_preds)\n",
    "    for i in range(len(items)):\n",
    "        item_probs = probs.itemgot(i)\n",
    "        item_dec_preds = decoded_preds.itemgot(i)\n",
    "        item_dec_labels = tuplify([tfm.decode(item_dec_preds[tfm_idx]) for tfm_idx, tfm in enumerate(trg_tfms)])\n",
    "        if trg_labels:\n",
    "            item_dec_labels = [trg_labels[int(lbl)] for item in item_dec_labels for lbl in item]\n",
    "\n",
    "        outs.append((item_dec_labels, [p.tolist() if p.dim() > 0 else p.item() for p in item_dec_preds], [p.tolist() for p in item_probs]))\n",
    "\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict\" class=\"doc_header\"><code>Learner.blurr_predict</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict</code>(**`items`**, **`rm_type_tfms`**=*`None`*)\n",
       "\n",
       "\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`items`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`rm_type_tfms`** : *`<class 'NoneType'>`*, *optional*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['pos'], [1], [[0.06736910343170166, 0.9326308369636536]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"I really liked the movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['neg'], [0], [[0.8637050986289978, 0.1362949013710022]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['pos'], [1], [[0.06736906617879868, 0.9326309561729431]]),\n",
       " (['neg'], [0], [[0.7076303958892822, 0.2923696041107178]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict([\"I really liked the movie\", \"I really hated the movie\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though not useful in sequence classification, we will also add a `blurr_generate` method to `Learner` that uses Hugging Face's `PreTrainedModel.generate` for text generation tasks.  \n",
    "\n",
    "For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_generate(self: Learner, inp, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text\n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    if isinstance(inp, str):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors=\"pt\", **tok_kwargs)\n",
    "    else:\n",
    "        # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "        input_ids = inp.as_subclass(Tensor)\n",
    "\n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "\n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) for txt in gen_texts]\n",
    "\n",
    "    if tfm.hf_arch == \"pegasus\":\n",
    "        outputs = [o.replace(\"<n>\", \" \") for o in outputs]\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_generate\" class=\"doc_header\"><code>Learner.blurr_generate</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_generate</code>(**`inp`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text\n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`inp`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_generate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"seq_class_learn_export\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['neg'], [0], [[0.9128817319869995, 0.08711829036474228]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the high-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blearner\n",
    "\n",
    "Instead of constructing our low-level `Learner`, we can use the `Blearner` class which provides sensible defaults for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "class Blearner(Learner):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your fast.ai DataLoaders\n",
    "        dls: DataLoaders,\n",
    "        # Your pretrained Hugging Face transformer\n",
    "        hf_model: PreTrainedModel,\n",
    "        # Your `HF_BaseModelCallback`\n",
    "        base_model_cb: HF_BaseModelCallback = HF_BaseModelCallback,\n",
    "        # Any kwargs you want to pass to your `BLearner`\n",
    "        **kwargs\n",
    "    ):\n",
    "        model = kwargs.get(\"model\", HF_BaseModelWrapper(hf_model))\n",
    "        loss_func = kwargs.pop(\"loss_func\", dls.loss_func if hasattr(dls, \"loss_func\") else None)\n",
    "        splitter = kwargs.pop(\"splitter\", hf_splitter)\n",
    "\n",
    "        super().__init__(dls, model=model, loss_func=loss_func, splitter=splitter, **kwargs)\n",
    "\n",
    "        self.add_cb(base_model_cb)\n",
    "        self.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Blearner(dls, hf_model, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.320718</td>\n",
       "      <td>0.285429</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You don't need to read this review.&lt;br /&gt;&lt;br /&gt;An earlier review, by pninson of Seattle, has already identified all the main shortcomings of this production. I can only amplify its basic arguments.&lt;br /&gt;&lt;br /&gt;Bleak House was a relatively late Dickens novel and is much darker than his earlier work. This is taken too literally by the director, Ross Devenish, who piles on the gloom and fog too much. When Ada, Rick and Esther appear, half an hour into the opening episode, it is a relief just to be</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This TV production of 1970 starring Susannah York and George C. Scott is another proof of how difficult it is to adopt \"Jane Eyre\" to the screen, and how much can go wrong in doing so. It is true that the movie suffered in the transfer to DVD - some scenes which were complete in the original were shortened and so badly edited that there are striking continuity gaps and that even one crucial scene between Jane and Rochester starts in the middle of a sentence! But even if the editing were better,</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['pos'], [1], [[0.03720264136791229, 0.9627973437309265]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['neg'], [0], [[0.839259684085846, 0.16074027121067047]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BlearnerForSequenceClassification\n",
    "\n",
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSequenceClassification(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForSequenceClassification\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else tuple(r[inp] for inp in attr)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_y(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else [r[inp] for inp in attr]\n",
    "\n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls,\n",
    "        # Your raw dataset\n",
    "        data,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = 2,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=cls.get_model_cls(), config_kwargs={\"num_labels\": n_labels}\n",
    "        )\n",
    "\n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if preprocess_func:\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, text_attr, label_attr)\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # defin our input/target getters\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            get_x = ColReader(text_attr)\n",
    "            get_y = ColReader(label_attr)\n",
    "        else:\n",
    "            get_x = partial(cls._get_x, attr=text_attr)\n",
    "            get_y = partial(cls._get_y, attr=label_attr)\n",
    "\n",
    "        # infer loss function and default metrics\n",
    "        if is_listy(label_attr):\n",
    "            trg_block = MultiCategoryBlock(encoded=True, vocab=label_attr)\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1ScoreMulti(), accuracy_multi])\n",
    "        else:\n",
    "            trg_block = CategoryBlock\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1Score(), accuracy])\n",
    "\n",
    "        # build our DataBlock and DataLoaders\n",
    "        blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), trg_block)\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls,\n",
    "        # Your pandas DataFrame\n",
    "        df: pd.DataFrame,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if n_labels is None:\n",
    "            n_labels = len(label_attr) if (is_listy(label_attr)) else len(df[label_attr].unique())\n",
    "\n",
    "        return cls._create_learner(\n",
    "            df, pretrained_model_name_or_path, preprocess_func, text_attr, label_attr, n_labels, dblock_splitter, dl_kwargs, learner_kwargs\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls,\n",
    "        # The path to your csv file\n",
    "        csv_file: Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        return cls.from_dataframe(\n",
    "            df,\n",
    "            pretrained_model_name_or_path=pretrained_model_name_or_path,\n",
    "            preprocess_func=preprocess_func,\n",
    "            text_attr=text_attr,\n",
    "            label_attr=label_attr,\n",
    "            n_labels=n_labels,\n",
    "            dblock_splitter=dblock_splitter,\n",
    "            dl_kwargs=dl_kwargs,\n",
    "            learner_kwargs=learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls,\n",
    "        # A list of dictionaries\n",
    "        ds: List[Dict],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if n_labels is None:\n",
    "            n_labels = len(label_attr) if (is_listy(label_attr)) else len(set([item[label_attr] for item in ds]))\n",
    "\n",
    "        return cls._create_learner(\n",
    "            ds, pretrained_model_name_or_path, preprocess_func, text_attr, label_attr, n_labels, dblock_splitter, dl_kwargs, learner_kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification.from_dataframe(\n",
    "    imdb_df, \"distilroberta-base\", text_attr=\"text\", label_attr=\"label\", dl_kwargs={\"bs\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.317437</td>\n",
       "      <td>0.257265</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meltdown opens on a scene of scientists preparing to conduct an important test on a missile system developed to deflect asteroids should they be on a collision course with earth. Nathan (Vincent Gale) mentions some misgivings to his, but the test appears to be an unqualified success. Then the asteroid breaks apart, and the largest piece is pushed into a direct collision path with earth. Fortunately, the huge rock skips off of earth's outer atmosphere and ricochets into space. Unfortunately, the</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPOILERS AHEAD &lt;br /&gt;&lt;br /&gt;15 PARK AVENUE: My Humble take on this film &lt;br /&gt;&lt;br /&gt;Now, for a viewer of cinema having tastes as severely limited as mine, niche films like 15 Park Avenue ought to be palatable to my sensibilities. With this thought, and a mild sense of embarrassment that I hadn't watched the complete film earlier, I watched this film last Saturday. There are some starting similarities with other works like the legendary Mulholland Drive (David Lynch) from which, this film borrows</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1',), [1], [[0.2653886377811432, 0.7346113920211792]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0',), [0], [[0.9267369508743286, 0.07326304912567139]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the low-level API\n",
    "\n",
    "Thanks to the `BlurrDataLoader`, there isn't really anything you have to do to use plain ol' PyTorch or fast.ai `Dataset`s and `DataLoaders` with Blurr.  Let's take a look at fine-tuning a model against Glue's MRPC dataset ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69ec08479784f888f23f1064ec32560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from blurr.data.core import preproc_hf_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-da007ba995d5f9bf.arrow\n",
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6c5b4d3ed33c58ac.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6a9662a9df4dd4981456cadec1c863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return hf_tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = raw_datasets[\"train\"].features[\"label\"].names\n",
    "\n",
    "trn_dl = BlurrDataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_tfm_kwargs={\"labels\": label_names},\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "val_dl = BlurrDataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_tfm_kwargs={\"labels\": label_names},\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification(dls, hf_model, loss_func=HF_PreCalculatedLoss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=6.30957365501672e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmLUlEQVR4nO3deXyV5Z338c8ve8gKIWwJOyggi2BUXFq1rnWpW93Gau2jdaxt7TZOfaYzUx+nM+3MdHv00bq0amutFLFWnWrr6NBSRZRNEUT2AAkkhAAn60nOcj1/nBOMIQkBcuecnPv7fr3y4tzLuc/v4iTnd67tvsw5h4iI+FdaogMQEZHEUiIQEfE5JQIREZ9TIhAR8TklAhERn1MiEBHxuYxEB3Ckhg8f7iZMmJDoMEREBpWVK1fudc6VdnfMs0RgZo8DlwJ7nHMzuzk+DXgCmAd8xzn3w75cd8KECaxYsaJfYxURSXVmtr2nY142DT0JXNTL8X3AXUCfEoCIiHjDs0TgnFtC7MO+p+N7nHPLgZBXMYiIyOGps1hExOcGRWexmd0O3A4wbty4Q46HQiGqqqoIBoMDHVrSyMnJoby8nMzMzESHIiKDzKBIBM65R4FHASoqKg65S15VVRUFBQVMmDABMxvw+BLNOUd9fT1VVVVMnDgx0eGIyCCTEk1DwWCQkpISXyYBADOjpKTE1zUiETl6Xg4ffQY4GxhuZlXAd4FMAOfcw2Y2ClgBFAJRM/s6MMM513CUr9cfYQ9afi+/SKp7dV0Nk0fkM7k0v9+v7eWooRucc6Odc5nOuXLn3C+ccw875x6OH6+J7y90zhXHHx9VEhhs8vNjb2RlZSUzZx4yxUJE5GOiUcedT69i0coqT66fEk1DR2zNQvjJTLi3OPbvmoWJjkhEpEf1ze2Eo45RhTmeXN9/iWDNQnjpLgjsBFzs35fuOqZkcM899/Dggw8e3L733nv53ve+x7nnnsu8efOYNWsWL7zwQq/XiEQi3H333Zx88snMnj2bRx55BICbb76Z3//+9wfPu/HGGw97LRFJLbUNsf6/kUoE/eT1+yDU+vF9odbY/qN03XXXsXDhR4lk4cKFfP7zn+f5559n1apVLF68mG9961v0tizoL37xC4qKili+fDnLly/nscceY9u2bdx66608+eSTAAQCAZYuXcoll1xy1LGKyOBTE4glglFF3iSCQTF8tF8Femhj62l/H8ydO5c9e/awa9cu6urqGDp0KKNGjeIb3/gGS5YsIS0tjerqampraxk1alS313j11VdZs2YNixYtioUTCLBp0yYuuOAC7rzzTurq6njuuee4+uqrycjw39sm4mc18RqBV01D/vtEKSqPNwt1s/8YXHPNNSxatIiamhquu+46nn76aerq6li5ciWZmZlMmDCh1+GdzjkeeOABLrzwwkOO3Xzzzfz6179mwYIFPPHEE8cUp4gMPjWBIGkGw/OzPLm+/5qGzv1nyMz9+L7M3Nj+Y3DdddexYMECFi1axDXXXEMgEGDEiBFkZmayePFitm/v8cZ/AFx44YX87Gc/IxSK3Xpp48aNNDc3A3DLLbfw05/+FIAZM2YcU5wiMvjUNAQZUZBDRro3H9n+qxHMvjb27+v3xZqDispjSaBj/1E64YQTaGxspKysjNGjR3PjjTdy2WWXMWvWLCoqKpg2bVqvz7/tttuorKxk3rx5OOcoLS092Ek8cuRIpk+fzhVXXHFMMYrI4FTbEGSkR/0DANZbB2YyqqiocF3XI1i/fj3Tp09PUETea2lpYdasWaxatYqioqIez0v1/wcRvzr/x39hUmkej9xUcdTXMLOVzrluL+C/pqFB5rXXXmP69Ol89atf7TUJiEjqqmkIetZRDH5sGhpkzjvvvMP2L4hI6mppD9MYDHvaNKQagYhIEjs4h8DDGkHKJILB1tfR3/xefpFU5fUcAkiRRJCTk0N9fb1vPww71iPIyfHuF0VEEsPrWcWQIn0E5eXlVFVVUVdXl+hQEqZjhTIRSS0HawRKBL3LzMzUylwikpJqA0EKcjIYkuXdx3VKNA2JiKQqr4eOghKBiEhSq2lo87RZCJQIRESSWm0g6Nk6BB2UCEREklQk6qhralPTkIiIX+1taiMSdWoaEhHxq90DMKsYlAhERJLWQEwmAyUCEZGk5fWi9R2UCEREklRNQ5DMdKMkz5slKjsoEYiIJKnaQGyJyrQ08/R1lAhERJJUTUOQkYXZnr+OEoGISJKqaQgyuijX89dRIhARSULOOWoGYFYxKBGIiCSlxrYwLe0RRhWpaUhExJdqAwMzdBSUCEREktJALFHZQYlARCQJDdSsYlAiEBFJSgM1qxiUCEREklJNQ5ChQzLJyUz3/LWUCEREklBNoG1AagPgYSIws8fNbI+Zre3huJnZ/Wa22czWmNk8r2IRERlsahpaB6R/ALytETwJXNTL8U8DU+M/twM/8zAWEZFBpSbg/cpkHTxLBM65JcC+Xk65HPiVi1kGFJvZaK/iEREZLEKRKPXNKdA01AdlwM5O21XxfYcws9vNbIWZrairqxuQ4EREEmVPYxvODczQURgkncXOuUedcxXOuYrS0tJEhyMi4qmaAVqiskMiE0E1MLbTdnl8n4iIb+1pDPKDV9YDMKk0b0BeM5GJ4EXg5vjooflAwDm3O4HxiIgk1Kod+7nsgTd4vzrA/73+RMaXDEwiyPDqwmb2DHA2MNzMqoDvApkAzrmHgZeBi4HNQAvwBa9iERFJdr95ewfffXEto4tyef7OU5g+unDAXtuzROCcu+Ewxx3wZa9eX0RksPj5X7fyvT+s55PHlXL/9SdSPMTbNYq78iwRiIhI3yzbuo+Jw/N44paTSfd4feLuDIpRQyIiqawtHKF4SGZCkgAoEYiIJFwwFCEnw/uby/VEiUBEJMGCoSg5mYn7OFYiEBFJsNZQZEBuN90TJQIRkQQLKhGIiPhbrGlIiUBExLfaQhH1EYiI+Jn6CEREfCwciRKOOg0fFRHxq2A4CkBulpqGRER8KRiKAKhpSETErw4mAjUNiYj4U0ciyNaoIRERfwqGYn0EahoSEfGpjhpBrhKBiIg/qUYgIuJzrQdHDamPQETElzR8VETE59RHICLicx0zizV8VETEp9rUNCQi4m+t7ZpZLCLia8FwhPQ0IzPdEhaDEoGISAIFQ1FyMtIwUyIQEfGlRK9XDEoEIiIJlejVyUCJQEQkodpC0YQOHQUlAhGRhAqGIgmdTAZKBCIiCRUMq2lIRMTXgqFoQm84B0oEIiIJ1doeSehkMlAiEBFJqGA4Qk6WEoGIiG+1haKqEYiI+FlsQlkK9xGY2UVmtsHMNpvZPd0cH29mr5vZGjP7s5mVexmPiEiySekJZWaWDjwIfBqYAdxgZjO6nPZD4FfOudnAfcD3vYpHRCTZOOdSvkZwCrDZObfVOdcOLAAu73LODOB/4o8Xd3NcRCRlhSKOqEvs6mTgbSIoA3Z22q6K7+vsPeCq+OMrgQIzK+l6ITO73cxWmNmKuro6T4IVERlowXDiF6WBxHcW/x1wlpmtBs4CqoFI15Occ4865yqccxWlpaUDHaOIiCeC8UVpshOcCDI8vHY1MLbTdnl830HOuV3EawRmlg9c7Zw74GFMIiJJIxiKrVeck5G6fQTLgalmNtHMsoDrgRc7n2Bmw82sI4b/DTzuYTwiIkmlo2koN1UnlDnnwsBXgD8B64GFzrl1ZnafmX0mftrZwAYz2wiMBP7Vq3hERJJNMJT49YrB26YhnHMvAy932ffPnR4vAhZ5GYOISLI62DTk885iERHfau2oEaTwPAIREenFwaahwVAjMLO8jk5dMzvOzD5jZpnehiYiktoGVSIAlgA5ZlYGvArcBDzpVVAiIn7QdrCPYHA0DZlzroXYmP+HnHPXACd4F5aISOprHWQ1AjOz04AbgT/E9yU2chGRQW6wNQ19ndiEr+fjcwEmEbtJnIiIHKVkmVncp3kEzrm/AH8BiHca73XO3eVlYCIiqS4YjpCZbmSkD4I+AjP7jZkVmlkesBb4wMzu9jY0EZHUFgwlfuF66HvT0AznXANwBfAKMJHYyCERETlKwVAk4Xcehb4ngsz4vIErgBedcyHAeRaViIgPBENRcrMSP6+3rxE8AlQCecASMxsPNHgVlIiIHyRL01BfO4vvB+7vtGu7mZ3jTUgiIv4QTIKF66HvncVFZvbjjuUizexHxGoHIiJylFqTYOF66HvT0ONAI3Bt/KcBeMKroERE/CAYiiZFjaCv6xFMds5d3Wn7/5jZux7EIyLiG8FQhNKC7ESH0ecaQauZndmxYWZnAK3ehCQi4g9t4cFVI7gD+JWZFcW39wOf9yYkERF/iI0aSnwfQV9HDb0HzDGzwvh2g5l9HVjjYWwiIimtdTCNGurgnGuIzzAG+KYH8YiI+EYwFCE3a5Algi6s36IQEfEZ51xs1FASNA0dSwS6xYSIyFFqC8duQZ0M9xrqtY/AzBrp/gPfgFxPIhIR8YFkWZQGDpMInHMFAxWIiIifdCxKk5sEiSDxjVMiIj70UY0g8R/DiY9ARMSHguHkaRpSIhARSYDWdtUIRER87aOF61UjEBHxpYNNQ4N8QpmIiBylto7OYtUIRET86WDTkPoIRET8qTWJJpQpEYiIJEDHPAJNKBMR8amPmoZSPBGY2UVmtsHMNpvZPd0cH2dmi81stZmtMbOLvYxHRCRZdNQIsgf53Ud7ZWbpwIPAp4EZwA1mNqPLaf8ILHTOzQWuBx7yKh4RkWQSDEXIykgjLS3xd/T3MhWdAmx2zm11zrUDC4DLu5zjgML44yJgl4fxiIgkjWAokhT9A9D3NYuPRhmws9N2FXBql3PuBV41s68CecB5HsYjIpI0gqFoUgwdhcR3Ft8APOmcKwcuBp4ys0NiMrPbzWyFma2oq6sb8CBFRPpbMJwc6xWDt4mgGhjbabs8vq+zW4GFAM65t4AcYHjXCznnHnXOVTjnKkpLSz0KV0Rk4ARDkaSYVQzeJoLlwFQzm2hmWcQ6g1/scs4O4FwAM5tOLBHoK7+IpLxWPzQNOefCwFeAPwHriY0OWmdm95nZZ+KnfQv4opm9BzwD3OKc01rIIpLygqHkaRrysrMY59zLwMtd9v1zp8cfAGd4GYOISDJqC0UoHpKV6DCAxHcWi4j4kkYNiYj4XGsSNQ0pEYiIJEAyTShTIhARSYBk6ixWIhARSYBgOEq2+ghERPwpGnW0h6O+mFAmIiLd6Fi4PjcJFq4HJQIRkQF3cFGaJFiLAJQIREQGXDCJ1isGJQIRkQGnRCAi4nOtBxNBcnwEJ0cUIiI+kkwL14MSgYjIgGtT05CIiL91DB9VIhAR8amPmoaS4yM4OaIQEfGR1vb4hDLVCERE/ElNQyIiPvfRzGIlAhERX+qYUKa7j4qI+FQwFMEMsnWvIRERfwqGIuRkpGNmiQ4FUCIQERlwybRwPSgRiIgMuGRaphKUCEREBlyrEoGIiL/FmoaUCEREfKstHFEfgYiIn3WMGkoWSgQiIgNMo4ZERHyuNRQhN0s1AhER31LTkIiIzwVDUbI1akhEZPBrbgtz5UNvcvez77GlrqnPz2sLJdeooYxEByAiMlj9/t1qVu84wLrqBhatquLiWaP58tlTmDGmsNfnaUKZiEgKcM7x1FvbmTG6kDfv+RRfOmsySzbUcfH9f+WuZ1YfXIWsqxferSYcdQwbkjXAEfdMiUBE5Cgsr9zPhzWN3HzaeEoLsvn7i6bxxj2f4q5PTeGlNbu4/tG32NMY/NhzfvP2Dr7+23eZP2kYN5w6LkGRH8rTRGBmF5nZBjPbbGb3dHP8J2b2bvxno5kd8DIeEZH+8qu3KinMyeDyE8sO7ivKzeSbFxzPozdVsLG2iSsfXMqGmkYAHluylX94/n3OPq6UJ79wCvnZydMy71kkZpYOPAicD1QBy83sRefcBx3nOOe+0en8rwJzvYpHRKS/7GkI8se1NXz+9Andzgc4f8ZIFv7tadz6y+V89mdLuWjmKJ5dWcUls0bzk+tOJCtJFqTp4GU0pwCbnXNbnXPtwALg8l7OvwF4xsN4RET6xTPv7CQcdXxu/vgez5lVXsTvv3wGZUNzeXZlFdecVM79N8xNuiQA3o4aKgN2dtquAk7t7kQzGw9MBP6nh+O3A7cDjBuXPO1qIuI/oUiU37yznU8eV8rE4Xm9njumOJdFXzqd5dv2cdZxpaSlJceKZF0lS2q6HljknOu2m90596hzrsI5V1FaWjrAoYmIfOS/P6iltqGNm3upDXSWn53BOdNGJG0SAG8TQTUwttN2eXxfd65HzUIiMgj86q1KyopzOWfaiESH0m+8TATLgalmNtHMsoh92L/Y9SQzmwYMBd7yMBYRkaPmnGPb3mZ+8/YOlm3dx+fmjyc9ib/hHynP+gicc2Ez+wrwJyAdeNw5t87M7gNWOOc6ksL1wALnnPMqFhGRIxWNOhYs38kra3ezpipAoDUEQFlxLtedPPYwzx5cbLB9/lZUVLgVK1YkOgwRSWGb9zTy7efeZ+X2/UwdkU/FhKHMKS9mzthipo7IJyM9WbpX+87MVjrnKro7ljwzGkREEiwUifLwn7fwwP9sJjcrnR9dM4er5pVhljrNQN1RIhARAXYHWrn1yRV8sLuBS2aP5t7LTqC0IDvRYQ0IJQIRSQnhSJQtdc2s2xVg3a4Gtte3cMnsUVw+p+ywQzd37mvhb36+jP3NIR656SQuPGHUAEWdHJQIUkhTW5h0syNaAq/6QCu7D7RSkJNJfk4GBTkZ5GdlJPWYZ5HmtjDrdjXwwa4A63c38sHuBjbWNtIWjgKQnZHGsLwsXltfy+NvVPIPF0/ntMkl3V5ra10TN/78bVraIzx926nMGVs8gCVJDkoESaL6QCtDMtMpHpJ5sD3SOceWumYWf7iH1z+sZee+VqaPLuTEsUXMGVvMcSMLWL+7gbe21rNsSz3vVwdITzPmjh3K/MklnDaphLnjig+573k4EmXxhjp+vWw7SzbV0XW8QFZ6GpNK85gyIp/jRhYwuTSfprYQ1ftbqTrQSvX+Vprbw6SnpZGZZgeH0bW0R2hqC9PUFqa5LUx6mjEkK50hWRnkZqYzpjiH+ZNKmD+phBmjC5Vs5IhV7m3myaWVPLtiJ83x2zwPHZLJjDGF3DR/PCeUFXLCmCImDc8jzYwX3qvmP/+4gRseW8Z500fyhTMmcPyoAkrysjAzNtQ0cuPP3wYcC26fz/TRva8jkKo0aijBmtvC3PfSB/x2RexuHEOy0ikfmsuY4ly27W1me30LANNGFTBlRD4f7G5ga13zx66RmW6cOLaY0yaV0BaJ8taWetZWB4g6SDMYXZRLWXEu5UNzKczN5E/ratgdCDKiIJvrTxnHvHHFNLdFaAyGaAyG2dvUxqY9TWysbaRqf+vB10kzGFmYQ1lx7DrhqCMSjRKOOByQl5VOfk4m+dkZ5GWlE446WtsjtIQitLaH2VLXzLa9sdiLh2Ry0rihDM3LIj87I/ac7AzSjPh1HeGoIyczjXHDhjB+WB7jhg2haEjmMf+fR6MOM1K+AzBVOOd4a2s9j79Ryesf1pKRZlw2ewyXzhnNjNFFjCzM7vW9DIYiPPFmJQ8t3kxjWxiIJY+pIwvYWNtIdkYaT982nykj8geqSAnR26ghJYIEWlN1gK8teJfK+mZuPWMio4tzqdrfEvvmvb+VUUU5nDNtBJ+aNoKy4tyDzwu0hlhbHWBDTSNTR+Zz0vihDMn6eOUu0Bpi+bZ9vFd1gKr9sW/x1Qda2dMYZP6kEm48dTznTh9B5mGGwTW3hamsb6YwJ5NRRTmHPf9wdgdaWba1nqWb61lTFaAhGDpYg4j24VcxPzuDrIw00tOMdIvVRsqH5jKrrIhZ5UXMKitiWF4Wm/c0sWlPE5tqm9i2t4l9ze0caA1xoCVEQzDEmKJczpwynDOnDueMKcMZlpc8i4RIzM59LTy3qorfrapmx74WhuVlceOp47hp/nhGFOYc8fUCrSHerwqwsbYx/rvRiBn88Jo5jC/p/Z5BqUCJIMlEoo5Hlmzhx69upLQgm59cdyLzJ3XfftnfnHNJ+U3YOUcwFMXhSE8zMtLSSLNYc9OOfS2xn/oWdgVaCUditYVo1BGKRNm6t5kPdjfQHm8f7iw3M51JpXkMz8+meEgmRbmZFOZksmlPI0u31NMYDGMG00cVUjFhKPPGDeWk8UMpH5pLWzjK9voWtu1tYtveFsqH5nL+jJHdLzG4ZiG8fh8EqqCoHM79Z5h97QD8zyWPjglYx48q4KTxQ/v8vGfe2cGaqgAAHb+aW/Y08fa2fZjBaZNKuHpeOZfMHp1UyzsONkoECdbaHmH1zv2srNzPyh37WbV9Pw3BMJfMGs2/XTmrX5o7/C4UibKpton3qw8QaA0xZUQ+U0cUUFac22NfRDgSZU11gDc27WXZ1nre23ngYLtzQU4GTW3hQ/pPOhYiubZiLDPLCmNJdc1C3Et3YaGPmtHIzIXL7vdNMgiGIty9aA0vvbeLjDTjO5dM55bTJxz2S8dTb1XyTy+sY+iQTDLS0w7+fw/Ly+Qzc8Zw5bzyj9WG5egpESTQ0i17ueuZ1extagfguHhTztnHj+CCGSOT8tu5X0Wijg01jazcsZ8PdzdQWpDNpNJ8Jg3PY1zJENZWBVi4YievrK2hLRyltCAb5xwvhu5gjO095HqNOaOp+cJypo4sSEBpBs7+5nZuf2oFyyv3883zj+P96gD//UEtV84t49+unNXjKLYlG+v4wpPLOef4Uh65qSKl7t2TjJQIgAMt7Ty6ZCtfPmcKeQOwRFw06nh4yRZ++KcNTByexz9cPJ2K8cP07T8FBFpDvPTeLlbvOEB2Zhr/+t4nMA79O4o6Y0r701xz0li+ecFxjDyKdu1kV7m3mS88uZzq/a386No5XDZnDNGo48HFm/nxaxuZPqqQR246ibHDhnzseZtqG7nqoaWUDxvCojtOG5C/Sb9TIgBeeLear//2XcYU5fJvV83irOO8W9cg0BriWwvf47X1tVw6ezQ/uHp2Uq1PKv3sJzMhsPOQ3ZGCcr5//LP88q1KMtLS+OInJnL7WZP7/XchUf0+63c3cOPP3ybqHI/dXMHJE4Z97PjiD/fwtQWrCYaiXHDCSK6tGMsZU4ZzoKWdKx56k2AoygtfPoMxavoZEEoEcSsq9/Ht59awpa6Zq+aW8Y+XzmBYXhaRqGPHvhY21jYSjTpOmjCUEQV9//YWiTq21jWxblcD63YFeGVtDTWBYJ/bSWWQW7MQXroLeugj2FHfwn/86UP+a81uhudn8befnMzn5o8/ool/EGuH/+8Panll7W52B4IEWkM0tIYItIaYMbqQ+2+Y22+jX9rDUW5+/G3mjRvK311w/CH9LDv3tXDVz5aSbsZvvngqk0q7H3q5c18Lv3hjG8+vribQGmJMUQ75ORlsr2/ht397Gif6cPJWoigRdBIMRXho8WYe+vMWCnMzGVWYw5a6poMzEjtMHJ7HyROGcsrEEs6cMpxRRR9PDJGoY8mmOp55ewdLNtURDMWen5WRxswxhbGmoC7fkCSF9WHU0Ood+/nRqxt5Y/Nehudnc8dZk/jc/PG9joRpD0dZvWM/z6+u5g9rdtPYFmZUYQ5TR+ZTGB8BlZeVzsL4PJSfXn8in5o28piL8+yKndy9aA0AV80t498/O/vg0OH6pjY++/Bb7Gtu59k7TuO4PvSBBEMRXltfy8IVVSzbWs+Pr53DpbPHHHOc0ndKBN34sKaBf3/lQ6Iu1oE7dWQBx40swDnH8sp9vLNtP8sr9x28B/nxIws46/hSTp9cwvtVARYs30n1gVaG52dxyazRzBlbzAljiphcmjcob1ErA+edbfv46WsbWbqlnuH52cwqK2RYXjYl+VkMy8uipS3MxtomNu1ppLK+hUjUMSQrnU/PHM3V88o4dVLJIR2rO+pbuOPXK/lgdwNfO3cqXzt36lHP3I5GHef/5C9kZaRzyaxR/PDVjZxzfCkP3jgP5+BvHlvGhtpGnr7tVE4af+RfdqJRp1nlCaBEcJSiUceHNY38dVMdf9lYx/LKfYQisf+vM6aU8DenjOf8GSPJytAHvxy5t7fW88SblVQdaKG+qZ365nbaw1HSDCaUfHSLj+mjCzlnWukhkwa7CoYifOf5tTy3qoozpwzn5tPGc+bU4Yd9Xlevrqvh9qdWcv8Nc/nMnDE8884OvvP8+8wZW0x+dgZLt9TzyOdO4rwZx17zkIGjRNBPmtvCrNy+n3HDhjBheOrPRJSB5ZyjuT1CRpod9cQp5xxPv72Df3/lQxrbwmRlpHHapBLOnT6CK+eWUZDT+6g15xxXPrSU+uY2Fn/r7IO12z+ureGuBatpD0f5j8/O5tqK1Fqhyw+UCER8pj0cZUXlPl7/cA+vr6+lsr6FqSPyefyWkw8ZytnZsq31XP/oMv7lipncNH/8x469t/MAuwNBLprpr1s0pwolAhGfe3PzXu58ehWZ6cZjN1cwd1z3t4C45Yl3WFsd4I1vf0q3c0gxvSUCNW6L+MAZU4bzuztPZ0hWBtc/uoyX3999yDkf7Grgzxvq+MIZE5UEfEaJQMQnJpfm8/ydpzOzrIg7n17Fd19Yy+vra6lvagPg4b9sIS8rnc+dOv4wV5JUo+muIj5Skp/N07edyj/+fi2/fnsHv3xrOwDjS4ZQtb+VW8+cqNug+JASgYjP5GSm88Nr5vAvl8/k/eoAq3fsZ/WOAxQPyeK2MycmOjxJACUCEZ/KzUrnlInDOGWiZsD7nfoIRER8TolARMTnlAhERHxOiUBExOeUCEREfE6JQETE55QIRER8TolARMTnBt3dR82sDtge3ywCAp0Od97u7vFwYO8xhtD1NY/0nO6OHW5fT+XsvP9Yy9aXcvV2Xl/3D/R7dqzl6ulYosvVU1xHck6q/i72dMwv71lP2+Odc6XdXtU5N2h/gEd72u7uMbCiv1/zSM/p7tjh9vVUzi7nHFPZ+lKu3s7r6/6Bfs+OtVx9fc/0u5g8v4t+f88Ot93dz2BvGnqpl+2eHvf3ax7pOd0dO9y+nso50OXq7by+7h/o9+xYy9XTsUSXq6/X8uPvYk/H/PKeHW77EIOuaehYmNkK18PCDINdqpZN5Rp8UrVsqVou8F9n8aOJDsBDqVo2lWvwSdWypWq5/FUjEBGRQ/mtRiAiIl0oEYiI+JwSgYiIzykRxJnZJ8zsYTP7uZktTXQ8/cXM0szsX83sATP7fKLj6U9mdraZ/TX+vp2d6Hj6k5nlmdkKM7s00bH0JzObHn+/FpnZlxIdT38xsyvM7DEz+62ZXZDoeI5USiQCM3vczPaY2dou+y8ysw1mttnM7untGs65vzrn7gD+C/ill/H2VX+UC7gcKAdCQJVXsR6pfiqbA5qAHJKkbP1ULoBvAwu9ifLo9NPf2fr439m1wBlexttX/VSu3zvnvgjcAVznZbxeSIlRQ2b2SWIfCL9yzs2M70sHNgLnE/uQWA7cAKQD3+9yif/lnNsTf95C4FbnXOMAhd+j/ihX/Ge/c+4RM1vknPvsQMXfm34q217nXNTMRgI/ds7dOFDx96SfyjUHKCGW4PY65/5rYKLvXX/9nZnZZ4AvAU85534zUPH3pJ8/P34EPO2cWzVA4feLlFi83jm3xMwmdNl9CrDZObcVwMwWAJc7574PdFvdNrNxQCAZkgD0T7nMrApoj29GPAz3iPTXexa3H8j2JNAj1E/v2dlAHjADaDWzl51zUS/j7ov+es+ccy8CL5rZH4CEJ4J+es8M+AHwymBLApAiiaAHZcDOTttVwKmHec6twBOeRdQ/jrRcvwMeMLNPAEu8DKwfHFHZzOwq4EKgGPh/nkZ2bI6oXM657wCY2S3Eaz2eRndsjvQ9Oxu4iljiftnLwI7Rkf6dfRU4DygysynOuYe9DK6/pXIiOGLOue8mOob+5pxrIZbgUo5z7nfEEl1Kcs49megY+ptz7s/AnxMcRr9zzt0P3J/oOI5WSnQW96AaGNtpuzy+b7BL1XJB6pYtVcsFqVu2VC1Xt1I5ESwHpprZRDPLAq4HXkxwTP0hVcsFqVu2VC0XpG7ZUrVc3UqJRGBmzwBvAcebWZWZ3eqcCwNfAf4ErAcWOufWJTLOI5Wq5YLULVuqlgtSt2ypWq4jkRLDR0VE5OilRI1ARESOnhKBiIjPKRGIiPicEoGIiM8pEYiI+JwSgYiIzykRSEows6YBfr1+WbPCYmsqBMzsXTP70Mx+2IfnXGFmM/rj9UVAiUCkW2bW6324nHOn9+PL/dU5dyIwF7jUzA53n/4riN2ZVKRfKBFIyjKzyWb2RzNbabGVzKbF919mZm+b2Wozey2+ngFmdq+ZPWVmbwJPxbcfN7M/m9lWM7ur07Wb4v+eHT++KP6N/un4LYkxs4vj+1aa2f1m1uu6As65VuBdYne+xMy+aGbLzew9M3vOzIaY2enAZ4D/jNciJvdUTpG+UiKQVPYo8FXn3EnA3wEPxfe/Acx3zs0FFgB/3+k5M4DznHM3xLenEbvV9SnAd80ss5vXmQt8Pf7cScAZZpYDPAJ8Ov76pYcL1syGAlP56Hbhv3POneycm0PsNge3OueWErvnzd3OuROdc1t6KadIn+g21JKSzCwfOB14Nv4FHT5avKYc+K2ZjQaygG2dnvpi/Jt5hz8459qANjPbA4zk0GUx33HOVcVf911gArEVr7Y65zqu/Qxwew/hfsLM3iOWBH7qnKuJ759pZt8jtt5CPrH73hxJOUX6RIlAUlUacCDe9t7VA8SWtnwxvlDKvZ2ONXc5t63T4wjd/8305Zze/NU5d6mZTQSWmdlC59y7wJPAFc659+KL1JzdzXN7K6dIn6hpSFKSc64B2GZm10BsKUEzmxM/XMRH95b/vEchbAAmdVoC8bALmsdrDz8gtnA9QAGwO94c1Xk95sb4scOVU6RPlAgkVQyJ30K44+ebxD48b403u6wDLo+fey+xppSVwF4vgok3L90J/DH+Oo1AoA9PfRj4ZDyB/BPwNvAm8GGncxYAd8c7uyfTczlF+kS3oRbxiJnlO+ea4qOIHgQ2Oed+kui4RLpSjUDEO1+Mdx6vI9Yc9UhiwxHpnmoEIiI+pxqBiIjPKRGIiPicEoGIiM8pEYiI+JwSgYiIzykRiIj43P8HTDGlR+bDZmQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.522119</td>\n",
       "      <td>0.467277</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.513096</td>\n",
       "      <td>0.466035</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.485044</td>\n",
       "      <td>0.466696</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-8, 1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spansion products are to be available from both AMD and Fujitsu, AMD said. Spansion Flash memory solutions are available worldwide from AMD and Fujitsu.</td>\n",
       "      <td>equivalent</td>\n",
       "      <td>equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, EPA officials would not confirm the 20 percent figure. Only in the past few weeks have officials settled on the 20 percent figure.</td>\n",
       "      <td>not_equivalent</td>\n",
       "      <td>not_equivalent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlbertForSequenceClassification',\n",
       " 'BartForSequenceClassification',\n",
       " 'BertForSequenceClassification',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CanineForSequenceClassification',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'HubertForSequenceClassification',\n",
       " 'IBertForSequenceClassification',\n",
       " 'LEDForSequenceClassification',\n",
       " 'LayoutLMForSequenceClassification',\n",
       " 'LayoutLMv2ForSequenceClassification',\n",
       " 'LongformerForSequenceClassification',\n",
       " 'MBartForSequenceClassification',\n",
       " 'MPNetForSequenceClassification',\n",
       " 'MegatronBertForSequenceClassification',\n",
       " 'MobileBertForSequenceClassification',\n",
       " 'OpenAIGPTForSequenceClassification',\n",
       " 'PerceiverForSequenceClassification',\n",
       " 'ReformerForSequenceClassification',\n",
       " 'RemBertForSequenceClassification',\n",
       " 'RoFormerForSequenceClassification',\n",
       " 'RobertaForSequenceClassification',\n",
       " 'SEWDForSequenceClassification',\n",
       " 'SEWForSequenceClassification',\n",
       " 'SqueezeBertForSequenceClassification',\n",
       " 'TransfoXLForSequenceClassification',\n",
       " 'UniSpeechForSequenceClassification',\n",
       " 'UniSpeechSatForSequenceClassification',\n",
       " 'Wav2Vec2ForSequenceClassification',\n",
       " 'WavLMForSequenceClassification',\n",
       " 'XLMForSequenceClassification',\n",
       " 'XLMRobertaForSequenceClassification',\n",
       " 'XLNetForSequenceClassification']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "[model_type for model_type in BLURR.get_models(task=\"SequenceClassification\") if (not model_type.startswith(\"TF\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "pretrained_model_names = [\n",
    "    \"hf-internal-testing/tiny-albert\",\n",
    "    \"hf-internal-testing/tiny-random-bart\",\n",
    "    \"hf-internal-testing/tiny-bert\",\n",
    "    \"google/bigbird-roberta-base\",\n",
    "    \"google/bigbird-pegasus-large-arxiv\",\n",
    "    \"hf-internal-testing/tiny-random-ctrl\",\n",
    "    \"camembert-base\",\n",
    "    \"hf-internal-testing/tiny-random-canine\",\n",
    "    \"YituTech/conv-bert-base\",\n",
    "    \"hf-internal-testing/tiny-deberta\",\n",
    "    \"hf-internal-testing/tiny-random-deberta-v2\",\n",
    "    \"hf-internal-testing/tiny-random-distilbert\",\n",
    "    \"hf-internal-testing/tiny-electra\",\n",
    "    \"google/fnet-base\",\n",
    "    \"hf-internal-testing/tiny-random-flaubert\",\n",
    "    \"hf-internal-testing/tiny-random-funnel\",\n",
    "    \"hf-internal-testing/tiny-random-gpt2\",\n",
    "    \"anton-l/gpt-j-tiny-random\",\n",
    "    \"hf-internal-testing/tiny-random-gpt_neo\",\n",
    "    \"kssteven/ibert-roberta-base\",\n",
    "    \"hf-internal-testing/tiny-random-led\",\n",
    "    \"hf-internal-testing/tiny-random-longformer\",\n",
    "    \"hf-internal-testing/tiny-random-mbart\",\n",
    "    \"hf-internal-testing/tiny-random-mpnet\",\n",
    "    # \"nvidia/megatron-bert-cased-345m\",                 could not test\n",
    "    \"hf-internal-testing/tiny-random-mobilebert\",\n",
    "    \"openai-gpt\",\n",
    "    \"google/reformer-crime-and-punishment\",\n",
    "    \"google/rembert\",\n",
    "    \"junnyu/roformer_chinese_sim_char_ft_small\",\n",
    "    \"roberta-base\",\n",
    "    \"squeezebert/squeezebert-uncased\",\n",
    "    \"hf-internal-testing/tiny-random-transfo-xl\",\n",
    "    \"xlm-mlm-en-2048\",\n",
    "    \"xlm-roberta-base\",\n",
    "    \"xlnet-base-cased\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a895359790ab4cbf8d73d6fe2dd4238d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-bb082f8a90ea273a.arrow\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-5a941c558a0690b2.arrow\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "raw_datasets = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "raw_datasets[0] = raw_datasets[0].add_column(\"is_valid\", [False] * len(raw_datasets[0]))\n",
    "raw_datasets[1] = raw_datasets[1].add_column(\"is_valid\", [True] * len(raw_datasets[1]))\n",
    "\n",
    "final_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n",
    "imdb_df = pd.DataFrame(final_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-albert ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \"big trail\" director raoul walsh's first</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tartbr /br /date of review - 5/26/02b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-bart ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First off, the editing of this film consisted of one major flaw which I don't underst</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-bert ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date of review - 5 / 26 / 02 &lt; br / &gt; &lt; br / &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/bigbird-roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbig_bird\n",
      "tokenizer:\tBigBirdTokenizerFast\n",
      "model:\t\tBigBirdForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/bigbird-pegasus-large-arxiv ===\n",
      "\n",
      "architecture:\tbigbird_pegasus\n",
      "tokenizer:\tPegasusTokenizerFast\n",
      "model:\t\tBigBirdPegasusForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tartbr /&gt;br /&gt;Date of review - 5/26/02br /&gt;br /&gt;Year of movie - 2001br</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-ctrl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/transformers/models/ctrl/modeling_ctrl.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / d_model_size)\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tctrl\n",
      "tokenizer:\tCTRLTokenizer\n",
      "model:\t\tCTRLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat inaccurate but wholly exhilarating biography of cavalry officer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie -</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, esp</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-canine ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tcanine\n",
      "tokenizer:\tCanineTokenizer\n",
      "model:\t\tCanineForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered consi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YituTech/conv-bert-base ===\n",
      "\n",
      "architecture:\tconvbert\n",
      "tokenizer:\tConvBertTokenizerFast\n",
      "model:\t\tConvBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray charles, has much in common with</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-deberta ===\n",
      "\n",
      "architecture:\tdeberta\n",
      "tokenizer:\tDebertaTokenizerFast\n",
      "model:\t\tDebertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-deberta-v2 ===\n",
      "\n",
      "architecture:\tdeberta_v2\n",
      "tokenizer:\tDebertaV2Tokenizer\n",
      "model:\t\tDebertaV2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001&lt;br /&gt;&lt;br</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-distilbert ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of bi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-electra ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul wal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the monkees, surprisingly, are a big favorite of mine. yes, they might have</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/fnet-base ===\n",
      "\n",
      "architecture:\tfnet\n",
      "tokenizer:\tFNetTokenizerFast\n",
      "model:\t\tFNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-flaubert ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \" Big Trail \" director Raoul Walsh' s first-rate western \" Th</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, especially the really</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-funnel ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "model:\t\tFunnelForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-gpt2 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt2\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPT2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== anton-l/gpt-j-tiny-random ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgptj\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPTJForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, especially the really bad ones. So I wouldn't call it naive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-gpt_neo ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt_neo\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPTNeoForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== kssteven/ibert-roberta-base ===\n",
      "\n",
      "architecture:\tibert\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tIBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story of Ray Charles, has much in common with \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-led ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-longformer ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell mo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mpnet ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "model:\t\tMPNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mobilebert ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of bi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== openai-gpt ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\topenai\n",
      "tokenizer:\tOpenAIGPTTokenizerFast\n",
      "model:\t\tOpenAIGPTForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on, \" a somewhat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray charles, has much in common with \" walk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/reformer-crime-and-punishment ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\treformer\n",
      "tokenizer:\tReformerTokenizerFast\n",
      "model:\t\tReformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/rembert ===\n",
      "\n",
      "architecture:\trembert\n",
      "tokenizer:\tRemBertTokenizerFast\n",
      "model:\t\tRemBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001&lt;br /&gt;&lt;br</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== junnyu/roformer_chinese_sim_char_ft_small ===\n",
      "\n",
      "architecture:\troformer\n",
      "tokenizer:\tRoFormerTokenizerFast\n",
      "model:\t\tRoFormerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul w</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "model:\t\tSqueezeBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first off, the editing of this film consisted of one major flaw which i don't understand how was missed - you consistently see the overhead microphones</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-transfo-xl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\ttransfo_xl\n",
      "tokenizer:\tTransfoXLTokenizer\n",
      "model:\t\tTransfoXLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat inaccurate</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray,\" the story of Ray Charles, has much in common with \"Walk the Line</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first-rate western \" they died with their boots on, \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray, \" the story of ray charles, has much in common with \"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Die</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story of Ray Charles, has much in common with</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story of Ray Charles, has much in common</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "bsz = 2\n",
    "seq_sz = 32\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    # 1. get/configure our Hugging Face objects\n",
    "    tok_class = RobertaTokenizer if (\"/ibert\" in model_name) else None\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
    "        model_name, model_cls=model_cls, tokenizer_cls=tok_class, config_kwargs={\"num_labels\": 2}\n",
    "    )\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if hf_tokenizer.pad_token is None:\n",
    "        hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "    try:\n",
    "        learn = None\n",
    "\n",
    "        # 2. get our DataLoaders\n",
    "        blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=seq_sz, padding=\"max_length\"), CategoryBlock)\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=ColSplitter(col=\"is_valid\"))\n",
    "\n",
    "        dls = dblock.dataloaders(imdb_df, bs=bsz)\n",
    "\n",
    "        # 3. configure our Learner\n",
    "        model = HF_BaseModelWrapper(hf_model)\n",
    "        learn = Learner(\n",
    "            dls,\n",
    "            model,\n",
    "            opt_func=partial(Adam),\n",
    "            loss_func=CrossEntropyLossFlat(),\n",
    "            metrics=[accuracy],\n",
    "            cbs=[HF_BaseModelCallback],\n",
    "            splitter=hf_splitter,\n",
    "        )\n",
    "\n",
    "        learn.freeze()\n",
    "\n",
    "        b = dls.one_batch()\n",
    "\n",
    "        # 4. train\n",
    "        print(\"*** TESTING DataLoaders ***\")\n",
    "        test_eq(len(b), bsz)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(len(preds[0]), bsz)\n",
    "        #         test_eq(preds[0].shape, torch.Size([bsz, 2]))\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=ShortEpochCallback(pct=0.2, short_valid=True))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        if learn:\n",
    "            del learn\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big_bird</td>\n",
       "      <td>BigBirdTokenizerFast</td>\n",
       "      <td>BigBirdForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigbird_pegasus</td>\n",
       "      <td>PegasusTokenizerFast</td>\n",
       "      <td>BigBirdPegasusForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>CTRLTokenizer</td>\n",
       "      <td>CTRLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>canine</td>\n",
       "      <td>CanineTokenizer</td>\n",
       "      <td>CanineForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>convbert</td>\n",
       "      <td>ConvBertTokenizerFast</td>\n",
       "      <td>ConvBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deberta</td>\n",
       "      <td>DebertaTokenizerFast</td>\n",
       "      <td>DebertaForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mat1 and mat2 shapes cannot be multiplied (2x32 and 768x768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deberta_v2</td>\n",
       "      <td>DebertaV2Tokenizer</td>\n",
       "      <td>DebertaV2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fnet</td>\n",
       "      <td>FNetTokenizerFast</td>\n",
       "      <td>FNetForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>forward() got an unexpected keyword argument 'output_attentions'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPT2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gptj</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPTJForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt_neo</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPTNeoForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ibert</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>IBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>openai</td>\n",
       "      <td>OpenAIGPTTokenizerFast</td>\n",
       "      <td>OpenAIGPTForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>reformer</td>\n",
       "      <td>ReformerTokenizerFast</td>\n",
       "      <td>ReformerForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>If training, make sure that config.axial_pos_shape factors: (512, 1024) multiply to sequence length. Got prod((512, 1024)) != sequence_length: 32. You might want to consider padding your sequence length to 524288 or changing config.axial_pos_shape.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rembert</td>\n",
       "      <td>RemBertTokenizerFast</td>\n",
       "      <td>RemBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>roformer</td>\n",
       "      <td>RoFormerTokenizerFast</td>\n",
       "      <td>RoFormerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>TransfoXLTokenizer</td>\n",
       "      <td>TransfoXLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=[\"arch\", \"tokenizer\", \"model\", \"result\", \"error\"])\n",
    "display_df(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental building blocks for training using Blurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
