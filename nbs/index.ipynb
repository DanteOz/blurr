{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blurr\n",
    "\n",
    "> A library designed for fastai developers who want to train and deploy Hugging Face transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named after the **fast**est **transformer** (well, at least of the Autobots), **BLURR** provides both a comprehensive and extensible framework for training and deploying ü§ó [huggingface](https://huggingface.co/transformers/) transformer models with [fastai](http://docs.fast.ai/) >= 2.0.\n",
    "\n",
    "Utilizing features like fastai's new `@typedispatch` and `@patch` decorators, along with a simple class hiearchy, **BLURR** provides fastai developers with the ability to train and deploy transformers on a variety of tasks. It includes a high, mid, and low-level API that will allow developers to use much of it out-of-the-box or customize it as needed.\n",
    "\n",
    "**Supported Text/NLP Tasks**:\n",
    "- Sequence Classification (multiclassification and multi-label classification)\n",
    "- Token Classification\n",
    "- Question Answering\n",
    "- Summarization\n",
    "- Tranlsation\n",
    "- Language Modeling (Causal and Masked)\n",
    "\n",
    "**Supported Vision Tasks**:\n",
    "- *In progress*\n",
    "\n",
    "**Supported Audio Tasks**:\n",
    "- *In progress*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now pip install blurr via `pip install ohmeow-blurr`\n",
    "\n",
    "Or, even better as this library is under *very* active development, create an editable install like this:\n",
    "```\n",
    "git clone https://github.com/ohmeow/blurr.git\n",
    "cd blurr\n",
    "pip install -e \".[dev]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check the documentation for more thorough examples of how to use this package.\n",
    "\n",
    "The following two packages need to be installed for blurr to work:\n",
    "1. fastai (see http://docs.fast.ai/ for installation instructions)\n",
    "2. huggingface transformers (see https://huggingface.co/transformers/installation.html for details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.text.data.all import *\n",
    "from blurr.text.modeling.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "imdb_df = pd.read_csv(path / \"texts.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get `n_labels` from data for config later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(imdb_df[\"label\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your ü§ó objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"bert-base-uncased\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = n_labels\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build your Data üß± and your DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=ColSplitter())\n",
    "\n",
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and üöÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|slow\n",
    "model = BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    hf_model,\n",
    "    opt_func=partial(Adam, decouple_wd=True),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=[accuracy],\n",
    "    cbs=[BaseModelCallback],\n",
    "    splitter=blurr_splitter,\n",
    ")\n",
    "\n",
    "learn.freeze()\n",
    "\n",
    "learn.fit_one_cycle(3, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|slow\n",
    "learn.show_results(learner=learn, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the high-level Blurr API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the high-level API we can reduce DataBlock, DataLoaders, and Learner creation into a ***single line of code***.\n",
    "\n",
    "Included in the high-level API is a general `BLearner` class (pronouned **\"Blurrner\"**) that you can use with hand crafted DataLoaders, as well as, task specific BLearners like `BLearnerForSequenceClassification` that will handle everything given your raw data sourced from a pandas DataFrame, CSV file, or list of dictionaries (for example a huggingface datasets dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|slow\n",
    "learn = BlearnerForSequenceClassification.from_data(imdb_df, pretrained_model_name, dl_kwargs={\"bs\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|slow\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|slow\n",
    "learn.show_results(learner=learn, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚≠ê Props\n",
    "\n",
    "A word of gratitude to the following individuals, repos, and articles upon which much of this work is inspired from:\n",
    "\n",
    "- The wonderful community that is the [fastai forum](https://forums.fast.ai/) and especially the tireless work of both Jeremy and Sylvain in building this amazing framework and place to learn deep learning.\n",
    "- All the great tokenizers, transformers, docs, examples, and people over at [huggingface](https://huggingface.co/)\n",
    "- [FastHugs](https://github.com/morganmcg1/fasthugs)\n",
    "- [Fastai with ü§óTransformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)](https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2)\n",
    "- [Fastai integration with BERT: Multi-label text classification identifying toxicity in texts](https://medium.com/@abhikjha/fastai-integration-with-bert-a0a66b1cecbe)\n",
    "- [fastinference](https://muellerzr.github.io/fastinference/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('blurr')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
