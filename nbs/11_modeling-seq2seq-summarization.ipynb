{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp modeling.seq2seq.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.seq2seq.summarization\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, inspect, torch\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from datasets import load_metric as hf_load_metric, list_metrics as hf_list_metrics\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar,master_bar\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM, logging,\n",
    "    PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    ")\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.seq2seq.core import Seq2SeqTextBlock, Seq2SeqBatchTokenizeTransform\n",
    "from blurr.modeling.core import BaseModelWrapper, BaseModelCallback, PreCalculatedLoss, Blearner\n",
    "from blurr.modeling.seq2seq.core import HF_Seq2SeqMetricsCallback, seq2seq_splitter\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.7.1\n",
      "fastai: 2.5.2\n",
      "transformers: 4.9.2\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "import os, ast, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions('torch fastai transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv'); len(cnndm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>\n",
       "      <td>John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>\n",
       "      <td>NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  (CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...   \n",
       "1  (CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              highlights  \\\n",
       "0  John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"   \n",
       "1                                                                                          NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "# pretrained_model_name = \"t5-small\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "#                                                                   model_cls=T5ForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"google/pegasus-cnn_dailymail\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "#                                                                   model_cls=PegasusForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "#                                                                   model_cls=BartForConditionalGeneration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.models.bart.configuration_bart.BartConfig,\n",
       " transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n",
       " transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen_kwargs = {}\n",
    "if (hf_arch in ['bart', 't5']):\n",
    "    text_gen_kwargs = {**hf_config.task_specific_params['summarization'], **{'max_length': 30, 'min_length': 10}}\n",
    "\n",
    "# not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "for k in text_gen_kwargs.copy():\n",
    "    if k not in generate_func_args: del text_gen_kwargs[k]\n",
    "\n",
    "if (hf_arch == 'mbart'):\n",
    "    text_gen_kwargs['decoder_start_token_id'] = hf_tokenizer.get_vocab()[\"en_XX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_kwargs = {}\n",
    "if (hf_arch == 'mbart'):\n",
    "    tok_kwargs['src_lang'], tok_kwargs['tgt_lang'] = \"en_XX\", \"en_XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, \n",
    "                                                  max_length=256, max_target_length=130,\n",
    "                                                  tok_kwargs=tok_kwargs, text_gen_kwargs=text_gen_kwargs)\n",
    "\n",
    "blocks = (Seq2SeqTextBlock(before_batch_tfm=before_batch_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('article'), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 256]), torch.Size([2, 69]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; (CNN) -- Home to up to 10 percent of all known species, Mexico is recognized as one of the most biodiverse regions on the planet. The twin threats of climate change and human encroachment on natural environments are, however, threatening the existence of the country's rich wildlife. And there is a great deal to lose. In the United Nations Environment Program (UNEP) World Conservation Monitoring Centre's list of megadiverse countries Mexico ranks 11th. The list represents a group of 17 countries that harbor the majority of the Earth's species and are therefore considered extremely biodiverse. From its coral reefs in the Caribbean Sea to its tropical jungles in Chiapas and the Yucatan peninsula and its deserts and prairies in the north, Mexico boasts an incredibly rich variety of flora and fauna. Some 574 out of 717 reptile species found in Mexico -- the most in any country -- can only be encountered within its borders. It is home to 502 types of mammals, 290 species of birds, 1,150 varieties of birds and 26,000 classifications of plants. Pronatura, a non-profit organization that works to promote conservation and sustainable development in Mexico, has selected six species which it says symbolize the problems faced by the&lt;/s&gt;</td>\n",
       "      <td>Mexico hosts to up to 10 percent of all known species on Earth.\\nIt is home to 502 types of mammals, 290 bird species and 26,000 types of plants.\\nHuman development and climate change is placing a big strain on its biodiversity.\\nThe Golden Eagle is under threat in spite of being the country's national symbol.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; Some U.S. officials this year are expected to get smartphones capable of handling classified government documents over cellular networks, according to people involved in the project. The phones will run a modified version of Google's Android software, which is being developed as part of an initiative that spans multiple federal agencies and government contractors, these people said. The smartphones are first being deployed to U.S. soldiers, people familiar with the project said. Later, federal agencies are expected to get phones for sending and receiving government cables while away from their offices, sources said. Eventually, local governments and corporations could give workers phones with similar software. The Army has been testing touchscreen devices at U.S. bases for nearly two years, said Michael McCarthy, a director for the Army's Brigade Modernization Command, in a phone interview. About 40 phones were sent to fighters overseas a year ago, and the Army plans to ship 50 more phones and 75 tablets to soldiers abroad in March, he said. \"We've had kind of an accelerated approval process,\" McCarthy said. \"This is a hugely significant event.\" Currently, the United States doesn't allow government workers or soldiers to use smartphones for sending classified messages because the devices have not met security certifications. Officials have said they worry that hackers or&lt;/s&gt;</td>\n",
       "      <td>Government, military officials to get Android phones capable of sharing secret documents.\\nThe phones will run a modified version of Google's Android software, sources say.\\nContractor: Google \"more cooperative\" than Apple working with government on phones.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_metrics = {\n",
    "        'rouge': {\n",
    "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
    "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "        },\n",
    "        'bertscore': {\n",
    "            'compute_kwargs': { 'lang': 'en' },\n",
    "            'returns': [\"precision\", \"recall\", \"f1\"]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam),\n",
    "                loss_func=CrossEntropyLossFlat(), #PreCalculatedLoss()\n",
    "                cbs=learn_cbs,\n",
    "                splitter=partial(seq2seq_splitter, arch=hf_arch)) #.to_native_fp16() #.to_fp16()\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaseModelWrapper (Input shape: 2)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 69 x 1024       \n",
       "Embedding                                 51470336   False     \n",
       "Embedding                                 51470336   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1024            \n",
       "BartLearnedPositionalEmbedding                      1050624    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Embedding                                 51470336   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1024            \n",
       "BartLearnedPositionalEmbedding                      1050624    False     \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 50264      \n",
       "Linear                                    51470336   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 560,701,440\n",
       "Total trainable params: 201,613,312\n",
       "Total non-trainable params: 359,088,128\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7f7b23004ee0>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 79, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds),preds['loss'].shape, preds['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 256]), 2, torch.Size([2, 79]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/fastai/callback/schedule.py:269: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=6.918309954926372e-05, steep=1.0964781722577754e-06, valley=3.630780702224001e-05, slide=1.4454397387453355e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAG1CAYAAAAMU3WaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSSElEQVR4nO3dd3iV9f3/8ec5J3vvBQkJEHbYQ0EUCrIUUIq4vipalbZYB3WvWqug1lqsVuuoglXr1vJrVRBlI8oG2ZsEQhII2fuc+/dHyJEQVpKTnPV6XFeucO5zn3Pe5yZwXvlMk2EYBiIiIiJuyuzsAkRERESaQ2FGRERE3JrCjIiIiLg1hRkRERFxawozIiIi4tYUZkRERMStKcyIiIiIW1OYEREREbfm4+wCWprNZuPw4cOEhoZiMpmcXY6IiIicB8MwKC4uJikpCbP57G0vHh9mDh8+THJysrPLEBERkSbIzMykbdu2Zz3H48NMaGgoUHsxwsLCnFyNiIiInI+ioiKSk5Ptn+Nn4/Fhpq5rKSwsTGFGRETEzZzPEBENABYRERG3pjAjIiIibs3ju5nOl9Vqpbq62tllSBP5+vpisVicXYaIiDiB14cZwzA4cuQIBQUFzi5FmikiIoKEhARNwRcR8TJeH2bqgkxcXBxBQUH6IHRDhmFQVlZGbm4uAImJiU6uSEREWpNXhxmr1WoPMtHR0c4uR5ohMDAQgNzcXOLi4tTlJCLiRbx6AHDdGJmgoCAnVyKOUPf3qLFPIiLexavDTB11LXkG/T2KiHgnhRkRERFxawozIiIi4tYUZhzBZoV9y2DzJ7XfbVZnV9TA4sWLMZlMjZqCPnXqVK644ooWq0lERMQRvHo2k0NsnQdfPwBFh38+FpYEY56FbhOcV9cpBg8eTHZ2NuHh4ef9mBdffBHDMFqwKhERcWeGYbjEeEW1zDTH1nnw0Y31gwxAUXbt8a3znFPXafj5+TV6Qbnw8HAiIiJarigREXFrX/90hIkvL+c/Gw45tQ6FmaayWWtbZDhdy8WJY18/2GJdTsOGDeN3v/sdd999N5GRkcTHx/P6669TWlrKzTffTGhoKB06dOCrr74CGnYzzZkzh4iICObPn0/Xrl0JCQlhzJgxZGdn21/j1G6mxr7mya9zsi+++KJeqHriiSfo3bs3b731FikpKYSEhPCb3/wGq9XKc889R0JCAnFxcTz99NOOv5AiItJkH6/NYmNWIduyi51ah8JMUx1Y2bBFph4Dig7VntdC5s6dS0xMDD/++CO/+93v+M1vfsNVV13F4MGDWbduHaNHj+aGG26grKzstI8vKyvj+eef51//+hdLly7l4MGD3HvvvS36mmeyZ88evvrqK77++mv+/e9/89Zbb3HZZZeRlZXFkiVLePbZZ3n00UdZtWpVo55XRERaRk5RBYt31K68flX/tk6tRWGmqUpyHHteE/Tq1YtHH32U9PR0HnroIQIDA4mJieG2224jPT2dxx9/nGPHjrFp06bTPr66upp//OMf9O/fn759+3LHHXfw7bfftuhrnonNZuOtt96iW7dujB8/nuHDh7Njxw5mz55N586dufnmm+ncuTOLFy9u1POKiEjL+GzdIWwG9GsXSYfYEKfWogHATRUS79jzmqBnz572P1ssFqKjo8nIyLAfi4+vfe3c3FzCwsIaPD4oKIgOHTrYbycmJtr3N3LEazZGamoqoaGh9Z7HYrFgNpvrHWvs84qIiOMZhsHHazMBuKqfc1tlQC0zTdducO2sJc40oNYEYW1qz2shvr6+9V/RZKp3rG5cis1mO+/Hn2v2UmNf02w2N3jO0203cK7nrTt2pvciIiKtZ93B4+zNKyXQ18JlPZ2/ua/CTFOZLbXTr4GGgebE7THP1J7nxWJjYykuLqa0tNR+bMOGDc4rSEREmu3jNVkAjM1IIDTA9xxntzyFmeboNgGmvANhp6TSsKTa4y60zoyzDBo0iKCgIB5++GF2797N+++/z5w5c5xdloiINFFZVQ3/3VQ783VK/2QnV1NLY2aaq9sE6HJZ7aylkpzaMTLtBnt9i0ydqKgo3n33Xe677z5ef/11Ro4cyRNPPMHtt9/u7NJERKQJvtp8hJLKGlKighiUFuXscgAwGR6+xGtRURHh4eEUFhY2GARbUVHBvn37SEtLIyAgwEkViqPo71NEpOVd8/r3rNqbz4xLO3HniPQWe52zfX6fSt1MIiIicl4OHitj1d58TCb4pQvMYqqjMCMiIiLn5ZMT07Ev6hhDm4hAJ1fzM4UZEREROSebzeDTdbV7MF3lIgN/6yjMiIiIyDmt3HOMQwXlhAX4MKpbyy0I2xQKMyIiInJOH62p7WKa0DuJAF/XmrGrMCMiIiJnVVhezfwtRwDXWVvmZAozIiIiclb/b+NhKmtsdI4PJaNNuLPLaUBhRkRERM7q4xNdTFf1b2vfg8+VKMyIiIjIGWUXlrMxqxCL2cQVfdo4u5zT0nYGDmC1WVmXu468sjxig2LpG9cXi5O2M5g6dSoFBQV88cUXTnl9ERHxLFsOFQGQHhdCTIi/k6s5PYWZZlp4YCHP/PgMOWU59mPxQfE8OPBBRrYb6cTKREREmm9rdm2Y6ZZ49i0FnEndTM2w8MBCZiyeUS/IAOSW5TJj8QwWHljYYq/9ySefkJGRQWBgINHR0YwcOZL77ruPuXPn8p///AeTyYTJZGLx4sUAHDp0iKuvvprIyEiio6OZOHEi+/fvr/ecb7/9Nl27diUgIIAuXbrwyiuv2O/bv38/JpOJDz74gMGDBxMQEED37t3tzy8iIp5p6+ETYSZJYcbjWG1WnvnxGQwa7tNZd+zZH5/FarM6/LWzs7O59tprueWWW9i2bRuLFy9m0qRJ/OEPf2DKlCmMGTOG7OxssrOzGTx4MGVlZQwfPpyQkBCWLl3K8uXLCQkJYcyYMVRVVQHwxhtv8Mgjj/D000+zbds2Zs6cyWOPPcbcuXPrvfZ9993H73//e9avX8/gwYOZMGECx44dc/h7FBER1+AOLTPqZmqidbnrGrTInMzA4EjZEdblrmNAwgCHvnZ2djY1NTVMmjSJdu3aAZCRkQFAYGAglZWVJCQk2M9/9913MZvNvPnmm/ZR6G+//TYREREsXryYUaNG8ac//Ym//OUvTJo0CYC0tDS2bt3Ka6+9xk033WR/rjvuuINf/vKXALz66qt8/fXX/POf/+T+++936HsUERHnK6qo5mB+GQBdFWY8T15ZnkPPa4xevXoxYsQIMjIyGD16NKNGjWLy5MlERkae9vy1a9eye/duQkND6x2vqKhgz5495OXlkZmZya9+9Stuu+02+/01NTWEh9dfT+DCCy+0/9nHx4f+/fuzbds2B747ERFxFduziwFICg8gMtjPydWcmcJME8UGxTr0vMawWCx88803rFy5kgULFvDSSy/xyCOP8MMPP5z2fJvNRr9+/Xjvvfca1hcbS0VFBVDb1TRo0KAGr3UurrjmgIiINN/Ww4WAa4+XAYWZJusb15f4oHhyy3JPO27GhIn4oHj6xvVtkdc3mUwMGTKEIUOG8Pjjj9OuXTs+//xz/Pz8sFrrj9Pp27cvH374IXFxcYSFNfyBDA8Pp02bNuzdu5frr7/+rK+7atUqLr74YqC25Wbt2rXccccdjntjIiLiMtxhvAxoAHCTWcwWHhz4IFAbXE5Wd/uBgQ+0yHozP/zwAzNnzmTNmjUcPHiQzz77jLy8PLp27UpqaiqbNm1ix44dHD16lOrqaq6//npiYmKYOHEiy5YtY9++fSxZsoS77rqLrKwsAJ544glmzZrFiy++yM6dO9m8eTNvv/02L7zwQr3X/vvf/87nn3/O9u3bmT59OsePH+eWW25x+HsUERHn23aim8nVW2YUZpphZLuRvDDsBeKC4uodjw+K54VhL7TYOjNhYWEsXbqUcePG0alTJx599FH+8pe/MHbsWG677TY6d+5M//79iY2NZcWKFQQFBbF06VJSUlKYNGkSXbt25ZZbbqG8vNzeUnPrrbfy5ptvMmfOHDIyMrjkkkuYM2cOaWlp9V77mWee4dlnn6VXr14sW7aM//znP8TExLTI+xQREeepttrYkXMizCS63n5MJzMZhtGwj8SDFBUVER4eTmFhYYMuloqKCvbt20daWhoBAQFNfg1XWgG4pezfv5+0tDTWr19P7969nV3OaTnq71NERGDHkWJGz15KqL8PG/8wCrO5dcdHnu3z+1RObZlZunQp48ePJykpCZPJVG8J/urqah544AEyMjIIDg4mKSmJG2+8kcOHDzuv4DOwmC0MSBjAuPbjGJAwwOOCjIiIeJ+t2bWDf7smhrV6kGksp4aZ0tJSevXqxcsvv9zgvrKyMtatW8djjz3GunXr+Oyzz9i5cycTJkxwQqUiIiLepW7l366Joec40/mcOptp7NixjB079rT3hYeH880339Q79tJLLzFw4EAOHjxISkpKa5QoJ6SmpuLhPZIiInIS+0wmFx/8C242NbuwsBCTyURERMQZz6msrKSystJ+u6ioqBUqExER8RyGYfy8J5OLD/4FN5rNVFFRwYMPPsh111131oFAs2bNIjw83P6VnJzcilWKiIi4vyNFFRwvq8ZiNpEeH+Lscs7JLcJMdXU111xzDTabrd5Ozqfz0EMPUVhYaP/KzMxspSpFREQ8Q12rTMfYEAJ8XX9Si8t3M1VXVzNlyhT27dvHd999d87pWf7+/vj7+7dSdSIiIp5nmxuNlwEXDzN1QWbXrl0sWrSI6OhoZ5ckIiLi8dxlG4M6Tg0zJSUl7N6923573759bNiwgaioKJKSkpg8eTLr1q3jv//9L1arlSNHjgAQFRWFn5/r7t4pIiLizuyDf92kZcapY2bWrFlDnz596NOnDwAzZsygT58+PP7442RlZTFv3jyysrLo3bs3iYmJ9q+VK1c6s2yPkJqayuzZs+23T120UEREvFNJZQ37j5UBtQvmuQOntswMGzbsrGuXuMu6JobVStmatdTk5eETG0tQ/36YLK4/YEpERORU2090MSWGBxAV7B69IC49ZsYdFC1YQM7MWdSc6AID8ElIIP7hhwgbNcqJlYmIiDSeu42XATeZmu2qihYs4NBdd9cLMgA1OTkcuutuihYsaJHXfe2112jTpg02m63e8QkTJnDTTTexZ88eJk6cSHx8PCEhIQwYMICFCxc26jUOHTrE1VdfTWRkJNHR0UycOJH9+/cDtXtq+fr62scw1fn973/PxRdf3Kz3JiIizuVu42VAYabJDKuVnJmz4HRdYSeO5cychWG1Ovy1r7rqKo4ePcqiRYvsx44fP878+fO5/vrrKSkpYdy4cSxcuJD169czevRoxo8fz8GDB8/r+cvKyhg+fDghISEsXbqU5cuXExISwpgxY6iqquLiiy+mffv2/Otf/7I/pqamhnfffZebb77Z4e9XRERaT13LjLuMlwGFmSYrW7O2QYtMPYZBzZEjlK1Z6/DXjoqKYsyYMbz//vv2Yx9//DFRUVGMGDGCXr16MW3aNDIyMkhPT+epp56iffv2zJs377ye/4MPPsBsNvPmm2+SkZFB165defvttzl48CCLFy8G4Fe/+hVvv/22/TH/+9//KCsrY8qUKQ59ryIi0npqrDa2HykG1M3kFWry8hx6XmNdf/31fPrpp/Z9qN577z2uueYaLBYLpaWl3H///XTr1o2IiAhCQkLYvn37ebfMrF27lt27dxMaGkpISAghISFERUVRUVHBnj17AJg6dSq7d+9m1apVALz11ltMmTKF4ODgFnm/IiLS8vYeLaWqxkawn4WUqCBnl3PeNAC4iXxiYx16XmONHz8em83G//73PwYMGMCyZct44YUXALjvvvuYP38+zz//PB07diQwMJDJkydTVVV1Xs9ts9no168f7733XoP7Yk+8n7i4OMaPH8/bb79N+/bt+fLLL+2tNiIi4p62ndTFZDabnFzN+VOYaaKg/v3wSUigJifn9ONmTCZ84uMJ6t+vRV4/MDCQSZMm8d5777F79246depEv361r7Vs2TKmTp3KlVdeCdQuTlg3ePd89O3blw8//JC4uLizbh9x6623cs0119C2bVs6dOjAkCFDmvWeRETEudxx8C+om6nJTBYL8Q8/dOLGKen1xO34hx9q0fVmrr/+ev73v//x1ltv8X//93/24x07duSzzz5jw4YNbNy4keuuu67BzKdzPW9MTAwTJ05k2bJl7Nu3jyVLlnDXXXeRlZVlP2/06NGEh4fz1FNPaeCviIgHcMdp2aAw0yxho0bR5sXZ+MTH1zvuEx9Pmxdnt/g6M7/4xS+Iiopix44dXHfddfbjf/3rX4mMjGTw4MGMHz+e0aNH07dv3/N+3qCgIJYuXUpKSgqTJk2ia9eu3HLLLZSXl9drqTGbzUydOhWr1cqNN97o0PcmIiKtyzAMt22ZUTdTM4WNGkXoiBFOWQHYYrFw+PDhBsdTU1P57rvv6h2bPn16vdundjudutpyQkICc+fOPWcN2dnZjBs3jsTExPOsWkREXFFucSXHSquwmE10ig91djmNojDjACaLheBBA51dRqsqLCxk9erVvPfee/znP/9xdjkiItJMda0yHWKDCfB1ry15FGakSSZOnMiPP/7ItGnTuPTSS51djoiINJO7jpcBhRlpIk3DFhHxLHXTsru4YZjRAGARERFhd24JAJ3iQ5xcSeMpzIiIiHg5q81g79FSADrGutfgX1CYERER8XpZx8uoqrHh72OmTWSgs8tpNIUZERERL1fXxdQ+NgSLG21jUEdhRkRExMvVhZmOce43XgYUZkRERLyePczEKsyIC5g6dSpXXHGF/fawYcO4++67z/qY1NRUZs+e3aJ1iYiI69qd594tM1pnxgFsNoPsXQWUFlUSHOZPYnqEy2yd/tlnn+Hr6+vsMkRExEUZhuH23UwKM820Z30uyz7cRWlBpf1YcIQ/Q69Op0OfOCdWVisqKsrZJYiIiAvLK66kuKIGswlSY4KcXU6TqJupGfasz+Xr136qF2QASgsq+fq1n9izPrfFXvuTTz4hIyODwMBAoqOjGTlyJKWlpQ3OO7WbKTc3l/HjxxMYGEhaWhrvvfdeg8cUFhZy++23ExcXR1hYGL/4xS/YuHFji70XERFxnrpWmZSoIPx93GtPpjpqmWkim81g2Ye7znrO8o92kdYr1uFdTtnZ2Vx77bU899xzXHnllRQXF7Ns2bIGO1+fztSpU8nMzOS7777Dz8+PO++8k9zcn0OXYRhcdtllREVF8eWXXxIeHs5rr73GiBEj2Llzp1p6REQ8jLuPlwGFmSbL3lXQoEXmVCXHK8neVUCbzpGOfe3sbGpqapg0aRLt2rUDICMj45yP27lzJ1999RWrVq1i0KBBAPzzn/+ka9eu9nMWLVrE5s2byc3Nxd/fH4Dnn3+eL774gk8++YTbb7/doe9FREScq65lpoPCjPcpLTp7kGnseY3Rq1cvRowYQUZGBqNHj2bUqFFMnjyZyMizh6Zt27bh4+ND//797ce6dOlCRESE/fbatWspKSkhOjq63mPLy8vZs2ePQ9+HiIg4n7tPywaFmSYLDvN36HmNYbFY+Oabb1i5ciULFizgpZde4pFHHuGHH3446+PquqFMpjN3e9lsNhITE0+7K/bJoUdERDyDu89kAoWZJktMjyA4wv+sXU0hkbXTtFuCyWRiyJAhDBkyhMcff5x27drx+eefn/UxXbt2paamhjVr1jBw4EAAduzYQUFBgf2cvn37cuTIEXx8fEhNTW2R2kVExDUUVVSTW1z7OebO3UyazdREZrOJoVenn/Wci6akt8h6Mz/88AMzZ85kzZo1HDx4kM8++4y8vLx6Y19Op3PnzowZM4bbbruNH374gbVr13LrrbcSGPjzpmIjR47kwgsv5IorrmD+/Pns37+flStX8uijj7JmzRqHvxcREXGeulaZ+DB/wgLcd00yhZlm6NAnjjHTehAcUb8rKSTSnzHTerTYOjNhYWEsXbqUcePG0alTJx599FH+8pe/MHbs2HM+9u233yY5OZlLLrmESZMm2adg1zGZTHz55ZdcfPHF3HLLLXTq1IlrrrmG/fv3Ex8f3yLvR0REnMMTupgATMb5zOd1Y0VFRYSHh1NYWEhYWFi9+yoqKti3bx9paWkEBAQ0+TVceQVgb+Kov08REW8x68ttvLZ0Lzdd2I4/Tuzh7HLqOdvn96k0ZsYBzGaTw6dfi4iItDRPaZlRN5OIiIiXqlswz50H/4LCjIiIiFeqqLaSmV8GqGVGRERE3ND+Y6XYDAgL8CE2xPFrorUmhRkREREvdPJ4mbMtpuoOFGaoXfVW3J/+HkVEzp+nDP4FL5/N5Ofnh9ls5vDhw8TGxuLn5+f26dQbGYZBVVUVeXl5mM1m/Pz8nF2SiIjLU5jxEGazmbS0NLKzszl8+LCzy5FmCgoKIiUlBbNZDY4iIueiMONB/Pz8SElJoaamBqvV6uxypIksFgs+Pj5qWRMROQ9Wm8Heo6UAdIwNdXI1zef1YQZql/D39fXF19d996UQERE5X1nHy6iqseHvY6ZNZOC5H+Di1B4vIiLiZeq6mNrHhmDxgO13FGZERES8jCeNlwGFGREREa9TF2Y6xAY7uRLHUJgRERHxMnV7MqllRkRERNyOYRjqZhIRERH3lVdcSXFFDWYTpMWom0lERETcTF2rTEpUEP4+FidX4xgKMyIiIl7E08bLgMKMiIiIV7HPZFKYEREREXdkH/wbqzAjIiIibsjTZjKBwoyIiIjXKKqoJre4ElA3k4iIiLihg8fKAIgJ8SMswHM2V1aYERER8RJ5JbWtMnGhAU6uxLEUZkRERLzE0RNdTDGh/k6uxLEUZkRERLzE0ZIqoLabyZMozIiIiHiJoye6mWLVMiMiIiLuKO9EN1NsiMKMiIiIuKG6lpkYhRkRERFxR+pmagFLly5l/PjxJCUlYTKZ+OKLL+rdbxgGTzzxBElJSQQGBjJs2DC2bNninGJFRETcXF03k1pmHKi0tJRevXrx8ssvn/b+5557jhdeeIGXX36Z1atXk5CQwKWXXkpxcXErVyoiIuLeqq02jpdVA543m8nHmS8+duxYxo4de9r7DMNg9uzZPPLII0yaNAmAuXPnEh8fz/vvv8+0adNas1QRERG3ll9aOy3bYjYRGeRZYcZlx8zs27ePI0eOMGrUKPsxf39/LrnkElauXHnGx1VWVlJUVFTvS0RExNvVdTFFB/thNpucXI1juWyYOXLkCADx8fH1jsfHx9vvO51Zs2YRHh5u/0pOTm7ROkVERNxBnofOZAIXDjN1TKb66dEwjAbHTvbQQw9RWFho/8rMzGzpEkVERFyep25lAE4eM3M2CQkJQG0LTWJiov14bm5ug9aak/n7++Pv73l/USIiIs1R1zLjaQvmgQu3zKSlpZGQkMA333xjP1ZVVcWSJUsYPHiwEysTERFxP0eLT+zLFOpZg3/ByS0zJSUl7N6923573759bNiwgaioKFJSUrj77ruZOXMm6enppKenM3PmTIKCgrjuuuucWLWIiIj7OerBLTNODTNr1qxh+PDh9tszZswA4KabbmLOnDncf//9lJeX89vf/pbjx48zaNAgFixYQGhoqLNKFhERcUv2fZk8cMyMyTAMw9lFtKSioiLCw8MpLCwkLCzM2eWIiIg4xaUvLGFXbgnv3TqIIR1jnF3OOTXm89tlx8yIiIiI43jqJpOgMCMiIuLxTt7KwBO7mRRmREREPNyxkp+3MogI9HVyNY6nMCMiIuLh6rqYPHErA1CYERER8Xj2BfM8sIsJFGZEREQ8Xt20bE8c/AsKMyIiIh7Pk2cygcKMiIiIx/PkrQxAYUZERMTjefImk6AwIyIi4vGOevBWBqAwIyIi4vE0ZkZERETcmqZmi4iIiNuqttooOLGVgVpmRERExO14+lYGoDAjIiLi0X5eMM8ztzIAhRkRERGP5umDf0FhRkRExKPlKcyIiIiIO8vz8DVmQGFGRETEo6mbSURERNza0ROzmWJCPHNfJlCYERER8Wh5xRWAuplERETETdW1zHjqJpOgMCMiIuLR7GNm1DIjIiIi7qaqxvO3MgCFGREREY91rLS2VcbHg7cyAIUZERERj3W0uHa8TLQHb2UACjMiIiIeyxvWmAGFGREREY/lDav/gsKMiIiIx/KGfZlAYUZERMRjqZtJRERE3Jq6mURERMSt/dwy47n7MoHCjIiIiMfyhq0MQGFGRETEY6mbSURERNxWVY2NwnLP38oAFGZEREQ80slbGYR78FYGoDAjIiLikeq6mDx9KwNQmBEREfFIdTOZPH28DCjMiIiIeKS6TSY9fbwMKMyIiIh4JG/ZygAUZkRERDySt0zLBoUZERERj+Qt+zKBwoyIiIhH8patDEBhRkRExCOpm0lERETcmrfsywRNDDOZmZlkZWXZb//444/cfffdvP766w4rTERERJqmssbqNVsZQBPDzHXXXceiRYsAOHLkCJdeeik//vgjDz/8ME8++aRDCxQREZHGOXaiVcbX4vlbGUATw8xPP/3EwIEDAfjoo4/o0aMHK1eu5P3332fOnDmOrE9EREQaqW7wb3Swv8dvZQBNDDPV1dX4+9c2Wy1cuJAJEyYA0KVLF7Kzsx1XnYiIiDSafSZTqOfPZIImhpnu3bvzj3/8g2XLlvHNN98wZswYAA4fPkx0dLRDCxQREZHGqZvJ5A3jZaCJYebZZ5/ltddeY9iwYVx77bX06tULgHnz5tm7n0RERMQ5vGkmE4BPUx40bNgwjh49SlFREZGRkfbjt99+O0FBQQ4rTkRERBrP3jLjBWvMQBNbZsrLy6msrLQHmQMHDjB79mx27NhBXFycQwsUERGRxvGmTSahiWFm4sSJvPPOOwAUFBQwaNAg/vKXv3DFFVfw6quvOrRAERERaRxvWv0Xmhhm1q1bx9ChQwH45JNPiI+P58CBA7zzzjv87W9/c2iBIiIi0jh1YSZOYebMysrKCA0NBWDBggVMmjQJs9nMBRdcwIEDBxxaoIiIiDROblEFoDBzVh07duSLL74gMzOT+fPnM2rUKAByc3MJCwtzaIEiIiJy/korayitsgIQFxbg5GpaR5PCzOOPP869995LamoqAwcO5MILLwRqW2n69Onj0AJFRETk/OWe6GIK8rMQ4t+kSctup0nvcvLkyVx00UVkZ2fb15gBGDFiBFdeeaXDihMREZHG8bYuJmhimAFISEggISGBrKwsTCYTbdq00YJ5IiIiTpZrH/zrHV1M0MRuJpvNxpNPPkl4eDjt2rUjJSWFiIgI/vSnP2Gz2RxWXE1NDY8++ihpaWkEBgbSvn17nnzySYe+hoiIiCepCzOxYWqZOatHHnmEf/7znzzzzDMMGTIEwzBYsWIFTzzxBBUVFTz99NMOKe7ZZ5/lH//4B3PnzqV79+6sWbOGm2++mfDwcO666y6HvIaIiIgnyS1WN9N5mTt3Lm+++aZ9t2yAXr160aZNG3772986LMx8//33TJw4kcsuuwyA1NRU/v3vf7NmzRqHPL+IiIinyVM30/nJz8+nS5cuDY536dKF/Pz8ZhdV56KLLuLbb79l586dAGzcuJHly5czbty4Mz6msrKSoqKiel8iIiLewtsWzIMmhplevXrx8ssvNzj+8ssv07Nnz2YXVeeBBx7g2muvpUuXLvj6+tKnTx/uvvturr322jM+ZtasWYSHh9u/kpOTHVaPiIiIq8stOhFmNGbm7J577jkuu+wyFi5cyIUXXojJZGLlypVkZmby5ZdfOqy4Dz/8kHfffZf333+f7t27s2HDBu6++26SkpK46aabTvuYhx56iBkzZthvFxUVKdCIiIjX+HnMjLqZzuqSSy5h586dXHnllRQUFJCfn8+kSZPYsmULb7/9tsOKu++++3jwwQe55ppryMjI4IYbbuCee+5h1qxZZ3yMv78/YWFh9b5ERES8QVWNjeNl1YB3dTM1eZ2ZpKSkBgN9N27cyNy5c3nrrbeaXRjU7gFlNtfPWxaLRVOzRURETiOvpLaLyddiIiLI18nVtB6XXud4/PjxPP3006SkpNC9e3fWr1/PCy+8wC233OLs0kRERFxO3eq/sSH+mEwmJ1fTelw6zLz00ks89thj/Pa3vyU3N5ekpCSmTZvG448/7uzSREREXM7PC+Z5z3gZcPEwExoayuzZs5k9e7azSxEREXF5uV44LRsaGWYmTZp01vsLCgqaU4uIiIg0Q54XbjIJjQwz4eHh57z/xhtvbFZBIiIi0jTeuMkkNDLMOHLatYiIiDiWPcx40YJ50MR1ZkRERMT1eOMmk6AwIyIi4jHsWxl4WTeTwoyIiIgHsNoMjpaom0lERETc1LHSSmwGmEwQHezn7HJalcKMiIiIB6jrYooO9sfH4l0f7971bkVERDxUnpcumAcKMyIiIh4hz0unZYPCjIiIiEfw1mnZoDAjIiLiEbx19V9QmBEREfEI9jVm1M0kIiIi7kjdTCIiIuLW6rqZYtXNJCIiIu7GMIyTxsyoZUZERETcTFF5DVU1NgBiFWZERETE3dSNlwkL8CHA1+LkalqfwoyIiIibs3cxhXnfeBlQmBEREXF73jyTCRRmRERE3J59jRmFGREREXFH6mYSERERt+bN07JBYUZERMTt5RbVjpnxxmnZoDAjIiLi9vK8eJNJUJgRERFxez+PmVHLjIiIiLiZsqoaSiprAI2ZERERETdU18UU6GshxN/HydU4h8KMiIiIGzu5i8lkMjm5GudQmBEREXFj3r5gHijMiIiIuLWftzLwzplMoDAjIiLi1uq6mbx1jRlQmBEREXFr9m4mL52WDQozIiIibk3dTAozIiIibi1P3UwKMyIiIu7M2zeZBIUZERERt1VVYyO/tApQmBERERE3dLSktlXGx2wiMsjPydU4j8KMiIiImzp5WrbZ7J2r/4LCjIiIiNvKLaqbyeS9XUygMCMiIuK2fm6Z8d5p2aAwIyIi4rZO3mTSmynMiIiIuKm8YnUzgcKMiIiI28qzrzGjbiYRERFxQ1owr5bCjIiIiJvSJpO1FGZERETckM1m2BfNUzeTiIiIuJ38sipqbAYmE8SEeO/qv6AwIyIi4pYy88sAiA72w8fi3R/n3v3uRURE3FBljZU/zNsCQM+2Ec4txgUozIiIiLiZp/67jU1ZhUQE+fKnK3o4uxynU5gRERFxI/M2HuZfqw4A8Nere9MmItDJFTmfwoyIiIib2J1bwoOfbgLgjuEdGd45zskVuQaFGRERETdQVlXDb99bS1mVlQvbR3PPpZ2cXZLLUJgRERFxcYZh8OjnP7Ezp4TYUH9evLY3FrPJ2WW5DIUZERERF/fB6kw+W38IswleuraP1y+SdyqFGRERERf206FC+zTs+0Z34YL20U6uyPUozIiIiLioyhord3+4gaoaGyO6xDHt4vbOLsklKcyIiIi4qH8s3svu3BJiQvz4y5RemDVO5rQUZkRERFzQnrwS/r5oNwCPj+9ORJB37790Ni4fZg4dOsT//d//ER0dTVBQEL1792bt2rXOLktERKTFGIbBI59vpspq45JOsYzvmejsklyaj7MLOJvjx48zZMgQhg8fzldffUVcXBx79uwhIiLC2aWJiIi0mI/XZrFqbz4BvmaeuqIHJpO6l87GpcPMs88+S3JyMm+//bb9WGpqqvMKEhERaWHHSiqZ+eU2AO4Z2YnkqCAnV+T6XLqbad68efTv35+rrrqKuLg4+vTpwxtvvHHWx1RWVlJUVFTvS0RExF089b9tFJRV0y0xjF9dlObsctyCS4eZvXv38uqrr5Kens78+fP59a9/zZ133sk777xzxsfMmjWL8PBw+1dycnIrViwiItJ0y3bl8fmJxfFmTcrAx+LSH9Muw2QYhuHsIs7Ez8+P/v37s3LlSvuxO++8k9WrV/P999+f9jGVlZVUVlbabxcVFZGcnExhYSFhYWEtXrOIiEhTlFdZGT17KQfzy5g6OJUnJnR3dklOVVRURHh4+Hl9frt05EtMTKRbt271jnXt2pWDBw+e8TH+/v6EhYXV+xIREXF1f/tuFwfzy0gMD+De0Z2dXY5bcekwM2TIEHbs2FHv2M6dO2nXrp2TKhIREXG8/UdLeWPpXgD+OKE7If4uPT/H5bh0mLnnnntYtWoVM2fOZPfu3bz//vu8/vrrTJ8+3dmliYiIOMyy3UepsRkMSotiVPcEZ5fjdlw6zAwYMIDPP/+cf//73/To0YM//elPzJ49m+uvv97ZpYmIiDjM1sOFAPRPjXRyJe7J5duxLr/8ci6//HJnlyEiItJithyuXUake1K4kytxTy7dMiMiIuLpaqw2th8pBqBboiatNIXCjIiIiBPtySulqsZGiL8PKVrtt0kUZkRERJxoa3bteJmuiaGYzdqDqSkUZkRERJxoyyGNl2kuhRkREREnqhv82y1J42WaSmFGRETESQzDYGv2iTCjwb9NpjAjIiLiJIcKyiksr8bXYqJTfKizy3FbCjMiIiJOsvVEF1PHuFD8fPSR3FS6ciIiIk7y82J56mJqDoUZERERJ7EP/tV4mWZRmBEREXGSbdlqmXEEhRkREREnOF5axaGCcgC6Ksw0i8KMiIiIE9S1yqREBREW4OvkatybwoyIiIgTaPCv4yjMiIiIOIEWy3MchRkREREn2HK4doPJ7m0UZppLYUZERKSVVVRb2ZNXCkC3RG0w2VwKMyIiIq1sx5FirDaD6GA/4sP8nV2O21OYERERaWUn75RtMpmcXI37U5gRERFpZVuza8fLdNNMJodQmBEREWll2sbAsRRmREREWpHVZrA9uxiA7kka/OsICjMtwGYzyCuupKrG5uxSRETExew7Wkp5tZVAXwtpMcHOLscj+Di7AE90zeur+HF/PgAh/j5EBvsSGeRHRJAfcaH+3Da0PZ0TQp1cpYiIOEPd+jJdEkOxmDX41xEUZhwsp6jCHmQASiprKKmsITO/3H5s6c48FtxzMRFBfs4oUUREnGirdsp2OIUZB1uz/zhQO6jr/dsGkV9axfGyagrKqsgvreLVxXvYe7SUx/+zhb9d28fJ1YqISGvbah/8q/EyjqIw42CrT7TKDEiNJOJE19LJ0uND+eWrK5m38TCjusdzec8kZ5QpIiJOYBiGPcyoZcZxNADYwdYcqA0z/VOjTnt/7+QIpg/rAMCjX/xEblFFq9UmIiLOlVNUybHSKixmk8ZOOpDCjAOVVNbYE3f/1MgznnfHL9LpnhRGQVk1D362GcMwWqtEERFxorrBvx1igwnwtTi5Gs+hMONAGw4WYDOgTUQgieGBZzzPz8fMC1N642cx8932XD5ak9mKVYqIiLNs1WJ5LUJhxoFOHi9zLp0TQrl3dCcAnvx/W8nML2vR2kRExPm22MfLaPCvIynMONC5xsuc6lcXtWdgahSlVVbu/XgjNpu6m0REPNVXm7NZuC0HgIy2CjOOpDDjIDVWG+sPFgBnHy9zMovZxPNX9SLIz8IP+/J5a8W+FqzwZxqjIyLSuv63KZs7/r2eGpvBxN5JDEo7v1965fwozDjItuxiyqqshAb40Cnu/Eeop0QH8ehl3QB4+sttXPrCEu77eCPv/XCALYcLqbE6bkuEvOJKbn9nDX3/9A3LduU57HlFROTM5m08zJ0frMdqM5jUpw0vTOmNyaSVfx1J68w4SN14mf7tIjE3cnnqawcms/bAcT5dl8Wu3BJ25Zbw8dosAAJ9LWS0CWdwx2hGdImnR5uwJv0j+PqnIzz8+WbyS6sA+O176/j8t0PoGBfS6OcSEZHz88X6Q8z4aAM2Ayb3a8uzv+ypLQxagMnw8D6HoqIiwsPDKSwsJCys5UaP//a9tXy5+Qj3je7M9OEdm/QcecWVbMgsYEPmcTZkFrAps5Diypp658SH+fOLLvGM7BrHkI4x55zaV1xRzR//31Y+ORGOuiaGEeBrZv3BAtpFB/HFb4cQGaxtFUREHO3TtVnc98lGbAZc3T+ZWZMyGv3LrjdrzOe3wowDGIbBoJnfkltcyYe3X8Cg9tEOeV6bzWBPXglrDxznu+25LN99lLIqq/3+AF8zF7SPJqNNON0Sw+iWFEZyZJD9H8uqvcf4/UcbOVRQjskEv76kA3ePTKekooYrXllBZn45A9OiePdXg/DzUY+jiIijfLQmkwc+3YRhwLUDU3j6ih4KMo2kMHOS1ggzB4+VcfGfF+FrMbH5idEtthBSRbWVVXuP8e22XL7dlsPhwoarBwf7WeiaGEZsqD9fbzmCYUByVCAvTOnNgJNmWe3MKeaXr6ykuLKGKf1rmz7Vhysi0jyGYfDWiv089b+tGAb83wUpPDlBQaYpGvP5rTEzDlA3XiajTXiLrugY4GthWOc4hnWO48mJ3dmWXcyP+46xLbuYrdlF7MgpprTKypoDx+2Pubp/Mo+N70aIf/2/6k7xobx0XR9umbOaj9Zk0TEuhNsv7tBitYuIeLoaq40n/7uVd74/AMDUwan8YXw3/aLYChRmHKAuPJzv+jKOYDKZ6JZU27VUp8ZqY+/RUrYeLmJvXgn9U6O4uFPsGZ9jWOc4Hr+8G0/8v63M+mo7aTEhXNotvjXKFxHxKKWVNfzu3+v5bnsuJhM8PLYrtw5NU5BpJQozDrDmpJlMzuRjMdMpPpRO8ec/Nfymwanszivh3VUHueuD9Xxw+wX0bBvRckWKiHiYI4UV3DJnNVuzi/D3MTP76t6MzUh0dlleRWGmmY6XVrErtwSAfk4OM01hMpn4w/ju7D9axvLdR5nw8gr6pEQwrkciY3okkBwV5OwSRURc1tbDRdwyZzVHiiqICfHjjRv70yfF/T4L3J3CTDOtPdHF1CE2mOgQfydX0zS+FjN/v74vd32wniU781h/sID1Bwt4+sttZLQJZ0yPBEZ2jScmxI8gPx8CfM1qOhURr7d4Ry7T31tHaZWVjnEhvD11gH4BdBKFmWayj5dp595LU4cH+jLn5oHkFlUwf8sRvtx8hB/2HWPzoUI2Hyrkz/N31Ds/0NdCkJ+FAF8LnRNC+WXftozoGqct7UXEK/x0qJBp/1pLZY2NwR2iefX6foQH+Tq7LK+lMNNM9vEy57kfk6uLCwvghgtTueHCVI6VVLJgaw5fbs5mzf7jlFf/vMZNebXVfvtQQTnfbc8lPNCXCb2SmNyvLT3bhqv1RkQ8Un5plT3IXNIpljdu7K+1upxMYaYZKqqtbMoqBKi3houniA7x59qBKVw7MAWoXcSvvNpKWZWVihPfiyuqWbwjj0/XZZFdWMG/Vh3gX6sO0DEuhMn92nLtwBTCA/Xbioh4hhqrjd/9ex2HCsppFx3E367poyDjAhRmmmHzoUKqrDZiQvxoF+35/aRms4lgfx+CT1mzpn9qFPdc2omVe47yydosvv7pCLtzS3jmq+28ungPv76kA1MHpxLod/YuKKvNyrrcdeSV5REbFEvfuL5YzOq2EhHX8ef5O1ix+xhBfhZev6G/upZchMJMM6zZ//N4GW/vUrGYTQxNj2VoeixFFdX8b1M2by3fx67cEp79ejtvrdjHnb/oyNUDUk77W8zCAwt55sdnyCnLsR+LD4rnwYEPMrLdyNZ8KyIip/XfTYd5beleAP48uRedE85/GQxpWWobawZPGy/jKGEBvlw7MIWv776YF6b0IjkqkLziSh77zxZGvLCYz9ZlYbX9vIvGwgMLmbF4Rr0gA5BblsuMxTNYeGBha78FEZF6th8p4r6PNwEw7ZL2XNZT68i4Eu3N1EQ2m0GfP31DYXk1X0wfQu/kCIc9t6epqrHx4eqD/O273eQVVwIQFexHx9gQUqMDWVZ5NyXWY6d9rAkT8UHxfP3Lr9XlJCJOUVhWzYS/L+fAsTKGpscw5+aBWLTXUotrzOe3WmaaaHdeCYXl1QT4mume1DIbWHoKPx8zN1yYytL7hvPg2C6EB/qSX1rFj/vz+XTb0jMGGQADgyNlR1iXu64VKxYRqWW1Gdz14XoOHCujbWQgf7umj4KMC9KYmSaqGy/TJzkSX4sy4fkI9LPYBwPvyilh79ESvjlwhCUF535sXllei9cnInKqVxbtZvGOPAJ8zbx2Qz8ig/2cXZKchsJME+WXVuLvY2aAxss0WoCvhYy24WS0DScpoSdL5p/7MbFBZ94wU0SkJaw/eJzZ3+4C4OkrMuieFO7kiuRMFGaa6I5fpHP7xR2orLGe+2Q5o75xfYkPiie3LBeDhsO3DAN8jUhifLo4oToR8VYllTXc/eEGrDaDCb2SmNS3jbNLkrNQmGkGPx+zFktqJovZwoMDH2TG4hmYMJ020BQfvozL/7aCGaM6M75XInGhAU6otJbNZlBSVUNxRQ1F5dX271VWG8H+PoQG+BDq70NIgA+hAb4E+Vowu2D/us1mkL2rgNKiSoLD/ElMj3DJOkWc5Y/ztnDgWBltIgL50xU9vH75DVen2UziEk63zkxCUAK/6nY3ny2L4scT0+ABerUN5xdd4hnRNY7uSWH1/pMxDIO84kr2HS1l/7FSsgsrOF5aRX5Zde330iqOl1VRWF5NSlQQvZMjar9SIkiPC603sO9YSSWbsgrZkFnAxqwCfjpUyLHSKhrzL8ZkghC/2pBTF3BCToSe8EBf2kQGkhwZRHJUEMmRgUQF+7X4f5p71uey7MNdlBZU2o8FR/gz9Op0OvSJa9HXFnEH/9uUzfT312EywQe3XcCg9tHOLskrNebzW2FGXMaZVgC22gzeXXWAT9dl2bePqBMf5s9FHWMpr65h39EyDhwrpayqaV1/QX4WMtqEEx3ix6asQrKOl5/xXD+LmbBAH8ICfAkN8MHPx0xJpZWSytrWmuKKmnpr6TSmhuTIIBLCA4gO8SMmxJ/oYD+iQ/yJDvEjPNCXymobFSf2xiqrqv1eUWXFZMJeT11wCg3wISLQ1x6S9qzP5evXfjrj64+Z1kOBRrxadmE5Y2Yvo7C8munDO3DfaHVxO4vCzEkUZjxLblEFi3bk8u22XJbvPnra4GI2QdvIIFJjgmkTEUh0sB+RwX5EBfsSGeRHVLAfwf4+7MopqW11ySxgU1YBpad5rg6xwfQ60XrTs20EbSICCQ3wOefu4IZhUFFto7iimpLK2nBT973u2PHSKrKOl3Mwv4zM42XkFFWe9TmbIyrYj+6JoQz8qQJzhe2M54VE+nPD04PV5SReyWYzuP7NH/h+7zF6tg3n098M1mxVJ1KYOYnCjOeqqLbyw758Vu/LJzLYj7SYINpFB5McGdTosUxWm8Hu3BI2ZB6noKyaHm1qZ1uFBbTevisV1VYOFZSTmV9GbnElx0qqOFZSybHSKo6WVJJfWts95u9jJsjPh0BfC4F+Fvt3q82guOLnlqGSyhqKTgQnw4DkajPXlPqfs44r7ulDm871Z+lZbQb5pVXkFlfgZzHTITZEgUc8zmtL9jDrq+0E+lr48q6hpMUEO7skr6YwcxKFGfF2FdVWduYUs27ZIUqX5Jzz/DWJJoLTwymrspJbXEFuUW2gOrnbLNTfh17JEfRJOfGVHNno9TcMq5WyNWupycvDJzaWoP79MFm0yrM4x0+HCrnylRVUWw2e/WUGVw9IcXZJXq8xn99uNZtp1qxZPPzww9x1113Mnj3b2eWIuIUAXws920YQ3dfgi/MIM7uLKsjcVNbguMkE0cF+lFVZKa6sYfnuoyzffdR+f2p0EB1iQ0iOCqJtZCBtI4NIjqr9Hh5Yv4WraMECcmbOoubIEfsxn4QE4h9+iLBRo5rxbkUab1dOMb95by3VVoPR3eOZ0j/Z2SVJI7lNmFm9ejWvv/46PXv2dHYpIm4pMT2C4Aj/erOYThUY7scfbuzG3mOlhAb4EhfqT1xoAHFhtQORfSxmaqw2duaUsD7zOOsPFrD+4HH25JWy/1gZ+481DEEAsaH+DE2PYVjnOAYc3EDB/fdy6rSwmpwcDt11N7w4W4FGWs38LUeY8eEGSqusJEcF8syknpqG7YbcopuppKSEvn378sorr/DUU0/Ru3fv826ZUTeTyM9aajZTYVk1mw4VcOBY7WDmrOPlZOWXkXm8nPzSKvt5ZsPGnPlPE1NRyGk/LkwmfOLj6fjtQnU5SYuy2Qxe/HYXL55Y4feC9lH8/bq+RIece1yZtA6P62aaPn06l112GSNHjuSpp54667mVlZVUVv78m2dRUVFLlyfiNjr0iWPMtB4N1pkJifTnoilNX2cmPMiXoemxDE1veF9pZQ0bMwtYsjOPrEXLia0obHhSHcOg5sgRytasJXjQwCbVInIuxRXV3PPhRhZuq+12vXlIKg+P66qZS27M5cPMBx98wLp161i9evV5nT9r1iz++Mc/tnBVIu6rQ5840nrFttoKwMH+PgzuGMPgjjEU2vZy+P+d+zFPzl2KKSuASzrFMiQ9plVnlYln25tXwm3vrGFPXil+PmaevqIHV2mMjNtz6TCTmZnJXXfdxYIFCwgIOL8l7B966CFmzJhhv11UVERysn5QRU5mNpsaTL9uDT6x57dh6NZKXzavzuSD1Zn4mE30axfJ8C5xDOscS+f4UI1pkEarsdr4aE0Ws77cRnFlDQlhAbx2Qz96JUc4uzRxAJceM/PFF19w5ZVXYjmp79xqtWIymTCbzVRWVta773Q0ZkbEdRhWK7tHjKQmJ6fBAGAATCbMcXFkvvw+K/cXsHhnLnvzSuudkhgeQHxYAIZhYDUMrLba8Q9Ww8Bs4sR2EbWrH4fWrYTs70Owvw/B/hYC/XwI8rUQ5G8hyK92W4l2UUFaN8dDGYbBN1tzePbr7ew58bM0IDWSV67vR2yoxse4Mo9ZZ6a4uJgDBw7UO3bzzTfTpUsXHnjgAXr06HHO51CYEXEtRQsW1M5agvqB5kRrS5tTZjMdPFbG4p25LNqey/d7j1FRfeYVjJsqKtiPgalRXNA+igs6RNMpLlThxgOsO3icWV9uY/X+4wBEBvly54h0/u+Cdhof4wY8JsyczrBhwzSbScTNNXWdmYpqK+sOHKe0yorFDGaTCbPJhMVc+91mGPYtI+pWQq77c2lVDeVVtftZlVXVnPhu5WhJJZU19QNSRJAvg9KiGJoey+juCfoN3s3szSvh+QU7+HJz7c+Xv4+ZW4emMe2SDhp/5UY8bjaTiHiWsFGjCB0xotErAAf4WhjcMcahtVTV2Nh8qIBVe/NZtfcYaw/Ubmkxf0sO87fk8Ph/fmJgWhSXZSQyukcCcaHnN35PWpdhGKzYfYy3V+zjux25GEbtPm2T+7Xlnks7kRge6OwSpQW5XctMY6llRkQao9pqY/OhQr7fc4wFW46w8aSd2k0mGJAaxdgeCQxIjaJTfGij9wETxyqrquHz9YeYs2I/u3JL7MdHdo3jvtFd6JwQ6sTqpDk8upupsRRmRKQ5MvPL+OqnbL7cfIQNmQX17vOzmOmaGEpG23B6tomgR5tw0uNDNB6jhRmGwfYjxXyx/hD//vEgRRU1AAT7WZjcry03DU6lfWyIk6uU5lKYOYnCjIg4yqGCcr7anM3iHXlsyiqwf4iezNdiIi0mmPS4UNLjQ+zfU6OD1YrTDDVWG6v3H2fB1iN8szWHrOPl9vvaRQdx04WpTO7fVmNiPIjCzEkUZkSkJRiGwcH8MjYfKmRzViGbsgr56VAhxZUNAw6AxWwiPtSfxIhAEsMDaHPie2JEIF0SQmkXHdzK78D1lVbWsGxXHgu25vDd9lwKyqrt9/n7mBmaHsu1A5MZ1jkOi2afeRyFmZMozIhIa7HZDA4XlrMrt4RdOcXsyilhV24Ju3NLKDlDyKnTJSGUcRmJjMtIoGOc947zyC2qYOG2XBZuy2H57qNUnTTTLDLIlxFd47m0WzxD02MI8tMcFk+mMHMShRkRcTbDMMgtruRQQTnZBRVkF5ZzuKCCwwXlHC4sZ+vhImpsP/9XnB4XwriMREZ3T6BNRCD+vmb8LGaPXfvmcEE5n68/xIKtOWw8ZVxSSlQQl3aLZ1S3ePq1i8RH45G8hsLMSRRmRMTVFZRVsWBrDl9tzmb57qNUW0//37KvxYS/jwU/HzORQb50ig+lc0IoXRJC6RRf21XlTt0tGzMLeHP5Pr7cnI31pDDXKzmCUd1qW2DS40K0fYWXUpg5icKMiLiTwvJqvt2Ww5ebj7BsV16DBf3OJsDXTHpcKJd0iuWKPm3oGNeMGT02KxxYCSU5EBIP7QaD+ezrAJ0Pq83gm61H+OfyffaVeQEGpUUxoXcSI7vGEx+mtXxEYaYehRkRcVeGYVBjM6issVFZbaXKaqOy2kZljY2cogp2HClmR04xO44Usyu3uMFWDxltwrmyTxvG90pq3CrGW+fB1w9A0eGfj4UlwZhnoduEJr2PPXmlfLc9h3+tOkBmfu1MJF+LifE9k7jlojR6tAlv9POKZ1OYOYnCjIh4A6utdnbVxswC5m08zJKdefauG4vZxEUdY7i8ZyIXtI+mbWTgmbtuts6Dj24ETv1oOHH+lHfOK9AUllWzfPdRlu3KY9muoxwq+HkqdUSQL9cPSuHGC1PVCiNnpDBzEoUZEfFGx0oq+e+mbD5ff6jBYn9xof70T42kX7so+reLpFtSWO1CfzYrzO5Rv0XmJAYmakISWTNxCbml1RRV1FBWWUNplZXSyhrKqmooqbSSmV/GpqwCThoGg5+PmYGpUYzpkcAv+7Yl0K/5XVbi2RRmTqIwIyLebt/RUj5ff4glO/PYcqiw3swpqB1rEx3szwB+YnbFY+d8vmuqHmWVrds5z0uPC2FoeiwXd4phUFq0Aow0ijaaFBERu7SYYGZc2okZl3aiotrKxswC1hw4ztoTX4Xl1RwqKKefOQf8zv18PcLKISqK8EBfgv19CPbzOfHdQpC/D1HBvgxKiyYpQps7SutQmBER8SIBvhYGtY9mUPtooHahvwP5ZRSVV+OfZYL5L5/zOR69ejikXdjSpYqcN4UZEREvZjbX7iUFQJvR8H0SFGXTcAAwgKl2VlO7wa1Zosg5aSlFERGpZbbUTr8G7LOX7E7cHvOMQ9abEXEkhRkREflZtwm106/DEusfD0s672nZIq1N3UwiIlJftwnQ5bIWWQFYpCUozIiISENmC6QNdXYVIudF3UwiIiLi1hRmRERExK0pzIiIiIhbU5gRERERt6YwIyIiIm5NYUZERETcmsKMiIiIuDWFGREREXFrCjMiIiLi1jx+BWDDqN35taioyMmViIiIyPmq+9yu+xw/G48PM8XFxQAkJyc7uRIRERFprOLiYsLDw896jsk4n8jjxmw2G4cPHyY0NBSTqXYL+wEDBrB69eoG557u+KnHTr5dVFREcnIymZmZhIWFtUj9Z6rVkY8913mNuV6nO36269oa1/BstTrqcU29hme6zxV/Fs9UlyMf5w3XUf+mHUM/i47hytexf//+fPfddyQlJWE2n31UjMe3zJjNZtq2bVvvmMViOe0Px+mOn3rsdOeEhYW12A/bmWp15GPPdV5jrtfpjp/PdW3Ja3i2Wh31uKZewzPd54o/i2d6TUc+zhuuo/5NO4Z+Fh3Dla+jj49Pg8/vM/HKAcDTp08/7+OnHjvTY1tKc17vfB97rvMac71Od/x8rmtLa+rrtfQ1PNN9rviz2JzX1HV0zOvp33TzX08/i2evwdGPc/R1PBOP72ZqSUVFRYSHh1NYWNiiydmT6Ro6hq6jY+g6Np+uoWPoOjaOV7bMOIq/vz9/+MMf8Pf3d3YpbkvX0DF0HR1D17H5dA0dQ9excdQyIyIiIm5NLTMiIiLi1hRmRERExK0pzIiIiIhbU5gRERERt6YwIyIiIm5NYaYV7Nixg969e9u/AgMD+eKLL5xdllvat28fw4cPp1u3bmRkZFBaWursktyOj4+P/Wfx1ltvdXY5bq2srIx27dpx7733OrsUt1RcXMyAAQPo3bs3GRkZvPHGG84uye1kZmYybNgwunXrRs+ePfn444+dXZJTaGp2KyspKSE1NZUDBw4QHBzs7HLcziWXXMJTTz3F0KFDyc/PJywsDB8fj9+Vw6FiYmI4evSos8vwCI888gi7du0iJSWF559/3tnluB2r1UplZSVBQUGUlZXRo0cPVq9eTXR0tLNLcxvZ2dnk5OTQu3dvcnNz6du3Lzt27PC6zxe1zLSyefPmMWLECK/7QXOELVu24Ovry9ChQwGIiopSkBGn2bVrF9u3b2fcuHHOLsVtWSwWgoKCAKioqMBqtaLfrxsnMTGR3r17AxAXF0dUVBT5+fnOLcoJFGaApUuXMn78eJKSkjCZTKftAnrllVdIS0sjICCAfv36sWzZsia91kcffcTVV1/dzIpdU0tfx127dhESEsKECRPo27cvM2fOdGD1rqE1fhaLioro168fF110EUuWLHFQ5a6lNa7jvffey6xZsxxUsWtqjetYUFBAr169aNu2Lffffz8xMTEOqt41tObny5o1a7DZbCQnJzezavejX2uB0tJSevXqxc0338wvf/nLBvd/+OGH3H333bzyyisMGTKE1157jbFjx7J161ZSUlIA6NevH5WVlQ0eu2DBApKSkoDaD5EVK1bwwQcftOwbcpKWvo7V1dUsW7aMDRs2EBcXx5gxYxgwYACXXnppi7+31tIaP4v79+8nKSmJn376icsuu4zNmzd73N4vLX0dV69eTadOnejUqRMrV65s8ffjLK3x8xgREcHGjRvJyclh0qRJTJ48mfj4+BZ/b62ltT5fjh07xo033sibb77Zsm/IVRlSD2B8/vnn9Y4NHDjQ+PWvf13vWJcuXYwHH3ywUc/9zjvvGNdff31zS3QLLXEdV65caYwePdp++7nnnjOee+65ZtfqqlryZ7HOmDFjjNWrVze1RLfQEtfxwQcfNNq2bWu0a9fOiI6ONsLCwow//vGPjirZJbXGz+Ovf/1r46OPPmpqiS6vpa5hRUWFMXToUOOdd95xRJluSd1M51BVVcXatWsZNWpUveOjRo1q9G9kntzFdC6OuI4DBgwgJyeH48ePY7PZWLp0KV27dm2Jcl2SI67h8ePH7b/hZWVlsXXrVtq3b+/wWl2ZI67jrFmzyMzMZP/+/Tz//PPcdtttPP744y1RrstyxHXMycmhqKgIqG25Xrp0KZ07d3Z4ra7KEdfQMAymTp3KL37xC2644YaWKNMtqJvpHI4ePYrVam3Q7BkfH8+RI0fO+3kKCwv58ccf+fTTTx1doltwxHX08fFh5syZXHzxxRiGwahRo7j88stbolyX5IhruG3bNqZNm4bZbMZkMvHiiy8SFRXVEuW6LEf9m/Z2jriOWVlZ/OpXv8IwDAzD4I477qBnz54tUa5LcsQ1XLFiBR9++CE9e/a0j8f517/+RUZGhqPLdWkKM+fJZDLVu20YRoNjZxMeHk5OTo6jy3I7zb2OY8eOZezYsY4uy6005xoOHjyYzZs3t0RZbqe5P4t1pk6d6qCK3FNzrmO/fv3YsGFDC1TlXppzDS+66CJsNltLlOVW1M10DjExMVgslgYpOTc316MGqbU0Xcfm0zV0DF1Hx9B1bD5dQ8dRmDkHPz8/+vXrxzfffFPv+DfffMPgwYOdVJX70XVsPl1Dx9B1dAxdx+bTNXQcdTNRuyrv7t277bf37dvHhg0biIqKIiUlhRkzZnDDDTfQv39/LrzwQl5//XUOHjzIr3/9aydW7Xp0HZtP19AxdB0dQ9ex+XQNW4mzplG5kkWLFhlAg6+bbrrJfs7f//53o127doafn5/Rt29fY8mSJc4r2EXpOjafrqFj6Do6hq5j8+katg7tzSQiIiJuTWNmRERExK0pzIiIiIhbU5gRERERt6YwIyIiIm5NYUZERETcmsKMiIiIuDWFGREREXFrCjMiIiLi1hRmRMSlpaamMnv2bGeXISIuTGFGRJg6dSpXXHGFs8s4rdWrV3P77be3+OukpqZiMpkwmUwEBgbSpUsX/vznP9PYRdIVvkRanzaaFBGnqK6uxtfX95znxcbGtkI1tZ588kluu+02KioqWLhwIb/5zW8ICwtj2rRprVaDiDSeWmZE5Jy2bt3KuHHjCAkJIT4+nhtuuIGjR4/a7//666+56KKLiIiIIDo6mssvv5w9e/bY79+/fz8mk4mPPvqIYcOGERAQwLvvvmtvEXr++edJTEwkOjqa6dOnU11dbX/sqS0dJpOJN998kyuvvJKgoCDS09OZN29evXrnzZtHeno6gYGBDB8+nLlz52IymSgoKDjr+wwNDSUhIYHU1FRuvfVWevbsyYIFC+z379mzh4kTJxIfH09ISAgDBgxg4cKF9vuHDRvGgQMHuOeee+ytPHVWrlzJxRdfTGBgIMnJydx5552Ulpae99+BiJyZwoyInFV2djaXXHIJvXv3Zs2aNXz99dfk5OQwZcoU+zmlpaXMmDGD1atX8+2332I2m7nyyiux2Wz1nuuBBx7gzjvvZNu2bYwePRqARYsWsWfPHhYtWsTcuXOZM2cOc+bMOWtNf/zjH5kyZQqbNm1i3LhxXH/99eTn5wO1wWny5MlcccUVbNiwgWnTpvHII4806j0bhsHixYvZtm1bvdajkpISxo0bx8KFC1m/fj2jR49m/PjxHDx4EIDPPvuMtm3b8uSTT5KdnU12djYAmzdvZvTo0UyaNIlNmzbx4Ycfsnz5cu64445G1SUiZ+DcTbtFxBXcdNNNxsSJE09732OPPWaMGjWq3rHMzEwDMHbs2HHax+Tm5hqAsXnzZsMwDGPfvn0GYMyePbvB67Zr186oqamxH7vqqquMq6++2n67Xbt2xl//+lf7bcB49NFH7bdLSkoMk8lkfPXVV4ZhGMYDDzxg9OjRo97rPPLIIwZgHD9+/PQX4MTr+Pn5GcHBwYavr68BGAEBAcaKFSvO+BjDMIxu3boZL7300hnrNQzDuOGGG4zbb7+93rFly5YZZrPZKC8vP+vzi8i5qWVGRM5q7dq1LFq0iJCQEPtXly5dAOxdSXv27OG6666jffv2hIWFkZaWBmBvsajTv3//Bs/fvXt3LBaL/XZiYiK5ublnralnz572PwcHBxMaGmp/zI4dOxgwYEC98wcOHHhe7/W+++5jw4YNLFmyhOHDh/PII48wePBg+/2lpaXcf//9dOvWjYiICEJCQti+fXuD93mqtWvXMmfOnHrXcPTo0dhsNvbt23detYnImWkAsIiclc1mY/z48Tz77LMN7ktMTARg/PjxJCcn88Ybb5CUlITNZqNHjx5UVVXVOz84OLjBc5w6CNhkMjXonmrMYwzDqDdWpe7Y+YiJiaFjx4507NiRTz/9lI4dO3LBBRcwcuRIoDbszJ8/n+eff56OHTsSGBjI5MmTG7zPU9lsNqZNm8add97Z4L6UlJTzqk1EzkxhRkTOqm/fvnz66aekpqbi49Pwv4xjx46xbds2XnvtNYYOHQrA8uXLW7tMuy5duvDll1/WO7ZmzZpGP09kZCS/+93vuPfee1m/fj0mk4lly5YxdepUrrzySqB2DM3+/fvrPc7Pzw+r1VrvWN++fdmyZQsdO3ZsdB0icm7qZhIRAAoLC9mwYUO9r4MHDzJ9+nTy8/O59tpr+fHHH9m7dy8LFizglltuwWq1EhkZSXR0NK+//jq7d+/mu+++Y8aMGU57H9OmTWP79u088MAD7Ny5k48++sg+oPjUFptzmT59Ojt27ODTTz8FoGPHjnz22Wds2LCBjRs3ct111zVoRUpNTWXp0qUcOnTIPuPrgQce4Pvvv2f69Ols2LCBXbt2MW/ePH73u981/w2LiMKMiNRavHgxffr0qff1+OOPk5SUxIoVK7BarYwePZoePXpw1113ER4ejtlsxmw288EHH7B27Vp69OjBPffcw5///GenvY+0tDQ++eQTPvvsM3r27Mmrr75qn83k7+/fqOeKjY3lhhtu4IknnsBms/HXv/6VyMhIBg8ezPjx4xk9ejR9+/at95gnn3yS/fv306FDB/saOT179mTJkiXs2rWLoUOH0qdPHx577DF7N52INI/JON/OZBERN/X000/zj3/8g8zMTGeXIiItQGNmRMTjvPLKKwwYMIDo6GhWrFjBn//8Z63pIuLBFGZExOPs2rWLp556ivz8fFJSUvj973/PQw895OyyRKSFqJtJRERE3JoGAIuIiIhbU5gRERERt6YwIyIiIm5NYUZERETcmsKMiIiIuDWFGREREXFrCjMiIiLi1hRmRERExK0pzIiIiIhb+/+R2a5OO8stYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.799327</td>\n",
       "      <td>1.663339</td>\n",
       "      <td>0.317453</td>\n",
       "      <td>0.153232</td>\n",
       "      <td>0.252488</td>\n",
       "      <td>0.893058</td>\n",
       "      <td>0.864607</td>\n",
       "      <td>0.878485</td>\n",
       "      <td>02:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN Student News) -- March 23, 2010. Download PDF maps related to today's show:. • Haiti • China. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN STUDENT NEWS ANCHOR: Happy birthday, Roger Bannister -- first man to run the mile in less than four minutes. In more than twice that time, you'll be up to speed on today's headlines. I'm Carl Azuz. First Up: Health Care. AZUZ: First up, it's the biggest expansion of the United States he</td>\n",
       "      <td>Find out what comes next after the passage of a health care reform bill.\\nLearn about a proposal that would change how student loans are funded.\\nFollow the steps that led to a showdown between China and Google.\\nUse the Daily Discussion to help studen</td>\n",
       "      <td>Check out the reaction to the U.S. House of Representatives passing a health care reform bill .\\nLearn about some of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington (CNN)Almost immediately following the news of the first terrorist attacks that eventually killed 17 people across France, the global community united around a Twitter hashtag \"Je suis Charlie\" and just days later foreign leaders linked arms with their French counterparts to lead a historic million-person strong rally. Meanwhile, explosives strapped to a girl who appeared to be about 10-years-old detonated on Saturday, killing at least 20 people, in a country whose encounters with ter</td>\n",
       "      <td>France and Nigeria experienced waves of terrorism during the first weeks of 2015.\\nWhile the terror attacks in Paris sparked international unified outrage, reaction to Nigeria was more muted.\\nSymbolism, politics and media all played a role in how Fra</td>\n",
       "      <td>Terrorist attacks in Paris and Nigeria fomented unprecedented international reaction .\\nThe response to the attacks in Nigeria paled in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off into France .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "About 10 men armed with pistols and small machine guns raided the Grand Casino Basel .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "\n",
      "=== Prediction 3 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off into France .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were about 600 people in the casino at the time of the robbery .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'summarize_export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\\nAbout 10']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlearnerForSummarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSummarization(Blearner):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        dls: DataLoaders, \n",
    "        hf_model: PreTrainedModel, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "            \n",
    "    @classmethod\n",
    "    def get_model_cls(cls): \n",
    "        return AutoModelForSeq2SeqLM\n",
    "    \n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp): \n",
    "        return f'summarize: {inp}'\n",
    "    \n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\n",
    "            'rouge': {\n",
    "                'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
    "                'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "            },\n",
    "            'bertscore': {\n",
    "                'compute_kwargs': { 'lang': 'en' },\n",
    "                'returns': [\"precision\", \"recall\", \"f1\"]\n",
    "            }\n",
    "        }\n",
    "            \n",
    "        return HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls, \n",
    "        # Your raw dataset\n",
    "        data, \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr:str='text', \n",
    "        # The attribute in your dataset that contains your target (summarized) text\n",
    "        summary_attr:str='summary', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = BLURR.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        if (hf_arch == 'mbart'): \n",
    "            hf_tok_kwargs = { **{'src_lang': 'en_XX', 'tgt_lang': 'en_XX'}, **hf_tok_kwargs }\n",
    "            \n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, \n",
    "                                                                          model_cls=model_cls, \n",
    "                                                                          tokenizer_kwargs=hf_tok_kwargs)\n",
    "        \n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if (preprocess_func):\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, text_attr, summary_attr)\n",
    "            \n",
    "        # update text generation kwargs\n",
    "        if (text_gen_kwargs is None and hf_arch in ['bart', 't5']):\n",
    "            text_gen_kwargs = hf_config.task_specific_params['summarization']\n",
    "        \n",
    "        # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args: del text_gen_kwargs[k]\n",
    "                \n",
    "        # update our text generation kwargs for mbart\n",
    "        if (hf_arch == 'mbart'):\n",
    "            text_gen_kwargs = { **{'decoder_start_token_id': 'en_XX'}, **text_gen_kwargs }\n",
    "            \n",
    "        # define getters\n",
    "        if (isinstance(data, pd.DataFrame)):\n",
    "            get_x = Pipeline(funcs=[ColReader(text_attr)])\n",
    "            get_y = ColReader(summary_attr)\n",
    "        else:\n",
    "            get_x = Pipeline(funcs=[ItemGetter(text_attr)])\n",
    "            get_y = ItemGetter(summary_attr)\n",
    "                               \n",
    "        if (hf_arch == 't5'):\n",
    "            get_x.add(cls._add_t5_prefix)\n",
    "            \n",
    "        # define our DataBlock and DataLoaders\n",
    "        before_batch_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                          max_length=max_length, \n",
    "                                                          max_target_length=max_target_length, \n",
    "                                                          text_gen_kwargs=text_gen_kwargs)\n",
    "        \n",
    "        blocks = (Seq2SeqTextBlock(before_batch_tfm=before_batch_tfm), noop)\n",
    "        dblock = DataBlock(blocks=blocks, \n",
    "                           get_x=get_x, \n",
    "                           get_y=get_y, \n",
    "                           splitter=dblock_splitter)\n",
    "        \n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "        \n",
    "        # return BLearner instance\n",
    "        learner_kwargs['splitter'] = learner_kwargs.pop('splitter', partial(seq2seq_splitter, arch=hf_arch))\n",
    "        learner_kwargs['loss_func'] = learner_kwargs.pop('loss_func', CrossEntropyLossFlat())\n",
    "        \n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls,\n",
    "        # Your pandas DataFrame\n",
    "        df, \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr:str='text', \n",
    "        # The attribute in your dataset that contains your target (summarized) text\n",
    "        summary_attr:str='summary', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=ColSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        \n",
    "        return cls._create_learner(df, \n",
    "                                   pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                   preprocess_func=preprocess_func, \n",
    "                                   text_attr=text_attr, \n",
    "                                   summary_attr=summary_attr, \n",
    "                                   max_length=max_length, \n",
    "                                   max_target_length=max_target_length,  \n",
    "                                   dblock_splitter=dblock_splitter, \n",
    "                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "        \n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls,\n",
    "        # The path to your csv file\n",
    "        csv_file:Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr:str='text', \n",
    "        # The attribute in your dataset that contains your target (summarized) text\n",
    "        summary_attr:str='summary', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=ColSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        return cls.from_dataframe(df, \n",
    "                                  pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                  preprocess_func=preprocess_func, \n",
    "                                  text_attr=text_attr, \n",
    "                                  summary_attr=summary_attr, \n",
    "                                  max_length=max_length, \n",
    "                                  max_target_length=max_target_length,  \n",
    "                                  dblock_splitter=dblock_splitter, \n",
    "                                  hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                  dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls,\n",
    "        # A list of dictionaries\n",
    "        ds:List[Dict], \n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path:Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset \n",
    "        preprocess_func:Callable=None, \n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr:str='text', \n",
    "        # The attribute in your dataset that contains your target (summarized) text\n",
    "        summary_attr:str='summary', \n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length:Union[int,str]=None, \n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length:Union[int,str]=None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter:Callable=RandomSplitter(),\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs:dict={}, \n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs:dict={}, \n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs:dict={}\n",
    "    ):\n",
    "        return cls._create_learner(ds, \n",
    "                                   pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                   preprocess_func=preprocess_func, \n",
    "                                   text_attr=text_attr, \n",
    "                                   summary_attr=summary_attr, \n",
    "                                   max_length=max_length, \n",
    "                                   max_target_length=max_target_length,  \n",
    "                                   dblock_splitter=dblock_splitter, \n",
    "                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs, \n",
    "                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSummarization.from_dataframe(cnndm_df, 'facebook/bart-large-cnn', \n",
    "                                                text_attr='article', summary_attr='highlights', \n",
    "                                                max_length=256, max_target_length=130,\n",
    "                                                dblock_splitter=RandomSplitter(),\n",
    "                                                dl_kwargs={'bs':2}).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.680803</td>\n",
       "      <td>1.656284</td>\n",
       "      <td>0.391191</td>\n",
       "      <td>0.175432</td>\n",
       "      <td>0.271317</td>\n",
       "      <td>0.876456</td>\n",
       "      <td>0.893137</td>\n",
       "      <td>0.884638</td>\n",
       "      <td>03:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[BlearnerForSummarization.get_metrics_cb()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN Student News) -- March 23, 2010. Download PDF maps related to today's show:. • Haiti • China. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN STUDENT NEWS ANCHOR: Happy birthday, Roger Bannister -- first man to run the mile in less than four minutes. In more than twice that time, you'll be up to speed on today's headlines. I'm Carl Azuz. First Up: Health Care. AZUZ: First up, it's the biggest expansion of the United States he</td>\n",
       "      <td>Find out what comes next after the passage of a health care reform bill.\\nLearn about a proposal that would change how student loans are funded.\\nFollow the steps that led to a showdown between China and Google.\\nUse the Daily Discussion to help studen</td>\n",
       "      <td>Find out why the U.S. House of Representatives passed a health care reform bill late Sunday night .\\nCheck out some of the reaction to last night's vote on the health care issue .\\nLearn about the impact of the earthquake in Haiti .\\nMeet a man who is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN Student News) -- Parents and Teachers: Watch with your students or record \"Gary + Tony Have a Baby\" when it airs on CNN on Thursday, June 24 at 8 p.m. ET. By recording the documentary, you agree that you will use the program for educational viewing purposes for a one-year period only. No other rights of any kind or nature whatsoever are granted, including, without limitation, any rights to sell, publish, distribute, post online or distribute in any other medium or forum, or use for any com</td>\n",
       "      <td>\"Gary + Tony Have a Baby\" is a documentary that follows the journey of a gay couple as they attempt to become parents.\\nParents and educators can use this guide to initiate discussion with students about the documentary.</td>\n",
       "      <td>\"Gary + Tony Have a Baby\" is a documentary that follows the journey of a gay couple as they attempt to become parents .\\nWe recommend that you preview this program and determine whether it is appropriate before showing it to students .\\nBy recording t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " Police: About 10 men armed with pistols and machine guns raided a casino in Switzerland .\n",
      "They made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were no serious injuries, but one guest was kicked in the head by one of the robbers .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " Police: About 10 men armed with pistols and machine guns raided a casino in Switzerland .\n",
      "They made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "\n",
      "=== Prediction 3 ===\n",
      " Police: About 10 men armed with pistols and machine guns raided a casino in Switzerland .\n",
      "They made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\n",
      "The robbers spoke French and drove vehicles with French lRicense plates .\n",
      "There were about 600 people in the casino at the time of the robbery .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Police: About 10 men armed with pistols and machine guns raided a casino in Switzerland .\\nThey made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe robbers spoke French and drove vehicles with French lRicense plates .\\nThere were no serious injuries, but one guest was kicked in the head by one of the robbers .']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = 'summarize_export'\n",
    "\n",
    "learn.metrics = None\n",
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_generate(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **summarization models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "[ model_type for model_type in BLURR.get_models(task='ConditionalGeneration') \n",
    " if (not model_type.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pretrained_model_names = [\n",
    "    'facebook/bart-base',\n",
    "    #'facebook/blenderbot_small-90M',\n",
    "    'allenai/led-base-16384',\n",
    "    'sshleifer/tiny-mbart',\n",
    "    'google/mt5-small',\n",
    "    'sshleifer/distill-pegasus-cnn-16-4',\n",
    "    't5-small', \n",
    "    #'microsoft/prophetnet-large-uncased',\n",
    "    #'microsoft/xprophetnet-large-wiki100-cased', # XLMProphetNet\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington (CNN)Almost immediately following the news of the first terrorist attacks that eventually killed 17 people across France, the global community united around a Twitter hashtag \"Je suis Charlie\" and just days later foreign leaders linked arms with their French counterparts to lead a historic million-person strong rally. Meanwhile, explosives strapped</td>\n",
       "      <td>France and Nigeria experienced waves of terrorism during the first weeks of 2015.\\nWhile the terror attacks in Paris sparked international unified outrage, reaction to Nigeria was more muted.\\nSymbolism,</td>\n",
       "      <td>Washington (CNN)Almost immediately following the news of the first terrorist attacks that eventually killed 17 people across France, the global community united around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Zehaf-Bibeau, the 32-year-old gunman who attacked the Canadian Parliament and killed a soldier last week, had a familiar profile. It is that of a young man alienated from mainstream society, with few friends, without a steady job, drifting from one place to another -- often</td>\n",
       "      <td>Like many \"lone wolf\" terrorists, Ottawa gunman was alienated drifter who converted to Islam.\\nConversion to militant Islam is often about seeking identity, purpose or adventure.\\nSome</td>\n",
       "      <td>Michael Zehaf-Bibeau, the 32-year-old gunman who attacked the Canadian Parliament and killed a soldier last week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/led-base-16384 ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some U.S. officials this year are expected to get smartphones capable of handling classified government documents over cellular networks, according to people involved in the project. The phones will run a modified version of Google's Android software, which is being developed as part of an initiative that spans multiple federal agencies and government contractors,</td>\n",
       "      <td>Government, military officials to get Android phones capable of sharing secret documents.\\nThe phones will run a modified version of Google's Android software, sources say.\\nContractor: Google \"more</td>\n",
       "      <td>Some U.S. officials this year are expected to get smartphones capable of handling classified government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Wondering where to go for your next holiday? Experts explain which destinations we should be checking out in 2014. Brazil: The World Cup. The modern game of football, or soccer, may have been born in England's public schools, but many will claim its soul has settled in Brazil.</td>\n",
       "      <td>New Zealand government threw $50 million into the construction of the Nga Haerenga cycle trails.\\nNosara in Costa Rica recently awarded a Blue Flag -- a certification awarded to</td>\n",
       "      <td>(CNN) -- Wondering where to go for your next holiday? Experts explain which destinations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/tiny-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Home to up to 10 percent of all known species, Mexico is recognized as one of the most biodiverse regions on the planet. The twin threats of climate change and human encroachment on natural environments are, however, threatening the existence of</td>\n",
       "      <td>Mexico hosts to up to 10 percent of all known species on Earth. It is home to 502 types of mammals, 290 bird species and 26,000 types of plants</td>\n",
       "      <td>เข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไป</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Police missed speaking with suspected Los Angeles International Airport shooter Paul Ciancia by \"a matter of minutes\" the day his family asked authorities to check on him after receiving disturbing messages, according to the chairman of the House Homeland Security Committee. By the time officers arrived at Ciancia's</td>\n",
       "      <td>Paul Ciancia began asking for a ride to the airport days before the shooting. Police performing a welfare check at his family's request missed him by less than an hour</td>\n",
       "      <td>เข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไป</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mt5-small ===\n",
      "\n",
      "architecture:\tmt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tMT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Home to up to 10 percent of all known species, Mexico is recognized as one of the most biodiverse regions on the planet. The twin threats of climate change and human encroachment on natural environments are, however, threatening the existence</td>\n",
       "      <td>Mexico hosts to up to 10 percent of all known species on Earth. It is home to 502 types of mammals, 290 bird species and 26,000 types of</td>\n",
       "      <td>&lt;extra_id_0&gt;.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- To Disney or not to Disney? For many travelers, especially those with children, it's not even a question they ask. They already know the answer. \"Yes.\" To these visitors, Disney is Mickey Mouse, princesses,</td>\n",
       "      <td>Disney represents magical stories and fun family to fans. Some parents delight in their children's wonder during a first visit to Disney. Some critics think the</td>\n",
       "      <td>&lt;extra_id_0&gt;.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/distill-pegasus-cnn-16-4 ===\n",
      "\n",
      "architecture:\tpegasus\n",
      "tokenizer:\tPegasusTokenizerFast\n",
      "model:\t\tPegasusForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London (CNN) -- In 1948, a hospital outside London witnessed the birth of the Paralympic movement, as a Jewish doctor who had fled Nazi Germany sought to change the lives of patients with spinal injuries -- and inspire new hope in them through sport. The first \"Stoke Mandeville Games\" were organized in 1948 to coincide with the</td>\n",
       "      <td>Paralympic movement was born in Stoke Mandeville, outside London, in 1948. 2012 Games will be the biggest yet, with 4,200 competitors from 165 countries. In an echo of the first,</td>\n",
       "      <td>The first \"Stoke Mandeville Games\" was organized in 1948 . The first \"Stoke Mandeville Games\" was organized in 1948 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN Student News) -- March 23, 2010. Download PDF maps related to today's show:. • Haiti • China. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN</td>\n",
       "      <td>Find out what comes next after the passage of a health care reform bill. Learn about a proposal that would change how student loans are funded. Follow the steps that led to a showdown between</td>\n",
       "      <td>Use the weekly Newsquiz to test your knowledge of stories you saw on CNN Student News . Use the weekly Newsquiz to test your knowledge of stories you saw on CNN Student News .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarize: (CNN) -- It's a congested, sprawling transport hub surrounded by 1950s architecture and predominantly used by commuters or tourists to cross the city of Istanbul. But proposed changes to Taksim Square have seen it become the flashpoint for protests that have</td>\n",
       "      <td>Taksim Square was where Istanbul's water was distributed -- Taksim means divide. The site is seen as symbolizing the seclar Turkish republic founded by Ataturk.</td>\n",
       "      <td>it's a congested, sprawling transport hub surrounded by 1950s architecture . proposed changes to Taksim Square have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summarize: (CNN) -- Two years after the United States pulled its forces out of Iraq, the country is, in the words of one analyst, \"a house of cards.\" \"It is a contraption held together solely by the reluctance of its many components to let</td>\n",
       "      <td>Sectarian divisions, terror, regional conflict and economic issues all threaten Iraqi stability. Continued violence could also threaten the country's oil exports and economy. All these</td>\n",
       "      <td>two years after the united states pulled its forces out of Iraq, the country is \"a house of cards\" one analyst says it is a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 64; trg_seq_sz = 40\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_tok_kwargs = {}\n",
    "    if (model_name == 'sshleifer/tiny-mbart'):\n",
    "        hf_tok_kwargs['src_lang'], hf_tok_kwargs['tgt_lang'] = \"en_XX\", \"en_XX\"\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      tokenizer_kwargs=hf_tok_kwargs)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "\n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = {}\n",
    "    if (hf_arch in ['bart', 't5']):\n",
    "        text_gen_kwargs = {**hf_config.task_specific_params['summarization'], **{'max_length': 30, 'min_length': 10}}\n",
    "    \n",
    "    # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "    generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "    for k in text_gen_kwargs.copy():\n",
    "        if k not in generate_func_args: del text_gen_kwargs[k]\n",
    "            \n",
    "    if (hf_arch == 'mbart'):\n",
    "        text_gen_kwargs['decoder_start_token_id'] = hf_tokenizer.get_vocab()[\"en_XX\"]\n",
    "            \n",
    "            \n",
    "    def add_t5_prefix(inp): return f'summarize: {inp}' if (hf_arch == 't5') else inp\n",
    "    \n",
    "    before_batch_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                      padding='max_length', \n",
    "                                                      max_length=inp_seq_sz, \n",
    "                                                      max_target_length=trg_seq_sz, \n",
    "                                                      text_gen_kwargs=text_gen_kwargs)\n",
    "    \n",
    "    blocks = (Seq2SeqTextBlock(before_batch_tfm=before_batch_tfm), noop)\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=Pipeline([ColReader('article'), add_t5_prefix]), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())\n",
    "\n",
    "    dls = dblock.dataloaders(cnndm_df, bs=bsz) \n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {\n",
    "        'rouge': {\n",
    "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
    "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    learn_cbs = [BaseModelCallback]\n",
    "    fit_cbs = [\n",
    "        ShortEpochCallback(0.05, short_valid=True), \n",
    "        HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "    ]\n",
    " \n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=ranger,\n",
    "                    loss_func=PreCalculatedLoss(),\n",
    "                    cbs=learn_cbs,\n",
    "                    splitter=partial(seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "    learn.create_opt() \n",
    "    learn.freeze()\n",
    "    \n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***\\n')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "#         print('*** TESTING One pass through the model ***')\n",
    "#         preds = learn.model(b[0])\n",
    "#         test_eq(preds[1].shape[0], bsz)\n",
    "#         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mt5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>MT5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pegasus</td>\n",
       "      <td>PegasusTokenizerFast</td>\n",
       "      <td>PegasusForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental bits to use Blurr for summarization tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
