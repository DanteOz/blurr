{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp callbacks\n",
    "# |default_cls_lvl 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# callbacks\n",
    "\n",
    "> Callbacks used by the BLURR library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import os\n",
    "\n",
    "import importlib, sys, torch\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_core import *\n",
    "from transformers import PreTrainedModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "import gc, pdb\n",
    "\n",
    "import GPUtil as GPU\n",
    "from IPython.display import display\n",
    "from fastai.text.all import *\n",
    "from fastcore.test import *\n",
    "from nbdev import nbdev_export\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.text.modeling.all import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_smi_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class CheckpointingNotSupported(Exception):\n",
    "    def __init__(self, msg=\"Model does not support gradient checkpointing.\"):\n",
    "        super().__init__(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class GradientCheckpointing(Callback):\n",
    "    \"\"\"A fastai callback to enable gradient checkpointing for compatible HuggingFace models.\"\"\"\n",
    "\n",
    "    def before_fit(self):\n",
    "        \"\"\"Enable gradient checkpointing on before_fit event.\"\"\"\n",
    "\n",
    "        # Check that huggingface model supports gradient checkpointing\n",
    "        if not self.model.hf_model.supports_gradient_checkpointing:\n",
    "            raise CheckpointingNotSupported()\n",
    "\n",
    "        if self.model.hf_model.is_gradient_checkpointing == False:\n",
    "            self.model.hf_model.gradient_checkpointing_enable()\n",
    "\n",
    "    def after_fit(self):\n",
    "        \"\"\"Disable gradient checkpointing on after_fit event.\"\"\"\n",
    "        if self.model.hf_model.is_gradient_checkpointing:\n",
    "            self.model.hf_model.gradient_checkpointing_disable()\n",
    "\n",
    "    @staticmethod\n",
    "    def supported(model: PreTrainedModel):\n",
    "        \"\"\"Tests whether a HuggingFace `PreTrainedModel` supports gradient checkpointing.\"\"\"\n",
    "        return model.supports_gradient_checkpointing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_memory(device_idx=nvidia_smi_idx):\n",
    "    return GPU.getGPUs()[device_idx].memoryUsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: load Data\n",
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "model_path = Path(\"models\")\n",
    "imdb_df = pd.read_csv(path / \"texts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'method-wrapper' object has no attribute '__annotations__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/wgilliam/development/projects/blurr/nbs/00b_callbacks.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdl-rig/home/wgilliam/development/projects/blurr/nbs/00b_callbacks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# step 2: create Learner\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdl-rig/home/wgilliam/development/projects/blurr/nbs/00b_callbacks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m learn \u001b[39m=\u001b[39m BlearnerForSequenceClassification\u001b[39m.\u001b[39;49mfrom_data(imdb_df, \u001b[39m\"\u001b[39;49m\u001b[39mroberta-large\u001b[39;49m\u001b[39m\"\u001b[39;49m, dl_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mbs\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m4\u001b[39;49m})\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdl-rig/home/wgilliam/development/projects/blurr/nbs/00b_callbacks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# train for a single epoch for baseline memory usage\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdl-rig/home/wgilliam/development/projects/blurr/nbs/00b_callbacks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m learn\u001b[39m.\u001b[39mfit_one_cycle(\u001b[39m1\u001b[39m, lr_max\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n",
      "File \u001b[0;32m~/development/projects/blurr/nbs/blurr/text/modeling/core.py:415\u001b[0m, in \u001b[0;36mBlearnerForSequenceClassification.from_data\u001b[0;34m(cls, data, pretrained_model_name_or_path, text_attr, label_attr, n_labels, dblock_splitter, dl_kwargs, learner_kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39m# build our DataBlock and DataLoaders\u001b[39;00m\n\u001b[1;32m    414\u001b[0m blocks \u001b[39m=\u001b[39m (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), trg_block)\n\u001b[0;32m--> 415\u001b[0m dblock \u001b[39m=\u001b[39m DataBlock(\n\u001b[1;32m    416\u001b[0m     blocks\u001b[39m=\u001b[39;49mblocks, get_x\u001b[39m=\u001b[39;49mpartial(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_x, attr\u001b[39m=\u001b[39;49mtext_attr), get_y\u001b[39m=\u001b[39;49mpartial(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_y, attr\u001b[39m=\u001b[39;49mlabel_attr), splitter\u001b[39m=\u001b[39;49mdblock_splitter\n\u001b[1;32m    417\u001b[0m )\n\u001b[1;32m    419\u001b[0m dls \u001b[39m=\u001b[39m dblock\u001b[39m.\u001b[39mdataloaders(data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdl_kwargs\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m    421\u001b[0m \u001b[39m# return BLearner instance\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/blurr/lib/python3.9/site-packages/fastcore/meta.py:150\u001b[0m, in \u001b[0;36m_funcs_kwargs.<locals>._init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg,MethodType): arg \u001b[39m=\u001b[39m MethodType(arg\u001b[39m.\u001b[39m\u001b[39m__func__\u001b[39m, \u001b[39mself\u001b[39m)\n\u001b[1;32m    149\u001b[0m         \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, k, arg)\n\u001b[0;32m--> 150\u001b[0m old_init(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/blurr/lib/python3.9/site-packages/fastai/data/block.py:99\u001b[0m, in \u001b[0;36mDataBlock.__init__\u001b[0;34m(self, blocks, dl_type, getters, n_inp, item_tfms, batch_tfms, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(b, \u001b[39m'\u001b[39m\u001b[39mdl_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl_type \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mdl_type\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m dl_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl_type \u001b[39m=\u001b[39m dl_type\n\u001b[0;32m---> 99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloaders \u001b[39m=\u001b[39m delegates(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdl_type\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m)(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloaders)\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls_kwargs \u001b[39m=\u001b[39m merge(\u001b[39m*\u001b[39mblocks\u001b[39m.\u001b[39mattrgot(\u001b[39m'\u001b[39m\u001b[39mdls_kwargs\u001b[39m\u001b[39m'\u001b[39m, {}))\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inp \u001b[39m=\u001b[39m ifnone(n_inp, \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(blocks)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/mambaforge/envs/blurr/lib/python3.9/site-packages/fastcore/meta.py:125\u001b[0m, in \u001b[0;36mdelegates.<locals>._f\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    122\u001b[0m k \u001b[39m=\u001b[39m sigd\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mkwargs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    123\u001b[0m s2 \u001b[39m=\u001b[39m {k:v\u001b[39m.\u001b[39mreplace(kind\u001b[39m=\u001b[39minspect\u001b[39m.\u001b[39mParameter\u001b[39m.\u001b[39mKEYWORD_ONLY) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(to_f)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m       \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mdefault \u001b[39m!=\u001b[39m inspect\u001b[39m.\u001b[39mParameter\u001b[39m.\u001b[39mempty \u001b[39mand\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sigd \u001b[39mand\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m but}\n\u001b[0;32m--> 125\u001b[0m anno \u001b[39m=\u001b[39m {k:v \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m to_f\u001b[39m.\u001b[39;49m\u001b[39m__annotations__\u001b[39;49m\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sigd \u001b[39mand\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m but}\n\u001b[1;32m    126\u001b[0m sigd\u001b[39m.\u001b[39mupdate(s2)\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m keep: sigd[\u001b[39m'\u001b[39m\u001b[39mkwargs\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m k\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'method-wrapper' object has no attribute '__annotations__'"
     ]
    }
   ],
   "source": [
    "# step 2: create Learner\n",
    "learn = BlearnerForSequenceClassification.from_data(imdb_df, \"roberta-large\", dl_kwargs={\"bs\": 4})\n",
    "\n",
    "# train for a single epoch for baseline memory usage\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)\n",
    "\n",
    "base_mem = gpu_memory()\n",
    "print(f\"{base_mem} MBs used.\")\n",
    "\n",
    "# Clear gpu memory\n",
    "reset_memory(learn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: create Learner\n",
    "learn = BlearnerForSequenceClassification.from_data(imdb_df, \"roberta-large\", dl_kwargs={\"bs\": 4})\n",
    "\n",
    "# train with GradientCheckpointing\n",
    "learn.fit_one_cycle(1, lr_max=1e-3, cbs=[GradientCheckpointing()])\n",
    "\n",
    "check_mem = gpu_memory()\n",
    "print(f\"{check_mem} MBs used.\")\n",
    "\n",
    "test_eq(base_mem > check_mem, True)\n",
    "reset_memory(learn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "nbdev_export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('blurr')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
