{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp text.modeling.seq2seq.translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text.modeling.seq2seq.translation\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... translation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import inspect, torch\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from transformers import AutoModelForSeq2SeqLM, PreTrainedModel, logging\n",
    "\n",
    "from blurr.text.data.seq2seq.core import Seq2SeqBatchTokenizeTransform, Seq2SeqTextBlock, default_text_gen_kwargs\n",
    "from blurr.text.modeling.core import BaseModelCallback, BaseModelWrapper, Blearner\n",
    "from blurr.text.modeling.seq2seq.core import Seq2SeqMetricsCallback, blurr_seq2seq_splitter\n",
    "from blurr.text.utils import NLP\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import ast, os, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "The objective in translation is to generate a representation of a given text in another style. For example, we may want to translate German into English or modern English into old English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.</td>\n",
       "      <td>In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?</td>\n",
       "      <td>\"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    de  \\\n",
       "0            Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.   \n",
       "1  \"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?   \n",
       "\n",
       "                                                                                                                                                                                     en  \n",
       "0  In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.  \n",
       "1                                                                                    \"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train\")\n",
    "dataset = dataset.shuffle(seed=32).select(range(1200))\n",
    "wmt_df = pd.DataFrame(dataset[\"translation\"], columns=[\"de\", \"en\"])\n",
    "len(wmt_df)\n",
    "wmt_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('marian',\n",
       " transformers.models.marian.tokenization_marian.MarianTokenizer,\n",
       " transformers.models.marian.configuration_marian.MarianConfig,\n",
       " transformers.models.marian.modeling_marian.MarianMTModel)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"de\"), get_y=ColReader(\"en\"), splitter=RandomSplitter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(wmt_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 168]), torch.Size([2, 140]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0][\"input_ids\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In▁Erwägung▁nachstehender▁Gründe▁sollte das▁Europäische▁Parlament▁keinerlei▁Doppelmoral tolerieren. Indessen und um▁politischen Druck auf▁Journalisten▁auszuüben, die▁Korruptionsfälle aufdecken, die in▁Verbindung mit▁hochrangigen▁Beamten und▁regieren</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Der▁Reichtum, die▁Macht und die Illegalität, die durch▁dieses▁versteckte System▁möglich▁gemacht▁werden,▁sind▁mittlerweile so▁umfassend,▁dass▁sie die▁Legitimität der▁Weltwirtschaft▁gefährden;▁insbesondere in▁einer Zeit▁beispielloser▁Einkommensungleich</td>\n",
       "      <td>The wealth, power, and illegality enabled by this hidden system are now so vast as to threaten the global economys legitimacy, especially at a time of unprecedented income inequality and large budget deficits, owing to governments inability political</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "seq2seq_metrics = {\"bleu\": {\"returns\": \"bleu\"}, \"meteor\": {\"returns\": \"meteor\"}, \"sacrebleu\": {\"returns\": \"score\"}}\n",
    "\n",
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat()\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "# learn = learn.to_native_fp16() #.to_fp16()\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 140, 58101]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 168]), 2, torch.Size([2, 140]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=7.585775847473997e-08, steep=4.786300905834651e-06, valley=0.0003311311302240938, slide=9.120108734350652e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.021572</td>\n",
       "      <td>1.998659</td>\n",
       "      <td>0.318232</td>\n",
       "      <td>0.566873</td>\n",
       "      <td>30.990441</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In der▁begrenzten Zeit, die▁mir▁gewährt▁wird, Herr▁Präsident,▁möchte▁ich▁abschließend▁sagen,▁dass▁ich▁daher▁denke,▁dass die▁Europäische Union die▁Forderung der WHO nach▁einer▁fairen▁Verteilung von▁Impfstoffen, zuallererst in den▁Gebieten mit▁hoher▁Sterblichkeit,▁ernsthaft▁unterstützen▁muss und▁dass wir▁auch die▁Bedingungen für private und▁öffentliche▁Partnerschaften▁schaffen und deren▁Entwicklung▁fördern▁müssen, um die▁Impfstoffknappheit in der Welt▁effektiv zu▁bekämpfen.</td>\n",
       "      <td>In the limited time granted to me, I shall conclude, Mr President, by saying that I therefore think that the European Union must wholeheartedly support the call by the WHO for a fair distribution of vaccines, first and foremost, in the areas of high mortality, and that we must also create the conditions for, and encourage the development of, private and public partnerships so as to effectively combat the shortage of vaccines in the world.</td>\n",
       "      <td>[In the limited time that I am granted, Mr President, I would like to conclude by saying that I therefore believe that the European Union must give serious support to the call by the WHO for fair distribution of vaccines, first and foremost in areas with high mortality, and that we must also create conditions for private and public partnerships and promote their development in order to effectively combat vaccine shortages in the world., I hope that our amendments will be accepted, because that would also be an opportunity to show the Member States where we want to go at the beginning of the 21st century, namely a common Europe, where all citizens, whatever their nationality, have the same rights and have the same opportunity to build this Europe together.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "We add here `Learner.blurr_translate` method to bring the results inline with the format returned via Hugging Face's pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': ['I like to drink beer',\n",
       "   'I like to drink beer.',\n",
       "   'I like to drink beer.']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_de, key=\"translation_texts\", num_return_sequences=3)\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_translate(self: Learner, inp, **kwargs):\n",
    "    preds = self.blurr_generate(inp, key=\"translation_texts\", **kwargs)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': ['I like to drink beer',\n",
       "   'I like to drink beer.',\n",
       "   'I like to drink beer.']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_translate(test_de, num_return_sequences=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"translation_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_translate(test_de)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForTranslation`\n",
    "\n",
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTranslation(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    def predict(self, text, **kwargs):\n",
    "        return self.blurr_translate(text, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(cls):\n",
    "        return AutoModelForSeq2SeqLM\n",
    "\n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp, src_lang_name, trg_lang_name):\n",
    "        return f\"translate {src_lang_name} to {trg_lang_name}: {inp}\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\"bleu\": {\"returns\": \"bleu\"}, \"meteor\": {\"returns\": \"meteor\"}, \"sacrebleu\": {\"returns\": \"score\"}}\n",
    "\n",
    "        return Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name: str = \"English\",\n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr: str = \"src_lang\",\n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name: str = \"English\",\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr: str = \"trg_lang\",\n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length: Union[int, str] = None,\n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length: Union[int, str] = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs: dict = {},\n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = NLP.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        if hf_arch == \"mbart\":\n",
    "            hf_tok_kwargs = {**{\"src_lang\": \"en_XX\", \"tgt_lang\": \"en_XX\"}, **hf_tok_kwargs}\n",
    "\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs\n",
    "        )\n",
    "\n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = {**text_gen_kwargs, **default_text_gen_kwargs(hf_config, hf_model, task=\"translation\")}\n",
    "\n",
    "        # not all \"translation\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args:\n",
    "                del text_gen_kwargs[k]\n",
    "\n",
    "        # update our text generation kwargs for mbart\n",
    "        if hf_arch == \"mbart\":\n",
    "            text_gen_kwargs = {**{\"decoder_start_token_id\": \"en_XX\"}, **text_gen_kwargs}\n",
    "\n",
    "        # build dblock, dls, and default metrics (optional)\n",
    "        get_x = Pipeline(funcs=[ColReader(src_lang_attr)])\n",
    "        get_y = ItemGetter(trg_lang_attr)\n",
    "\n",
    "        if hf_arch == \"t5\":\n",
    "            get_x.add(partial(cls._add_t5_prefix, src_lang_name=src_lang_name, trg_lang_name=trg_lang_name))\n",
    "\n",
    "        batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            max_length=max_length,\n",
    "            max_target_length=max_target_length,\n",
    "            text_gen_kwargs=text_gen_kwargs,\n",
    "        )\n",
    "\n",
    "        blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        learner_kwargs[\"splitter\"] = learner_kwargs.pop(\"splitter\", partial(blurr_seq2seq_splitter, arch=hf_arch))\n",
    "        learner_kwargs[\"loss_func\"] = learner_kwargs.pop(\"loss_func\", PreCalculatedCrossEntropyLoss())\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTranslation.from_data(\n",
    "    wmt_df,\n",
    "    \"Helsinki-NLP/opus-mt-de-en\",\n",
    "    src_lang_name=\"German\",\n",
    "    src_lang_attr=\"de\",\n",
    "    trg_lang_name=\"English\",\n",
    "    trg_lang_attr=\"en\",\n",
    "    dl_kwargs={\"bs\": 2},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.259140</td>\n",
       "      <td>2.004386</td>\n",
       "      <td>0.301326</td>\n",
       "      <td>0.542822</td>\n",
       "      <td>28.683969</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForTranslation.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Schließen die▁vorgeschlagenen▁Anwendungszwecke▁Empfehlungen über die▁Bekämpfung von oder den▁Schutz▁gegen▁Organismen ein, die▁unter den in der▁vorgesehenen▁Anwendungsregion▁herrschenden▁Bedingungen in▁bezug auf▁Landwirtschaft,▁Pflanzenschutz und Umwelt -▁einschließlich der▁Witterungsverhältnisse - nach den▁Erfahrungen und dem▁wissenschaftlichen▁Erkenntnisstand nicht▁als▁schädlich▁gelten, oder▁ist▁davon▁auszugehen,▁daß die▁anderen▁Wirkungen▁unter▁diesen▁Bedingungen den▁beabsichtigten▁Zweck nicht</td>\n",
       "      <td>Where relevant, yield response when the product is used and reduction of loss in storage must be quantitatively and/or qualitatively similar to those resulting from the use of suitable reference products. If no suitable reference product exists, the</td>\n",
       "      <td>[Where the proposed uses include recommendations on the control of or protection against organisms which are not considered harmful under the conditions prevailing in the intended application region in respect of agriculture, plant health and the environment, including climatic conditions, on the basis of experience and scientific knowledge, or where it is assumed that the other effects do not meet the intended purpose under such conditions, no authorisation shall be granted for such uses., This is not intended to deny the importance of traditional energy sources - and I could do so all the less at the moment when Algerian gas reaches Spain and Spain to Portugal and the rest of Europe through such an important construction as the gas pipeline connecting Algeria via Morocco to our continent and our Union, but, of course, the emphasis this report places on renewable and sustainable energy sources and energy saving is very much applauded.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_translate(test_de)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = \"translation_export\"\n",
    "\n",
    "learn.metrics = None\n",
    "learn = learn.to_fp32()\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_generate(test_de)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **translation models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained translation models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model_type for model_type in NLP.get_models(task=\"ConditionalGeneration\") if (not model_type.startswith(\"TF\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    \"facebook/bart-base\",\n",
    "    \"facebook/wmt19-de-en\",  # FSMT\n",
    "    \"Helsinki-NLP/opus-mt-de-en\",  # MarianMT\n",
    "    #'sshleifer/tiny-mbart',\n",
    "    #'google/mt5-small',\n",
    "    \"t5-small\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train\")\n",
    "dataset = dataset.shuffle(seed=32).select(range(1200))\n",
    "wmt_df = pd.DataFrame(dataset[\"translation\"], columns=[\"de\", \"en\"])\n",
    "len(wmt_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In Erwägung nachstehender Gründe sollte das Europäische Parlament keinerlei Doppelmoral tolerieren. Indessen und um politischen Druck auf Journalisten auszuüben, die Korruptionsfälle aufdecken, die in Verbindung mit hochrangigen Beamten und regierenden Politikern der Partei stehen, hat die ungarische Staatsverwaltung vor Kurzem Schritte eingeleitet, um Straf</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration i</td>\n",
       "      <td>[ \"In Erwägung nachstehender Gründe so, Schließen die vorgeschlagenen Anwendungs]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/wmt19-de-en ===\n",
      "\n",
      "architecture:\tfsmt\n",
      "tokenizer:\tFSMTTokenizer\n",
      "model:\t\tFSMTForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schließen die vorgeschlagenen Anwendungszwecke Empfehlungen über die Bekämpfung von oder den Schutz gegen Organismen ein, die unter den in der vorgesehenen Anwendungsregion herrschenden Bedingungen in bezug auf Landwirtschaft, Pflanzenschutz und Umwelt - einschließlich der Witterungsverhältnisse - nach den Erfahrungen und dem wissenschaftlichen Erkenntnisstand nicht als schädlich gelten, oder ist davon auszugehen, daß die anderen Wirkungen unter diesen Bedingungen den beabsichtigten Zweck nicht</td>\n",
       "      <td>Where relevant, yield response when the product is used and reduction of loss in storage must be quantitatively and / or qualitatively similar to those resulting from the use of suitable reference products. If no suitable reference product exists, th</td>\n",
       "      <td>[If the proposed uses include recommendations on the control or protection against organisms which, on the basis of experience and scientific knowledge, are not considered to be harmful in the agricultural, phytosanitary and environmental conditions in the intended region of application, including climatic conditions, or if the other effects under these conditions are not deemed to fulfil the intended purpose, no authorisation shall be granted for these purposes., That is why we have listened to you and asked you to introduce a further transparent consultation procedure on the Anti-Counterfeiting Trade Agreement (ACTA) to ensure that the European Parliament and the citizens represented by this Parliament are regularly and fully informed about the progress of the negotiations, while respecting the non-disclosure clauses that, as you have just explained to us, are linked to the agreement.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Helsinki-NLP/opus-mt-de-en ===\n",
      "\n",
      "architecture:\tmarian\n",
      "tokenizer:\tMarianTokenizer\n",
      "model:\t\tMarianMTModel\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Wenn wir eine▁Unterscheidung▁zwischen „der▁Politik (verstanden▁als▁Kampf um die▁Macht) und den▁Erfahrungen, in▁denen▁Produktionsprozesse von Gesellschaftlichkeit oder von▁Wertschätzungen mit im Spiel▁sind,▁behaupten,▁dann▁können wir▁auch▁zwischen dem militanten▁politischen▁Aktivisten (der▁seinen▁Diskurs auf▁irgendeine▁Einheit von▁Gewissheiten▁gründet) und dem▁forschenden Militanten (der▁seine▁Perspektive▁ausgehend von▁kritischen▁Fragen▁hinsichtlich▁dieser▁Gewissheiten anordnet)▁unterscheiden.</td>\n",
       "      <td>Lets say that the difference can be presented in the following terms: the inside (and so the outside) defines a position organized from a certain limit that we consider relevant.</td>\n",
       "      <td>[If we maintain a distinction between \"politics\" (understood as the struggle for power) and the experiences in which production processes of sociality or appreciation are involved, then we can also distinguish between the militant political activist (who bases his discourse on some unity of certainties) and the researching militant (who orders his perspective from critical questions regarding these certainties)., (IT) Mr President, Commissioner, ladies and gentlemen, just as the resolution on natural disasters presented by the Group of the European People's Party (Christian Democrats) is, I would nevertheless like to draw attention to a number of points raised this evening, which are not covered by the resolution and which are the subject of my amendments.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate German to English: Schließen die vorgeschlagenen Anwendungszwecke Empfehlungen über die Bekämpfung von oder den Schutz gegen Organismen ein, die unter den in der vorgesehenen Anwendungsregion herrschenden Bedingungen in bezug auf Landwirtschaft, Pflanzenschutz und Umwelt - einschließlich der Witterungsverhältnisse - nach den Erfahrungen und dem wissenschaftlichen Erkenntnisstand nicht als schädlich gelten, oder ist davon auszugehen, daß die anderen Wirkungen unter diesen Bedingungen de</td>\n",
       "      <td>Where relevant, yield response when the product is used and reduction of loss in storage must be quantitatively and/or qualitatively similar to those resulting from the use of suitable reference products. If no suitable reference product exists, the</td>\n",
       "      <td>[Schließen die vorgeschlagenen Anwendungszwecke Empfehlungen über die Bekämpfung, Damit soll keineswegs die Bedeutung der traditionellen Energiequellen geleugne]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "# hide_output\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 128\n",
    "trg_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    hf_tok_kwargs = {}\n",
    "    if model_name == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"de_DE\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs)\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task=\"translation\")\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"translate German to English: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=inp_seq_sz,\n",
    "        max_target_length=trg_seq_sz,\n",
    "        text_gen_kwargs=text_gen_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(blocks=blocks, get_x=Pipeline([ColReader(\"de\"), add_t5_prefix]), get_y=ColReader(\"en\"), splitter=RandomSplitter())\n",
    "\n",
    "    dls = dblock.dataloaders(wmt_df, bs=bsz)\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {}\n",
    "\n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    fit_cbs = [ShortEpochCallback(0.05, short_valid=True), Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=ranger,\n",
    "        loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "        cbs=[BaseModelCallback],\n",
    "        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    "    ).to_fp16()\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print(\"*** TESTING DataLoaders ***\\n\")\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(preds[1].shape[0], bsz)\n",
    "        #         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsmt</td>\n",
       "      <td>FSMTTokenizer</td>\n",
       "      <td>FSMTForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marian</td>\n",
       "      <td>MarianTokenizer</td>\n",
       "      <td>MarianMTModel</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "# hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=[\"arch\", \"tokenizer\", \"model_name\", \"result\", \"error\"])\n",
    "display_df(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental bits to use Blurr for translation tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
