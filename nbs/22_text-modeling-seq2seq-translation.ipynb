{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp text.modeling.seq2seq.translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text.modeling.seq2seq.translation\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... translation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import inspect, torch\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from transformers import AutoModelForSeq2SeqLM, PreTrainedModel, logging\n",
    "\n",
    "from blurr.text.data.seq2seq.core import Seq2SeqBatchTokenizeTransform, Seq2SeqTextBlock, default_text_gen_kwargs\n",
    "from blurr.text.modeling.core import BaseModelCallback, BaseModelWrapper, Blearner\n",
    "from blurr.text.modeling.seq2seq.core import Seq2SeqMetricsCallback, blurr_seq2seq_splitter\n",
    "from blurr.text.utils import NLP\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.6\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import ast, os, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "The objective in translation is to generate a representation of a given text in another style. For example, we may want to translate German into English or modern English into old English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.</td>\n",
       "      <td>In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?</td>\n",
       "      <td>\"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    de  \\\n",
       "0            Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.   \n",
       "1  \"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?   \n",
       "\n",
       "                                                                                                                                                                                     en  \n",
       "0  In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.  \n",
       "1                                                                                    \"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train\")\n",
    "dataset = dataset.shuffle(seed=32).select(range(1200))\n",
    "wmt_df = pd.DataFrame(dataset[\"translation\"], columns=[\"de\", \"en\"])\n",
    "len(wmt_df)\n",
    "wmt_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('marian',\n",
       " transformers.models.marian.tokenization_marian.MarianTokenizer,\n",
       " transformers.models.marian.configuration_marian.MarianConfig,\n",
       " transformers.models.marian.modeling_marian.MarianMTModel)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"de\"), get_y=ColReader(\"en\"), splitter=RandomSplitter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(wmt_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 168]), torch.Size([2, 140]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0][\"input_ids\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In▁Erwägung▁nachstehender▁Gründe▁sollte das▁Europäische▁Parlament▁keinerlei▁Doppelmoral tolerieren. Indessen und um▁politischen Druck auf▁Journalisten▁auszuüben, die▁Korruptionsfälle aufdecken, die in▁Verbindung mit▁hochrangigen▁Beamten und▁regieren</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die Oberligamannschaft Empor▁Lauter wurde 1954 nach Rostock▁delegiert und bestritt am▁14. November 1954 vor 17 000▁Zuschauern▁gegen Chemie Karl-Marx-Stadt (0:0) das▁erste Oberligapunktspiel im▁Ostseestadion. Die▁Gründung des FC Hansa Rostock▁fand▁dan</td>\n",
       "      <td>Bundesliga, was founded on December 28, 1965, when the football department of SC Empor was made independent of their parent sports club under a government sanctioned program that would groom young talent and provide the East German (DDR) national tea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "seq2seq_metrics = {\"bleu\": {\"returns\": \"bleu\"}, \"meteor\": {\"returns\": \"meteor\"}, \"sacrebleu\": {\"returns\": \"score\"}}\n",
    "\n",
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat()\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "# learn = learn.to_native_fp16() #.to_fp16()\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaseModelWrapper (Input shape: 2 x 168)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 140 x 512       \n",
       "Embedding                                 29747712   False     \n",
       "Embedding                                 29747712   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 512             \n",
       "MarianSinusoidalPositionalEmbedding                      262144     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Embedding                                 29747712   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 512             \n",
       "MarianSinusoidalPositionalEmbedding                      262144     False     \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 58101     \n",
       "Linear                                    29747712   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 163,653,632\n",
       "Total trainable params: 25,236,480\n",
       "Total non-trainable params: 138,417,152\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7fdfa9ab18b0>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 140, 58101]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 168]), 2, torch.Size([2, 140]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=6.309573450380412e-08, steep=1.0964781722577754e-06, valley=0.0003981071640737355, slide=1.4454397387453355e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.066144</td>\n",
       "      <td>2.020720</td>\n",
       "      <td>0.294544</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>28.638813</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Die Messe Frankfurt hat im▁Jahr 2006 in▁Kooperation mit Stylepark ein▁neues und▁bisher so▁noch nicht▁existierendes Format▁etabliert: The Design Annual.Bei The Design Annual▁handelt es sich um eine▁jährlich▁stattfindende Veranstaltung für High-End Design, die Frankfurt am Main▁auch 2008▁wieder zum Zentrum des▁internationalen Designgeschehens▁werden▁lässt. In der▁Frankfurter Festhalle▁präsentieren die▁beiden Partner die▁besten▁Hersteller des High-End Designsegments▁aus den▁Bereichen▁Möbel und▁Auße</td>\n",
       "      <td>In 2006, Messe Frankfurt in cooperation with Stylepark established a new and quite unprecedented format for a trade fair, namely The Design Annual.</td>\n",
       "      <td>[Messe Frankfurt established a new format in 2006 in cooperation with Stylepark: The Design Annual.The Design Annual is an annual high-end design event that will once again make Frankfurt the centre of international design in 2008. In the Frankfurt Festhalle, the two partners will present the best manufacturers of the high-end design segment in the areas of furniture and outdoor furniture, textiles and floor coverings, bathroom and kitchens, office furniture, lighting, accessories, cutlery, electrical installations and home entertainment., If there are eggs that are not legally produced after January 2012, these eggs must not be marketed, and if there is evidence of non-compliance with the provision, the Commission could, of course, take all the measures it is entitled to under the current legal framework - and initiate infringement procedures to ensure that EU legislation is properly implemented.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "We add here `Learner.blurr_translate` method to bring the results inline with the format returned via Hugging Face's pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': ['I like to drink beer',\n",
       "   'I like to drink beer.',\n",
       "   'I like to drink']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_de, key=\"translation_texts\", num_return_sequences=3)\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_translate(self: Learner, inp, **kwargs):\n",
    "    preds = self.blurr_generate(inp, key=\"translation_texts\", **kwargs)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': ['I like to drink beer',\n",
       "   'I like to drink beer.',\n",
       "   'I like to drink']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_translate(test_de, num_return_sequences=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"translation_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_translate(test_de)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForTranslation`\n",
    "\n",
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTranslation(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    def predict(self, text, **kwargs):\n",
    "        return self.blurr_translate(text, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(cls):\n",
    "        return AutoModelForSeq2SeqLM\n",
    "\n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp, src_lang_name, trg_lang_name):\n",
    "        return f\"translate {src_lang_name} to {trg_lang_name}: {inp}\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\"bleu\": {\"returns\": \"bleu\"}, \"meteor\": {\"returns\": \"meteor\"}, \"sacrebleu\": {\"returns\": \"score\"}}\n",
    "\n",
    "        return Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name: str = \"English\",\n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr: str = \"src_lang\",\n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name: str = \"English\",\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr: str = \"trg_lang\",\n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length: Union[int, str] = None,\n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length: Union[int, str] = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs: dict = {},\n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = NLP.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        if hf_arch == \"mbart\":\n",
    "            hf_tok_kwargs = {**{\"src_lang\": \"en_XX\", \"tgt_lang\": \"en_XX\"}, **hf_tok_kwargs}\n",
    "\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs\n",
    "        )\n",
    "\n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = {**text_gen_kwargs, **default_text_gen_kwargs(hf_config, hf_model, task=\"translation\")}\n",
    "\n",
    "        # not all \"translation\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args:\n",
    "                del text_gen_kwargs[k]\n",
    "\n",
    "        # update our text generation kwargs for mbart\n",
    "        if hf_arch == \"mbart\":\n",
    "            text_gen_kwargs = {**{\"decoder_start_token_id\": \"en_XX\"}, **text_gen_kwargs}\n",
    "\n",
    "        # build dblock, dls, and default metrics (optional)\n",
    "        get_x = Pipeline(funcs=[ColReader(src_lang_attr)])\n",
    "        get_y = ItemGetter(trg_lang_attr)\n",
    "\n",
    "        if hf_arch == \"t5\":\n",
    "            get_x.add(partial(cls._add_t5_prefix, src_lang_name=src_lang_name, trg_lang_name=trg_lang_name))\n",
    "\n",
    "        batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            max_length=max_length,\n",
    "            max_target_length=max_target_length,\n",
    "            text_gen_kwargs=text_gen_kwargs,\n",
    "        )\n",
    "\n",
    "        blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        learner_kwargs[\"splitter\"] = learner_kwargs.pop(\"splitter\", partial(blurr_seq2seq_splitter, arch=hf_arch))\n",
    "        learner_kwargs[\"loss_func\"] = learner_kwargs.pop(\"loss_func\", PreCalculatedCrossEntropyLoss())\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForTranslation.from_data(\n",
    "    wmt_df,\n",
    "    \"Helsinki-NLP/opus-mt-de-en\",\n",
    "    src_lang_name=\"German\",\n",
    "    src_lang_attr=\"de\",\n",
    "    trg_lang_name=\"English\",\n",
    "    trg_lang_attr=\"en\",\n",
    "    dl_kwargs={\"bs\": 2},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.060747</td>\n",
       "      <td>2.086900</td>\n",
       "      <td>0.332818</td>\n",
       "      <td>0.555242</td>\n",
       "      <td>32.818199</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForTranslation.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Die▁Zunahme der▁Gewalttätigkeiten▁bei▁nationalen und▁internationalen Sportveranstaltungen▁resultiert nicht▁aus dem▁Fehlen von▁Informationsnetzen und▁ausreichenden▁Unterdrückungsmechanismen,▁sondern▁ist auf die▁Kommerzialisierung des Sports, die▁damit▁zusammenhängenden▁enormen▁wirtschaftlichen▁Interessen, die▁Förderung▁eines desorientierenden'sportlichen'▁Geistes des Fanatismus (Fußballrowdytums)▁sowie die Propagierung▁einer▁Psychologie der▁Gewalt▁insbesondere▁unter den▁Jugendlichen▁zurückzuführe</td>\n",
       "      <td>The increase in violent clashes at national and international sporting events is not due to a lack of information networks or adequate suppression mechanisms; it is due to the commercialisation of sport, the huge financial interests tied up in it, th</td>\n",
       "      <td>[The increase in violence at national and international sporting events is not due to the lack of information networks and adequate mechanisms of repression, but to the commercialisation of sport, the associated enormous economic interests, the promotion of a disorienting 'sporty' spirit of fanaticism (football rovdytums) and the promotion of a psychology of violence, especially among young people., Perhaps, however, you would like to ask someone - as Mr Corbett will always be in such cases - to look at our Rules of Procedure, because it is rather strange in this respect: if more than 50 amendments are tabled in plenary on a report, the President, after consultation with the chairman, can ask the committee responsible to hold a meeting to consider the amendments.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_translate(test_de)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = \"translation_export\"\n",
    "\n",
    "learn.metrics = None\n",
    "learn = learn.to_fp32()\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_generate(test_de)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **translation models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained translation models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model_type for model_type in NLP.get_models(task=\"ConditionalGeneration\") if (not model_type.startswith(\"TF\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    \"facebook/bart-base\",\n",
    "    \"facebook/wmt19-de-en\",  # FSMT\n",
    "    \"Helsinki-NLP/opus-mt-de-en\",  # MarianMT\n",
    "    #'sshleifer/tiny-mbart',\n",
    "    #'google/mt5-small',\n",
    "    \"t5-small\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train\")\n",
    "dataset = dataset.shuffle(seed=32).select(range(1200))\n",
    "wmt_df = pd.DataFrame(dataset[\"translation\"], columns=[\"de\", \"en\"])\n",
    "len(wmt_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daher haben wir Ihnen zugehört und Sie gebeten, ein weiterführendes transparentes Konsultationsverfahren zum Abkommen zur Bekämpfung von Produkt- und Markenpiraterie (ACTA) einzuführen, das gewährleisten soll, dass das Europäische Parlament und die von diesem Parlament repräsentierten Bürgerinnen und Bürger regelmä</td>\n",
       "      <td>Therefore, we have listened to you and we ask you to introduce an ongoing, transparent consultation procedure on the AntiCounterfeiting Trade Agreement (ACTA), ensuring that the European Parliament and the citizens represented by this Chamber are re</td>\n",
       "      <td>[Daher haben wir Ihnen zugehört und Sie g,  Es ist jetzt wirklich an der Zeit, daß nicht]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/wmt19-de-en ===\n",
      "\n",
      "architecture:\tfsmt\n",
      "tokenizer:\tFSMTTokenizer\n",
      "model:\t\tFSMTForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In Erwägung nachstehender Gründe sollte das Europäische Parlament keinerlei Doppelmoral tolerieren. Indessen und um politischen Druck auf Journalisten auszuüben, die Korruptionsfälle aufdecken, die in Verbindung mit hochrangigen Beamten und regierenden Politikern der Partei stehen, hat die ungarische Staatsverwaltung vor Kurzem Schritte eingeleitet, um Strafverfahren gegen derartige Vertreter der Medien anzustrengen - nämlich gegen Herrn Tamás Pindroch, den Journalisten von Magyar Hírlap -, wob</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>\n",
       "      <td>[\"Considering the following reasons, the European Parliament should not tolerate any double standards. However, and in order to exert political pressure on journalists who expose cases of corruption linked to senior officials and ruling politicians of the party, the Hungarian State Administration has recently taken steps to bring criminal proceedings against such representatives of the media - namely against Mr Tamás Pindroch, the journalist of Magyar Hírlap - taking into account in particular the fact that criminal proceedings have been opened against the journalist who investigated scandals,, The time has come for the European Parliament to be given a voice worthy of the democratic development of this European Union, not only in relation to the annual economic report and the economic policy guidelines, but also in relation to all the questions relating to the excessive deficit procedure and also in relation to the discussion of the stability plans and convergence programmes.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Helsinki-NLP/opus-mt-de-en ===\n",
      "\n",
      "architecture:\tmarian\n",
      "tokenizer:\tMarianTokenizer\n",
      "model:\t\tMarianMTModel\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Wenn es nach dem▁Januar 2012▁noch▁Eier▁gibt, die nicht legal▁erzeugt▁werden,▁dürfen diese▁Eier nicht▁vermarktet▁werden, und▁wenn eine▁Nichteinhaltung der▁Bestimmung▁nachgewiesen▁wird,▁könnte die▁Kommission▁natürlich▁sämtliche▁Maßnahmen▁ergreifen, die▁ihr▁gemäß dem▁aktuellen▁rechtlichen▁Rahmen zustehen - und▁Vertragsverletzungsverfahren initiieren, um eine vorschriftsmäßige▁Umsetzung der EU-Rechtsvorschriften zu▁gewährleisten.</td>\n",
       "      <td>After January 2012, if there are still eggs which are not legally produced, those eggs cannot be marketed, and if non-compliance is demonstrated, the Commission could, of course, undertake all the measures available under the current legal framework</td>\n",
       "      <td>[If there are eggs that are not legally produced after January 2012, these eggs must not be marketed and if non-compliance with the provision is detected, the Commission could, of course, take all the measures it is entitled to under the current legal framework - and initiate infringement proceedings to ensure the correct implementation of EU legislation., If we bear in mind the enormous amount of work we have to do together over the next few years - and that is not enough for the German Presidency, we should not expect any miracles from the Germans, I also say this to the address of my own presidency, which will come here - then we all know that we must reform the decisive actors, the institutions.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate German to English: Damit soll keineswegs die Bedeutung der traditionellen Energiequellen geleugnet werden - und ich könnte dies im Augenblick umso weniger tun, als algerisches Gas über eine so wichtige Konstruktion wie die Gasleitung, die Algerien über Marokko mit unserem Kontinent und unserer Union verbindet, nach Spanien und von Spanien nach Portugal und ins übrige Europa gelangt, aber natürlich findet der Schwerpunkt, den dieser Bericht auf erneuerbare und dauerhafte Energiequellen</td>\n",
       "      <td>This does not, of course, mean that I deny the importance of conventional energy sources; I could hardly do so when Algerian gas is starting to reach Spain, and from Spain, Portugal and the rest of Europe, through so major a structure as the gas pipe</td>\n",
       "      <td>[Damit soll keineswegs die Bedeutung der traditionellen Energiequellen geleugne, Somit ist das Parlament dazu in der Lage, den gesamten Verlauf mittels der ihm von]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "# hide_output\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 128\n",
    "trg_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    hf_tok_kwargs = {}\n",
    "    if model_name == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"de_DE\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs)\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task=\"translation\")\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"translate German to English: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=inp_seq_sz,\n",
    "        max_target_length=trg_seq_sz,\n",
    "        text_gen_kwargs=text_gen_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(blocks=blocks, get_x=Pipeline([ColReader(\"de\"), add_t5_prefix]), get_y=ColReader(\"en\"), splitter=RandomSplitter())\n",
    "\n",
    "    dls = dblock.dataloaders(wmt_df, bs=bsz)\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {}\n",
    "\n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    fit_cbs = [ShortEpochCallback(0.05, short_valid=True), Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=ranger,\n",
    "        loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "        cbs=[BaseModelCallback],\n",
    "        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    "    ).to_fp16()\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print(\"*** TESTING DataLoaders ***\\n\")\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(preds[1].shape[0], bsz)\n",
    "        #         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsmt</td>\n",
       "      <td>FSMTTokenizer</td>\n",
       "      <td>FSMTForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marian</td>\n",
       "      <td>MarianTokenizer</td>\n",
       "      <td>MarianMTModel</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "# hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=[\"arch\", \"tokenizer\", \"model_name\", \"result\", \"error\"])\n",
    "display_df(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental bits to use Blurr for translation tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_text-examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
