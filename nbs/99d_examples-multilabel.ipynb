{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp examples.multilabel_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label classification\n",
    "\n",
    "> This is an example of how to use blurr for multilabel classification tasks using both the mid and high level Blurr API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "from fastai.callback.hook import _print_shapes\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what we're running with ...\n",
      "\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Here's what we're running with ...\\n\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# cuda\n",
    "# hide\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by building our `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset civil_comments (/home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43f32a68c914fa5863eebab443a5b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n",
       "        num_rows: 1804874\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n",
       "        num_rows: 97320\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n",
       "        num_rows: 97320\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = datasets.load_dataset(\"civil_comments\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-8b5168c3a65cf5ce.arrow\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-0ee0733b0b10f4a7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "# --- Option 1: Experimental subset (using 10k training examples) ---\n",
    "raw_train_df = raw_datasets[\"train\"].shuffle(seed=42).select(range(10000)).to_pandas()\n",
    "raw_valid_df = raw_datasets[\"validation\"].shuffle(seed=42).select(range(2000)).to_pandas()\n",
    "\n",
    "# --- Option 2: Full dataset (using the predefined training and validation sets) ---\n",
    "# raw_train_df = pd.DataFrame(raw_datasets['train'], columns=list(raw_datasets['train'].features.keys()))\n",
    "# raw_valid_df = pd.DataFrame(raw_datasets['validation'], columns=list(raw_datasets['validation'].features.keys()))\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "toxic_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "print(len(toxic_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>text</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Socialists? What the hell does that have to do with climate science? Good grief.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>And I always thought that Eric Trump was the dumbest son.  Sorry, Eric!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I’m disappointed there’s no report from CB on the transportation committee meeting today and the discussion about eminent domain.  It centered on the Bloodbank and the HART CEO’s lack of knowledge that HART filed a lawsuit against the Bloodbank the day before Councilmember Anderson asked about the status of that property (May 16).\\n\\nTo sum it up, Murthy nor the board knew that HART was suing the Bloodbank.  It’s troubling that a lawsuit can be started without explicit authority from the CEO and board.\\n\\nThe other part of the discussion that was disappointing was the deputy corporation co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nothing like subsidizing a country that is threatening trade barriers with us.\\n\\nBut again we are talking about Kathleen and her cronies.  I do love electric cars, but in a province that still allows gas blowing leaf blowers, classic cars that admit 100 times what normal ICE emit, two cycle outboard marine engines, idiotic two cycle jet skis and snowmobiles....and the list goes on and on. If she wants real easy environmental solutions get rid of these dinosaur beasts. Its easy, politically tough in certain jurisdictions, and quit pandering to the US car companies and wealthy individuals w...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The only way to save the rhino is to legalize the trade in horn and allow the farmers to breed the animals and make a profit. Nobody is seriously thinking that legal trade will satisfy the demand or stop the poaching entirely, but farmers will have enough money to jack up security. Rhino numbers will undoubtedly increase, and isn't that the primary consideration? One thing we know: the ban is a disaster. This entire poaching catastrophe has taken place with the BAN INTACT. We can't be entirely sure what will work, but we know without a doubt what is not working: the BAN. Kill the ban or ki...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identity_attack    insult   obscene  severe_toxicity  sexual_explicit  \\\n",
       "0              0.0  0.200000  0.300000         0.000000              0.0   \n",
       "1              0.0  0.794118  0.088235         0.029412              0.0   \n",
       "2              0.0  0.000000  0.000000         0.000000              0.0   \n",
       "3              0.0  0.166667  0.000000         0.000000              0.0   \n",
       "4              0.0  0.000000  0.000000         0.000000              0.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Socialists? What the hell does that have to do with climate science? Good grief.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  And I always thought that Eric Trump was the dumbest son.  Sorry, Eric!   \n",
       "2  I’m disappointed there’s no report from CB on the transportation committee meeting today and the discussion about eminent domain.  It centered on the Bloodbank and the HART CEO’s lack of knowledge that HART filed a lawsuit against the Bloodbank the day before Councilmember Anderson asked about the status of that property (May 16).\\n\\nTo sum it up, Murthy nor the board knew that HART was suing the Bloodbank.  It’s troubling that a lawsuit can be started without explicit authority from the CEO and board.\\n\\nThe other part of the discussion that was disappointing was the deputy corporation co...   \n",
       "3  Nothing like subsidizing a country that is threatening trade barriers with us.\\n\\nBut again we are talking about Kathleen and her cronies.  I do love electric cars, but in a province that still allows gas blowing leaf blowers, classic cars that admit 100 times what normal ICE emit, two cycle outboard marine engines, idiotic two cycle jet skis and snowmobiles....and the list goes on and on. If she wants real easy environmental solutions get rid of these dinosaur beasts. Its easy, politically tough in certain jurisdictions, and quit pandering to the US car companies and wealthy individuals w...   \n",
       "4  The only way to save the rhino is to legalize the trade in horn and allow the farmers to breed the animals and make a profit. Nobody is seriously thinking that legal trade will satisfy the demand or stop the poaching entirely, but farmers will have enough money to jack up security. Rhino numbers will undoubtedly increase, and isn't that the primary consideration? One thing we know: the ban is a disaster. This entire poaching catastrophe has taken place with the BAN INTACT. We can't be entirely sure what will work, but we know without a doubt what is not working: the BAN. Kill the ban or ki...   \n",
       "\n",
       "   threat  toxicity  is_valid  \n",
       "0     0.0  0.300000     False  \n",
       "1     0.0  0.808824     False  \n",
       "2     0.0  0.000000     False  \n",
       "3     0.0  0.166667     False  \n",
       "4     0.0  0.000000     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['identity_attack',\n",
       " 'insult',\n",
       " 'obscene',\n",
       " 'toxicity',\n",
       " 'severe_toxicity',\n",
       " 'sexual_explicit',\n",
       " 'threat']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_cols = [\"identity_attack\", \"insult\", \"obscene\", \"toxicity\", \"severe_toxicity\", \"sexual_explicit\", \"threat\"]\n",
    "lbl_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>text</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Socialists? What the hell does that have to do with climate science? Good grief.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>And I always thought that Eric Trump was the dumbest son.  Sorry, Eric!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I’m disappointed there’s no report from CB on the transportation committee meeting today and the discussion about eminent domain.  It centered on the Bloodbank and the HART CEO’s lack of knowledge that HART filed a lawsuit against the Bloodbank the day before Councilmember Anderson asked about the status of that property (May 16).\n",
       "\n",
       "To sum it up, Murthy nor the board knew that HART was suing the Bloodbank.  It’s troubling that a lawsuit can be started without explicit authority from the CEO and board.\n",
       "\n",
       "The other part of the discussion that was disappointing was the deputy corporation counse...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nothing like subsidizing a country that is threatening trade barriers with us.\n",
       "\n",
       "But again we are talking about Kathleen and her cronies.  I do love electric cars, but in a province that still allows gas blowing leaf blowers, classic cars that admit 100 times what normal ICE emit, two cycle outboard marine engines, idiotic two cycle jet skis and snowmobiles....and the list goes on and on. If she wants real easy environmental solutions get rid of these dinosaur beasts. Its easy, politically tough in certain jurisdictions, and quit pandering to the US car companies and wealthy individuals who...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The only way to save the rhino is to legalize the trade in horn and allow the farmers to breed the animals and make a profit. Nobody is seriously thinking that legal trade will satisfy the demand or stop the poaching entirely, but farmers will have enough money to jack up security. Rhino numbers will undoubtedly increase, and isn't that the primary consideration? One thing we know: the ban is a disaster. This entire poaching catastrophe has taken place with the BAN INTACT. We can't be entirely sure what will work, but we know without a doubt what is not working: the BAN. Kill the ban or ki...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identity_attack  insult  obscene  severe_toxicity  sexual_explicit  \\\n",
       "0                0       0        0                0                0   \n",
       "1                0       1        0                0                0   \n",
       "2                0       0        0                0                0   \n",
       "3                0       0        0                0                0   \n",
       "4                0       0        0                0                0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Socialists? What the hell does that have to do with climate science? Good grief.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  And I always thought that Eric Trump was the dumbest son.  Sorry, Eric!   \n",
       "2  I’m disappointed there’s no report from CB on the transportation committee meeting today and the discussion about eminent domain.  It centered on the Bloodbank and the HART CEO’s lack of knowledge that HART filed a lawsuit against the Bloodbank the day before Councilmember Anderson asked about the status of that property (May 16).\n",
       "\n",
       "To sum it up, Murthy nor the board knew that HART was suing the Bloodbank.  It’s troubling that a lawsuit can be started without explicit authority from the CEO and board.\n",
       "\n",
       "The other part of the discussion that was disappointing was the deputy corporation counse...   \n",
       "3  Nothing like subsidizing a country that is threatening trade barriers with us.\n",
       "\n",
       "But again we are talking about Kathleen and her cronies.  I do love electric cars, but in a province that still allows gas blowing leaf blowers, classic cars that admit 100 times what normal ICE emit, two cycle outboard marine engines, idiotic two cycle jet skis and snowmobiles....and the list goes on and on. If she wants real easy environmental solutions get rid of these dinosaur beasts. Its easy, politically tough in certain jurisdictions, and quit pandering to the US car companies and wealthy individuals who...   \n",
       "4  The only way to save the rhino is to legalize the trade in horn and allow the farmers to breed the animals and make a profit. Nobody is seriously thinking that legal trade will satisfy the demand or stop the poaching entirely, but farmers will have enough money to jack up security. Rhino numbers will undoubtedly increase, and isn't that the primary consideration? One thing we know: the ban is a disaster. This entire poaching catastrophe has taken place with the BAN INTACT. We can't be entirely sure what will work, but we know without a doubt what is not working: the BAN. Kill the ban or ki...   \n",
       "\n",
       "   threat  toxicity  is_valid  \n",
       "0       0         0     False  \n",
       "1       0         1     False  \n",
       "2       0         0     False  \n",
       "3       0         0     False  \n",
       "4       0         0     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = toxic_df.round({col: 0 for col in lbl_cols})\n",
    "toxic_df = toxic_df.convert_dtypes()\n",
    "\n",
    "toxic_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build our Hugging Face objects\n",
    "\n",
    "For our huggingface model, let's used the distilled version of RoBERTa. This should allow us to train the model on bigger mini-batches without much performance loss.  Even on my 1080Ti, I should be able to train all the parameters (which isn't possible with the `roberta-base` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta\n",
      "<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>\n",
      "<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n",
      "<class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(lbl_cols)\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\n",
    "hf_model.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "print(hf_arch)\n",
    "print(type(hf_config))\n",
    "print(type(hf_tokenizer))\n",
    "print(type(hf_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have to configure the `num_labels` to the number of labels we are predicting. Given that our labels are already encoded, we use a `MultiCategoryBlock` with encoded=True and vocab equal to the columns with our 1's and 0's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build our `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), MultiCategoryBlock(encoded=True, vocab=lbl_cols))\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(lbl_cols), splitter=ColSplitter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(toxic_df, bs=4, val_bs=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 512]), torch.Size([4, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0][\"input_ids\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build our `Learner`\n",
    "\n",
    "With our DataLoaders built, we can now build our `Learner` and train.  We'll use mixed precision so we can train with bigger batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=BCEWithLogitsLossFlat(), #PreCalculatedBCELoss()\n",
    "    metrics=[partial(accuracy_multi, thresh=0.2)],\n",
    "    cbs=[BaseModelCallback],\n",
    "    splitter=blurr_splitter,\n",
    ").to_fp16()\n",
    "\n",
    "learn.loss_func.thresh = 0.15\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7]),\n",
       " SequenceClassifierOutput(loss=TensorMultiCategory(0.7054, device='cuda:1', grad_fn=<AliasBackward0>), logits=tensor([[ 0.0056,  0.0058,  0.0899, -0.0384, -0.0436,  0.1465,  0.0253],\n",
       "         [-0.0124, -0.0015,  0.0711, -0.0317, -0.0454,  0.1252,  0.0474],\n",
       "         [-0.0108,  0.0043,  0.0814, -0.0313, -0.0343,  0.1184,  0.0344],\n",
       "         [-0.0164,  0.0045,  0.0682, -0.0369, -0.0569,  0.1384,  0.0486]],\n",
       "        device='cuda:1', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(b[0])\n",
    "preds.logits.shape, preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0012022644514217973)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.063359</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>0.984928</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was \"ultimately a local law enforcement matter.\"  Then after that, \"Obama administration leaders\" told Reuters that the Obama administration had \"ordered\" federal law enforcement not to have a \"conflict\" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"But local economist Paul Brewbaker said the monetary savings of abandoning the project doesn’t take into account how such a move would derail Honolulu’s efforts to achieve higher urban density and improved urban mobility, and would further discourage companies from investing in Hawaii\"\\n\\nAgain, rail was first touted for traffic decongestion, then for affordable housing, but it's  really for TOD - Transit Oriented Development - for corporations to develop in Hawaii. It may sound okay from a business standpoint but Oahu is a small island. \\n\\nWhat about the small private mom-and-pop property owners along the Honolulu Rail Corridor? Will the city/state abuse its powers of eminent domain to pave the way for bigger private corporate development? When will the public know about this little secret of Honolulu Rail?\\n\\nThe  Rail powers-that-be acted intransigently to railroad this project.  They grossly UNDER-estimated the projected costs, KNOWING they could blackmail Oahu into this present stage.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.066212</td>\n",
       "      <td>0.063625</td>\n",
       "      <td>0.984928</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=slice(1e-8, 1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was \"ultimately a local law enforcement matter.\"  Then after that, \"Obama administration leaders\" told Reuters that the Obama administration had \"ordered\" federal law enforcement not to have a \"conflict\" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clearly, Emily is more orientated toward lessening our (locally) homeless problem than Skov, and certainly doesn't advocate situations as you described, nor taking-on the nation's homeless problem.  She's also far more aware of the connection between the big developer tax exemptions and affordable housing.\\n\\nEmily also opposes rezoning R1 neighborhoods (SW-SAZ), and advocates a community-driven process (refinement plan), rather than a top-down city forced policy.  \\n\\nMeanwhile Skov has been silent, until the city finally shelved the SW-SAZ.  Then subsequently he followed the city, as expected, and said at the City Club debate on May 15th 2016, the community will need to be “deeply involved”, but he still hasn’t qualified his position on rezoning R-1 neighborhoods.  At the mayor's Sept 19th forum on the matter, Skov testified and I've never heard anybody say so much, and mean so little.\\n\\nEmily will stand-up against Ruiz and the incompetent city staff far better than a city rubber-stamper.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.thresh = 0.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((#2) ['insult','toxicity'],),\n",
       "  [[False, True, False, True, False, False, False]],\n",
       "  [[0.003469890682026744,\n",
       "    0.03926875442266464,\n",
       "    0.0035106493160128593,\n",
       "    0.05223085731267929,\n",
       "    1.6280514500977006e-06,\n",
       "    0.001151399570517242,\n",
       "    0.0006771942717023194]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Those damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. \n",
    "No enchiladas for them!\n",
    "\"\"\"\n",
    "learn.blurr_predict(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 7]), torch.Size([2000, 7]), torch.Size([2000]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, targs, losses = learn.get_preds(with_loss=True)\n",
    "preds.shape, targs.shape, losses.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API\n",
    "\n",
    "With the high-level API, we can create our DataBlock, DataLoaders, and Blearner in one line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build our Hugging Face objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta\n",
      "<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>\n",
      "<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n",
      "<class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(lbl_cols)\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\n",
    "hf_model.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "print(hf_arch)\n",
    "print(type(hf_config))\n",
    "print(type(hf_tokenizer))\n",
    "print(type(hf_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Configure our `BlearnerForSequenceClassification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification.from_dataframe(\n",
    "    toxic_df, pretrained_model_name, text_attr=\"text\", label_attr=lbl_cols, dl_kwargs={\"bs\": 4}\n",
    ")\n",
    "\n",
    "learn.loss_func.thresh = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.077175</td>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.984928</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was \"ultimately a local law enforcement matter.\"  Then after that, \"Obama administration leaders\" told Reuters that the Obama administration had \"ordered\" federal law enforcement not to have a \"conflict\" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The most notable shift during the quarter was the strong increase to real estate – from 30 per cent of the portfolio to 32 per cent, an increase of 6.6 per cent.\"  If these rich investors are betting on Canadian real estate, they're going to lose a bundle, better to invest in American real estate at this point.  This is what Prem Watsa says about Canadian real estate: \"In April of 2017, Watsa brought attention to concerns of a real estate bubble in Toronto. Watsa asserts that most Canadian banks cannot survive a 50% drop in the value of real estate. \"It's going to come down, and a lot of people are going to get hurt\" said Watsa during Fairfax's annual general meeting.\"  https://en.wikipedia.org/wiki/Prem_Watsa\\n\\nSide bar: Home Capital Group is close to bankruptcy and Walton Group files for creditor protection, two major Canadian RE institutions... Equitable is the next one in the batter box of bankruptcy, they had to borrow money too.   Looking awfully like the Canadian Lehman moment.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((#0) [],),\n",
       "  [[False, False, False, False, False, False, False]],\n",
       "  [[0.004305047914385796,\n",
       "    0.0510530099272728,\n",
       "    0.003411045530810952,\n",
       "    0.07158450782299042,\n",
       "    7.013055665083812e-07,\n",
       "    0.0003604147641453892,\n",
       "    0.0005645937635563314]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Those damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. \n",
    "No enchiladas for them!\n",
    "\"\"\"\n",
    "learn.blurr_predict(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 7]), torch.Size([2000, 7]), torch.Size([2000]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, targs, losses = learn.get_preds(with_loss=True)\n",
    "preds.shape, targs.shape, losses.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build our Hugging Face objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta\n",
      "<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>\n",
      "<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n",
      "<class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(lbl_cols)\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\n",
    "hf_model.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "print(hf_arch)\n",
    "print(type(hf_config))\n",
    "print(type(hf_tokenizer))\n",
    "print(type(hf_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare your dataset\n",
    "\n",
    "We'll create a `labels` column that includes the OHE labels for each example. The raw values come in the form of probabilities ranging from 0. to 1., so we simply round those >= .51 to 1.0, else set it to 0. for our purposes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset civil_comments (/home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1edbcf02cb048d9b0d75fca3f1d204f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n",
       "     num_rows: 1000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n",
       "     num_rows: 500\n",
       " })]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = datasets.load_dataset(\"civil_comments\", split=[\"train[:1000]\", \"validation[:500]\"])\n",
    "raw_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569db040832d48c6937cd723df27a3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73078f35afb4296ad3684299452e05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    inputs = hf_tokenizer(example[\"text\"], truncation=True)\n",
    "    targets = [\n",
    "        float(round(example[lbl])) for lbl in [\"identity_attack\", \"insult\", \"obscene\", \"severe_toxicity\", \"sexual_explicit\", \"threat\", \"toxicity\"]\n",
    "    ]\n",
    "    return {**inputs, **{\"labels\": targets}}\n",
    "\n",
    "\n",
    "tokenized_datasets = [ds.map(tokenize_function, batched=False) for ds in raw_datasets]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build our `DataLoaders`\n",
    "\n",
    "By assigning the aforementioned labels to the `label_names` argument of our `BlurrDataLoader`s, we get the friendly label printed when we run `show_batch` or `show_results` intead of the label's index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"identity_attack\", \"insult\", \"obscene\", \"severe_toxicity\", \"sexual_explicit\", \"threat\", \"toxicity\"]\n",
    "\n",
    "trn_dl = BlurrDataLoader(\n",
    "    tokenized_datasets[0],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_decode_kwargs={\"labels\": label_names},\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "val_dl = BlurrDataLoader(\n",
    "    tokenized_datasets[1],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_decode_kwargs={\"labels\": label_names},\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 109]), torch.Size([8, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0][\"input_ids\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The preserve was sold big time to the public, the only version available to the public before the ballot was the version with the preserve. Yes it was deleted from the ballot language, but that is a pull the wool over the eyes trick that gives Metro the excuse to not be accountable. But they and the zoo are accountable for their statements -- which were unequivacally that there would be an offiste preserve for the elephants.  This just proves that we cannot trust our government to tell the trut</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is just freaking sad. Another great place lost to greedy developers building more huge apartments in an already crowded area. So long Portland, you are becoming the worst city ever.</td>\n",
       "      <td>[obscene, toxicity]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=BCEWithLogitsLossFlat(),\n",
    "    metrics=[partial(accuracy_multi, thresh=0.2)],\n",
    "    cbs=[BaseModelCallback],\n",
    "    splitter=blurr_splitter,\n",
    ").to_fp16()\n",
    "\n",
    "learn.loss_func.thresh = 0.1\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>0.185167</td>\n",
       "      <td>0.983714</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donkeys by 20 yo! 🐴</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why, in your feeble mind both helping and placing flags cannot be done for some reason? These soldiers died under the flag, give them the respect to rest under it. Quit calling displaying the flag littering.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your sequence classification model isn't training, make sure you have set the `num_labels` correctly (95% of the time this is the culprit).  And with this example, you can see that Blurr can make both your multiclassification and multilabel classification tasks a breeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
