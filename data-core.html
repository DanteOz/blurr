---

title: data.core


keywords: fastai
sidebar: home_sidebar

summary: "This module contains the core bits required to use the fastai DataBlock API and/or mid-level data processing pipelines to organize your data in a way modelable by Hugging Face transformer implementations."
description: "This module contains the core bits required to use the fastai DataBlock API and/or mid-level data processing pipelines to organize your data in a way modelable by Hugging Face transformer implementations."
nb_path: "nbs/01_data-core.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_data-core.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>What we&#39;re running with at the time this documentation was generated:
torch: 1.10.2+cu102
fastai: 2.5.3
transformers: 4.16.2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup"> </a></h2><p>We'll use a subset of <code>imdb</code> to demonstrate how to configure your blurr code for sequence classification tasks</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;imdb&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">])</span>
<span class="n">raw_datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s2">&quot;is_valid&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">raw_datasets</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s2">&quot;is_valid&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_datasets</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">final_ds</span> <span class="o">=</span> <span class="n">concatenate_datasets</span><span class="p">([</span><span class="n">raw_datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)),</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">))])</span>
<span class="n">imdb_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">final_ds</span><span class="p">)</span>
<span class="n">imdb_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)
Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-65b5588450d6b196.arrow
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>label</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>This movie was horrible. I swear they didn't even write a script they just kinda winged it through out the whole movie. Ice-T was annoying as hell. *SPOILERS Phht more like reasons not to watch it* They sit down and eat breakfast for 20 minutes. he coulda been long gone. The ground was hard it would of been close to impossible to to track him with out dogs. And when ICE-T is on that Hill and uses that Spaz-15 Assault SHOTGUN like its a sniper rifle (and then cuts down a tree with eight shells?? It would take 1000's of shells to cut down a tree that size.) Shotguns and hand guns are conside...</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>I have seen this movie at the cinema many years ago, and one thing surprised me so negatively that I could not see any redeeming virtues in the movies: Dennis Quaid was cast as a policeman that never smiles or grin, while his smile and grin are two of his trademarks. Danny Glover was cast as the bad guy, but - again - most viewers' imagination could not go far enough as to believe him in that role. Also, Jared Leto was not believable as the former medicine student. The tension was just not there, since the killer was known very early. The finale was, again, neither dramatic nor tense: nobo...</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>This is a fantastic series first and foremost. It is very well done and very interesting. As a huge WWII buff, I had learned a lot before seeing this series. One of the best things this has going for it is all the interviews with past individuals back when the war was relatively fresh in their minds, comparatively speaking that is. It is nothing against the men that you see getting interviewed in the programs of today, it is just that most of these men weren't really involved in the upper echelons of what was happening then. One of the best parts is the narrating by Sir Laurence Oliver. I ...</td>
      <td>1</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Kurosawa really blew it on this one. Every genius is allowed a failure. The concept is fine but the execution is badly blurred.&lt;br /&gt;&lt;br /&gt;There is an air of fantasy about this film making it something of an art film. The poverty stricken of Tokyo deserve a fairer and more realistic portrayal. Many of them have interesting stories to tell. A very disappointing film.</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>MGM were unsure of how to market Garbo when she first arrived in Hollywood. Mayer had a lot of faith in her and her appearance in "Torrent" justified that. She did not speak a word of English so she must have found it difficult to work, also Ricardo Cortez did not make it very easy for her.&lt;br /&gt;&lt;br /&gt;The torrent of the title is the river Juscar that winds through a sleepy little village in Spain. Leonora (Greta Garbo) hopes someday that her voice will bring great wealth and happiness to her struggling parents. Leonora and Don Rafael (Ricardo Cortez) are in love but he is under his mother'...</td>
      <td>1</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>
<span class="n">labels</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;neg&#39;, &#39;pos&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;roberta-base&quot;</span>  <span class="c1"># &quot;bert-base-multilingual-cased&quot;</span>
<span class="n">n_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span>
    <span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">,</span> <span class="n">config_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_labels&quot;</span><span class="p">:</span> <span class="n">n_labels</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;roberta&#39;,
 transformers.models.roberta.configuration_roberta.RobertaConfig,
 transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,
 transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocessing">Preprocessing<a class="anchor-link" href="#Preprocessing"> </a></h2><p>Starting with version 2.0, BLURR provides a preprocessing base class that can be used to build task specific, pre-processed datasets, from either DataFrames or Hugging Face Datasets.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Preprocessor" class="doc_header"><code>class</code> <code>Preprocessor</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L37" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Preprocessor</code>(<strong><code>hf_tokenizer</code></strong>:<code>PreTrainedTokenizerBase</code>, <strong><code>batch_size</code></strong>:<code>int</code>=<em><code>1000</code></em>, <strong><code>text_attr</code></strong>:<code>str</code>=<em><code>'text'</code></em>, <strong><code>text_pair_attr</code></strong>:<code>Optional</code>[<code>str</code>]=<em><code>None</code></em>, <strong><code>tok_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>)</p>
</blockquote>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>hf_tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'&gt;</code></em>  <p>A Hugging Face tokenizer</p></li>
</ul>
<ul>
<li><strong><code>batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The number of examples to process at a time</p></li>
</ul>
<ul>
<li><strong><code>text_attr</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em>  <p>The attribute holding the text</p></li>
</ul>
<ul>
<li><strong><code>text_pair_attr</code></strong> : <em><code>typing.Union[str, NoneType]</code></em>, <em>optional</em>   <p>The attribute holding the text_pair</p></li>
</ul>
<ul>
<li><strong><code>tok_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>    <p>Tokenization kwargs that will be applied with calling the tokenizer</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ClassificationPreprocessor"><a href="/blurr/data-core.html#ClassificationPreprocessor"><code>ClassificationPreprocessor</code></a><a class="anchor-link" href="#ClassificationPreprocessor"> </a></h3><p>Starting with version 2.0, BLURR provides a sequence classification preprocessing class that can be used to preprocess DataFrames or Hugging Face Datasets.</p>
<p>This class can be used for pre-processing both multiclass and multilabel classification datasets, and includes a <code>proc_text</code> attribute with any modifications made to your <code>text_attrs</code> as a result of the parameters you pass in during tokenization (e.g., if you specify a <code>max_length</code> the <code>proc_text</code> will result in truncated text where examples were longer than what you specified). This class works for both slow and fast tokenizers</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ClassificationPreprocessor" class="doc_header"><code>class</code> <code>ClassificationPreprocessor</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L104" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ClassificationPreprocessor</code>(<strong><code>hf_tokenizer</code></strong>:<code>PreTrainedTokenizerBase</code>, <strong><code>batch_size</code></strong>:<code>int</code>=<em><code>1000</code></em>, <strong><code>is_multilabel</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>id_attr</code></strong>:<code>Optional</code>[<code>str</code>]=<em><code>None</code></em>, <strong><code>text_attr</code></strong>:<code>str</code>=<em><code>'text'</code></em>, <strong><code>text_pair_attr</code></strong>:<code>Optional</code>[<code>str</code>]=<em><code>None</code></em>, <strong><code>label_attrs</code></strong>:<code>Union</code>[<code>str</code>, <code>List</code>[<code>str</code>]]=<em><code>'label'</code></em>, <strong><code>is_valid_attr</code></strong>:<code>Optional</code>[<code>str</code>]=<em><code>'is_valid'</code></em>, <strong><code>label_mapping</code></strong>:<code>Optional</code>[<code>List</code>[<code>str</code>]]=<em><code>None</code></em>, <strong><code>tok_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>) :: <a href="/blurr/data-core.html#Preprocessor"><code>Preprocessor</code></a></p>
</blockquote>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>hf_tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'&gt;</code></em>  <p>A Hugging Face tokenizer</p></li>
</ul>
<ul>
<li><strong><code>batch_size</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>The number of examples to process at a time</p></li>
</ul>
<ul>
<li><strong><code>is_multilabel</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em> <p>Whether the dataset should be processed for multi-label; if True, will ensure `label_attrs` are
converted to a value of either 0 or 1 indiciating the existence of the class in the example</p></li>
</ul>
<ul>
<li><strong><code>id_attr</code></strong> : <em><code>typing.Union[str, NoneType]</code></em>, <em>optional</em>  <p>The unique identifier in the dataset</p></li>
</ul>
<ul>
<li><strong><code>text_attr</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>, <em>optional</em>  <p>The attribute holding the text</p></li>
</ul>
<ul>
<li><strong><code>text_pair_attr</code></strong> : <em><code>typing.Union[str, NoneType]</code></em>, <em>optional</em>   <p>The attribute holding the text_pair</p></li>
</ul>
<ul>
<li><strong><code>label_attrs</code></strong> : <em><code>typing.Union[str, typing.List[str]]</code></em>, <em>optional</em>  <p>The attribute holding the label(s) of the example</p></li>
</ul>
<ul>
<li><strong><code>is_valid_attr</code></strong> : <em><code>typing.Union[str, NoneType]</code></em>, <em>optional</em>    <p>The attribute that should be created if your are processing individual training and validation
datasets into a single dataset, and will indicate to which each example is associated</p></li>
</ul>
<ul>
<li><strong><code>label_mapping</code></strong> : <em><code>typing.Union[typing.List[str], NoneType]</code></em>, <em>optional</em>   <p>A list indicating the valid labels for the dataset (optional, defaults to the unique set of labels
found in the full dataset)</p></li>
</ul>
<ul>
<li><strong><code>tok_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>    <p>Tokenization kwargs that will be applied with calling the tokenizer</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Using-a-DataFrame">Using a <code>DataFrame</code><a class="anchor-link" href="#Using-a-DataFrame"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ClassificationPreprocessor</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">label_mapping</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">tok_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="mi">24</span><span class="p">})</span>
<span class="n">proc_df</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">process_df</span><span class="p">(</span><span class="n">imdb_df</span><span class="p">)</span>
<span class="n">proc_df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">proc_df</span><span class="p">)</span>
<span class="n">proc_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>proc_text</th>
      <th>text</th>
      <th>label</th>
      <th>is_valid</th>
      <th>label_name</th>
      <th>text_start_char_idx</th>
      <th>text_end_char_idx</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>This movie was horrible. I swear they didn't even write a script they just kinda winged it through out</td>
      <td>This movie was horrible. I swear they didn't even write a script they just kinda winged it through out the whole movie. Ice-T was annoying as hell. *SPOILERS Phht more like reasons not to watch it* They sit down and eat breakfast for 20 minutes. he coulda been long gone. The ground was hard it would of been close to impossible to to track him with out dogs. And when ICE-T is on that Hill and uses that Spaz-15 Assault SHOTGUN like its a sniper rifle (and then cuts down a tree with eight shells?? It would take 1000's of shells to cut down a tree that size.) Shotguns and hand guns are conside...</td>
      <td>0</td>
      <td>False</td>
      <td>neg</td>
      <td>0</td>
      <td>102</td>
    </tr>
    <tr>
      <th>1</th>
      <td>I have seen this movie at the cinema many years ago, and one thing surprised me so negatively that I could</td>
      <td>I have seen this movie at the cinema many years ago, and one thing surprised me so negatively that I could not see any redeeming virtues in the movies: Dennis Quaid was cast as a policeman that never smiles or grin, while his smile and grin are two of his trademarks. Danny Glover was cast as the bad guy, but - again - most viewers' imagination could not go far enough as to believe him in that role. Also, Jared Leto was not believable as the former medicine student. The tension was just not there, since the killer was known very early. The finale was, again, neither dramatic nor tense: nobo...</td>
      <td>0</td>
      <td>False</td>
      <td>neg</td>
      <td>0</td>
      <td>106</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Using-a-Hugging-Face-Dataset">Using a Hugging Face <code>Dataset</code><a class="anchor-link" href="#Using-a-Hugging-Face-Dataset"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ClassificationPreprocessor</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">label_mapping</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">proc_ds</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">process_hf_dataset</span><span class="p">(</span><span class="n">final_ds</span><span class="p">)</span>
<span class="n">proc_ds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Dataset({
    features: [&#39;proc_text&#39;, &#39;text&#39;, &#39;label&#39;, &#39;is_valid&#39;, &#39;label_name&#39;, &#39;text_start_char_idx&#39;, &#39;text_end_char_idx&#39;, &#39;__index_level_0__&#39;],
    num_rows: 1200
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Mid-level-API">Mid-level API<a class="anchor-link" href="#Mid-level-API"> </a></h2><p>Base tokenization, batch transform, and DataBlock methods</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TextInput"><a href="/blurr/data-core.html#TextInput"><code>TextInput</code></a><a class="anchor-link" href="#TextInput"> </a></h3><p>A <a href="/blurr/data-core.html#TextInput"><code>TextInput</code></a> object is returned from the decodes method of <a href="/blurr/data-core.html#BatchDecodeTransform"><code>BatchDecodeTransform</code></a> as a means to customize @typedispatched functions like <code>DataLoaders.show_batch</code> and <code>Learner.show_results</code>. It uses the "input_ids" of a Hugging Face object as the representative tensor for <code>show</code> methods</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TextInput" class="doc_header"><code>class</code> <code>TextInput</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L185" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TextInput</code>(<strong><code>x</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>TensorBase</code></p>
</blockquote>
<p>The base represenation of your inputs; used by the various fastai <code>show</code> methods</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="BatchTokenizeTransform"><a href="/blurr/data-core.html#BatchTokenizeTransform"><code>BatchTokenizeTransform</code></a><a class="anchor-link" href="#BatchTokenizeTransform"> </a></h3><p>Inspired by this <a href="https://docs.fast.ai/tutorial.transformers.html">article</a>, inputs can come in as raw text, a list of words (e.g., tasks like Named Entity Recognition (NER), where you want to predict the label of each token), or as a dictionary that includes extra information you want to use during post-processing (as of v.2).</p>
<p><strong>On-the-fly Batch-Time Tokenization</strong>:</p>
<p>Part of the inspiration had to do with the mechanics of the huggingrace tokenizer, in particular how by default it returns a collated mini-batch of data given a list of sequences. And where do we get a list of examples with fastai? In the <code>before_batch_tfms</code>!  So I thought, "Hey, why not allow folks to do everything dynamically at batch time without having to do any pre-processing in advance?" The result being the ability to allow Blurr to do all the tokenization work for you at batch time.  The benefits include: <em>less code</em>, <em>faster mini-batch creation</em>, <em>less RAM utilization</em> and time spent tokenizing (really helps with very large datasets), and <em>more flexibility</em>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BatchTokenizeTransform" class="doc_header"><code>class</code> <code>BatchTokenizeTransform</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L192" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BatchTokenizeTransform</code>(<strong><code>hf_arch</code></strong>:<code>str</code>, <strong><code>hf_config</code></strong>:<code>PretrainedConfig</code>, <strong><code>hf_tokenizer</code></strong>:<code>PreTrainedTokenizerBase</code>, <strong><code>hf_model</code></strong>:<code>PreTrainedModel</code>, <strong><code>ignore_token_id</code></strong>:<code>int</code>=<em><code>-100</code></em>, <strong><code>max_length</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong><code>padding</code></strong>:<code>Union</code>[<code>bool</code>, <code>str</code>]=<em><code>True</code></em>, <strong><code>truncation</code></strong>:<code>Union</code>[<code>bool</code>, <code>str</code>]=<em><code>True</code></em>, <strong><code>is_split_into_words</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>tok_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Transform</code></p>
</blockquote>
<p>Handles everything you need to assemble a mini-batch of inputs and targets, as well as
decode the dictionary produced as a byproduct of the tokenization process in the <code>encodes</code> method.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>hf_arch</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>    <p>The abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)</p></li>
</ul>
<ul>
<li><strong><code>hf_config</code></strong> : <em><code>&lt;class 'transformers.configuration_utils.PretrainedConfig'&gt;</code></em>    <p>A specific configuration instance you want to use</p></li>
</ul>
<ul>
<li><strong><code>hf_tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'&gt;</code></em>  <p>A Hugging Face tokenizer</p></li>
</ul>
<ul>
<li><strong><code>hf_model</code></strong> : <em><code>&lt;class 'transformers.modeling_utils.PreTrainedModel'&gt;</code></em>   <p>A Hugging Face model</p></li>
</ul>
<ul>
<li><strong><code>ignore_token_id</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>The token ID that should be ignored when calculating the loss</p></li>
</ul>
<ul>
<li><strong><code>max_length</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em> <p>To control the length of the padding/truncation. It can be an integer or None,
in which case it will default to the maximum length the model can accept. If the model has no
specific maximum input length, truncation/padding to max_length is deactivated.
See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)</p></li>
</ul>
<ul>
<li><strong><code>padding</code></strong> : <em><code>typing.Union[bool, str]</code></em>, <em>optional</em>  <p>To control the `padding` applied to your `hf_tokenizer` during tokenization. If None, will default to
`False` or `'do_not_pad'.
See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)</p></li>
</ul>
<ul>
<li><strong><code>truncation</code></strong> : <em><code>typing.Union[bool, str]</code></em>, <em>optional</em>   <p>To control `truncation` applied to your `hf_tokenizer` during tokenization. If None, will default to
`False` or `do_not_truncate`.
See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)</p></li>
</ul>
<ul>
<li><strong><code>is_split_into_words</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>   <p>The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. Set this to `True`
if your inputs are pre-tokenized (not numericalized)</p></li>
</ul>
<ul>
<li><strong><code>tok_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>    <p>Any other keyword arguments you want included when using your `hf_tokenizer` to tokenize your inputs</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="BatchDecodeTransform"><a href="/blurr/data-core.html#BatchDecodeTransform"><code>BatchDecodeTransform</code></a><a class="anchor-link" href="#BatchDecodeTransform"> </a></h3><p>With fastai 2.1.5, before batch transforms no longer have a <code>decodes</code> method ... and so, I've introduced a standard batch transform here (one that occurs "after" the batch has been created) that will do the decoding for us.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BatchDecodeTransform" class="doc_header"><code>class</code> <code>BatchDecodeTransform</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L285" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BatchDecodeTransform</code>(<strong><code>input_return_type</code></strong>:<code>Type</code>[<code>CT_co</code>]=<em><code>TextInput</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Transform</code></p>
</blockquote>
<p>A class used to cast your inputs as <code>input_return_type</code> for fastai <code>show</code> methods</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>input_return_type</code></strong> : <em><code>typing.Type</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TextBlock"><a href="/blurr/data-core.html#TextBlock"><code>TextBlock</code></a><a class="anchor-link" href="#TextBlock"> </a></h3><p>A basic wrapper that links defaults transforms for the Data Block API, <a href="/blurr/data-core.html#TextBlock"><code>TextBlock</code></a> is designed with sensible defaults to minimize user effort in defining their transforms pipeline. It handles setting up your <a href="/blurr/data-core.html#BatchTokenizeTransform"><code>BatchTokenizeTransform</code></a> and <a href="/blurr/data-core.html#BatchDecodeTransform"><code>BatchDecodeTransform</code></a> transforms regardless of data source (e.g., this will work with files, DataFrames, whatever).</p>
<p>You must either pass in your own instance of a <a href="/blurr/data-core.html#BatchTokenizeTransform"><code>BatchTokenizeTransform</code></a> class or the Hugging Face objects returned from <a href="/blurr/utils.html#BLURR.get_hf_objects"><code>BLURR.get_hf_objects</code></a> (e.g.,architecture, config, tokenizer, and model). The other args are optional.</p>
<p>We also include a <a href="/blurr/data-core.html#blurr_sort_func"><code>blurr_sort_func</code></a> that works with <code>SortedDL</code> to properly sort based on the number of tokens in each example.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="blurr_sort_func" class="doc_header"><code>blurr_sort_func</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L297" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>blurr_sort_func</code>(<strong><code>example</code></strong>, <strong><code>hf_tokenizer</code></strong>:<code>PreTrainedTokenizerBase</code>, <strong><code>is_split_into_words</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>tok_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>)</p>
</blockquote>
<p>This method is used by the <code>SortedDL</code> to ensure your dataset is sorted <em>after</em> tokenization</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><p><strong><code>example</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></p>
</li>
<li><p><strong><code>hf_tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'&gt;</code></em>  <p>A Hugging Face tokenizer</p></p>
</li>
</ul>
<ul>
<li><strong><code>is_split_into_words</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>   <p>The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. Set this to `True`
if your inputs are pre-tokenized (not numericalized)</p></li>
</ul>
<ul>
<li><strong><code>tok_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>    <p>Any other keyword arguments you want to include during tokenization</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TextBlock" class="doc_header"><code>class</code> <code>TextBlock</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L313" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TextBlock</code>(<strong><code>hf_arch</code></strong>:<code>Optional</code>[<code>str</code>]=<em><code>None</code></em>, <strong><code>hf_config</code></strong>:<code>Optional</code>[<code>PretrainedConfig</code>]=<em><code>None</code></em>, <strong><code>hf_tokenizer</code></strong>:<code>Optional</code>[<code>PreTrainedTokenizerBase</code>]=<em><code>None</code></em>, <strong><code>hf_model</code></strong>:<code>Optional</code>[<code>PreTrainedModel</code>]=<em><code>None</code></em>, <strong><code>ignore_token_id</code></strong>=<em><code>-100</code></em>, <strong><code>batch_tokenize_tfm</code></strong>:<code>Optional</code>[<a href="/blurr/data-core.html#BatchTokenizeTransform"><code>BatchTokenizeTransform</code></a>]=<em><code>None</code></em>, <strong><code>batch_decode_tfm</code></strong>:<code>Optional</code>[<a href="/blurr/data-core.html#BatchDecodeTransform"><code>BatchDecodeTransform</code></a>]=<em><code>None</code></em>, <strong><code>max_length</code></strong>:<code>Optional</code>[<code>int</code>]=<em><code>None</code></em>, <strong><code>padding</code></strong>:<code>Union</code>[<code>bool</code>, <code>str</code>]=<em><code>True</code></em>, <strong><code>truncation</code></strong>:<code>Union</code>[<code>bool</code>, <code>str</code>]=<em><code>True</code></em>, <strong><code>is_split_into_words</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>input_return_type</code></strong>:<code>Type</code>[<code>CT_co</code>]=<em><code>TextInput</code></em>, <strong><code>dl_type</code></strong>:<code>Optional</code>[<code>DataLoader</code>]=<em><code>None</code></em>, <strong><code>batch_tokenize_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>batch_decode_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>tok_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>text_gen_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>TransformBlock</code></p>
</blockquote>
<p>The core <code>TransformBlock</code> to prepare your inputs for training in Blurr with fastai's <code>DataBlock</code> API</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>hf_arch</code></strong> : <em><code>typing.Union[str, NoneType]</code></em>, <em>optional</em>  <p>The abbreviation/name of your Hugging Face transformer architecture (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_config</code></strong> : <em><code>typing.Union[transformers.configuration_utils.PretrainedConfig, NoneType]</code></em>, <em>optional</em>  <p>A Hugging Face configuration object (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_tokenizer</code></strong> : <em><code>typing.Union[transformers.tokenization_utils_base.PreTrainedTokenizerBase, NoneType]</code></em>, <em>optional</em>    <p>A Hugging Face tokenizer (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_model</code></strong> : <em><code>typing.Union[transformers.modeling_utils.PreTrainedModel, NoneType]</code></em>, <em>optional</em> <p>A Hugging Face model (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>ignore_token_id</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>The token ID that should be ignored when calculating the loss</p></li>
</ul>
<ul>
<li><strong><code>batch_tokenize_tfm</code></strong> : <em><code>typing.Union[blurr.data.core.BatchTokenizeTransform, NoneType]</code></em>, <em>optional</em>    <p>The before_batch_tfm you want to use to tokenize your raw data on the fly
(defaults to an instance of `BatchTokenizeTransform`)</p></li>
</ul>
<ul>
<li><strong><code>batch_decode_tfm</code></strong> : <em><code>typing.Union[blurr.data.core.BatchDecodeTransform, NoneType]</code></em>, <em>optional</em>    <p>The batch_tfm you want to decode your inputs into a type that can be used in the fastai show methods,
(defaults to BatchDecodeTransform)</p></li>
</ul>
<ul>
<li><strong><code>max_length</code></strong> : <em><code>typing.Union[int, NoneType]</code></em>, <em>optional</em>   <p>To control the length of the padding/truncation. It can be an integer or None,
in which case it will default to the maximum length the model can accept. If the model has no
specific maximum input length, truncation/padding to max_length is deactivated.
See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)</p></li>
</ul>
<ul>
<li><strong><code>padding</code></strong> : <em><code>typing.Union[bool, str]</code></em>, <em>optional</em>  <p>To control the `padding` applied to your `hf_tokenizer` during tokenization. If None, will default to
`False` or `'do_not_pad'.
See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)</p></li>
</ul>
<ul>
<li><strong><code>truncation</code></strong> : <em><code>typing.Union[bool, str]</code></em>, <em>optional</em>   <p>To control `truncation` applied to your `hf_tokenizer` during tokenization. If None, will default to
`False` or `do_not_truncate`.
See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)</p></li>
</ul>
<ul>
<li><strong><code>is_split_into_words</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>   <p>The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. Set this to `True`
if your inputs are pre-tokenized (not numericalized)</p></li>
</ul>
<ul>
<li><strong><code>input_return_type</code></strong> : <em><code>typing.Type</code></em>, <em>optional</em>    <p>The return type your decoded inputs should be cast too (used by methods such as `show_batch`)</p></li>
</ul>
<ul>
<li><strong><code>dl_type</code></strong> : <em><code>typing.Union[fastai.data.load.DataLoader, NoneType]</code></em>, <em>optional</em>  <p>The type of `DataLoader` you want created (defaults to `SortedDL`)</p></li>
</ul>
<ul>
<li><strong><code>batch_tokenize_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em> <p>Any keyword arguments you want applied to your `batch_tokenize_tfm`</p></li>
</ul>
<ul>
<li><strong><code>batch_decode_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>Any keyword arguments you want applied to your `batch_decode_tfm` (will be set as a fastai `batch_tfms`)</p></li>
</ul>
<ul>
<li><strong><code>tok_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>    <p>Any keyword arguments you want your Hugging Face tokenizer to use during tokenization</p></li>
</ul>
<ul>
<li><strong><code>text_gen_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>Any keyword arguments you want to have applied with generating text</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Low-level-API">Low-level API<a class="anchor-link" href="#Low-level-API"> </a></h2><p>For working with PyTorch and/or fast.ai Datasets &amp; DataLoaders, the low-level API allows you to get back fast.ai specific features such as <code>show_batch</code>, <code>show_results</code>, etc... when using plain ol' PyTorch Datasets, Hugging Face Datasets, etc...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BlurrBatchCreator" class="doc_header"><code>class</code> <code>BlurrBatchCreator</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L405" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BlurrBatchCreator</code>(<strong><code>hf_tokenizer</code></strong>:<code>PreTrainedTokenizerBase</code>, <strong><code>data_collator</code></strong>:<code>Type</code>[<code>CT_co</code>]=<em><code>None</code></em>)</p>
</blockquote>
<p>A class that can be assigned to a <code>TfmdDL.create_batch</code> method; used to in Blurr's low-level API
to create batches that can be used in the Blurr library</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>hf_tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'&gt;</code></em>  <p>Your Hugging Face tokenizer</p></li>
</ul>
<ul>
<li><strong><code>data_collator</code></strong> : <em><code>typing.Type</code></em>, <em>optional</em>    <p>Defaults to use Hugging Face's DataCollatorWithPadding(tokenizer=hf_tokenizer)</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BlurrBatchDecodeTransform" class="doc_header"><code>class</code> <code>BlurrBatchDecodeTransform</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L433" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BlurrBatchDecodeTransform</code>(<strong><code>hf_arch</code></strong>:<code>Optional</code>[<code>str</code>]=<em><code>None</code></em>, <strong><code>hf_config</code></strong>:<code>Optional</code>[<code>PretrainedConfig</code>]=<em><code>None</code></em>, <strong><code>hf_tokenizer</code></strong>:<code>Optional</code>[<code>PreTrainedTokenizerBase</code>]=<em><code>None</code></em>, <strong><code>hf_model</code></strong>:<code>Optional</code>[<code>PreTrainedModel</code>]=<em><code>None</code></em>, <strong><code>ignore_token_id</code></strong>:<code>int</code>=<em><code>-100</code></em>, <strong><code>is_split_into_words</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>tok_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>text_gen_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>input_return_type</code></strong>:<code>Type</code>[<code>CT_co</code>]=<em><code>TextInput</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/blurr/data-core.html#BatchDecodeTransform"><code>BatchDecodeTransform</code></a></p>
</blockquote>
<p>A class used to cast your inputs into something understandable in fastai <code>show</code> methods</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>hf_arch</code></strong> : <em><code>typing.Union[str, NoneType]</code></em>, <em>optional</em>  <p>The abbreviation/name of your Hugging Face transformer architecture (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_config</code></strong> : <em><code>typing.Union[transformers.configuration_utils.PretrainedConfig, NoneType]</code></em>, <em>optional</em>  <p>A Hugging Face configuration object (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_tokenizer</code></strong> : <em><code>typing.Union[transformers.tokenization_utils_base.PreTrainedTokenizerBase, NoneType]</code></em>, <em>optional</em>    <p>A Hugging Face tokenizer (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_model</code></strong> : <em><code>typing.Union[transformers.modeling_utils.PreTrainedModel, NoneType]</code></em>, <em>optional</em> <p>A Hugging Face model (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>ignore_token_id</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em>    <p>The token ID to ignore when calculating loss/metrics</p></li>
</ul>
<ul>
<li><strong><code>is_split_into_words</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em>   <p>The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. Set this to `True`
if your inputs are pre-tokenized (not numericalized)</p></li>
</ul>
<ul>
<li><strong><code>tok_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>    <p>Any other keyword arguments you want included when using your `hf_tokenizer` to tokenize your inputs</p></li>
</ul>
<ul>
<li><strong><code>text_gen_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>Any text generation keyword arguments</p></li>
</ul>
<ul>
<li><strong><code>input_return_type</code></strong> : <em><code>typing.Type</code></em>, <em>optional</em>    <p>The return type your decoded inputs should be cast too (used by methods such as `show_batch`)</p></li>
</ul>
<ul>
<li><strong><code>kwargs</code></strong> : <em><code>&lt;class 'inspect._empty'&gt;</code></em></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BlurrDataLoader" class="doc_header"><code>class</code> <code>BlurrDataLoader</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L471" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BlurrDataLoader</code>(<strong><code>dataset</code></strong>:<code>Union</code>[<code>Dataset</code>, <code>Datasets</code>], <strong><code>hf_arch</code></strong>:<code>str</code>, <strong><code>hf_config</code></strong>:<code>PretrainedConfig</code>, <strong><code>hf_tokenizer</code></strong>:<code>PreTrainedTokenizerBase</code>, <strong><code>hf_model</code></strong>:<code>PreTrainedModel</code>, <strong><code>batch_creator</code></strong>:<code>Optional</code>[<a href="/blurr/data-core.html#BlurrBatchCreator"><code>BlurrBatchCreator</code></a>]=<em><code>None</code></em>, <strong><code>batch_decode_tfm</code></strong>:<code>Optional</code>[<a href="/blurr/data-core.html#BlurrBatchDecodeTransform"><code>BlurrBatchDecodeTransform</code></a>]=<em><code>None</code></em>, <strong><code>preproccesing_func</code></strong>:<code>Callable</code>[<code>Union</code>[<code>Dataset</code>, <code>Datasets</code>], <code>PreTrainedTokenizerBase</code>, <code>PreTrainedModel</code>, <code>Union</code>[<code>Dataset</code>, <code>Datasets</code>]]=<em><code>None</code></em>, <strong><code>batch_decode_kwargs</code></strong>:<code>dict</code>=<em><code>{}</code></em>, <strong><code>bs</code></strong>=<em><code>64</code></em>, <strong><code>shuffle</code></strong>=<em><code>False</code></em>, <strong><code>num_workers</code></strong>=<em><code>None</code></em>, <strong><code>verbose</code></strong>=<em><code>False</code></em>, <strong><code>do_setup</code></strong>=<em><code>True</code></em>, <strong><code>pin_memory</code></strong>=<em><code>False</code></em>, <strong><code>timeout</code></strong>=<em><code>0</code></em>, <strong><code>batch_size</code></strong>=<em><code>None</code></em>, <strong><code>drop_last</code></strong>=<em><code>False</code></em>, <strong><code>indexed</code></strong>=<em><code>None</code></em>, <strong><code>n</code></strong>=<em><code>None</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>, <strong><code>persistent_workers</code></strong>=<em><code>False</code></em>, <strong><code>wif</code></strong>=<em><code>None</code></em>, <strong><code>before_iter</code></strong>=<em><code>None</code></em>, <strong><code>after_item</code></strong>=<em><code>None</code></em>, <strong><code>before_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_iter</code></strong>=<em><code>None</code></em>, <strong><code>create_batches</code></strong>=<em><code>None</code></em>, <strong><code>create_item</code></strong>=<em><code>None</code></em>, <strong><code>create_batch</code></strong>=<em><code>None</code></em>, <strong><code>retain</code></strong>=<em><code>None</code></em>, <strong><code>get_idxs</code></strong>=<em><code>None</code></em>, <strong><code>sample</code></strong>=<em><code>None</code></em>, <strong><code>shuffle_fn</code></strong>=<em><code>None</code></em>, <strong><code>do_batch</code></strong>=<em><code>None</code></em>) :: <code>TfmdDL</code></p>
</blockquote>
<p>A class that makes creating a fast.ai <code>DataLoader</code> that works with Blurr</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dataset</code></strong> : <em><code>typing.Union[torch.utils.data.dataset.Dataset, fastai.data.core.Datasets]</code></em>    <p>A standard PyTorch Dataset</p></li>
</ul>
<ul>
<li><strong><code>hf_arch</code></strong> : <em><code>&lt;class 'str'&gt;</code></em>    <p>The abbreviation/name of your Hugging Face transformer architecture (not required if passing in an
instance of `BatchTokenizeTransform` to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_config</code></strong> : <em><code>&lt;class 'transformers.configuration_utils.PretrainedConfig'&gt;</code></em>    <p>A Hugging Face configuration object (not required if passing in an instance of `BatchTokenizeTransform`
to `before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'&gt;</code></em>  <p>A Hugging Face tokenizer (not required if passing in an instance of `BatchTokenizeTransform` to
`before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>hf_model</code></strong> : <em><code>&lt;class 'transformers.modeling_utils.PreTrainedModel'&gt;</code></em>   <p>A Hugging Face model (not required if passing in an instance of `BatchTokenizeTransform` to
`before_batch_tfm`)</p></li>
</ul>
<ul>
<li><strong><code>batch_creator</code></strong> : <em><code>typing.Union[blurr.data.core.BlurrBatchCreator, NoneType]</code></em>, <em>optional</em>  <p>An instance of `BlurrBatchCreator` or equivalent (defaults to `BlurrBatchCreator`)</p></li>
</ul>
<ul>
<li><strong><code>batch_decode_tfm</code></strong> : <em><code>typing.Union[blurr.data.core.BlurrBatchDecodeTransform, NoneType]</code></em>, <em>optional</em>   <p>The batch_tfm used to decode Blurr batches (defaults to `BlurrBatchDecodeTransform`)</p></li>
</ul>
<ul>
<li><strong><code>preproccesing_func</code></strong> : <em><code>typing.Callable[[typing.Union[torch.utils.data.dataset.Dataset, fastai.data.core.Datasets], transformers.tokenization_utils_base.PreTrainedTokenizerBase, transformers.modeling_utils.PreTrainedModel], typing.Union[torch.utils.data.dataset.Dataset, fastai.data.core.Datasets]]</code></em>, <em>optional</em>    <p>(optional) A preprocessing function that will be applied to your dataset</p></li>
</ul>
<ul>
<li><strong><code>batch_decode_kwargs</code></strong> : <em><code>&lt;class 'dict'&gt;</code></em>, <em>optional</em>   <p>Keyword arguments to be applied to your `batch_decode_tfm`</p></li>
</ul>
<ul>
<li><p><strong><code>bs</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>shuffle</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>num_workers</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>verbose</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>do_setup</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>pin_memory</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>timeout</code></strong> : <em><code>&lt;class 'int'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>batch_size</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>drop_last</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>indexed</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>n</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>device</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>persistent_workers</code></strong> : <em><code>&lt;class 'bool'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>wif</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>before_iter</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>after_item</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>before_batch</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>after_batch</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>after_iter</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>create_batches</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>create_item</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>create_batch</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>retain</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>get_idxs</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>sample</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>shuffle_fn</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
<li><p><strong><code>do_batch</code></strong> : <em><code>&lt;class 'NoneType'&gt;</code></em>, <em>optional</em></p>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Utility-classes-and-methods">Utility classes and methods<a class="anchor-link" href="#Utility-classes-and-methods"> </a></h2><p>These methods are use internally for getting blurr transforms associated to your <code>DataLoaders</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_blurr_tfm" class="doc_header"><code>get_blurr_tfm</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L565" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_blurr_tfm</code>(<strong><code>tfms_list</code></strong>:<code>Pipeline</code>, <strong><code>tfm_class</code></strong>:<code>Transform</code>=<em><code>BatchTokenizeTransform</code></em>)</p>
</blockquote>
<p>Given a fastai DataLoaders batch transforms, this method can be used to get at a transform
instance used in your Blurr DataBlock</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>tfms_list</code></strong> : <em><code>&lt;class 'fastcore.transform.Pipeline'&gt;</code></em>  <p>A list of transforms (e.g., dls.after_batch, dls.before_batch, etc...)</p></li>
</ul>
<ul>
<li><strong><code>tfm_class</code></strong> : <em><code>&lt;class 'fastcore.transform.Transform'&gt;</code></em>, <em>optional</em> <p>The transform to find</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="first_blurr_tfm" class="doc_header"><code>first_blurr_tfm</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L579" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>first_blurr_tfm</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>tfms</code></strong>:<code>List</code>[<code>Transform</code>]=<em><code>[&lt;class 'blurr.data.core.BatchTokenizeTransform'&gt;, &lt;class 'blurr.data.core.BatchDecodeTransform'&gt;, &lt;class 'blurr.data.core.BlurrBatchDecodeTransform'&gt;]</code></em>)</p>
</blockquote>
<p>This convenience method will find the first Blurr transform required for methods such as
<code>show_batch</code> and <code>show_results</code>. The returned transform should have everything you need to properly
decode and 'show' your Hugging Face inputs/targets</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dls</code></strong> : <em><code>&lt;class 'fastai.data.core.DataLoaders'&gt;</code></em>   <p>Your fast.ai `DataLoaders</p></li>
</ul>
<ul>
<li><strong><code>tfms</code></strong> : <em><code>typing.List[fastcore.transform.Transform]</code></em>, <em>optional</em>   <p>The Blurr transforms to look for in order</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="show_batch"><code>show_batch</code><a class="anchor-link" href="#show_batch"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Examples">Examples<a class="anchor-link" href="#Examples"> </a></h2><p>The following eamples demonstrate several approaches to construct your <code>DataBlock</code> for sequence classication tasks using the mid-level API, and also an example on how to accomplish the same using the low-level API and standard PyTorch/Hugging Face/fast.ai Datasets and DataLoaders.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-the-mid-level-API">Using the mid-level API<a class="anchor-link" href="#Using-the-mid-level-API"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Batch-Time-Tokenization">Batch-Time Tokenization<a class="anchor-link" href="#Batch-Time-Tokenization"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Step-1:-Get-your-Hugging-Face-objects.">Step 1: Get your Hugging Face objects.<a class="anchor-link" href="#Step-1:-Get-your-Hugging-Face-objects."> </a></h5><p>There are a bunch of ways we can get at the four Hugging Face elements we need (e.g., architecture name, tokenizer, config, and model).  We can just create them directly, or we can use one of the helper methods available via <a href="/blurr/utils.html#BLURR"><code>BLURR</code></a>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;distilroberta-base&quot;</span>  <span class="c1"># &quot;distilbert-base-uncased&quot; &quot;bert-base-uncased&quot;</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Step-2:-Create-your-DataBlock">Step 2: Create your <code>DataBlock</code><a class="anchor-link" href="#Step-2:-Create-your-DataBlock"> </a></h5>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextBlock</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> <span class="n">batch_tokenize_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">labels</span><span class="p">}),</span> <span class="n">CategoryBlock</span><span class="p">)</span>
<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">),</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">ColSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Step-3:-Build-your-DataLoaders">Step 3: Build your <code>DataLoaders</code><a class="anchor-link" href="#Step-3:-Build-your-DataLoaders"> </a></h5>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">imdb_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 4, torch.Size([4, 512]), 4)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a look at the actual types represented by our batch</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">explode_types</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{tuple: [dict, fastai.torch_core.TensorCategory]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Anyone who visited drive-ins in the 1950s, 60s, and 70s, must have seen a film or two by American International Pictures, a distributor that resembled 1980s giant Cannon Films. Wherever movie-goers ventured, AIP would be right there to supply the latest en vogue titles - in the 50s came horror movies like 'Voodoo Woman' and 'The Undead;' in the 60s were Frankie Avalon-Annette Funicello beach comedies and biker flicks like 'The Glory Stompers;' and into the 70s, AIP churned out grindhouse-level</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>1</th>
      <td>You don't need to read this review.&lt;br /&gt;&lt;br /&gt;An earlier review, by pninson of Seattle, has already identified all the main shortcomings of this production. I can only amplify its basic arguments.&lt;br /&gt;&lt;br /&gt;Bleak House was a relatively late Dickens novel and is much darker than his earlier work. This is taken too literally by the director, Ross Devenish, who piles on the gloom and fog too much. When Ada, Rick and Esther appear, half an hour into the opening episode, it is a relief just to be</td>
      <td>pos</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Using-a-preprocessed-dataset">Using a preprocessed dataset<a class="anchor-link" href="#Using-a-preprocessed-dataset"> </a></h4><p>Preprocessing your raw data is the more traditional approach to using Transformers, and is required when you are working with documents longer than your model can handle (where you typically want to tell your tokenizer to create "chunks" of text from such documents by setting <code>return_overflowing_tokens": True</code>).</p>
<p>A preprocessed dataset is used in the same way a non-preprocessed dataset is.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Step-1a:-Get-your-Hugging-Face-objects.">Step 1a: Get your Hugging Face objects.<a class="anchor-link" href="#Step-1a:-Get-your-Hugging-Face-objects."> </a></h5>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Step-1b.-Preprocess-dataset">Step 1b. Preprocess dataset<a class="anchor-link" href="#Step-1b.-Preprocess-dataset"> </a></h5>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ClassificationPreprocessor</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">label_mapping</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">proc_ds</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">process_hf_dataset</span><span class="p">(</span><span class="n">final_ds</span><span class="p">)</span>
<span class="n">proc_ds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Dataset({
    features: [&#39;proc_text&#39;, &#39;text&#39;, &#39;label&#39;, &#39;is_valid&#39;, &#39;label_name&#39;, &#39;text_start_char_idx&#39;, &#39;text_end_char_idx&#39;, &#39;__index_level_0__&#39;],
    num_rows: 1200
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Step-2:-Create-your-DataBlock">Step 2: Create your <code>DataBlock</code><a class="anchor-link" href="#Step-2:-Create-your-DataBlock"> </a></h5>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextBlock</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> <span class="n">batch_tokenize_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">labels</span><span class="p">}),</span> <span class="n">CategoryBlock</span><span class="p">)</span>
<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">ItemGetter</span><span class="p">(</span><span class="s2">&quot;proc_text&quot;</span><span class="p">),</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ItemGetter</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Step-3:-Build-your-DataLoaders">Step 3: Build your <code>DataLoaders</code><a class="anchor-link" href="#Step-3:-Build-your-DataLoaders"> </a></h5>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">proc_ds</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>You Are Alone is a beautiful, almost delicate film, smart directed, crisply written, with two complex and riveting performances, and a twist of an ending that no one will see coming, but will make you want to see the film a second time to go back and catch up on all the clues you misread.&lt;br /&gt;&lt;br /&gt;The story, about a highschool girl who drowns her depression and awkwardness by working a few hours a week as a $500 an hour "schoolgirl" escort, and the depressed next-door neighbor who discovers h</td>
      <td>pos</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Every once in a while, a group of friends, with a minimal budget but bags of enthusiasm and talent, will create a low budget masterpiece that takes the world of horror by storm. Raimi and co. did it with The Evil Dead, Jackson and pals succeeded with Bad Taste; and Myrick and Sanchez made a mint with The Blair Witch Project.&lt;br /&gt;&lt;br /&gt;Director Todd Sheets and his chums, however, are destined to wallow forever in relative obscurity if Zombie Bloodbath is anything to go by. A lesson in how not t</td>
      <td>neg</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Passing-extra-information">Passing extra information<a class="anchor-link" href="#Passing-extra-information"> </a></h4><p>As of v.2, BLURR now also allows you to pass extra information alongside your inputs in the form of a dictionary.  If you use this approach, you must assign your text(s) to the <code>text</code> attribute of the dictionary.  This is a useful approach when splitting long documents into chunks, but wanting to score/predict by example rather than chunk (for example in extractive question answering tasks).</p>
<p>Note: A good place to access to this extra information during training/validation is in the <code>before_batch</code> method of a <code>Callback</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextBlock</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> <span class="n">batch_tokenize_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">labels</span><span class="p">}),</span> <span class="n">CategoryBlock</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_x</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">item</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;another_val&quot;</span><span class="p">:</span> <span class="s2">&quot;testing123&quot;</span> <span class="p">}</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">get_x</span><span class="p">,</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">ColSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">imdb_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 4, torch.Size([4, 512]), 4)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Anyone who visited drive-ins in the 1950s, 60s, and 70s, must have seen a film or two by American International Pictures, a distributor that resembled 1980s giant Cannon Films. Wherever movie-goers ventured, AIP would be right there to supply the latest en vogue titles - in the 50s came horror movies like 'Voodoo Woman' and 'The Undead;' in the 60s were Frankie Avalon-Annette Funicello beach comedies and biker flicks like 'The Glory Stompers;' and into the 70s, AIP churned out grindhouse-level</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>1</th>
      <td>I really wanted to love this show. I truly, honestly did.&lt;br /&gt;&lt;br /&gt;For the first time, gay viewers get their own version of the "The Bachelor". With the help of his obligatory "hag" Andra, James, a good looking, well-to-do thirty-something has the chance of love with 15 suitors (or "mates" as they are referred to in the show). The only problem is half of them are straight and James doesn't know this. If James picks a gay one, they get a trip to New Zealand, and If he picks a straight one, str</td>
      <td>neg</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-the-low-level-API">Using the low-level API<a class="anchor-link" href="#Using-the-low-level-API"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-1:-Build-your-datasets">Step 1: Build your datasets<a class="anchor-link" href="#Step-1:-Build-your-datasets"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;glue&quot;</span><span class="p">,</span> <span class="s2">&quot;mrpc&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">hf_tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;sentence1&quot;</span><span class="p">],</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;sentence2&quot;</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6e3b62256f7dcee8.arrow
Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a37d5e554eb61497.arrow
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-2:-Dataset-pre-processing-(optional)">Step 2: Dataset pre-processing (optional)<a class="anchor-link" href="#Step-2:-Dataset-pre-processing-(optional)"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="preproc_hf_dataset" class="doc_header"><code>preproc_hf_dataset</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/core.py#L653" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>preproc_hf_dataset</code>(<strong><code>dataset</code></strong>:<code>Union</code>[<code>Dataset</code>, <code>Datasets</code>], <strong><code>hf_tokenizer</code></strong>:<code>PreTrainedTokenizerBase</code>, <strong><code>hf_model</code></strong>:<code>PreTrainedModel</code>)</p>
</blockquote>
<p>This method can be used to preprocess most Hugging Face Datasets for use in Blurr and other training
libraries</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong><code>dataset</code></strong> : <em><code>typing.Union[torch.utils.data.dataset.Dataset, fastai.data.core.Datasets]</code></em>    <p>A standard PyTorch Dataset or fast.ai Datasets</p></li>
</ul>
<ul>
<li><strong><code>hf_tokenizer</code></strong> : <em><code>&lt;class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'&gt;</code></em>  <p>A Hugging Face tokenizer</p></li>
</ul>
<ul>
<li><strong><code>hf_model</code></strong> : <em><code>&lt;class 'transformers.modeling_utils.PreTrainedModel'&gt;</code></em>   <p>A Hugging Face model</p></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-3:-Build-your-DataLoaders.">Step 3: Build your <code>DataLoaders</code>.<a class="anchor-link" href="#Step-3:-Build-your-DataLoaders."> </a></h4><p>Use <a href="/blurr/data-core.html#BlurrDataLoader"><code>BlurrDataLoader</code></a> to build Blurr friendly dataloaders from your datasets. Passing <code>{'labels': label_names}</code> to your <code>batch_tfm_kwargs</code> will ensure that your lable/target names will be displayed in methods like <code>show_batch</code> and <code>show_results</code> (just as it works with the mid-level API)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">label_names</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>

<span class="n">trn_dl</span> <span class="o">=</span> <span class="n">BlurrDataLoader</span><span class="p">(</span>
    <span class="n">tokenized_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
    <span class="n">hf_arch</span><span class="p">,</span>
    <span class="n">hf_config</span><span class="p">,</span>
    <span class="n">hf_tokenizer</span><span class="p">,</span>
    <span class="n">hf_model</span><span class="p">,</span>
    <span class="n">preproccesing_func</span><span class="o">=</span><span class="n">preproc_hf_dataset</span><span class="p">,</span>
    <span class="n">batch_decode_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">label_names</span><span class="p">},</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">val_dl</span> <span class="o">=</span> <span class="n">BlurrDataLoader</span><span class="p">(</span>
    <span class="n">tokenized_datasets</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span>
    <span class="n">hf_arch</span><span class="p">,</span>
    <span class="n">hf_config</span><span class="p">,</span>
    <span class="n">hf_tokenizer</span><span class="p">,</span>
    <span class="n">hf_model</span><span class="p">,</span>
    <span class="n">preproccesing_func</span><span class="o">=</span><span class="n">preproc_hf_dataset</span><span class="p">,</span>
    <span class="n">batch_decode_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">label_names</span><span class="p">},</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">trn_dl</span><span class="p">,</span> <span class="n">val_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([8, 71])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Details of the research appear in the Nov. 5 issue of the Journal of the American Medical Association. The results, published in the Journal of the American Medical Association, involved just 47 heart attack patients.</td>
      <td>not_equivalent</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Under Mexican law, bounty hunting is considered a form of kidnapping. Bounty hunting is illegal in Mexico, and the bounty hunter was charged with kidnapping.</td>
      <td>equivalent</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h2><p>The tests below to ensure the core DataBlock code above works for <strong>all</strong> pretrained sequence classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.</p>
<p><strong>Note</strong>: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue <em>(or a PR if you'd like to fix it yourself)</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>arch</th>
      <th>tokenizer</th>
      <th>model_name</th>
      <th>result</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>albert</td>
      <td>AlbertTokenizerFast</td>
      <td>hf-internal-testing/tiny-albert</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>bart</td>
      <td>BartTokenizerFast</td>
      <td>hf-internal-testing/tiny-random-bart</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>bert</td>
      <td>BertTokenizerFast</td>
      <td>hf-internal-testing/tiny-bert</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>big_bird</td>
      <td>BigBirdTokenizerFast</td>
      <td>google/bigbird-roberta-base</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>bigbird_pegasus</td>
      <td>PegasusTokenizerFast</td>
      <td>google/bigbird-pegasus-large-arxiv</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>5</th>
      <td>ctrl</td>
      <td>CTRLTokenizer</td>
      <td>hf-internal-testing/tiny-random-ctrl</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>6</th>
      <td>camembert</td>
      <td>CamembertTokenizerFast</td>
      <td>camembert-base</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>7</th>
      <td>canine</td>
      <td>CanineTokenizer</td>
      <td>hf-internal-testing/tiny-random-canine</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>8</th>
      <td>convbert</td>
      <td>ConvBertTokenizerFast</td>
      <td>YituTech/conv-bert-base</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>9</th>
      <td>deberta</td>
      <td>DebertaTokenizerFast</td>
      <td>hf-internal-testing/tiny-deberta</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>10</th>
      <td>deberta_v2</td>
      <td>DebertaV2Tokenizer</td>
      <td>hf-internal-testing/tiny-random-deberta-v2</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>11</th>
      <td>distilbert</td>
      <td>DistilBertTokenizerFast</td>
      <td>hf-internal-testing/tiny-random-distilbert</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>12</th>
      <td>electra</td>
      <td>ElectraTokenizerFast</td>
      <td>hf-internal-testing/tiny-electra</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>13</th>
      <td>fnet</td>
      <td>FNetTokenizerFast</td>
      <td>google/fnet-base</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>14</th>
      <td>flaubert</td>
      <td>FlaubertTokenizer</td>
      <td>hf-internal-testing/tiny-random-flaubert</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>15</th>
      <td>funnel</td>
      <td>FunnelTokenizerFast</td>
      <td>hf-internal-testing/tiny-random-funnel</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>16</th>
      <td>gpt2</td>
      <td>GPT2TokenizerFast</td>
      <td>hf-internal-testing/tiny-random-gpt2</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>17</th>
      <td>gptj</td>
      <td>GPT2TokenizerFast</td>
      <td>anton-l/gpt-j-tiny-random</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>18</th>
      <td>gpt_neo</td>
      <td>GPT2TokenizerFast</td>
      <td>hf-internal-testing/tiny-random-gpt_neo</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>19</th>
      <td>ibert</td>
      <td>RobertaTokenizer</td>
      <td>kssteven/ibert-roberta-base</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>20</th>
      <td>led</td>
      <td>LEDTokenizerFast</td>
      <td>hf-internal-testing/tiny-random-led</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>21</th>
      <td>longformer</td>
      <td>LongformerTokenizerFast</td>
      <td>hf-internal-testing/tiny-random-longformer</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>22</th>
      <td>mbart</td>
      <td>MBartTokenizerFast</td>
      <td>hf-internal-testing/tiny-random-mbart</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>23</th>
      <td>mpnet</td>
      <td>MPNetTokenizerFast</td>
      <td>hf-internal-testing/tiny-random-mpnet</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>24</th>
      <td>mobilebert</td>
      <td>MobileBertTokenizerFast</td>
      <td>hf-internal-testing/tiny-random-mobilebert</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>25</th>
      <td>openai</td>
      <td>OpenAIGPTTokenizerFast</td>
      <td>openai-gpt</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>26</th>
      <td>reformer</td>
      <td>ReformerTokenizerFast</td>
      <td>google/reformer-crime-and-punishment</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>27</th>
      <td>rembert</td>
      <td>RemBertTokenizerFast</td>
      <td>google/rembert</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>28</th>
      <td>roformer</td>
      <td>RoFormerTokenizerFast</td>
      <td>junnyu/roformer_chinese_sim_char_ft_small</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>29</th>
      <td>roberta</td>
      <td>RobertaTokenizerFast</td>
      <td>roberta-base</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>30</th>
      <td>squeezebert</td>
      <td>SqueezeBertTokenizerFast</td>
      <td>squeezebert/squeezebert-uncased</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>31</th>
      <td>transfo_xl</td>
      <td>TransfoXLTokenizer</td>
      <td>hf-internal-testing/tiny-random-transfo-xl</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>32</th>
      <td>xlm</td>
      <td>XLMTokenizer</td>
      <td>xlm-mlm-en-2048</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>33</th>
      <td>xlm_roberta</td>
      <td>XLMRobertaTokenizerFast</td>
      <td>xlm-roberta-base</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>34</th>
      <td>xlnet</td>
      <td>XLNetTokenizerFast</td>
      <td>xlnet-base-cased</td>
      <td>PASSED</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>blurr.data.core</code> module contains the fundamental bits for all data preprocessing tasks</p>

</div>
</div>
</div>
</div>
 

