---

title: modeling.token_classification


keywords: fastai
sidebar: home_sidebar

summary: "This module contains custom models, loss functions, custom splitters, etc... for token classification tasks (e.g., Named entity recognition (NER), Part-of-speech tagging (POS), etc...). The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image."
description: "This module contains custom models, loss functions, custom splitters, etc... for token classification tasks (e.g., Named entity recognition (NER), Part-of-speech tagging (POS), etc...). The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image."
nb_path: "nbs/03_modeling-token-classification.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/03_modeling-token-classification.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>What we&#39;re running with at the time this documentation was generated:
torch: 1.10.1+cu111
fastai: 2.5.3
transformers: 4.16.2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup"> </a></h2><p>We'll use a subset of <code>conll2003</code> to demonstrate how to configure your BLURR code for token classification</p>
<p><strong>Note</strong>: Make sure you set the <code>config.num_labels</code> attribute to the number of labels your model is predicting. The model will update its last layer accordingly as la transfer learning.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;conll2003&quot;</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ner_tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Labels: </span><span class="si">{</span><span class="n">labels</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">conll2003_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span>
<span class="n">conll2003_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset conll2003 (/home/wgilliam/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Labels: [&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;, &#39;B-MISC&#39;, &#39;I-MISC&#39;]
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>chunk_tags</th>
      <th>id</th>
      <th>ner_tags</th>
      <th>pos_tags</th>
      <th>tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[11, 21, 11, 12, 21, 22, 11, 12, 0]</td>
      <td>0</td>
      <td>[3, 0, 7, 0, 0, 0, 7, 0, 0]</td>
      <td>[22, 42, 16, 21, 35, 37, 16, 21, 7]</td>
      <td>[EU, rejects, German, call, to, boycott, British, lamb, .]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[11, 12]</td>
      <td>1</td>
      <td>[1, 2]</td>
      <td>[22, 22]</td>
      <td>[Peter, Blackburn]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[11, 12]</td>
      <td>2</td>
      <td>[5, 0]</td>
      <td>[22, 11]</td>
      <td>[BRUSSELS, 1996-08-22]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 13, 11, 21, 22, 11, 12, 17, 11, 21, 17, 11, 12, 12, 21, 22, 22, 13, 11, 0]</td>
      <td>3</td>
      <td>[0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>
      <td>[12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 35, 24, 35, 37, 16, 21, 15, 24, 41, 15, 16, 21, 21, 20, 37, 40, 35, 21, 7]</td>
      <td>[The, European, Commission, said, on, Thursday, it, disagreed, with, German, advice, to, consumers, to, shun, British, lamb, until, scientists, determine, whether, mad, cow, disease, can, be, transmitted, to, sheep, .]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 12, 21, 13, 11, 12, 21, 22, 11, 13, 11, 1, 13, 11, 17, 11, 12, 12, 21, 1, 0]</td>
      <td>4</td>
      <td>[5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]</td>
      <td>[22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 22, 38, 15, 22, 24, 20, 37, 21, 15, 24, 16, 15, 22, 15, 12, 16, 21, 38, 17, 7]</td>
      <td>[Germany, 's, representative, to, the, European, Union, 's, veterinary, committee, Werner, Zwingmann, said, on, Wednesday, consumers, should, buy, sheepmeat, from, countries, other, than, Britain, until, the, scientific, advice, was, clearer, .]</td>
    </tr>
  </tbody>
</table>
</div></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span>
<span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;roberta-base&quot;</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>

<span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;roberta&#39;,
 transformers.models.roberta.configuration_roberta.RobertaConfig,
 transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,
 transformers.models.roberta.modeling_roberta.RobertaForTokenClassification)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_eq</span><span class="p">(</span><span class="n">hf_config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_tok_tfm</span> <span class="o">=</span> <span class="n">TokenClassBatchTokenizeTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">)</span>
<span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextBlock</span><span class="p">(</span><span class="n">batch_tokenize_tfm</span><span class="o">=</span><span class="n">batch_tok_tfm</span><span class="p">,</span> <span class="n">input_return_type</span><span class="o">=</span><span class="n">TokenClassTextInput</span><span class="p">),</span> <span class="n">TokenCategoryBlock</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">),</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;ner_tags&quot;</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">conll2003_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word / target label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[('MARKET', 'O'), ('TALK', 'O'), ('-', 'O'), ('USDA', 'B-ORG'), ('net', 'O'), ('change', 'O'), ('in', 'O'), ('weekly', 'O'), ('export', 'O'), ('commitments', 'O'), ('for', 'O'), ('the', 'O'), ('week', 'O'), ('ended', 'O'), ('August', 'O'), ('22', 'O'), (',', 'O'), ('includes', 'O'), ('old', 'O'), ('crop', 'O'), ('and', 'O'), ('new', 'O'), ('crop', 'O'), (',', 'O'), ('were', 'O'), (':', 'O'), ('wheat', 'O'), ('up', 'O'), ('595,400', 'O'), ('tonnes', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('corn', 'O'), ('up', 'O'), ('1,900', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('319,600', 'O'), ('new', 'O'), (';', 'O'), ('soybeans', 'O'), ('down', 'O'), ('12,300', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('300,800', 'O'), ('new', 'O'), (';', 'O'), ('upland', 'O'), ('cotton', 'O'), ('up', 'O'), ('50,400', 'O'), ('bales', 'O'), ('new', 'O'), (',', 'O'), ('nil', 'O'), ('old', 'O'), (';', 'O'), ('soymeal', 'O'), ('54,800', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('100,600', 'O'), ('new', 'O'), (',', 'O'), ('soyoil', 'O'), ('nil', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('75,000', 'O'), ('new', 'O'), (';', 'O'), ('barley', 'O'), ('up', 'O'), ('1,700', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('sorghum', 'O'), ('6,200', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('156,700', 'O'), ('new', 'O'), (';', 'O'), ('pima', 'O'), ('cotton', 'O'), ('up', 'O'), ('4,000', 'O'), ('bales', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('rice', 'O'), ('up', 'O'), ('49,900', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), ('...', 'O')]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[('But', 'O'), ('Nutricia', 'B-ORG'), ('shrugged', 'O'), ('off', 'O'), ('its', 'O'), ('ex-div', 'O'), ('tag', 'O'), ('to', 'O'), ('soar', 'O'), ('a', 'O'), ('further', 'O'), ('4.10', 'O'), ('guilders', 'O'), ('to', 'O'), ('214.40', 'O'), ('continuing', 'O'), ('its', 'O'), ('explosive', 'O'), ('rally', 'O'), ('sparked', 'O'), ('by', 'O'), ('the', 'O'), ('51', 'O'), ('percent', 'O'), ('jump', 'O'), ('in', 'O'), ('first', 'O'), ('half', 'O'), ('net', 'O'), ('profits', 'O'), ('last', 'O'), ('week', 'O'), (',', 'O'), ('which', 'O'), ('set', 'O'), ('the', 'O'), ('market', 'O'), ('alight', 'O'), ('on', 'O'), ('Friday', 'O'), (',', 'O'), ('sending', 'O'), ('the', 'O'), ('shares', 'O'), ('up', 'O'), ('18.40', 'O'), ('at', 'O'), ('210.00', 'O'), ('by', 'O'), ('the', 'O'), ('close', 'O'), ('.', 'O')]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Mid-level-API">Mid-level API<a class="anchor-link" href="#Mid-level-API"> </a></h2><p>In this section, we'll add helpful metrics for token classification tasks</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="calculate_token_class_metrics" class="doc_header"><code>calculate_token_class_metrics</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/token_classification.py#L42" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>calculate_token_class_metrics</code>(<strong><code>pred_toks</code></strong>, <strong><code>targ_toks</code></strong>, <strong><code>metric_key</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TokenClassMetricsCallback"><a href="/blurr/modeling-token-classification.html#TokenClassMetricsCallback"><code>TokenClassMetricsCallback</code></a><a class="anchor-link" href="#TokenClassMetricsCallback"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TokenClassMetricsCallback" class="doc_header"><code>class</code> <code>TokenClassMetricsCallback</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/token_classification.py#L60" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TokenClassMetricsCallback</code>(<strong><code>tok_metrics</code></strong>=<em><code>['accuracy', 'precision', 'recall', 'f1']</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Callback</code></p>
</blockquote>
<p>A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the
<code>seqeval</code> library.  Additionally, this metric knows how to <em>not</em> include your 'ignore_token' in it's
calculations.</p>
<p>See <a href="https://github.com/chakki-works/seqeval">here</a> for more information on <code>seqeval</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Training">Training<a class="anchor-link" href="#Training"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
<span class="n">learn_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">BaseModelCallback</span><span class="p">]</span>
<span class="n">fit_cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">TokenClassMetricsCallback</span><span class="p">()]</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">PreCalculatedCrossEntropyLoss</span><span class="p">(),</span> <span class="n">cbs</span><span class="o">=</span><span class="n">learn_cbs</span><span class="p">,</span> <span class="n">splitter</span><span class="o">=</span><span class="n">blurr_splitter</span><span class="p">)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># learn.summary()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span> <span class="n">preds</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2,
 transformers.modeling_outputs.TokenClassifierOutput,
 odict_keys([&#39;loss&#39;, &#39;logits&#39;]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, 3, torch.Size([4, 156]), 4, torch.Size([4, 156]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([4, 156, 9])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">preds</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">preds</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([624, 9]) torch.Size([624])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggest_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">minimum</span><span class="p">,</span> <span class="n">steep</span><span class="p">,</span> <span class="n">valley</span><span class="p">,</span> <span class="n">slide</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(minimum=0.0007585775572806596, steep=7.585775892948732e-05, valley=0.0002754228771664202, slide=0.0006918309954926372)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">,</span> <span class="n">moms</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span> <span class="n">cbs</span><span class="o">=</span><span class="n">fit_cbs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>precision</th>
      <th>recall</th>
      <th>f1</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.056181</td>
      <td>0.053085</td>
      <td>0.988523</td>
      <td>0.937287</td>
      <td>0.927591</td>
      <td>0.932414</td>
      <td>03:09</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">token_classification_report</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

         LOC       0.95      0.96      0.95      1486
        MISC       0.88      0.85      0.87       689
         ORG       0.91      0.90      0.91      1216
         PER       0.97      0.96      0.97      1346

   micro avg       0.94      0.93      0.93      4737
   macro avg       0.93      0.92      0.92      4737
weighted avg       0.94      0.93      0.93      4737

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Showing-results">Showing results<a class="anchor-link" href="#Showing-results"> </a></h4><p>Below we'll add in additional functionality to more intuitively show the results of our model.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>token / target label / predicted label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[('Compared', 'O', 'O'), ('with', 'O', 'O'), ('the', 'O', 'O'), ('end', 'O', 'O'), ('of', 'O', 'O'), ('last', 'O', 'O'), ('year', 'O', 'O'), (',', 'O', 'O'), ('when', 'O', 'O'), ('T&amp;N', 'B-ORG', 'B-ORG')]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[('"', 'O', 'O'), ('I', 'O', 'O'), ('still', 'O', 'O'), ('feel', 'O', 'O'), ('it', 'O', 'O'), ("'s", 'O', 'O'), ('embarrassing', 'O', 'O'), ('what', 'O', 'O'), ('happened', 'O', 'O'), ('and', 'O', 'O')]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Prediction">Prediction<a class="anchor-link" href="#Prediction"> </a></h4><p>The default <code>Learner.predict</code> method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer. Starting with version 2.0 of BLURR, we bring token prediction in-line with Hugging Face's token classification pipeline, both in terms of supporting the same aggregation strategies via Blurr's <a href="/blurr/modeling-token-classification.html#TokenAggregationStrategies"><code>TokenAggregationStrategies</code></a> class, and also the output via BLURR's <code>@patch</code>ed <code>Learner</code> method, <code>blurr_predict_tokens</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TokenAggregationStrategies" class="doc_header"><code>class</code> <code>TokenAggregationStrategies</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/token_classification.py#L198" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TokenAggregationStrategies</code>(<strong><code>hf_tokenizer</code></strong>:<code>PreTrainedTokenizerBase</code>, <strong><code>labels</code></strong>:<code>List</code>[<code>str</code>], <strong><code>non_entity_label</code></strong>:<code>str</code>=<em><code>'O'</code></em>)</p>
</blockquote>
<p>Provides the equivalanet of Hugging Face's token classification pipeline's <code>aggregation_strategy</code> support across various
token classication tasks (e.g, NER, POS, chunking, etc...)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Learner.blurr_predict_tokens" class="doc_header"><code>Learner.blurr_predict_tokens</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/token_classification.py#L291" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Learner.blurr_predict_tokens</code>(<strong><code>items</code></strong>:<code>Union</code>[<code>str</code>, List[str]<code>\], **</code>aggregation_strategy<code>**:</code>str<code>=*</code>'simple'<code>*, **</code>non_entity_label<code>**:</code>str<code>=*</code>'O'<code>*, **</code>slow_word_ids_func<code>**:</code>Optional<code>\[</code>Callable<code>\]=*</code>None`*)</p>
</blockquote>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>items</code></strong></td>
<td><code>List[str]]</code></td>
<td></td>
<td>The str (or list of strings) you want to get token classification predictions for</td>
</tr>
<tr>
<td><strong><code>aggregation_strategy</code></strong></td>
<td><code>str</code></td>
<td><code>simple</code></td>
<td>How entities are grouped and scored</td>
</tr>
<tr>
<td><strong><code>non_entity_label</code></strong></td>
<td><code>str</code></td>
<td><code>O</code></td>
<td>The label used to idendity non-entity related words/tokens</td>
</tr>
<tr>
<td><strong><code>slow_word_ids_func</code></strong></td>
<td><code>Callable]</code></td>
<td>``</td>
<td>If using a slow tokenizer, users will need to prove a <code>slow_word_ids_func</code> that accepts a<br />tokenizzer, example index, and a batch encoding as arguments and in turn returnes the<br />equavlient of fast tokenizer's `word_ids``</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_predict_tokens</span><span class="p">(</span>
    <span class="n">items</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;My name is Wayde and I live in San Diego and using Hugging Face&quot;</span><span class="p">,</span> <span class="s2">&quot;Bayern Munich is a soccer team in Germany&quot;</span><span class="p">],</span>
    <span class="n">aggregation_strategy</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2
[{&#39;entity_group&#39;: &#39;ORG&#39;, &#39;score&#39;: 0.9877575635910034, &#39;word&#39;: &#39;Bayern Munich&#39;, &#39;start&#39;: 0, &#39;end&#39;: 13}, {&#39;entity_group&#39;: &#39;LOC&#39;, &#39;score&#39;: 0.997735857963562, &#39;word&#39;: &#39;Germany&#39;, &#39;start&#39;: 34, &#39;end&#39;: 41}]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.&quot;</span>
<span class="n">txt2</span> <span class="o">=</span> <span class="s2">&quot;I wish covid was over so I could go to Germany and watch Bayern Munich play in the Bundesliga.&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_predict_tokens</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[{&#39;entity_group&#39;: &#39;PER&#39;, &#39;score&#39;: 0.9462278187274933, &#39;word&#39;: &#39;Wayde Gilliam&#39;, &#39;start&#39;: 15, &#39;end&#39;: 28}, {&#39;entity_group&#39;: &#39;ORG&#39;, &#39;score&#39;: 0.4752950668334961, &#39;word&#39;: &#39;ohmeow&#39;, &#39;start&#39;: 34, &#39;end&#39;: 40}, {&#39;entity_group&#39;: &#39;LOC&#39;, &#39;score&#39;: 0.997099757194519, &#39;word&#39;: &#39;California&#39;, &#39;start&#39;: 56, &#39;end&#39;: 66}]]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">blurr_predict_tokens</span><span class="p">([</span><span class="n">txt</span><span class="p">,</span> <span class="n">txt2</span><span class="p">])</span>
<span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[{&#39;entity_group&#39;: &#39;PER&#39;, &#39;score&#39;: 0.9462278187274933, &#39;word&#39;: &#39;Wayde Gilliam&#39;, &#39;start&#39;: 15, &#39;end&#39;: 28}, {&#39;entity_group&#39;: &#39;ORG&#39;, &#39;score&#39;: 0.4752950668334961, &#39;word&#39;: &#39;ohmeow&#39;, &#39;start&#39;: 34, &#39;end&#39;: 40}, {&#39;entity_group&#39;: &#39;LOC&#39;, &#39;score&#39;: 0.997099757194519, &#39;word&#39;: &#39;California&#39;, &#39;start&#39;: 56, &#39;end&#39;: 66}]

[{&#39;entity_group&#39;: &#39;LOC&#39;, &#39;score&#39;: 0.99735426902771, &#39;word&#39;: &#39;Germany&#39;, &#39;start&#39;: 39, &#39;end&#39;: 46}, {&#39;entity_group&#39;: &#39;ORG&#39;, &#39;score&#39;: 0.9840308725833893, &#39;word&#39;: &#39;Bayern Munich&#39;, &#39;start&#39;: 57, &#39;end&#39;: 70}, {&#39;entity_group&#39;: &#39;MISC&#39;, &#39;score&#39;: 0.9386674165725708, &#39;word&#39;: &#39;Bundesliga&#39;, &#39;start&#39;: 83, &#39;end&#39;: 93}]

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Inference">Inference<a class="anchor-link" href="#Inference"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">export_fname</span> <span class="o">=</span> <span class="s2">&quot;tok_class_learn_export&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>
<span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">export_fname</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">inf_learn</span><span class="o">.</span><span class="n">blurr_predict_tokens</span><span class="p">([</span><span class="n">txt</span><span class="p">,</span> <span class="n">txt2</span><span class="p">])</span>
<span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[{&#39;entity_group&#39;: &#39;PER&#39;, &#39;score&#39;: 0.9462278783321381, &#39;word&#39;: &#39;Wayde Gilliam&#39;, &#39;start&#39;: 15, &#39;end&#39;: 28}, {&#39;entity_group&#39;: &#39;ORG&#39;, &#39;score&#39;: 0.4752952655156453, &#39;word&#39;: &#39;ohmeow&#39;, &#39;start&#39;: 34, &#39;end&#39;: 40}, {&#39;entity_group&#39;: &#39;LOC&#39;, &#39;score&#39;: 0.997099757194519, &#39;word&#39;: &#39;California&#39;, &#39;start&#39;: 56, &#39;end&#39;: 66}]

[{&#39;entity_group&#39;: &#39;LOC&#39;, &#39;score&#39;: 0.99735426902771, &#39;word&#39;: &#39;Germany&#39;, &#39;start&#39;: 39, &#39;end&#39;: 46}, {&#39;entity_group&#39;: &#39;ORG&#39;, &#39;score&#39;: 0.9840309321880341, &#39;word&#39;: &#39;Bayern Munich&#39;, &#39;start&#39;: 57, &#39;end&#39;: 70}, {&#39;entity_group&#39;: &#39;MISC&#39;, &#39;score&#39;: 0.9386672973632812, &#39;word&#39;: &#39;Bundesliga&#39;, &#39;start&#39;: 83, &#39;end&#39;: 93}]

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="High-level-API">High-level API<a class="anchor-link" href="#High-level-API"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="BLearnerForTokenClassification"><code>BLearnerForTokenClassification</code><a class="anchor-link" href="#BLearnerForTokenClassification"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BlearnerForTokenClassification" class="doc_header"><code>class</code> <code>BlearnerForTokenClassification</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/token_classification.py#L342" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BlearnerForTokenClassification</code>(<strong><code>dls</code></strong>:<code>DataLoaders</code>, <strong><code>hf_model</code></strong>:<code>PreTrainedModel</code>, <strong><code>base_model_cb</code></strong>:<a href="/blurr/modeling-core.html#BaseModelCallback"><code>BaseModelCallback</code></a>=<em><code>BaseModelCallback</code></em>, <strong><code>loss_func</code></strong>=<em><code>None</code></em>, <strong><code>opt_func</code></strong>=<em><code>Adam</code></em>, <strong><code>lr</code></strong>=<em><code>0.001</code></em>, <strong><code>splitter</code></strong>=<em><code>trainable_params</code></em>, <strong><code>cbs</code></strong>=<em><code>None</code></em>, <strong><code>metrics</code></strong>=<em><code>None</code></em>, <strong><code>path</code></strong>=<em><code>None</code></em>, <strong><code>model_dir</code></strong>=<em><code>'models'</code></em>, <strong><code>wd</code></strong>=<em><code>None</code></em>, <strong><code>wd_bn_bias</code></strong>=<em><code>False</code></em>, <strong><code>train_bn</code></strong>=<em><code>True</code></em>, <strong><code>moms</code></strong>=<em><code>(0.95, 0.85, 0.95)</code></em>) :: <a href="/blurr/modeling-core.html#Blearner"><code>Blearner</code></a></p>
</blockquote>
<p>Group together a <code>model</code>, some <code>dls</code> and a <code>loss_func</code> to handle training</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Define-your-Blearner">Define your <a href="/blurr/modeling-core.html#Blearner"><code>Blearner</code></a><a class="anchor-link" href="#Define-your-Blearner"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">BlearnerForTokenClassification</span><span class="o">.</span><span class="n">from_data</span><span class="p">(</span>
    <span class="n">conll2003_df</span><span class="p">,</span>
    <span class="s2">&quot;distilroberta-base&quot;</span><span class="p">,</span>
    <span class="n">tokens_attr</span><span class="o">=</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span>
    <span class="n">token_labels_attr</span><span class="o">=</span><span class="s2">&quot;ner_tags&quot;</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">dl_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;bs&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word / target label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[('MARKET', 'O'), ('TALK', 'O'), ('-', 'O'), ('USDA', 'B-ORG'), ('net', 'O'), ('change', 'O'), ('in', 'O'), ('weekly', 'O'), ('export', 'O'), ('commitments', 'O'), ('for', 'O'), ('the', 'O'), ('week', 'O'), ('ended', 'O'), ('August', 'O'), ('22', 'O'), (',', 'O'), ('includes', 'O'), ('old', 'O'), ('crop', 'O'), ('and', 'O'), ('new', 'O'), ('crop', 'O'), (',', 'O'), ('were', 'O'), (':', 'O'), ('wheat', 'O'), ('up', 'O'), ('595,400', 'O'), ('tonnes', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('corn', 'O'), ('up', 'O'), ('1,900', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('319,600', 'O'), ('new', 'O'), (';', 'O'), ('soybeans', 'O'), ('down', 'O'), ('12,300', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('300,800', 'O'), ('new', 'O'), (';', 'O'), ('upland', 'O'), ('cotton', 'O'), ('up', 'O'), ('50,400', 'O'), ('bales', 'O'), ('new', 'O'), (',', 'O'), ('nil', 'O'), ('old', 'O'), (';', 'O'), ('soymeal', 'O'), ('54,800', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('100,600', 'O'), ('new', 'O'), (',', 'O'), ('soyoil', 'O'), ('nil', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('75,000', 'O'), ('new', 'O'), (';', 'O'), ('barley', 'O'), ('up', 'O'), ('1,700', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('sorghum', 'O'), ('6,200', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('156,700', 'O'), ('new', 'O'), (';', 'O'), ('pima', 'O'), ('cotton', 'O'), ('up', 'O'), ('4,000', 'O'), ('bales', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('rice', 'O'), ('up', 'O'), ('49,900', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), ('...', 'O')]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[('Under', 'O'), ('the', 'O'), ('agreement', 'O'), (',', 'O'), ('IVAC', 'B-ORG'), ('and', 'O'), ('Advanced', 'B-ORG'), ('Medical', 'I-ORG'), ("'s", 'O'), ('wholly', 'O'), ('owned', 'O'), ('subsidiary', 'O'), (',', 'O'), ('IMED', 'B-ORG'), ('Corp.', 'I-ORG'), (',', 'O'), ('will', 'O'), ('merge', 'O'), ('to', 'O'), ('form', 'O'), ('a', 'O'), ('new', 'O'), ('company', 'O'), ('that', 'O'), ('will', 'O'), ('develop', 'O'), ('and', 'O'), ('manufacture', 'O'), ('infusion', 'O'), ('pumps', 'O'), ('that', 'O'), ('regulate', 'O'), ('the', 'O'), ('amount', 'O'), ('of', 'O'), ('intravenous', 'O'), ('fluid', 'O'), ('being', 'O'), ('administered', 'O'), ('to', 'O'), ('a', 'O'), ('patient', 'O'), (',', 'O'), ('as', 'O'), ('well', 'O'), ('as', 'O'), ('proprietary', 'O'), ('disposable', 'O'), ('products', 'O'), ('.', 'O')]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Train">Train<a class="anchor-link" href="#Train"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">,</span> <span class="n">moms</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span> <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">BlearnerForTokenClassification</span><span class="o">.</span><span class="n">get_metrics_cb</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>precision</th>
      <th>recall</th>
      <th>f1</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.052853</td>
      <td>0.054780</td>
      <td>0.988713</td>
      <td>0.932124</td>
      <td>0.927176</td>
      <td>0.929643</td>
      <td>03:54</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>token / target label / predicted label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[('The', 'O', 'O'), ('agreement', 'O', 'O'), ('resolved', 'O', 'O'), ('a', 'O', 'O'), ('dispute', 'O', 'O'), ('that', 'O', 'O'), ('arose', 'O', 'O'), ('in', 'O', 'O'), ('June', 'O', 'O'), ('when', 'O', 'O')]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[('In', 'O', 'O'), ('Houston', 'B-LOC', 'B-LOC'), (',', 'O', 'O'), ('Orlando', 'B-PER', 'B-PER'), ('Miller', 'I-PER', 'I-PER'), ("'s", 'O', 'O'), ('two-run', 'O', 'O'), ('homer', 'O', 'O'), ('with', 'O', 'O'), ('one', 'O', 'O')]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">token_classification_report</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

         LOC       0.96      0.95      0.95      1465
        MISC       0.84      0.88      0.86       674
         ORG       0.91      0.89      0.90      1319
         PER       0.97      0.97      0.97      1252

   micro avg       0.93      0.93      0.93      4710
   macro avg       0.92      0.92      0.92      4710
weighted avg       0.93      0.93      0.93      4710

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Prediction">Prediction<a class="anchor-link" href="#Prediction"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.&quot;</span>
<span class="n">txt2</span> <span class="o">=</span> <span class="s2">&quot;I wish covid was over so I could watch Lewandowski score some more goals for Bayern Munich in the Bundesliga.&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">txt</span><span class="p">,</span> <span class="n">txt2</span><span class="p">])</span>
<span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[{&#39;entity_group&#39;: &#39;PER&#39;, &#39;score&#39;: 0.9840600043535233, &#39;word&#39;: &#39;Wayde Gilliam&#39;, &#39;start&#39;: 15, &#39;end&#39;: 28}, {&#39;entity_group&#39;: &#39;LOC&#39;, &#39;score&#39;: 0.9965631365776062, &#39;word&#39;: &#39;California&#39;, &#39;start&#39;: 56, &#39;end&#39;: 66}]

[{&#39;entity_group&#39;: &#39;PER&#39;, &#39;score&#39;: 0.5179193019866943, &#39;word&#39;: &#39;cov&#39;, &#39;start&#39;: 7, &#39;end&#39;: 10}, {&#39;entity_group&#39;: &#39;PER&#39;, &#39;score&#39;: 0.9869977831840515, &#39;word&#39;: &#39;Lewandowski&#39;, &#39;start&#39;: 39, &#39;end&#39;: 50}, {&#39;entity_group&#39;: &#39;ORG&#39;, &#39;score&#39;: 0.9902820885181427, &#39;word&#39;: &#39;Bayern Munich&#39;, &#39;start&#39;: 77, &#39;end&#39;: 90}, {&#39;entity_group&#39;: &#39;MISC&#39;, &#39;score&#39;: 0.9799767732620239, &#39;word&#39;: &#39;Bundesliga&#39;, &#39;start&#39;: 98, &#39;end&#39;: 108}]

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h2><p>The tests below to ensure the token classification training code above works for <strong>all</strong> pretrained token classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.</p>
<p><strong>Note</strong>: Feel free to modify the code below to test whatever pretrained token classification models you are working with ... and if any of your pretrained token classification models fail, please submit a github issue <em>(or a PR if you'd like to fix it yourself)</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;conll2003&quot;</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ner_tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>
<span class="n">conll2003_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Reusing dataset conll2003 (/home/wgilliam/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>arch</th>
      <th>tokenizer</th>
      <th>model_name</th>
      <th>result</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>albert</td>
      <td>AlbertTokenizerFast</td>
      <td>AlbertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>bert</td>
      <td>BertTokenizerFast</td>
      <td>BertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>big_bird</td>
      <td>BigBirdTokenizerFast</td>
      <td>BigBirdForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>camembert</td>
      <td>CamembertTokenizerFast</td>
      <td>CamembertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>convbert</td>
      <td>ConvBertTokenizerFast</td>
      <td>ConvBertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>5</th>
      <td>deberta</td>
      <td>DebertaTokenizerFast</td>
      <td>DebertaForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>6</th>
      <td>bert</td>
      <td>BertTokenizerFast</td>
      <td>BertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>7</th>
      <td>electra</td>
      <td>ElectraTokenizerFast</td>
      <td>ElectraForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>8</th>
      <td>funnel</td>
      <td>FunnelTokenizerFast</td>
      <td>FunnelForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>9</th>
      <td>gpt2</td>
      <td>GPT2TokenizerFast</td>
      <td>GPT2ForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>10</th>
      <td>layoutlm</td>
      <td>LayoutLMTokenizerFast</td>
      <td>LayoutLMForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>11</th>
      <td>longformer</td>
      <td>LongformerTokenizerFast</td>
      <td>LongformerForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>12</th>
      <td>mpnet</td>
      <td>MPNetTokenizerFast</td>
      <td>MPNetForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>13</th>
      <td>ibert</td>
      <td>RobertaTokenizerFast</td>
      <td>IBertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>14</th>
      <td>mobilebert</td>
      <td>MobileBertTokenizerFast</td>
      <td>MobileBertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>15</th>
      <td>rembert</td>
      <td>RemBertTokenizerFast</td>
      <td>RemBertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>16</th>
      <td>roformer</td>
      <td>RoFormerTokenizerFast</td>
      <td>RoFormerForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>17</th>
      <td>roberta</td>
      <td>RobertaTokenizerFast</td>
      <td>RobertaForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>18</th>
      <td>squeezebert</td>
      <td>SqueezeBertTokenizerFast</td>
      <td>SqueezeBertForTokenClassification</td>
      <td>PASSED</td>
      <td></td>
    </tr>
    <tr>
      <th>19</th>
      <td>xlm_roberta</td>
      <td>XLMRobertaTokenizerFast</td>
      <td>XLMRobertaForTokenClassification</td>
      <td>FAILED</td>
      <td>CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 10.91 GiB total capacity; 8.84 GiB already allocated; 17.25 MiB free; 9.17 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</td>
    </tr>
    <tr>
      <th>20</th>
      <td>xlnet</td>
      <td>XLNetTokenizerFast</td>
      <td>XLNetForTokenClassification</td>
      <td>FAILED</td>
      <td>CUDA out of memory. Tried to allocate 94.00 MiB (GPU 1; 10.91 GiB total capacity; 8.84 GiB already allocated; 17.25 MiB free; 9.17 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary"> </a></h2><p>This module includes all the low, mid, and high-level API bits for token classification tasks training and inference.</p>

</div>
</div>
</div>
</div>
 

